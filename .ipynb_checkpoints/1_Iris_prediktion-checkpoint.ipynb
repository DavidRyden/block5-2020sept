{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Kort om att gå från R till Python\n",
    "\n",
    "- Ni förväntas inte kunna skriva Python-kod, men ni kommer delvis känna igen arbetssättet från R\n",
    "\n",
    "\n",
    "- Python är likt R ett populärt open source-språk inom data science, det är bra att få en inblick även i detta språk\n",
    "\n",
    "\n",
    "\n",
    "- Vi kör koden i en \"Jupyter Notebook\", även det populärt inom Data Science. Notebooks stödjer både Python och R\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Python\n",
    "- \"General-purpose\" programmeringsspråk - data science bara ett applikationsområde\n",
    "- Förlåtande för nybörjare, men därav mer risk för implicita fel, ex, \"123\" * 3\n",
    "- Tacksamt att implementera, många data engineers kan python \n",
    "- TVINGAR dig att skriva prydligt, får felmeddelande utan korrekt indentering\n",
    "\n",
    "- Python har betydligt sämre paket för klassisk statistik och regression jämfört med R, regression i populära Scikitlearn ger inte ens p-värden\n",
    "\n",
    "\n",
    "#### R\n",
    "- Fokuserat och mer utvecklat för Statistisk programmering\n",
    "- Oförlåtande för nybörjare, mindre risk för implicita fel - exempelvis mean(x, na.rm=TRUE), beräkningar kan enbart göras på tillåtna datatyper\n",
    "- bättre för visualiseringar med ggplot2\n",
    "- Trevlig app och rapport-generering med knitr och Shiny\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Snabba exempel\n",
    "\n",
    "- \"<-\" i R ersätts med \"=\" i Python \n",
    "\n",
    "(precis som i R är \"==\" det man använder som lika med-tecken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Kör denna cell med \"Shift + Enter\"\n",
    "siffra_python = 1+2 \n",
    "print(siffra_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Förlåtande\n",
    "\n",
    "- Python är förlåtande för nybörjare, men därav mer risk för implicita fel, ex, \"123\" * 3 fungerar, men är inte en matematisk operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123123123\n"
     ]
    }
   ],
   "source": [
    "#Det går att multiplicera strängen \"123\" i python, men det är inte en matematisk operation\n",
    "strang_ggr_num = \"123\"*3\n",
    "print(strang_ggr_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prydlighet\n",
    "\n",
    "Nedan fungerar, det är korrekt med indenteringen efter både for och if-satsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Slut\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2]:\n",
    "    print(i)\n",
    "    if(i==2):\n",
    "        print(\"Slut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nedan fungerar inte, vi får IndentationError då vi inte indenterat efter if-satsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-80-95df71d784a5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-80-95df71d784a5>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print(\"Slut\")\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2]:\n",
    "    print(i)\n",
    "    if(i==2):\n",
    "    print(\"Slut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Övning 1: Enkel logistisk modell\n",
    "\n",
    "I denna övning testar vi att göra en enkel logistisk modell utifrån Iris-datasetet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Importera bibliotek\n",
    "\n",
    "Vi importerar de python-bibliotek som vi behöver för att bearbeta vårt dataset\n",
    "\n",
    "- numpy används för matrisberäkningar, extremt vanligt att använda tillsammans med pandas\n",
    "- matplotlib för grafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hjälpfunktioner\n",
    "\n",
    "- Används senare för att plotta modellutvärdering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training():\n",
    "    \n",
    "    print(\"accuracy, train: \", history.history['accuracy'][-1])\n",
    "    print(\"accuracy, test: \", history.history['val_accuracy'][-1])\n",
    "    \n",
    "    # Credd : https://janakiev.com/notebooks/keras-iris/\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Iris-data med 2 klasser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Data import & preparering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vi importerar vid bibliotek från sklearn, ett mycket populärt bibiliotek för typiska funktioner inom data science\n",
    " \n",
    " - load_iris för att hämta iris-data\n",
    " - train_test_split för att enkelt dela upp data i train och test\n",
    " - Onehotencoder för att skapa target-variaber som är dummies\n",
    " - StandardScaler för att senare normalisera input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapreparering är importerad från : https://janakiev.com/notebooks/keras-iris/\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "#Bestämmer seed inför sampling\n",
    "seed = 444\n",
    "#Anger seed för tensorflow respektive numpy-beräkningar\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vi hämtar iris-datasetet som vi arbetat med tidigare\n",
    "\n",
    "- Vi har oberoende variablerna 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)' och 'petal width (cm)'\n",
    "- Vi vill klassificera om blomman är versicolor(Y=1) eller inte (Y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hämtar iris-data\n",
    "iris = load_iris()\n",
    "X = iris['data'][0:100] # Hämta endast 100 observationer\n",
    "y = iris['target'][0:100]\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding (= skapar dummy-varibler)\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Standardiserar data till medelvärde 0 och varians 1 \n",
    "# Standardisering av värden hjälper neurala nätverk att konvergera\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Delar upp data i training och test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features : 4\n",
      "n_classes : 2\n",
      "\n",
      " Standardiserade features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      " [[-0.894  0.002 -0.944 -1.22 ]\n",
      " [ 0.359 -0.418  0.928  0.914]\n",
      " [-0.581  0.842 -1.013 -0.864]]\n",
      "\n",
      "Y (1=Versicolor) \n",
      " [[0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Vi delar upp data test i train och test\n",
    "X_train, X_test, Y_train_, Y_test_ = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "#Vi skapar variabler för antalet features och klasser, används till neurala nätverket\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "# Anpassa format för binär klassificering (1 target variabel)\n",
    "Y_train = Y_train_[:,1].reshape(50,1)\n",
    "Y_test = Y_test_[:,1].reshape(50,1)\n",
    "\n",
    "print(\"n_features : \" + str(n_features))\n",
    "print(\"n_classes : \" + str(n_classes))\n",
    "\n",
    "\n",
    "print( \"\\n Standardiserade features: \\n\",feature_names,\"\\n\",X_train[0:3])\n",
    "print (\"\\nY (1=Versicolor)\",\"\\n\", Y_train[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistisk regression (sigmoid aktivering)\n",
    "\n",
    "Vi skapar nu en logistisk regression med ett neuralt nätverk:\n",
    "\n",
    "- Vi använder \"tensorflow\" som \"backend\" till vårt neurala nätverk\n",
    "- Paketet \"keras\" som numera finns i tensorflow används som \"frontend\"\n",
    "\n",
    "- Vi skapar ett sekventiellt neuralt nätverk (funktionen \"Sequential()\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#Sekventiellt neuralt nätverk\n",
    "logistic_regression_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I vårt tomma sekventiella nätverk lägger vi till ett \"Dense\"/\"fully connected\" hidden layer:\n",
    "\n",
    "1. Detta lager tar 4 dimensoner som input (våra oberoende variabler)\n",
    "\n",
    "2. Ger 1 dimension output på mellan 0-1, efter sannolikhet att observationen är versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.add(Dense(1, input_dim=n_features, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I kompilering anger vi övriga val:\n",
    "- Optimizer = sgd (stochastic gradient descent:    theta(t+1) = theta(t) - learning_rate * gradient)\n",
    "- Loss-funktion = binary crossentropy, då vi har binär output-variabel\n",
    "- Den metric vi optimerar för är accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.compile(optimizer='sgd',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summering av vår skapade modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Träna modell\n",
    "\n",
    "Vi tränar modellen i 500 epoker med funktion fit()\n",
    "\n",
    "För varje epok ser vi hur loss och accuracy förändras på både vårt train och validation-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 50 samples\n",
      "Epoch 1/500\n",
      "50/50 [==============================] - 1s 18ms/sample - loss: 1.0050 - accuracy: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "50/50 [==============================] - 0s 414us/sample - loss: 0.9837 - accuracy: 0.0000e+00 - val_loss: 0.9882 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.9628 - accuracy: 0.0000e+00 - val_loss: 0.9667 - val_accuracy: 0.0200\n",
      "Epoch 4/500\n",
      "50/50 [==============================] - 0s 315us/sample - loss: 0.9424 - accuracy: 0.0200 - val_loss: 0.9457 - val_accuracy: 0.0400\n",
      "Epoch 5/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.9225 - accuracy: 0.0200 - val_loss: 0.9254 - val_accuracy: 0.0400\n",
      "Epoch 6/500\n",
      "50/50 [==============================] - 0s 312us/sample - loss: 0.9032 - accuracy: 0.0600 - val_loss: 0.9055 - val_accuracy: 0.0400\n",
      "Epoch 7/500\n",
      "50/50 [==============================] - 0s 311us/sample - loss: 0.8842 - accuracy: 0.1200 - val_loss: 0.8862 - val_accuracy: 0.0600\n",
      "Epoch 8/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.8659 - accuracy: 0.1400 - val_loss: 0.8676 - val_accuracy: 0.1600\n",
      "Epoch 9/500\n",
      "50/50 [==============================] - 0s 401us/sample - loss: 0.8484 - accuracy: 0.1600 - val_loss: 0.8497 - val_accuracy: 0.1800\n",
      "Epoch 10/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.8312 - accuracy: 0.2000 - val_loss: 0.8318 - val_accuracy: 0.2400\n",
      "Epoch 11/500\n",
      "50/50 [==============================] - 0s 353us/sample - loss: 0.8144 - accuracy: 0.2200 - val_loss: 0.8148 - val_accuracy: 0.2600\n",
      "Epoch 12/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.7981 - accuracy: 0.2400 - val_loss: 0.7979 - val_accuracy: 0.2600\n",
      "Epoch 13/500\n",
      "50/50 [==============================] - 0s 333us/sample - loss: 0.7822 - accuracy: 0.2600 - val_loss: 0.7817 - val_accuracy: 0.3200\n",
      "Epoch 14/500\n",
      "50/50 [==============================] - 0s 580us/sample - loss: 0.7670 - accuracy: 0.2800 - val_loss: 0.7659 - val_accuracy: 0.3600\n",
      "Epoch 15/500\n",
      "50/50 [==============================] - 0s 361us/sample - loss: 0.7522 - accuracy: 0.2800 - val_loss: 0.7508 - val_accuracy: 0.3800\n",
      "Epoch 16/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.7375 - accuracy: 0.3800 - val_loss: 0.7358 - val_accuracy: 0.4000\n",
      "Epoch 17/500\n",
      "50/50 [==============================] - 0s 312us/sample - loss: 0.7235 - accuracy: 0.4200 - val_loss: 0.7217 - val_accuracy: 0.4200\n",
      "Epoch 18/500\n",
      "50/50 [==============================] - 0s 332us/sample - loss: 0.7101 - accuracy: 0.4400 - val_loss: 0.7079 - val_accuracy: 0.4600\n",
      "Epoch 19/500\n",
      "50/50 [==============================] - 0s 290us/sample - loss: 0.6971 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.4800\n",
      "Epoch 20/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.6843 - accuracy: 0.5000 - val_loss: 0.6812 - val_accuracy: 0.5600\n",
      "Epoch 21/500\n",
      "50/50 [==============================] - 0s 329us/sample - loss: 0.6718 - accuracy: 0.5200 - val_loss: 0.6682 - val_accuracy: 0.5600\n",
      "Epoch 22/500\n",
      "50/50 [==============================] - 0s 287us/sample - loss: 0.6595 - accuracy: 0.5800 - val_loss: 0.6557 - val_accuracy: 0.5800\n",
      "Epoch 23/500\n",
      "50/50 [==============================] - 0s 432us/sample - loss: 0.6477 - accuracy: 0.5800 - val_loss: 0.6436 - val_accuracy: 0.6400\n",
      "Epoch 24/500\n",
      "50/50 [==============================] - 0s 315us/sample - loss: 0.6363 - accuracy: 0.6400 - val_loss: 0.6319 - val_accuracy: 0.7000\n",
      "Epoch 25/500\n",
      "50/50 [==============================] - 0s 358us/sample - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6205 - val_accuracy: 0.7400\n",
      "Epoch 26/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.6145 - accuracy: 0.7200 - val_loss: 0.6093 - val_accuracy: 0.7400\n",
      "Epoch 27/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.71 - 0s 435us/sample - loss: 0.6040 - accuracy: 0.7400 - val_loss: 0.5984 - val_accuracy: 0.7800\n",
      "Epoch 28/500\n",
      "50/50 [==============================] - 0s 326us/sample - loss: 0.5938 - accuracy: 0.7800 - val_loss: 0.5880 - val_accuracy: 0.8200\n",
      "Epoch 29/500\n",
      "50/50 [==============================] - 0s 453us/sample - loss: 0.5839 - accuracy: 0.8200 - val_loss: 0.5780 - val_accuracy: 0.8400\n",
      "Epoch 30/500\n",
      "50/50 [==============================] - 0s 321us/sample - loss: 0.5743 - accuracy: 0.8400 - val_loss: 0.5679 - val_accuracy: 0.8400\n",
      "Epoch 31/500\n",
      "50/50 [==============================] - 0s 423us/sample - loss: 0.5649 - accuracy: 0.8400 - val_loss: 0.5582 - val_accuracy: 0.8400\n",
      "Epoch 32/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.5557 - accuracy: 0.8400 - val_loss: 0.5488 - val_accuracy: 0.8400\n",
      "Epoch 33/500\n",
      "50/50 [==============================] - 0s 485us/sample - loss: 0.5469 - accuracy: 0.8600 - val_loss: 0.5395 - val_accuracy: 0.8600\n",
      "Epoch 34/500\n",
      "50/50 [==============================] - 0s 349us/sample - loss: 0.5381 - accuracy: 0.8600 - val_loss: 0.5306 - val_accuracy: 0.8800\n",
      "Epoch 35/500\n",
      "50/50 [==============================] - 0s 455us/sample - loss: 0.5297 - accuracy: 0.8800 - val_loss: 0.5218 - val_accuracy: 0.8800\n",
      "Epoch 36/500\n",
      "50/50 [==============================] - 0s 329us/sample - loss: 0.5214 - accuracy: 0.8800 - val_loss: 0.5132 - val_accuracy: 0.8800\n",
      "Epoch 37/500\n",
      "50/50 [==============================] - 0s 344us/sample - loss: 0.5134 - accuracy: 0.9000 - val_loss: 0.5049 - val_accuracy: 0.9000\n",
      "Epoch 38/500\n",
      "50/50 [==============================] - 0s 389us/sample - loss: 0.5056 - accuracy: 0.9000 - val_loss: 0.4970 - val_accuracy: 0.9000\n",
      "Epoch 39/500\n",
      "50/50 [==============================] - 0s 328us/sample - loss: 0.4980 - accuracy: 0.9200 - val_loss: 0.4892 - val_accuracy: 0.9000\n",
      "Epoch 40/500\n",
      "50/50 [==============================] - 0s 319us/sample - loss: 0.4907 - accuracy: 0.9200 - val_loss: 0.4815 - val_accuracy: 0.9000\n",
      "Epoch 41/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.90 - 0s 434us/sample - loss: 0.4834 - accuracy: 0.9400 - val_loss: 0.4741 - val_accuracy: 0.9200\n",
      "Epoch 42/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.4765 - accuracy: 0.9400 - val_loss: 0.4669 - val_accuracy: 0.9400\n",
      "Epoch 43/500\n",
      "50/50 [==============================] - 0s 582us/sample - loss: 0.4697 - accuracy: 0.9400 - val_loss: 0.4600 - val_accuracy: 0.9400\n",
      "Epoch 44/500\n",
      "50/50 [==============================] - 0s 589us/sample - loss: 0.4630 - accuracy: 0.9400 - val_loss: 0.4531 - val_accuracy: 0.9600\n",
      "Epoch 45/500\n",
      "50/50 [==============================] - 0s 443us/sample - loss: 0.4565 - accuracy: 0.9400 - val_loss: 0.4464 - val_accuracy: 0.9800\n",
      "Epoch 46/500\n",
      "50/50 [==============================] - 0s 587us/sample - loss: 0.4502 - accuracy: 0.9400 - val_loss: 0.4398 - val_accuracy: 0.9800\n",
      "Epoch 47/500\n",
      "50/50 [==============================] - 0s 492us/sample - loss: 0.4440 - accuracy: 0.9800 - val_loss: 0.4334 - val_accuracy: 0.9800\n",
      "Epoch 48/500\n",
      "50/50 [==============================] - 0s 550us/sample - loss: 0.4379 - accuracy: 0.9800 - val_loss: 0.4273 - val_accuracy: 0.9800\n",
      "Epoch 49/500\n",
      "50/50 [==============================] - 0s 337us/sample - loss: 0.4320 - accuracy: 0.9800 - val_loss: 0.4211 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "50/50 [==============================] - 0s 238us/sample - loss: 0.4262 - accuracy: 0.9800 - val_loss: 0.4152 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "50/50 [==============================] - 0s 287us/sample - loss: 0.4206 - accuracy: 0.9800 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "50/50 [==============================] - 0s 306us/sample - loss: 0.4151 - accuracy: 0.9800 - val_loss: 0.4036 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "50/50 [==============================] - 0s 333us/sample - loss: 0.4097 - accuracy: 0.9800 - val_loss: 0.3981 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.4045 - accuracy: 0.9800 - val_loss: 0.3927 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "50/50 [==============================] - 0s 541us/sample - loss: 0.3993 - accuracy: 0.9800 - val_loss: 0.3873 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 279us/sample - loss: 0.3943 - accuracy: 0.9800 - val_loss: 0.3822 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "50/50 [==============================] - 0s 504us/sample - loss: 0.3894 - accuracy: 0.9800 - val_loss: 0.3772 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.3846 - accuracy: 0.9800 - val_loss: 0.3722 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "50/50 [==============================] - 0s 555us/sample - loss: 0.3798 - accuracy: 0.9800 - val_loss: 0.3674 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "50/50 [==============================] - 0s 511us/sample - loss: 0.3752 - accuracy: 0.9800 - val_loss: 0.3626 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "50/50 [==============================] - 0s 503us/sample - loss: 0.3707 - accuracy: 0.9800 - val_loss: 0.3580 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "50/50 [==============================] - 0s 462us/sample - loss: 0.3663 - accuracy: 0.9800 - val_loss: 0.3535 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "50/50 [==============================] - 0s 588us/sample - loss: 0.3621 - accuracy: 0.9800 - val_loss: 0.3491 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "50/50 [==============================] - 0s 514us/sample - loss: 0.3579 - accuracy: 0.9800 - val_loss: 0.3448 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.3538 - accuracy: 0.9800 - val_loss: 0.3406 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "50/50 [==============================] - 0s 480us/sample - loss: 0.3498 - accuracy: 0.9800 - val_loss: 0.3365 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "50/50 [==============================] - 0s 376us/sample - loss: 0.3459 - accuracy: 0.9800 - val_loss: 0.3325 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.3420 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "50/50 [==============================] - 0s 392us/sample - loss: 0.3383 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "50/50 [==============================] - 0s 618us/sample - loss: 0.3346 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.3310 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "50/50 [==============================] - 0s 739us/sample - loss: 0.3275 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "50/50 [==============================] - 0s 455us/sample - loss: 0.3240 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "50/50 [==============================] - 0s 507us/sample - loss: 0.3205 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "50/50 [==============================] - 0s 530us/sample - loss: 0.3172 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "50/50 [==============================] - 0s 500us/sample - loss: 0.3139 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "50/50 [==============================] - 0s 564us/sample - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.3075 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "50/50 [==============================] - 0s 597us/sample - loss: 0.3045 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "50/50 [==============================] - 0s 553us/sample - loss: 0.3014 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "50/50 [==============================] - 0s 516us/sample - loss: 0.2984 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "50/50 [==============================] - 0s 428us/sample - loss: 0.2955 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.2926 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "50/50 [==============================] - 0s 397us/sample - loss: 0.2870 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "50/50 [==============================] - 0s 614us/sample - loss: 0.2843 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "50/50 [==============================] - 0s 499us/sample - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "50/50 [==============================] - 0s 665us/sample - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.2739 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "50/50 [==============================] - 0s 602us/sample - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "50/50 [==============================] - 0s 486us/sample - loss: 0.2689 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "50/50 [==============================] - 0s 528us/sample - loss: 0.2642 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.2618 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "50/50 [==============================] - 0s 424us/sample - loss: 0.2595 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "50/50 [==============================] - 0s 430us/sample - loss: 0.2572 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.2550 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "50/50 [==============================] - 0s 643us/sample - loss: 0.2528 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "50/50 [==============================] - 0s 494us/sample - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.2486 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "50/50 [==============================] - 0s 528us/sample - loss: 0.2465 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "50/50 [==============================] - 0s 486us/sample - loss: 0.2444 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.2424 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "50/50 [==============================] - 0s 467us/sample - loss: 0.2405 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "50/50 [==============================] - 0s 668us/sample - loss: 0.2385 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.2366 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "50/50 [==============================] - 0s 571us/sample - loss: 0.2348 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "50/50 [==============================] - 0s 358us/sample - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "50/50 [==============================] - 0s 466us/sample - loss: 0.2293 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 458us/sample - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "50/50 [==============================] - 0s 475us/sample - loss: 0.2258 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "50/50 [==============================] - 0s 433us/sample - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "50/50 [==============================] - 0s 608us/sample - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "50/50 [==============================] - 0s 489us/sample - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "50/50 [==============================] - 0s 473us/sample - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "50/50 [==============================] - 0s 433us/sample - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "50/50 [==============================] - 0s 590us/sample - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "50/50 [==============================] - 0s 550us/sample - loss: 0.2068 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "50/50 [==============================] - 0s 475us/sample - loss: 0.2053 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "50/50 [==============================] - 0s 467us/sample - loss: 0.2039 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "50/50 [==============================] - 0s 664us/sample - loss: 0.2025 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "50/50 [==============================] - 0s 471us/sample - loss: 0.2011 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "50/50 [==============================] - 0s 572us/sample - loss: 0.1998 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "50/50 [==============================] - 0s 672us/sample - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "50/50 [==============================] - 0s 711us/sample - loss: 0.1971 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "50/50 [==============================] - 0s 560us/sample - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "50/50 [==============================] - 0s 464us/sample - loss: 0.1945 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "50/50 [==============================] - 0s 455us/sample - loss: 0.1932 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.1920 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.1907 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.1895 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "50/50 [==============================] - 0s 493us/sample - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "50/50 [==============================] - 0s 641us/sample - loss: 0.1872 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "50/50 [==============================] - 0s 823us/sample - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "50/50 [==============================] - 0s 595us/sample - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "50/50 [==============================] - 0s 494us/sample - loss: 0.1837 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "50/50 [==============================] - 0s 530us/sample - loss: 0.1825 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "50/50 [==============================] - 0s 518us/sample - loss: 0.1814 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "50/50 [==============================] - 0s 738us/sample - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "50/50 [==============================] - 0s 596us/sample - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 1.00 - 0s 526us/sample - loss: 0.1781 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "50/50 [==============================] - 0s 655us/sample - loss: 0.1771 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "50/50 [==============================] - 0s 441us/sample - loss: 0.1760 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "50/50 [==============================] - 0s 591us/sample - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "50/50 [==============================] - 0s 408us/sample - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.1729 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "50/50 [==============================] - 0s 714us/sample - loss: 0.1719 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "50/50 [==============================] - 0s 739us/sample - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "50/50 [==============================] - 0s 631us/sample - loss: 0.1699 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "50/50 [==============================] - 0s 675us/sample - loss: 0.1689 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "50/50 [==============================] - 0s 502us/sample - loss: 0.1680 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "50/50 [==============================] - 0s 485us/sample - loss: 0.1661 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "50/50 [==============================] - 0s 701us/sample - loss: 0.1652 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "50/50 [==============================] - 0s 580us/sample - loss: 0.1642 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "50/50 [==============================] - 0s 628us/sample - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "50/50 [==============================] - 0s 589us/sample - loss: 0.1624 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.1615 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.1607 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 480us/sample - loss: 0.1598 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "50/50 [==============================] - 0s 548us/sample - loss: 0.1589 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "50/50 [==============================] - 0s 551us/sample - loss: 0.1581 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "50/50 [==============================] - 0s 1ms/sample - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "50/50 [==============================] - 0s 879us/sample - loss: 0.1564 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "50/50 [==============================] - 0s 512us/sample - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "50/50 [==============================] - 0s 548us/sample - loss: 0.1548 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "50/50 [==============================] - 0s 620us/sample - loss: 0.1539 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "50/50 [==============================] - 0s 655us/sample - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "50/50 [==============================] - 0s 508us/sample - loss: 0.1523 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "50/50 [==============================] - 0s 546us/sample - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "50/50 [==============================] - 0s 516us/sample - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "50/50 [==============================] - 0s 371us/sample - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "50/50 [==============================] - 0s 801us/sample - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "50/50 [==============================] - 0s 857us/sample - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "50/50 [==============================] - 0s 641us/sample - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "50/50 [==============================] - 0s 652us/sample - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "50/50 [==============================] - 0s 525us/sample - loss: 0.1463 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "50/50 [==============================] - 0s 743us/sample - loss: 0.1455 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "50/50 [==============================] - 0s 681us/sample - loss: 0.1448 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.1441 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "50/50 [==============================] - 0s 537us/sample - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "50/50 [==============================] - 0s 397us/sample - loss: 0.1420 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "50/50 [==============================] - 0s 347us/sample - loss: 0.1413 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.1407 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "50/50 [==============================] - 0s 626us/sample - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "50/50 [==============================] - 0s 511us/sample - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "50/50 [==============================] - 0s 527us/sample - loss: 0.1386 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "50/50 [==============================] - 0s 556us/sample - loss: 0.1380 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "50/50 [==============================] - 0s 514us/sample - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "50/50 [==============================] - 0s 525us/sample - loss: 0.1361 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "50/50 [==============================] - 0s 535us/sample - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "50/50 [==============================] - 0s 547us/sample - loss: 0.1348 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "50/50 [==============================] - 0s 503us/sample - loss: 0.1342 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "50/50 [==============================] - 0s 591us/sample - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "50/50 [==============================] - 0s 573us/sample - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "50/50 [==============================] - 0s 652us/sample - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "50/50 [==============================] - 0s 627us/sample - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "50/50 [==============================] - 0s 580us/sample - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "50/50 [==============================] - 0s 753us/sample - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "50/50 [==============================] - 0s 733us/sample - loss: 0.1295 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "50/50 [==============================] - 0s 569us/sample - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "50/50 [==============================] - 0s 613us/sample - loss: 0.1284 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "50/50 [==============================] - 0s 475us/sample - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.1272 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "50/50 [==============================] - 0s 624us/sample - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "50/50 [==============================] - 0s 501us/sample - loss: 0.1262 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "50/50 [==============================] - 0s 1ms/sample - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "50/50 [==============================] - 0s 734us/sample - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "50/50 [==============================] - 0s 573us/sample - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "50/50 [==============================] - 0s 790us/sample - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "50/50 [==============================] - 0s 473us/sample - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "50/50 [==============================] - 0s 422us/sample - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.1215 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "50/50 [==============================] - 0s 649us/sample - loss: 0.1210 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "50/50 [==============================] - 0s 600us/sample - loss: 0.1200 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "50/50 [==============================] - 0s 433us/sample - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "50/50 [==============================] - 0s 646us/sample - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "50/50 [==============================] - 0s 695us/sample - loss: 0.1172 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.1162 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "50/50 [==============================] - 0s 704us/sample - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "50/50 [==============================] - 0s 579us/sample - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "50/50 [==============================] - 0s 503us/sample - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "50/50 [==============================] - 0s 440us/sample - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "50/50 [==============================] - 0s 417us/sample - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "50/50 [==============================] - 0s 467us/sample - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "50/50 [==============================] - 0s 419us/sample - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.1118 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "50/50 [==============================] - 0s 559us/sample - loss: 0.1114 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "50/50 [==============================] - 0s 576us/sample - loss: 0.1110 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "50/50 [==============================] - 0s 715us/sample - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "50/50 [==============================] - 0s 405us/sample - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "50/50 [==============================] - 0s 547us/sample - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "50/50 [==============================] - 0s 536us/sample - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "50/50 [==============================] - 0s 389us/sample - loss: 0.1090 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "50/50 [==============================] - 0s 503us/sample - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "50/50 [==============================] - 0s 662us/sample - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "50/50 [==============================] - 0s 468us/sample - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "50/50 [==============================] - 0s 450us/sample - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "50/50 [==============================] - 0s 594us/sample - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "50/50 [==============================] - 0s 450us/sample - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "50/50 [==============================] - 0s 558us/sample - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "50/50 [==============================] - 0s 636us/sample - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "50/50 [==============================] - 0s 435us/sample - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "50/50 [==============================] - 0s 634us/sample - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "50/50 [==============================] - 0s 833us/sample - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "50/50 [==============================] - 0s 621us/sample - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "50/50 [==============================] - 0s 464us/sample - loss: 0.1022 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "50/50 [==============================] - 0s 753us/sample - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "50/50 [==============================] - 0s 476us/sample - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "50/50 [==============================] - 0s 596us/sample - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.1004 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "50/50 [==============================] - 0s 423us/sample - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "50/50 [==============================] - 0s 427us/sample - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "50/50 [==============================] - 0s 498us/sample - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "50/50 [==============================] - 0s 724us/sample - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "50/50 [==============================] - 0s 409us/sample - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "50/50 [==============================] - 0s 586us/sample - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "50/50 [==============================] - 0s 416us/sample - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "50/50 [==============================] - 0s 392us/sample - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "50/50 [==============================] - 0s 658us/sample - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "50/50 [==============================] - 0s 514us/sample - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "50/50 [==============================] - 0s 452us/sample - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "50/50 [==============================] - 0s 572us/sample - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "50/50 [==============================] - 0s 655us/sample - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "50/50 [==============================] - 0s 821us/sample - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "50/50 [==============================] - 0s 549us/sample - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "50/50 [==============================] - 0s 855us/sample - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "50/50 [==============================] - 0s 603us/sample - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "50/50 [==============================] - 0s 500us/sample - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "50/50 [==============================] - 0s 676us/sample - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "50/50 [==============================] - 0s 463us/sample - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "50/50 [==============================] - 0s 371us/sample - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "50/50 [==============================] - 0s 945us/sample - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "50/50 [==============================] - 0s 544us/sample - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "50/50 [==============================] - 0s 441us/sample - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "50/50 [==============================] - 0s 497us/sample - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "50/50 [==============================] - 0s 680us/sample - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "50/50 [==============================] - 0s 512us/sample - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "50/50 [==============================] - 0s 528us/sample - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "50/50 [==============================] - 0s 553us/sample - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "50/50 [==============================] - 0s 403us/sample - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "50/50 [==============================] - 0s 441us/sample - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "50/50 [==============================] - 0s 846us/sample - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "50/50 [==============================] - 0s 700us/sample - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "50/50 [==============================] - 0s 647us/sample - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "50/50 [==============================] - 0s 457us/sample - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "50/50 [==============================] - 0s 592us/sample - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "50/50 [==============================] - 0s 488us/sample - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "50/50 [==============================] - 0s 665us/sample - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "50/50 [==============================] - 0s 578us/sample - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "50/50 [==============================] - 0s 502us/sample - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "50/50 [==============================] - 0s 591us/sample - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "50/50 [==============================] - 0s 574us/sample - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "50/50 [==============================] - 0s 448us/sample - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "50/50 [==============================] - 0s 752us/sample - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "50/50 [==============================] - 0s 885us/sample - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "50/50 [==============================] - 0s 626us/sample - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "50/50 [==============================] - 0s 338us/sample - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/500\n",
      "50/50 [==============================] - 0s 714us/sample - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "50/50 [==============================] - 0s 636us/sample - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "50/50 [==============================] - 0s 530us/sample - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "50/50 [==============================] - 0s 527us/sample - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "50/50 [==============================] - 0s 596us/sample - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "50/50 [==============================] - 0s 466us/sample - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "50/50 [==============================] - 0s 665us/sample - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "50/50 [==============================] - 0s 740us/sample - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "50/50 [==============================] - 0s 972us/sample - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "50/50 [==============================] - 0s 461us/sample - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "50/50 [==============================] - 0s 675us/sample - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "50/50 [==============================] - 0s 665us/sample - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "50/50 [==============================] - 0s 476us/sample - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "50/50 [==============================] - 0s 554us/sample - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "50/50 [==============================] - 0s 594us/sample - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "50/50 [==============================] - 0s 408us/sample - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "50/50 [==============================] - 0s 619us/sample - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "50/50 [==============================] - 0s 659us/sample - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "50/50 [==============================] - 0s 597us/sample - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "50/50 [==============================] - 0s 378us/sample - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "50/50 [==============================] - 0s 459us/sample - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "50/50 [==============================] - 0s 666us/sample - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "50/50 [==============================] - 0s 512us/sample - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "50/50 [==============================] - 0s 627us/sample - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "50/50 [==============================] - 0s 825us/sample - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "50/50 [==============================] - 0s 497us/sample - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "50/50 [==============================] - 0s 616us/sample - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "50/50 [==============================] - 0s 488us/sample - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "50/50 [==============================] - 0s 465us/sample - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "50/50 [==============================] - 0s 690us/sample - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "50/50 [==============================] - 0s 424us/sample - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "50/50 [==============================] - 0s 457us/sample - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "50/50 [==============================] - 0s 549us/sample - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "50/50 [==============================] - 0s 445us/sample - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "50/50 [==============================] - 0s 501us/sample - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "50/50 [==============================] - 0s 657us/sample - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "50/50 [==============================] - 0s 837us/sample - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "50/50 [==============================] - 0s 690us/sample - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "50/50 [==============================] - 0s 551us/sample - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "50/50 [==============================] - 0s 574us/sample - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "50/50 [==============================] - 0s 803us/sample - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "50/50 [==============================] - 0s 615us/sample - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "50/50 [==============================] - 0s 693us/sample - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "50/50 [==============================] - 0s 549us/sample - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "50/50 [==============================] - 0s 398us/sample - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "50/50 [==============================] - 0s 460us/sample - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "50/50 [==============================] - 0s 501us/sample - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "50/50 [==============================] - 0s 462us/sample - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "50/50 [==============================] - 0s 438us/sample - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "50/50 [==============================] - 0s 570us/sample - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "50/50 [==============================] - 0s 550us/sample - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "50/50 [==============================] - 0s 870us/sample - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "50/50 [==============================] - 0s 1ms/sample - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "50/50 [==============================] - 0s 505us/sample - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "50/50 [==============================] - 0s 699us/sample - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "50/50 [==============================] - 0s 478us/sample - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "50/50 [==============================] - 0s 573us/sample - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "50/50 [==============================] - 0s 701us/sample - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "50/50 [==============================] - 0s 462us/sample - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "50/50 [==============================] - 0s 570us/sample - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "50/50 [==============================] - 0s 427us/sample - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "50/50 [==============================] - 0s 532us/sample - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "50/50 [==============================] - 0s 496us/sample - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "50/50 [==============================] - 0s 407us/sample - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "50/50 [==============================] - 0s 664us/sample - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "50/50 [==============================] - 0s 489us/sample - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "50/50 [==============================] - 0s 476us/sample - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "50/50 [==============================] - 0s 483us/sample - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "50/50 [==============================] - 0s 593us/sample - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "50/50 [==============================] - 0s 369us/sample - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "50/50 [==============================] - 0s 550us/sample - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "50/50 [==============================] - 0s 581us/sample - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "50/50 [==============================] - 0s 507us/sample - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "50/50 [==============================] - 0s 556us/sample - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "50/50 [==============================] - 0s 525us/sample - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "50/50 [==============================] - 0s 478us/sample - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "50/50 [==============================] - 0s 637us/sample - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/500\n",
      "50/50 [==============================] - 0s 490us/sample - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "50/50 [==============================] - 0s 544us/sample - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "50/50 [==============================] - 0s 535us/sample - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "50/50 [==============================] - 0s 556us/sample - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "50/50 [==============================] - 0s 879us/sample - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "50/50 [==============================] - 0s 681us/sample - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "50/50 [==============================] - 0s 463us/sample - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "50/50 [==============================] - 0s 553us/sample - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "50/50 [==============================] - 0s 721us/sample - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "50/50 [==============================] - 0s 620us/sample - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "50/50 [==============================] - 0s 572us/sample - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "50/50 [==============================] - 0s 535us/sample - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "50/50 [==============================] - 0s 428us/sample - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "50/50 [==============================] - 0s 669us/sample - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "50/50 [==============================] - 0s 543us/sample - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "50/50 [==============================] - 0s 664us/sample - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "50/50 [==============================] - 0s 655us/sample - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "50/50 [==============================] - 0s 517us/sample - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "50/50 [==============================] - 0s 528us/sample - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "50/50 [==============================] - 0s 430us/sample - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "50/50 [==============================] - 0s 406us/sample - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "50/50 [==============================] - 0s 685us/sample - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "50/50 [==============================] - 0s 550us/sample - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "50/50 [==============================] - 0s 507us/sample - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "50/50 [==============================] - 0s 656us/sample - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "50/50 [==============================] - 0s 445us/sample - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "50/50 [==============================] - 0s 491us/sample - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "50/50 [==============================] - 0s 583us/sample - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "50/50 [==============================] - 0s 403us/sample - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "50/50 [==============================] - 0s 464us/sample - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "50/50 [==============================] - 0s 514us/sample - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 1.00 - 0s 504us/sample - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "50/50 [==============================] - 0s 672us/sample - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "50/50 [==============================] - 0s 480us/sample - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# i \"history\" sparar vi träningshistoriken som används vid utvärdering av modellen\n",
    "history = logistic_regression_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utvärdera modell\n",
    "Vi utvärderar accuracy och loss i modellen:\n",
    "\n",
    "- Vad ser vi för skillnader mellan train och test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  1.0\n",
      "accuracy, test:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucXWV97/HPd+4zmcl1JhBIyASIShAFnKMg1huIQK2c03rjlKMiNse+RGnVtvHUoqLtEXuxKlSbaiqiFfFWoy8sWtRaj0UIGBCIIReBjCRkZpLMZGYy99/5Y62Z184wyewks/ee2ev7fr32K3s969l7/Z5hWL95nmetZykiMDMzA6godQBmZjZ7OCmYmdkEJwUzM5vgpGBmZhOcFMzMbIKTgpmZTXBSsEyQ1CopJFXlUfetkn5ajLjMZhsnBZt1JD0uaUhS86TyzemJvbU0kZmVPycFm61+DVw1viHpHKC+dOHMDvn0dMxOhJOCzVa3AW/O2X4L8MXcCpIWSPqipA5JT0j6gKSKdF+lpL+R1ClpJ/DbU3z285J2S/qNpI9KqswnMElfk7RHUrekn0g6O2dfvaS/TePplvRTSfXpvpdI+pmkA5J2SXprWv5jSW/P+Y7Dhq/S3tE7JW0DtqVln0y/o0fS/ZJ+K6d+paT/I2mHpIPp/hWSbpH0t5Pa8h1Jf5RPuy0bnBRstroHmC/prPRk/UbgS5PqfBpYAJwOvIwkiVyT7vsD4DXAeUAb8LpJn70VGAHOTOtcCryd/HwPWA0sBR4Avpyz72+AFwAvBhYDfwqMSTot/dyngRbgXGBznscD+O/Ai4A16fZ96XcsBv4F+JqkunTfe0h6WVcA84G3Af1pm6/KSZzNwMXAV44hDit3EeGXX7PqBTwOXAJ8APi/wGXAD4AqIIBWoBIYBNbkfO5/Az9O3/8QeEfOvkvTz1YBJ6Wfrc/ZfxXwo/T9W4Gf5hnrwvR7F5D8kXUIeP4U9d4PfOsI3/Fj4O0524cdP/3+V04Tx/7x4wJbgSuPUG8L8Kr0/XXAnaX+7+3X7Hp5fNJms9uAnwCrmDR0BDQDNcATOWVPAKem708Bdk3aN24lUA3sljReVjGp/pTSXstfAq8n+Yt/LCeeWqAO2DHFR1ccoTxfh8Um6b0kPZtTSJLG/DSG6Y51K3A1SZK9GvjkCcRkZcjDRzZrRcQTJBPOVwDfnLS7ExgmOcGPOw34Tfp+N8nJMXffuF0kPYXmiFiYvuZHxNlM738CV5L0ZBaQ9FoAlMY0AJwxxed2HaEcoA9oyNk+eYo6E8sZp/MHfwa8AVgUEQuB7jSG6Y71JeBKSc8HzgL+9Qj1LKOcFGy2u5Zk6KQvtzAiRoE7gL+U1CRpJclY+vi8wx3AuyUtl7QIWJfz2d3A94G/lTRfUoWkMyS9LI94mkgSShfJifyvcr53DNgA/J2kU9IJ3wsl1ZLMO1wi6Q2SqiQtkXRu+tHNwO9KapB0Ztrm6WIYATqAKkk3kPQUxn0O+Iik1Uo8T9KSNMZ2kvmI24BvRMShPNpsGeKkYLNaROyIiE1H2P0ukr+ydwI/JZlw3ZDu+yfgLuBBksngyT2NN5MMPz1KMh7/dWBZHiF9kWQo6jfpZ++ZtP99wC9JTrz7gJuAioh4kqTH8960fDPw/PQznwCGgKdJhne+zNHdRTJp/VgaywCHDy/9HUlS/D7QA3yewy/nvRU4hyQxmB1GEX7IjlmWSHopSY+qNe3dmE1wT8EsQyRVA9cDn3NCsKk4KZhlhKSzgAMkw2R/X+JwbJby8JGZmU1wT8HMzCbMuZvXmpubo7W1tdRhmJnNKffff39nRLRMV2/OJYXW1lY2bTrSFYpmZjYVSU9MX8vDR2ZmlsNJwczMJjgpmJnZhDk3pzCV4eFh2tvbGRgYKHUoRVNXV8fy5cuprq4udShmVkbKIim0t7fT1NREa2srOUshl62IoKuri/b2dlatWlXqcMysjBRs+EjSBkl7JT18hP2S9ClJ2yU9JOn84z3WwMAAS5YsyURCAJDEkiVLMtUzMrPiKOScwhdInph1JJeTPNJwNbAW+MyJHCwrCWFc1tprZsVRsOGjiPiJpNajVLkS+GIk62zcI2mhpGXpWvflIQL6OmBsNK/qI2NjDAznv0bZ4MF93PO59xxvdGY2xyw+/0qedX4+j/04fqWcUziVw9eAb0/LnpEUJK0l6U1w2mmnTd5dcl1dXVx88cUA7Nmzh8rKSlpaWiDGuPfbn6OmZvrJ4Gv++IP82Tuv4dlntOZ93JrRXp63a8P0Fc2sLNw3fxmUcVKYavxjytX5ImI9sB6gra1t1q3gt2TJEjZv3gzAhz70IRobG3nf+94HfZ3QvQuWriEqa4gIKiqmHrH7569uZNvTB/l1hTi9pTGv46pnCxUfPjBj7TCz2e1FRThGKe9TaOfwZ+guB54qUSwFsf2xX/HcV76ed7zz3Zx//vns3r2btWvX0tbWxtlnn82NN944UfclL3kJDz64mSoFCxcuZN26dTz/+c/nwgsvZO/evSVshZllSSl7ChuB6yTdTpIAu2diPuHD33mER5/qOeHgcq05ZT4f/J18numeGhli9EA7I4cO8uhjO/n4P/wzN9yULF9//fs/yKJFixkZGeH1v3MZL730NTzrOWcxNDLGWEBtVQXd3d287GUv42Mf+xjvec972LBhA+vWrZvmoGZmJ65gSUHSV4CXA82S2oEPAtUAEfFZ4E6SZ9ZuB/qBawoVS9ENHaSivwONjdC68jRWPvt57O8bAuAr//IVvnn7bYyMjNDx9B5+8eDDtKw4g5GxoFKiobaK+vp6Lr/8cgBe8IIX8J//+Z+lbI2ZZUghrz66apr9Abxzpo97TH/RF8rYCIOVjWyLU5m/YCFnn7oAgG3btnHHreu59957WbhwIVdffTUt8yo4+9QFNNRUcsbSRuqrK6mpqZn4qsrKSkZGRkrVEjPLGK99NNMiYGyUYdVQWXH4XHpPTw9NTU3Mnz+f3bt3c9ddd5UoSDOzqZXFMhezSowCwRDPTArnn38+a9as4bnPfS6nn346F110UWliNDM7gjn3jOa2traY/JCdLVu2cNZZZ5UookkGumHfTp6qWk4/9Zy5NL/LS4/HrGq3mc1qku6PiLbp6nn4aKaNJOsRHYpqqiq8FIWZzS1OCjNtZBAqqhgaq3BSMLM5x0lhhkQEHfu7ob+LgahmZDSorHRSMLO5xUlhhgyNjhH9XQB0M4+aqgoaaz2Pb2Zzi89aM2RwZIxahhmrqOWkk1dwUqkDMjM7Du4pzJDB4SQpUF1b6lDMzI6bewoz4Om9HbzsFa+kjiH2dO6nsqo6WTobuPfeew+7Q/loNmzYwBVXXMHJJ59cyHDNzI7ISWEG1DQu4F/v+iHPqWjnQzd/hcbFS5Ols4/Rhg0bOP/8850UzKxknBRmwODwGHUaTjYqDv+R3nrrrdxyyy0MDQ3x4he/mJtvvpmxsTGuueYaNm/eTESwdu1aTjrpJDZv3swb3/hG6uvrj6mHYWY2U8ovKXxvHez55cx+58nnwOUfO+LuwZFRGipGkkcE5SSFhx9+mG9961v87Gc/o6qqirVr13L77bdzxhln0NnZyS9/mcR54MABFi5cyKc//Wluvvlmzj333JmN38wsT+WXFIrsUG83iwd2U6/hJCHkPFnt3//937nvvvtoa0vuLD906BArVqzg1a9+NVu3buX666/niiuu4NJLLy1V+GZmhym/pHCUv+gLYbRvH/MYYKyyHhoWHLYvInjb297GRz7ykWd87qGHHuJ73/sen/rUp/jGN77B+vXrixWymdkR+ZLUE1Q5NsiQaqk66dnQdPgE8SWXXMIdd9xBZ2cnAF1dXTz55JN0dHQQEbz+9a/nwx/+MA888AAATU1NHDx4sOhtMDMbV349hSKriiGGKudNue+cc87hgx/8IJdccgljY2NUV1fz2c9+lsrKSq699loiAkncdNNNAFxzzTW8/e1v90SzmZWMl84+XiMDDHU9Qc1oP701LTQ2Ly/u8fHS2WaWPy+dXWgDB6kZ7acn6qluXFzqaMzMZoSTwnGKkQFGo4LeeSuprWsodThmZjOibJJCsYfBYniAQaqprSrNj3CuDfuZ2dxQFkmhrq6Orq6uop4oR8eTQnVl0Y45LiLo6uqirq6u6Mc2s/JWFlcfLV++nPb2djo6OopyvLGxMSp6nqKHeTR1DyMV/2E6dXV1LF9e/MltMytvZZEUqqurWbVqVdGOt/3Bn3LmXW/ggQs+yZoL31q045qZFVpZDB8V24FdjwKweOVzSxyJmdnMKoueQtG038++L72ZZw3sZzTEslVrSh2RmdmMclI4FjvuZvFAO/9W9UoWrjqPC3wpqpmVGSeFYzCy9zH2RDOPXfhx3n3x6lKHY2Y24zyncAyGn/4VO8eWcUZLY6lDMTMrCCeFfEVQdWAnO+IUTm+ZegE8M7O5zkkhX0N9VI/0sScWs2yBbxozs/JU0KQg6TJJWyVtl7Ruiv2nSfqRpF9IekjSFYWM54Qc2gfAAZqYX1dd4mDMzAqjYElBUiVwC3A5sAa4StLkazg/ANwREecBbwL+oVDxnLD+LgAGaxdRUVH8O5jNzIqhkD2FFwLbI2JnRAwBtwNXTqoTwPz0/QLgqQLGc2LSpDBWu6jEgZiZFU4hk8KpwK6c7fa0LNeHgKsltQN3Au+a6oskrZW0SdKmYq1v9Az9yfCR5i0pzfHNzIqgkElhqjGWycuYXgV8ISKWA1cAt0l6RkwRsT4i2iKiraWlpQCh5iFNChVOCmZWxgqZFNqBFTnby3nm8NC1wB0AEfFfQB3QXMCYjl9/F6NUUOunrJlZGStkUrgPWC1plaQakonkjZPqPAlcDCDpLJKkUKLxoaOL/i66o4GFjfWlDsXMrGAKlhQiYgS4DrgL2EJyldEjkm6U9Nq02nuBP5D0IPAV4K0xSx8pNtLbyf5oYvE8X45qZuWroGsfRcSdJBPIuWU35Lx/FLiokDHMlNHeLvbRxKKGmlKHYmZWML6jOU/R38X+cFIws/LmpJCnikP7kqQwz0nBzMqXk0I+Iqga3Md+mljspGBmZcxJIR9DfVSODbMvGlnU4IlmMytfTgr5OLgb8GJ4Zlb+nBTyccebAThU2+zF8MysrDkp5OPQfg5ULGL3kgtKHYmZWUE5KUwnAg7t5zu8lJUtC0sdjZlZQRX05rWyMNwPIwO0DzdwxlI/htPMypt7CtNJn6OwjyZOb3ZSMLPy5qQwnTQpHIhGFvpuZjMrc04K00mfo7Avmmis9WibmZU3J4XppElhP03Mc1IwszLnpDCdQ0lSOBCN7imYWdlzUpjOYA8AB2lwUjCzsuekMJ3BXkZUzaiqqKv2j8vMypvPctMZ6mWoooF5tVVIXuLCzMqbx0OmM3iQgYp6Gqv8ozKz8ueewnQGe+mX5xPMLBucFKYzdJA+6n05qpllgpPCdAZ76aPOPQUzywQnhekM9dIzVsf8eicFMyt/TgrTiMFeOoaqWbnEi+GZWflzUphGDPRwcKzOK6SaWSY4KRxNBBru4yD1nN7SWOpozMwKzknhaIb6EEFf1NG6pKHU0ZiZFZyTwtEM9QLQRz3z66tLHIyZWeE5KRzNYJIUBisaqK70j8rMyp/PdEczdBCA0WpPMptZNjgpHM1gkhTGqj3JbGbZUNCkIOkySVslbZe07gh13iDpUUmPSPqXQsZzzNLho7GaphIHYmZWHAW7TVdSJXAL8CqgHbhP0saIeDSnzmrg/cBFEbFf0tJCxXNc0olm1Xr4yMyyoZA9hRcC2yNiZ0QMAbcDV06q8wfALRGxHyAi9hYwnmOXDh9V1LqnYGbZMG1SkHSdpEXH8d2nArtyttvTslzPAp4l6f9JukfSZUeIYa2kTZI2dXR0HEcoxyntKVTUzy/eMc3MSiifnsLJJEM/d6RzBPk+fmyqejFpuwpYDbwcuAr4nKSFz/hQxPqIaIuItpaWljwPPwMGexlD1NR5otnMsmHapBARHyA5cX8eeCuwTdJfSTpjmo+2AytytpcDT01R59sRMRwRvwa2pseaHQYP0h91zKvzjWtmlg15zSlERAB70tcIsAj4uqSPH+Vj9wGrJa2SVAO8Cdg4qc6/Aq8AkNRMMpy085haUEAHuvfRS50fsGNmmTHt2U7Su4G3AJ3A54A/iYhhSRXANuBPp/pcRIxIug64C6gENkTEI5JuBDZFxMZ036WSHgVG0+/umomGzYRdu56kKhp5zsmeaDazbMjnT+Bm4Hcj4oncwogYk/Sao30wIu4E7pxUdkPO+wDek75mnZbBJ9lR18oV5ywrdShmZkWRz/DRncC+8Q1JTZJeBBARWwoVWMmNDNEyspu9taeVOhIzs6LJJyl8BujN2e5Ly8rbPf9AJWPsq1tZ6kjMzIomn6SgdJgHSIaNKOCd0LPGvesB2D3/eSUOxMysePJJCjslvVtSdfq6nll0hVDBjAzwVV7NQJOHj8wsO/JJCu8AXgz8huS+ghcBawsZ1KwwfIiDo9U01voeBTPLjmmHgdL1iN5UhFhmjwgY7qcvqmmsrSx1NGZmRZPPfQp1wLXA2UDdeHlEvK2AcZXWyAAAA1HLUt+4ZmYZks/w0W0k6x+9GvgPkuUqDhYyqJIbPgTAIWp8N7OZZUo+SeHMiPgLoC8ibgV+GzinsGGV2HA/AIeopdFJwcwyJJ+kMJz+e0DSc4EFQGvBIpoNxnsK4Z6CmWVLPme89enzFD5AsqBdI/AXBY2q1NKewgA1LJlXU+JgzMyK56hJIV30rid9MtpPgNOLElWpTcwp1LKq2Y/iNLPsOOrwUXr38nVFimX2SHsKDfOaPHxkZpmSz5zCDyS9T9IKSYvHXwWPrIR27U3W/2tZtKDEkZiZFVc+fwaP34/wzpyyoIyHkh769R5WABedtWLaumZm5SSfO5pXFSOQ2WR0qA+Ay88r27xnZjalfO5ofvNU5RHxxZkPZ3aIwWROgeqG0gZiZlZk+Qwf/bec93XAxcADQNkmhbHh8aRQX9pAzMyKLJ/ho3flbktaQLL0RdmaN9jBIeqod0/BzDImn6uPJusHVs90ILNJy+AudlcvB6nUoZiZFVU+cwrfIbnaCJIksga4o5BBldqykV08UX92+V5eZWZ2BPnMKfxNzvsR4ImIaC9QPKU3PMDSsb38ov6KUkdiZlZ0+SSFJ4HdETEAIKleUmtEPF7QyEqldw8VBH31y0odiZlZ0eUzp/A1YCxnezQtK0/9XQBEXVnftG1mNqV8kkJVRAyNb6Tvy3bp0JHeTgCiYUmJIzEzK758kkKHpNeOb0i6EugsXEilNdjTAYDmOSmYWfbkM6fwDuDLkm5Ot9uBKe9yLgc9+55mHtC0+KRSh2JmVnT53Ly2A7hAUiOgiCjr5zMf3Pc0LVHBylM80Wxm2TPt8JGkv5K0MCJ6I+KgpEWSPlqM4EphsLuDAzSyqqWx1KGYmRVdPnMKl0fEgfGN9ClsZXsR/2hfJwcr5lNXXVnqUMzMii6fpFApqXZ8Q1I9UHuU+nPa/IGnOFBzcqnDMDMriXySwpeAuyVdK+la4AfArfl8uaTLJG2VtF3SuqPUe52kkNSWX9gFEsGy4Xb21Z1W0jDMzEoln4nmj0t6CLgEEPBvwMrpPiepErgFeBXJFUv3SdoYEY9OqtcEvBv4+bGHP8N6nqKeAXoaM/dcITMzIP9VUveQ3NX8eyTPU9iSx2deCGyPiJ3pDW+3A1dOUe8jwMeBgTxjKZjofAyAwfleCs/MsumISUHSsyTdIGkLcDOwi+SS1FdExM1H+lyOU9PPjGtPy3KPcR6wIiK+e7QvkrRW0iZJmzo6OvI49PEZ2LMVgJHFZb0yuJnZER2tp/Arkl7B70TESyLi0yTrHuVrqocRxMROqQL4BPDe6b4oItZHRFtEtLW0tBxDCMdm+OlfcTDqqVt0SsGOYWY2mx0tKfweybDRjyT9k6SLmfpEfyTtwIqc7eXAUznbTcBzgR9Lehy4ANhY0snmzu3siGUsbizbpZ3MzI7qiEkhIr4VEW8EngP8GPhj4CRJn5F0aR7ffR+wWtIqSTXAm4CNOd/fHRHNEdEaEa3APcBrI2LT8TfnxNQc2M7OOIWFDU4KZpZN0040R0RfRHw5Il5D8tf+ZuCIl5fmfG4EuA64i2Ri+o6IeETSjbkL7M0aQ33U9e9m59gyGmvzWRLKzKz8HNPZLyL2Af+YvvKpfydw56SyG45Q9+XHEsuM69oOwI44hdqq43l0tZnZ3Oez37jObQDsjGXUOCmYWUb57DeuazuBeDxOprbK6x6ZWTY5KYzrfZqB6gUMUuPhIzPLLJ/9xvV3cahqIYCTgpllls9+4/r30V+1gMoKUVXpH4uZZZPPfuP699FbucC9BDPLNJ8Bx/V3OSmYWeb5DAgQAf1dHNR8X3lkZpnmpAAweBDGhulRE7XV/pGYWXb5DAhwaB8A3Wry8JGZZZrPgAADPQD0RIPvZjazTPMZEGCoF4CeqPOcgpllmpMCwGCSFA6O1Xn4yMwyzWdAgKGDAHSPOimYWbb5DAgTPYXusRoPH5lZpjkpwMScQvdorS9JNbNM8xkQJnoKW/aFh4/MLNN8BgQY7GG4oo5RKplfV13qaMzMSsZJAWCol37VA/CuV64ucTBmZqXjpAAw2MvBsTouXXMSCxrcUzCz7HJSGBsjdv2c7rFazljaWOpozMxKyklhy7dR9y56xho4vXleqaMxMyspJ4U9vwTgj4f/0D0FM8s8J4XObRxoWMkelnBGs5OCmWWbk0LnNn5TuYLmxhpPMptZ5jkp7H+cnaNLOd29BDOzjCeFkSEYOcSTh2o5Y6knmc3Msp0U0jWPOoaq3VMwMyPrSWEwWTK7jzr3FMzMcFIAoDfq3VMwM6PASUHSZZK2Stouad0U+98j6VFJD0m6W9LKQsbzDOnw0WBFA8sX1Rf10GZms1HBkoKkSuAW4HJgDXCVpDWTqv0CaIuI5wFfBz5eqHimlC6Z3Th/EVWV2e40mZlBYXsKLwS2R8TOiBgCbgeuzK0QET+KiP508x5geQHjeab0MZzNi5cU9bBmZrNVIZPCqcCunO32tOxIrgW+N9UOSWslbZK0qaOjY8YCjHROYUnz4hn7TjOzuayQSUFTlMWUFaWrgTbgr6faHxHrI6ItItpaWlpmLMDBvm4A5s9fNGPfaWY2l1UV8LvbgRU528uBpyZXknQJ8OfAyyJisIDxPMNAbzd1QEPTwmIe1sxs1ipkT+E+YLWkVZJqgDcBG3MrSDoP+EfgtRGxt4CxTGmwv4eBqGZRU0OxD21mNisVLClExAhwHXAXsAW4IyIekXSjpNem1f4aaAS+JmmzpI1H+LqCGOvtpJt5LGqoKeZhzcxmrUIOHxERdwJ3Tiq7Ief9JYU8/nSqD+xgeyxj2TwnBTMzyPgdzY29j7NzbBkL3VMwMwOynBT6uqgbPsCvOYX5dQXtMJmZzRnZTQrdyS0U3XWnIE119ayZWfZkNymMJFe/Lpq/oMSBmJnNHplNCjFyCIDmRfNLHImZ2eyR2aTQ09sHwMmLfeOamdm4zCaFvfuSJS5OXuLhIzOzcZlNCh37k6SwvMXrHpmZjctsUtjX3QPASYvcUzAzG5fZpLC/J1k2u6LGT1wzMxuX2aRwqD99tk9VbWkDMTObRTKbFGJkIHlTVVfaQMzMZpHMJoXxm9eo9LpHZmbjMpsUNDrIsGrBS1yYmU3IZFIYGhmjOoYYdS/BzOwwmUwKfYMj1DLMWIWTgplZrkwmhd7BEWo1TFT6yiMzs1zZTQo4KZiZTZbJpDA+fOTLUc3MDpfJpJD0FIag2j0FM7NcmUwKfYOj1GqYCvcUzMwOk9GkkAwfVdQ4KZiZ5cpkUugZGKZZ3VTMW1LqUMzMZpWqUgdQCj09PSxXJ7H02aUOxcxsVslkT6HqwA4A1Ly6xJGYmc0u2UsKW77D/3jiL5P3zc8qbSxmZrNM9pLC/V9gyfBuflb3Umjx8JGZWa7sJYXObdxT2cZtyz8EldWljsbMbFbJVlIYPgQHnmTb2MksbPBieGZmk2UrKezbCQQPDyxl8Tz3EszMJstWUuh8DIAdcQqXnb2sxMGYmc0+BU0Kki6TtFXSdknrpthfK+mr6f6fS2otZDx0bgPg7HPO45zlCwp6KDOzuahgSUFSJXALcDmwBrhK0ppJ1a4F9kfEmcAngJsKFQ/AyN7H+E00s+KklkIexsxszipkT+GFwPaI2BkRQ8DtwJWT6lwJ3Jq+/zpwsVSYhybf981PUvXI19gxtozTW+YV4hBmZnNeIZPCqcCunO32tGzKOhExAnQDz1iQSNJaSZskbero6DiuYKoal/BA40vZ2vq/+K0z3VMwM5tKIdc+muov/jiOOkTEemA9QFtb2zP25+O8S6+GS6/m/OP5sJlZRhSyp9AOrMjZXg48daQ6kqqABcC+AsZkZmZHUcikcB+wWtIqSTXAm4CNk+psBN6Svn8d8MOIOK6egJmZnbiCDR9FxIik64C7gEpgQ0Q8IulGYFNEbAQ+D9wmaTtJD+FNhYrHzMymV9DnKUTEncCdk8puyHk/ALy+kDGYmVn+snVHs5mZHZWTgpmZTXBSMDOzCU4KZmY2QXPtClBJHcATx/nxZqBzBsOZC9zmbHCbs+FE2rwyIqZdzmHOJYUTIWlTRLSVOo5icpuzwW3OhmK02cNHZmY2wUnBzMwmZC0prC91ACXgNmeD25wNBW9zpuYUzMzs6LLWUzAzs6NwUjAzswmZSQqSLpO0VdJ2SetKHc9MkbRB0l5JD+eULZb0A0nb0n8XpeWS9Kn0Z/CQpDn5zCFJKyT9SNIWSY9Iuj4tL9t2S6qTdK+kB9M2fzgtXyXp52mbv5ouU4+k2nR7e7q/tZTxHy9JlZJ+Iem76XZZtxdA0uOSfilps6RNaVnRfrczkRQkVQK3AJcDa4CrJK0pbVQz5gvAZZPK1gF3R8Rq4O50G5L2r05fa4HPFCnGmTYCvDcizgIuAN6Z/vcs53YPAq+MiOcD5wKXSboAuAn4RNrm/cC1af1rgf0RcSbwibTeXHQ9sCVnu9zbO+4VEXGidKSnAAAEJUlEQVRuzj0JxfvdjoiyfwEXAnflbL8feH+p45rB9rUCD+dsbwWWpe+XAVvT9/8IXDVVvbn8Ar4NvCor7QYagAeAF5Hc3VqVlk/8npM8x+TC9H1VWk+ljv0Y27k8PQG+EvguyeN7y7a9Oe1+HGieVFa03+1M9BSAU4FdOdvtaVm5OikidgOk/y5Ny8vu55AOE5wH/Jwyb3c6lLIZ2Av8ANgBHIiIkbRKbrsm2pzu7waWFDfiE/b3wJ8CY+n2Esq7veMC+L6k+yWtTcuK9rtd0IfszCKaoiyL1+KW1c9BUiPwDeCPIqJHmqp5SdUpyuZcuyNiFDhX0kLgW8BZU1VL/53TbZb0GmBvRNwv6eXjxVNULYv2TnJRRDwlaSnwA0m/OkrdGW93VnoK7cCKnO3lwFMliqUYnpa0DCD9d29aXjY/B0nVJAnhyxHxzbS47NsNEBEHgB+TzKcslDT+x11uuybanO5fQPLI27niIuC1kh4HbicZQvp7yre9EyLiqfTfvSTJ/4UU8Xc7K0nhPmB1euVCDcmzoDeWOKZC2gi8JX3/FpIx9/HyN6dXLFwAdI93SecSJV2CzwNbIuLvcnaVbbsltaQ9BCTVA5eQTMD+CHhdWm1ym8d/Fq8DfhjpoPNcEBHvj4jlEdFK8v/rDyPi9ynT9o6TNE9S0/h74FLgYYr5u13qSZUiTt5cATxGMg7756WOZwbb9RVgNzBM8lfDtSRjqXcD29J/F6d1RXIV1g7gl0BbqeM/zja/hKSL/BCwOX1dUc7tBp4H/CJt88PADWn56cC9wHbga0BtWl6Xbm9P959e6jacQNtfDnw3C+1N2/dg+npk/FxVzN9tL3NhZmYTsjJ8ZGZmeXBSMDOzCU4KZmY2wUnBzMwmOCmYmdkEJwWzSSSNpitUjr9mbFVdSa3KWdHWbLbJyjIXZsfiUEScW+ogzErBPQWzPKXr3N+UPtfgXklnpuUrJd2drmd/t6TT0vKTJH0rfQbCg5JenH5VpaR/Sp+L8P30DmWzWcFJweyZ6icNH70xZ19PRLwQuJlkLR7S91+MiOcBXwY+lZZ/CviPSJ6BcD7JHaqQrH1/S0ScDRwAfq/A7THLm+9oNptEUm9ENE5R/jjJg252pgvy7YmIJZI6SdawH07Ld0dEs6QOYHlEDOZ8Ryvwg0geloKkPwOqI+KjhW+Z2fTcUzA7NnGE90eqM5XBnPejeG7PZhEnBbNj88acf/8rff8zkpU8AX4f+Gn6/m7gD2HiATnzixWk2fHyXyhmz1SfPuFs3L9FxPhlqbWSfk7yB9VVadm7gQ2S/gToAK5Jy68H1ku6lqRH8IckK9qazVqeUzDLUzqn0BYRnaWOxaxQPHxkZmYT3FMwM7MJ7imYmdkEJwUzM5vgpGBmZhOcFMzMbIKTgpmZTfj/rzhAzpn+2EIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Sannolikheter bakom prediktioner\n",
      " Versicolor = 1 \n",
      " [[0.991]\n",
      " [0.054]\n",
      " [0.979]\n",
      " [0.032]\n",
      " [0.049]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor'\n",
    "category = (logistic_regression_model.predict(X_test[0:5]) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "probabilities = logistic_regression_model.predict(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktioner\\n Versicolor = 1\",\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Multinomialt problem - Iris med 3 klasser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vi utökar övningen till identifiering av alla 3 klasser: 'setosa', 'versicolor' och 'virginica'\n",
    " \n",
    "Vi förändrar input data:\n",
    "- Istället för EN dummy-variabel (1=Versicolor) är vårt Y nu 3 dummy-variabler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data import & preparering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features : 4\n",
      "n_classes : 3\n",
      "\n",
      " Standardiserade features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      " [[ 0.069 -0.132  0.251  0.396]\n",
      " [ 1.038  0.098  0.535  0.396]\n",
      " [ 2.25  -0.592  1.672  1.054]]\n",
      "\n",
      "Y:  ['setosa' 'versicolor' 'virginica'] \n",
      " [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding (= skapar dummy-varibler)\n",
    "enc = OneHotEncoder(categories=\"auto\")\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Standardiserar data till medelvärde 0 och varians 1 \n",
    "# Standardisering av värden hjälper neurala nätverk att konvergera\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "print(\"n_features : \" + str(n_features))\n",
    "print(\"n_classes : \" + str(n_classes))\n",
    "\n",
    "print( \"\\n Standardiserade features: \\n\",feature_names,\"\\n\",X_train[0:3])\n",
    "print (\"\\nY: \",names,\"\\n\", Y_train[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial logistisk regression (Softmax)\n",
    "\n",
    "Till skillnad från vårt binära problem kan vi inte använda \"sigmoid\" som aktiveringsfunktion\n",
    "- Aktiveringsfunktionen \"softmax\" kan hantera problem där flera kategorier ska prediceras\n",
    "- Vi måste byta ut vår loss-funktion när vi har flera klasser, från \"binary_crossentropy\" till \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 8ms/sample - loss: 1.0101 - accuracy: 0.6267 - val_loss: 1.0191 - val_accuracy: 0.6267\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.9915 - accuracy: 0.6267 - val_loss: 0.9978 - val_accuracy: 0.6267\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 494us/sample - loss: 0.9716 - accuracy: 0.6267 - val_loss: 0.9776 - val_accuracy: 0.6267\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.9527 - accuracy: 0.6267 - val_loss: 0.9570 - val_accuracy: 0.6267\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.9340 - accuracy: 0.6267 - val_loss: 0.9388 - val_accuracy: 0.6267\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.9162 - accuracy: 0.6267 - val_loss: 0.9199 - val_accuracy: 0.6267\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.8987 - accuracy: 0.6267 - val_loss: 0.9039 - val_accuracy: 0.6400\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.8838 - accuracy: 0.6267 - val_loss: 0.8885 - val_accuracy: 0.6400\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.8690 - accuracy: 0.6267 - val_loss: 0.8716 - val_accuracy: 0.6400\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 241us/sample - loss: 0.8534 - accuracy: 0.6267 - val_loss: 0.8571 - val_accuracy: 0.6400\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.8395 - accuracy: 0.6267 - val_loss: 0.8418 - val_accuracy: 0.6400\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.8250 - accuracy: 0.6267 - val_loss: 0.8264 - val_accuracy: 0.6400\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.8105 - accuracy: 0.6267 - val_loss: 0.8127 - val_accuracy: 0.6400\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.7976 - accuracy: 0.6267 - val_loss: 0.7982 - val_accuracy: 0.6400\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.7843 - accuracy: 0.6133 - val_loss: 0.7870 - val_accuracy: 0.6400\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.7735 - accuracy: 0.6133 - val_loss: 0.7740 - val_accuracy: 0.6400\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.7613 - accuracy: 0.6133 - val_loss: 0.7622 - val_accuracy: 0.6400\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.7506 - accuracy: 0.6000 - val_loss: 0.7514 - val_accuracy: 0.6400\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.7401 - accuracy: 0.5867 - val_loss: 0.7412 - val_accuracy: 0.6533\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.7306 - accuracy: 0.5867 - val_loss: 0.7291 - val_accuracy: 0.6533\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.7188 - accuracy: 0.6000 - val_loss: 0.7175 - val_accuracy: 0.6533\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.7080 - accuracy: 0.6000 - val_loss: 0.7078 - val_accuracy: 0.6533\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.6989 - accuracy: 0.5867 - val_loss: 0.6995 - val_accuracy: 0.6533\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 243us/sample - loss: 0.6908 - accuracy: 0.5733 - val_loss: 0.6902 - val_accuracy: 0.6533\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.6823 - accuracy: 0.5600 - val_loss: 0.6824 - val_accuracy: 0.6667\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.6748 - accuracy: 0.5600 - val_loss: 0.6748 - val_accuracy: 0.6800\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.6682 - accuracy: 0.5600 - val_loss: 0.6681 - val_accuracy: 0.7067\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.6613 - accuracy: 0.5733 - val_loss: 0.6608 - val_accuracy: 0.7067\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.6543 - accuracy: 0.5733 - val_loss: 0.6521 - val_accuracy: 0.7067\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.6462 - accuracy: 0.6000 - val_loss: 0.6459 - val_accuracy: 0.7200\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.6404 - accuracy: 0.6133 - val_loss: 0.6395 - val_accuracy: 0.7200\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.6343 - accuracy: 0.6133 - val_loss: 0.6325 - val_accuracy: 0.7333\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.6278 - accuracy: 0.6267 - val_loss: 0.6265 - val_accuracy: 0.7733\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.6223 - accuracy: 0.6267 - val_loss: 0.6211 - val_accuracy: 0.7600\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.6170 - accuracy: 0.6133 - val_loss: 0.6150 - val_accuracy: 0.7600\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.6113 - accuracy: 0.6133 - val_loss: 0.6096 - val_accuracy: 0.7467\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 239us/sample - loss: 0.6065 - accuracy: 0.6267 - val_loss: 0.6050 - val_accuracy: 0.7467\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.6019 - accuracy: 0.6400 - val_loss: 0.5991 - val_accuracy: 0.7467\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 454us/sample - loss: 0.5964 - accuracy: 0.6533 - val_loss: 0.5945 - val_accuracy: 0.7467\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.5920 - accuracy: 0.6533 - val_loss: 0.5892 - val_accuracy: 0.7733\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.5871 - accuracy: 0.6400 - val_loss: 0.5843 - val_accuracy: 0.7733\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 494us/sample - loss: 0.5827 - accuracy: 0.6400 - val_loss: 0.5806 - val_accuracy: 0.7733\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 533us/sample - loss: 0.5791 - accuracy: 0.6400 - val_loss: 0.5761 - val_accuracy: 0.7733\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 0.5750 - accuracy: 0.6400 - val_loss: 0.5721 - val_accuracy: 0.7733\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 593us/sample - loss: 0.5714 - accuracy: 0.6400 - val_loss: 0.5686 - val_accuracy: 0.7733\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 541us/sample - loss: 0.5680 - accuracy: 0.6400 - val_loss: 0.5651 - val_accuracy: 0.7733\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 496us/sample - loss: 0.5648 - accuracy: 0.6400 - val_loss: 0.5617 - val_accuracy: 0.7733\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.5615 - accuracy: 0.6667 - val_loss: 0.5582 - val_accuracy: 0.7733\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.5583 - accuracy: 0.6667 - val_loss: 0.5548 - val_accuracy: 0.7867\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 568us/sample - loss: 0.5550 - accuracy: 0.7067 - val_loss: 0.5514 - val_accuracy: 0.7867\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.5518 - accuracy: 0.7200 - val_loss: 0.5484 - val_accuracy: 0.7733\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 606us/sample - loss: 0.5490 - accuracy: 0.7200 - val_loss: 0.5455 - val_accuracy: 0.7733\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 425us/sample - loss: 0.5465 - accuracy: 0.7200 - val_loss: 0.5432 - val_accuracy: 0.7733\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.5441 - accuracy: 0.7200 - val_loss: 0.5404 - val_accuracy: 0.7733\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 531us/sample - loss: 0.5418 - accuracy: 0.7200 - val_loss: 0.5383 - val_accuracy: 0.7733\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 0.5395 - accuracy: 0.7200 - val_loss: 0.5354 - val_accuracy: 0.7467\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.5370 - accuracy: 0.7200 - val_loss: 0.5332 - val_accuracy: 0.7467\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 494us/sample - loss: 0.5349 - accuracy: 0.7333 - val_loss: 0.5310 - val_accuracy: 0.7467\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 528us/sample - loss: 0.5327 - accuracy: 0.7333 - val_loss: 0.5287 - val_accuracy: 0.7467\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 501us/sample - loss: 0.5306 - accuracy: 0.7467 - val_loss: 0.5266 - val_accuracy: 0.7467\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.5285 - accuracy: 0.7467 - val_loss: 0.5241 - val_accuracy: 0.7467\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.5262 - accuracy: 0.7467 - val_loss: 0.5221 - val_accuracy: 0.7467\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.5243 - accuracy: 0.7467 - val_loss: 0.5202 - val_accuracy: 0.7467\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.5223 - accuracy: 0.7467 - val_loss: 0.5180 - val_accuracy: 0.7600\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.5203 - accuracy: 0.7467 - val_loss: 0.5161 - val_accuracy: 0.7600\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.5186 - accuracy: 0.7467 - val_loss: 0.5139 - val_accuracy: 0.7600\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.5167 - accuracy: 0.7467 - val_loss: 0.5114 - val_accuracy: 0.7467\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.5142 - accuracy: 0.7467 - val_loss: 0.5098 - val_accuracy: 0.7467\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.5125 - accuracy: 0.7467 - val_loss: 0.5076 - val_accuracy: 0.7600\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.5106 - accuracy: 0.7467 - val_loss: 0.5055 - val_accuracy: 0.7733\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.5088 - accuracy: 0.7467 - val_loss: 0.5040 - val_accuracy: 0.7733\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.5073 - accuracy: 0.7467 - val_loss: 0.5023 - val_accuracy: 0.7733\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.5055 - accuracy: 0.7467 - val_loss: 0.5005 - val_accuracy: 0.7867\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.5038 - accuracy: 0.7467 - val_loss: 0.4987 - val_accuracy: 0.7867\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.5022 - accuracy: 0.7467 - val_loss: 0.4969 - val_accuracy: 0.7867\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.5007 - accuracy: 0.7467 - val_loss: 0.4957 - val_accuracy: 0.7867\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.4992 - accuracy: 0.7600 - val_loss: 0.4937 - val_accuracy: 0.7867\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.4974 - accuracy: 0.7600 - val_loss: 0.4922 - val_accuracy: 0.7867\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.4960 - accuracy: 0.7733 - val_loss: 0.4908 - val_accuracy: 0.7867\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.4946 - accuracy: 0.7733 - val_loss: 0.4895 - val_accuracy: 0.7867\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.4933 - accuracy: 0.7733 - val_loss: 0.4879 - val_accuracy: 0.7867\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.4917 - accuracy: 0.7733 - val_loss: 0.4862 - val_accuracy: 0.7867\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.4901 - accuracy: 0.7733 - val_loss: 0.4848 - val_accuracy: 0.7867\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.4888 - accuracy: 0.7867 - val_loss: 0.4835 - val_accuracy: 0.7867\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 559us/sample - loss: 0.4875 - accuracy: 0.7867 - val_loss: 0.4819 - val_accuracy: 0.7867\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.4860 - accuracy: 0.7867 - val_loss: 0.4805 - val_accuracy: 0.7867\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.4846 - accuracy: 0.7867 - val_loss: 0.4790 - val_accuracy: 0.7867\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 872us/sample - loss: 0.4832 - accuracy: 0.7867 - val_loss: 0.4775 - val_accuracy: 0.7867\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 583us/sample - loss: 0.4820 - accuracy: 0.8000 - val_loss: 0.4766 - val_accuracy: 0.7867\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.4809 - accuracy: 0.8000 - val_loss: 0.4756 - val_accuracy: 0.7867\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.4798 - accuracy: 0.8000 - val_loss: 0.4743 - val_accuracy: 0.7867\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 524us/sample - loss: 0.4788 - accuracy: 0.8000 - val_loss: 0.4733 - val_accuracy: 0.7867\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 547us/sample - loss: 0.4775 - accuracy: 0.8000 - val_loss: 0.4720 - val_accuracy: 0.7867\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.4763 - accuracy: 0.8000 - val_loss: 0.4709 - val_accuracy: 0.7867\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.4751 - accuracy: 0.8000 - val_loss: 0.4696 - val_accuracy: 0.8000\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.4741 - accuracy: 0.8000 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.4730 - accuracy: 0.8000 - val_loss: 0.4676 - val_accuracy: 0.8000\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.4719 - accuracy: 0.8133 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.4707 - accuracy: 0.8133 - val_loss: 0.4652 - val_accuracy: 0.8000\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.4697 - accuracy: 0.8133 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.4685 - accuracy: 0.8133 - val_loss: 0.4633 - val_accuracy: 0.8000\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.4675 - accuracy: 0.8133 - val_loss: 0.4623 - val_accuracy: 0.8000\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.4664 - accuracy: 0.8133 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.4655 - accuracy: 0.8133 - val_loss: 0.4605 - val_accuracy: 0.8000\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.4647 - accuracy: 0.8133 - val_loss: 0.4596 - val_accuracy: 0.8000\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.4636 - accuracy: 0.8133 - val_loss: 0.4587 - val_accuracy: 0.8000\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.4626 - accuracy: 0.8133 - val_loss: 0.4578 - val_accuracy: 0.8000\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.4617 - accuracy: 0.8133 - val_loss: 0.4567 - val_accuracy: 0.8000\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 808us/sample - loss: 0.4607 - accuracy: 0.8133 - val_loss: 0.4558 - val_accuracy: 0.8000\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 682us/sample - loss: 0.4597 - accuracy: 0.8133 - val_loss: 0.4547 - val_accuracy: 0.8000\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 538us/sample - loss: 0.4587 - accuracy: 0.8133 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 1ms/sample - loss: 0.4578 - accuracy: 0.8133 - val_loss: 0.4530 - val_accuracy: 0.8000\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 1ms/sample - loss: 0.4569 - accuracy: 0.8133 - val_loss: 0.4520 - val_accuracy: 0.8000\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 1ms/sample - loss: 0.4559 - accuracy: 0.8133 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 519us/sample - loss: 0.4550 - accuracy: 0.8133 - val_loss: 0.4500 - val_accuracy: 0.8000\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.4540 - accuracy: 0.8133 - val_loss: 0.4490 - val_accuracy: 0.8000\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 520us/sample - loss: 0.4531 - accuracy: 0.8133 - val_loss: 0.4483 - val_accuracy: 0.8000\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.4522 - accuracy: 0.8133 - val_loss: 0.4473 - val_accuracy: 0.8000\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.4513 - accuracy: 0.8133 - val_loss: 0.4463 - val_accuracy: 0.8000\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.4504 - accuracy: 0.8133 - val_loss: 0.4455 - val_accuracy: 0.8000\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.4496 - accuracy: 0.8133 - val_loss: 0.4446 - val_accuracy: 0.8000\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.4487 - accuracy: 0.8133 - val_loss: 0.4438 - val_accuracy: 0.8000\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.4480 - accuracy: 0.8133 - val_loss: 0.4432 - val_accuracy: 0.8133\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.4472 - accuracy: 0.8133 - val_loss: 0.4424 - val_accuracy: 0.8133\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.4463 - accuracy: 0.8133 - val_loss: 0.4416 - val_accuracy: 0.8133\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.4454 - accuracy: 0.8133 - val_loss: 0.4407 - val_accuracy: 0.8133\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.4446 - accuracy: 0.8133 - val_loss: 0.4402 - val_accuracy: 0.8133\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.4438 - accuracy: 0.8133 - val_loss: 0.4395 - val_accuracy: 0.8133\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.4431 - accuracy: 0.8133 - val_loss: 0.4388 - val_accuracy: 0.8133\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.4424 - accuracy: 0.8133 - val_loss: 0.4379 - val_accuracy: 0.8133\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.4416 - accuracy: 0.8133 - val_loss: 0.4373 - val_accuracy: 0.8133\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 489us/sample - loss: 0.4408 - accuracy: 0.8133 - val_loss: 0.4365 - val_accuracy: 0.8133\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.4401 - accuracy: 0.8133 - val_loss: 0.4356 - val_accuracy: 0.8133\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.4393 - accuracy: 0.8133 - val_loss: 0.4349 - val_accuracy: 0.8133\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.4385 - accuracy: 0.8133 - val_loss: 0.4342 - val_accuracy: 0.8133\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 467us/sample - loss: 0.4378 - accuracy: 0.8133 - val_loss: 0.4334 - val_accuracy: 0.8133\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.4371 - accuracy: 0.8133 - val_loss: 0.4327 - val_accuracy: 0.8133\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.4365 - accuracy: 0.8133 - val_loss: 0.4319 - val_accuracy: 0.8133\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.4356 - accuracy: 0.8133 - val_loss: 0.4312 - val_accuracy: 0.8133\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 228us/sample - loss: 0.4350 - accuracy: 0.8133 - val_loss: 0.4305 - val_accuracy: 0.8133\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.4344 - accuracy: 0.8133 - val_loss: 0.4298 - val_accuracy: 0.8133\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.4336 - accuracy: 0.8133 - val_loss: 0.4292 - val_accuracy: 0.8133\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.4329 - accuracy: 0.8133 - val_loss: 0.4285 - val_accuracy: 0.8133\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.4323 - accuracy: 0.8133 - val_loss: 0.4280 - val_accuracy: 0.8133\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.4315 - accuracy: 0.8133 - val_loss: 0.4274 - val_accuracy: 0.8133\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.4308 - accuracy: 0.8133 - val_loss: 0.4268 - val_accuracy: 0.8133\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.4302 - accuracy: 0.8133 - val_loss: 0.4261 - val_accuracy: 0.8133\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.4295 - accuracy: 0.8133 - val_loss: 0.4255 - val_accuracy: 0.8133\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.4288 - accuracy: 0.8133 - val_loss: 0.4249 - val_accuracy: 0.8133\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.4281 - accuracy: 0.8133 - val_loss: 0.4242 - val_accuracy: 0.8133\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.4273 - accuracy: 0.8133 - val_loss: 0.4236 - val_accuracy: 0.8133\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.4267 - accuracy: 0.8133 - val_loss: 0.4230 - val_accuracy: 0.8133\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.4262 - accuracy: 0.8133 - val_loss: 0.4223 - val_accuracy: 0.8133\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.4254 - accuracy: 0.8133 - val_loss: 0.4216 - val_accuracy: 0.8133\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.4248 - accuracy: 0.8133 - val_loss: 0.4210 - val_accuracy: 0.8133\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.4242 - accuracy: 0.8133 - val_loss: 0.4204 - val_accuracy: 0.8133\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.4236 - accuracy: 0.8133 - val_loss: 0.4197 - val_accuracy: 0.8133\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.4230 - accuracy: 0.8133 - val_loss: 0.4192 - val_accuracy: 0.8133\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.4225 - accuracy: 0.8133 - val_loss: 0.4186 - val_accuracy: 0.8133\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.4217 - accuracy: 0.8133 - val_loss: 0.4180 - val_accuracy: 0.8133\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.4212 - accuracy: 0.8133 - val_loss: 0.4175 - val_accuracy: 0.8133\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.4205 - accuracy: 0.8133 - val_loss: 0.4170 - val_accuracy: 0.8133\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.4199 - accuracy: 0.8133 - val_loss: 0.4164 - val_accuracy: 0.8133\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.4193 - accuracy: 0.8133 - val_loss: 0.4159 - val_accuracy: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.4187 - accuracy: 0.8133 - val_loss: 0.4152 - val_accuracy: 0.8133\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.4181 - accuracy: 0.8133 - val_loss: 0.4147 - val_accuracy: 0.8267\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.4176 - accuracy: 0.8133 - val_loss: 0.4142 - val_accuracy: 0.8267\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 595us/sample - loss: 0.4170 - accuracy: 0.8133 - val_loss: 0.4136 - val_accuracy: 0.8267\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.4164 - accuracy: 0.8133 - val_loss: 0.4131 - val_accuracy: 0.8267\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.4158 - accuracy: 0.8133 - val_loss: 0.4126 - val_accuracy: 0.8267\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.4153 - accuracy: 0.8133 - val_loss: 0.4122 - val_accuracy: 0.8267\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.4147 - accuracy: 0.8133 - val_loss: 0.4116 - val_accuracy: 0.8267\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.4142 - accuracy: 0.8133 - val_loss: 0.4111 - val_accuracy: 0.8267\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.4136 - accuracy: 0.8133 - val_loss: 0.4107 - val_accuracy: 0.8267\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 531us/sample - loss: 0.4130 - accuracy: 0.8133 - val_loss: 0.4102 - val_accuracy: 0.8267\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.4125 - accuracy: 0.8133 - val_loss: 0.4095 - val_accuracy: 0.8267\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.4119 - accuracy: 0.8133 - val_loss: 0.4089 - val_accuracy: 0.8267\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 495us/sample - loss: 0.4114 - accuracy: 0.8133 - val_loss: 0.4085 - val_accuracy: 0.8267\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.4108 - accuracy: 0.8133 - val_loss: 0.4081 - val_accuracy: 0.8267\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.4103 - accuracy: 0.8133 - val_loss: 0.4076 - val_accuracy: 0.8267\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.4097 - accuracy: 0.8133 - val_loss: 0.4070 - val_accuracy: 0.8267\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.4092 - accuracy: 0.8133 - val_loss: 0.4064 - val_accuracy: 0.8267\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.4086 - accuracy: 0.8133 - val_loss: 0.4059 - val_accuracy: 0.8267\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.4082 - accuracy: 0.8133 - val_loss: 0.4056 - val_accuracy: 0.8267\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.4076 - accuracy: 0.8133 - val_loss: 0.4050 - val_accuracy: 0.8267\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.4070 - accuracy: 0.8133 - val_loss: 0.4046 - val_accuracy: 0.8267\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.4065 - accuracy: 0.8133 - val_loss: 0.4040 - val_accuracy: 0.8267\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 480us/sample - loss: 0.4064 - accuracy: 0.8133 - val_loss: 0.4037 - val_accuracy: 0.8267\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 494us/sample - loss: 0.4054 - accuracy: 0.8133 - val_loss: 0.4032 - val_accuracy: 0.8267\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 499us/sample - loss: 0.4049 - accuracy: 0.8133 - val_loss: 0.4028 - val_accuracy: 0.8267\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.4044 - accuracy: 0.8133 - val_loss: 0.4024 - val_accuracy: 0.8267\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.4039 - accuracy: 0.8133 - val_loss: 0.4018 - val_accuracy: 0.8267\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.4033 - accuracy: 0.8133 - val_loss: 0.4013 - val_accuracy: 0.8267\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.4029 - accuracy: 0.8133 - val_loss: 0.4009 - val_accuracy: 0.8267\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.4022 - accuracy: 0.8133 - val_loss: 0.4005 - val_accuracy: 0.8267\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.4017 - accuracy: 0.8133 - val_loss: 0.4000 - val_accuracy: 0.8267\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 517us/sample - loss: 0.4012 - accuracy: 0.8133 - val_loss: 0.3997 - val_accuracy: 0.8267\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 485us/sample - loss: 0.4007 - accuracy: 0.8133 - val_loss: 0.3993 - val_accuracy: 0.8267\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.4002 - accuracy: 0.8133 - val_loss: 0.3989 - val_accuracy: 0.8267\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 0.3996 - accuracy: 0.8133 - val_loss: 0.3987 - val_accuracy: 0.8267\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 511us/sample - loss: 0.3990 - accuracy: 0.8133 - val_loss: 0.3982 - val_accuracy: 0.8267\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 754us/sample - loss: 0.3988 - accuracy: 0.8133 - val_loss: 0.3978 - val_accuracy: 0.8267\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.3981 - accuracy: 0.8133 - val_loss: 0.3972 - val_accuracy: 0.8267\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.3976 - accuracy: 0.8133 - val_loss: 0.3967 - val_accuracy: 0.8267\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 503us/sample - loss: 0.3972 - accuracy: 0.8133 - val_loss: 0.3962 - val_accuracy: 0.8267\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 494us/sample - loss: 0.3967 - accuracy: 0.8133 - val_loss: 0.3959 - val_accuracy: 0.8400\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 582us/sample - loss: 0.3961 - accuracy: 0.8133 - val_loss: 0.3955 - val_accuracy: 0.8400\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 476us/sample - loss: 0.3956 - accuracy: 0.8133 - val_loss: 0.3952 - val_accuracy: 0.8400\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.3951 - accuracy: 0.8133 - val_loss: 0.3948 - val_accuracy: 0.8400\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.3946 - accuracy: 0.8133 - val_loss: 0.3945 - val_accuracy: 0.8400\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.3942 - accuracy: 0.8133 - val_loss: 0.3939 - val_accuracy: 0.8400\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.3937 - accuracy: 0.8133 - val_loss: 0.3935 - val_accuracy: 0.8400\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 0.3932 - accuracy: 0.8133 - val_loss: 0.3930 - val_accuracy: 0.8400\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 574us/sample - loss: 0.3928 - accuracy: 0.8133 - val_loss: 0.3926 - val_accuracy: 0.8400\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.3923 - accuracy: 0.8133 - val_loss: 0.3922 - val_accuracy: 0.8400\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.3919 - accuracy: 0.8133 - val_loss: 0.3918 - val_accuracy: 0.8400\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 542us/sample - loss: 0.3914 - accuracy: 0.8133 - val_loss: 0.3915 - val_accuracy: 0.8400\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.3910 - accuracy: 0.8133 - val_loss: 0.3912 - val_accuracy: 0.8533\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 509us/sample - loss: 0.3905 - accuracy: 0.8133 - val_loss: 0.3908 - val_accuracy: 0.8533\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.3901 - accuracy: 0.8133 - val_loss: 0.3905 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.3895 - accuracy: 0.8133 - val_loss: 0.3901 - val_accuracy: 0.8533\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3892 - accuracy: 0.8133 - val_loss: 0.3897 - val_accuracy: 0.8533\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.3887 - accuracy: 0.8133 - val_loss: 0.3893 - val_accuracy: 0.8533\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 457us/sample - loss: 0.3883 - accuracy: 0.8133 - val_loss: 0.3890 - val_accuracy: 0.8533\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 564us/sample - loss: 0.3878 - accuracy: 0.8133 - val_loss: 0.3886 - val_accuracy: 0.8533\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 532us/sample - loss: 0.3874 - accuracy: 0.8133 - val_loss: 0.3883 - val_accuracy: 0.8533\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 520us/sample - loss: 0.3869 - accuracy: 0.8133 - val_loss: 0.3880 - val_accuracy: 0.8533\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.3864 - accuracy: 0.8133 - val_loss: 0.3876 - val_accuracy: 0.8533\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.3860 - accuracy: 0.8133 - val_loss: 0.3872 - val_accuracy: 0.8533\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.3856 - accuracy: 0.8133 - val_loss: 0.3869 - val_accuracy: 0.8533\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.3851 - accuracy: 0.8133 - val_loss: 0.3865 - val_accuracy: 0.8533\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 520us/sample - loss: 0.3847 - accuracy: 0.8133 - val_loss: 0.3862 - val_accuracy: 0.8533\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.3842 - accuracy: 0.8133 - val_loss: 0.3859 - val_accuracy: 0.8533\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3838 - accuracy: 0.8133 - val_loss: 0.3855 - val_accuracy: 0.8533\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 476us/sample - loss: 0.3835 - accuracy: 0.8133 - val_loss: 0.3852 - val_accuracy: 0.8533\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.3830 - accuracy: 0.8133 - val_loss: 0.3849 - val_accuracy: 0.8533\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.3825 - accuracy: 0.8267 - val_loss: 0.3845 - val_accuracy: 0.8533\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.3823 - accuracy: 0.8267 - val_loss: 0.3841 - val_accuracy: 0.8533\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3818 - accuracy: 0.8267 - val_loss: 0.3836 - val_accuracy: 0.8533\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.3813 - accuracy: 0.8267 - val_loss: 0.3833 - val_accuracy: 0.8533\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.3808 - accuracy: 0.8267 - val_loss: 0.3829 - val_accuracy: 0.8533\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.93 - 0s 403us/sample - loss: 0.3804 - accuracy: 0.8267 - val_loss: 0.3825 - val_accuracy: 0.8533\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.3800 - accuracy: 0.8267 - val_loss: 0.3822 - val_accuracy: 0.8533\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 514us/sample - loss: 0.3797 - accuracy: 0.8267 - val_loss: 0.3818 - val_accuracy: 0.8533\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.3792 - accuracy: 0.8267 - val_loss: 0.3815 - val_accuracy: 0.8533\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.3789 - accuracy: 0.8267 - val_loss: 0.3810 - val_accuracy: 0.8533\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3785 - accuracy: 0.8267 - val_loss: 0.3808 - val_accuracy: 0.8533\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 0.3781 - accuracy: 0.8267 - val_loss: 0.3804 - val_accuracy: 0.8533\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.3776 - accuracy: 0.8267 - val_loss: 0.3801 - val_accuracy: 0.8533\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3772 - accuracy: 0.8267 - val_loss: 0.3799 - val_accuracy: 0.8533\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.3769 - accuracy: 0.8267 - val_loss: 0.3795 - val_accuracy: 0.8533\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.3764 - accuracy: 0.8267 - val_loss: 0.3791 - val_accuracy: 0.8533\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.3760 - accuracy: 0.8267 - val_loss: 0.3788 - val_accuracy: 0.8533\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.3756 - accuracy: 0.8267 - val_loss: 0.3785 - val_accuracy: 0.8533\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 506us/sample - loss: 0.3752 - accuracy: 0.8267 - val_loss: 0.3782 - val_accuracy: 0.8533\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.3748 - accuracy: 0.8267 - val_loss: 0.3778 - val_accuracy: 0.8533\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.3743 - accuracy: 0.8267 - val_loss: 0.3776 - val_accuracy: 0.8533\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.3740 - accuracy: 0.8267 - val_loss: 0.3773 - val_accuracy: 0.8533\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 0.3736 - accuracy: 0.8267 - val_loss: 0.3769 - val_accuracy: 0.8533\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 555us/sample - loss: 0.3732 - accuracy: 0.8267 - val_loss: 0.3766 - val_accuracy: 0.8533\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 537us/sample - loss: 0.3728 - accuracy: 0.8267 - val_loss: 0.3763 - val_accuracy: 0.8533\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.3724 - accuracy: 0.8267 - val_loss: 0.3759 - val_accuracy: 0.8533\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3721 - accuracy: 0.8267 - val_loss: 0.3757 - val_accuracy: 0.8533\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3717 - accuracy: 0.8267 - val_loss: 0.3753 - val_accuracy: 0.8533\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3713 - accuracy: 0.8267 - val_loss: 0.3751 - val_accuracy: 0.8533\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 611us/sample - loss: 0.3708 - accuracy: 0.8267 - val_loss: 0.3747 - val_accuracy: 0.8533\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 520us/sample - loss: 0.3704 - accuracy: 0.8267 - val_loss: 0.3744 - val_accuracy: 0.8533\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.3701 - accuracy: 0.8400 - val_loss: 0.3741 - val_accuracy: 0.8533\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3697 - accuracy: 0.8400 - val_loss: 0.3739 - val_accuracy: 0.8533\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.3693 - accuracy: 0.8400 - val_loss: 0.3735 - val_accuracy: 0.8533\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.3690 - accuracy: 0.8400 - val_loss: 0.3732 - val_accuracy: 0.8533\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.3685 - accuracy: 0.8400 - val_loss: 0.3730 - val_accuracy: 0.8533\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.3682 - accuracy: 0.8400 - val_loss: 0.3727 - val_accuracy: 0.8533\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 458us/sample - loss: 0.3678 - accuracy: 0.8400 - val_loss: 0.3725 - val_accuracy: 0.8533\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.3674 - accuracy: 0.8400 - val_loss: 0.3721 - val_accuracy: 0.8533\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3670 - accuracy: 0.8400 - val_loss: 0.3718 - val_accuracy: 0.8533\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.3667 - accuracy: 0.8400 - val_loss: 0.3713 - val_accuracy: 0.8533\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 502us/sample - loss: 0.3665 - accuracy: 0.8400 - val_loss: 0.3710 - val_accuracy: 0.8533\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3659 - accuracy: 0.8533 - val_loss: 0.3707 - val_accuracy: 0.8533\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.3656 - accuracy: 0.8400 - val_loss: 0.3704 - val_accuracy: 0.8533\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.3652 - accuracy: 0.8533 - val_loss: 0.3702 - val_accuracy: 0.8533\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 508us/sample - loss: 0.3649 - accuracy: 0.8533 - val_loss: 0.3700 - val_accuracy: 0.8533\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.3645 - accuracy: 0.8400 - val_loss: 0.3698 - val_accuracy: 0.8533\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.3641 - accuracy: 0.8400 - val_loss: 0.3696 - val_accuracy: 0.8533\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.3637 - accuracy: 0.8400 - val_loss: 0.3692 - val_accuracy: 0.8533\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3633 - accuracy: 0.8400 - val_loss: 0.3690 - val_accuracy: 0.8533\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.3632 - accuracy: 0.8400 - val_loss: 0.3686 - val_accuracy: 0.8533\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.3626 - accuracy: 0.8533 - val_loss: 0.3683 - val_accuracy: 0.8533\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 652us/sample - loss: 0.3623 - accuracy: 0.8533 - val_loss: 0.3680 - val_accuracy: 0.8533\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.3620 - accuracy: 0.8533 - val_loss: 0.3675 - val_accuracy: 0.8533\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 0.3616 - accuracy: 0.8533 - val_loss: 0.3672 - val_accuracy: 0.8533\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 535us/sample - loss: 0.3613 - accuracy: 0.8533 - val_loss: 0.3669 - val_accuracy: 0.8533\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 538us/sample - loss: 0.3609 - accuracy: 0.8533 - val_loss: 0.3665 - val_accuracy: 0.8533\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.3607 - accuracy: 0.8533 - val_loss: 0.3663 - val_accuracy: 0.8533\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.3602 - accuracy: 0.8533 - val_loss: 0.3659 - val_accuracy: 0.8533\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.3599 - accuracy: 0.8533 - val_loss: 0.3656 - val_accuracy: 0.8533\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.3596 - accuracy: 0.8533 - val_loss: 0.3654 - val_accuracy: 0.8533\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.3594 - accuracy: 0.8533 - val_loss: 0.3651 - val_accuracy: 0.8533\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.3589 - accuracy: 0.8533 - val_loss: 0.3649 - val_accuracy: 0.8533\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 541us/sample - loss: 0.3585 - accuracy: 0.8533 - val_loss: 0.3646 - val_accuracy: 0.8533\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.3583 - accuracy: 0.8533 - val_loss: 0.3644 - val_accuracy: 0.8533\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 242us/sample - loss: 0.3578 - accuracy: 0.8533 - val_loss: 0.3642 - val_accuracy: 0.8667\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3575 - accuracy: 0.8533 - val_loss: 0.3641 - val_accuracy: 0.8667\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 514us/sample - loss: 0.3571 - accuracy: 0.8533 - val_loss: 0.3638 - val_accuracy: 0.8667\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.3567 - accuracy: 0.8533 - val_loss: 0.3634 - val_accuracy: 0.8667\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.3564 - accuracy: 0.8533 - val_loss: 0.3632 - val_accuracy: 0.8667\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.3560 - accuracy: 0.8533 - val_loss: 0.3629 - val_accuracy: 0.8667\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.3557 - accuracy: 0.8533 - val_loss: 0.3626 - val_accuracy: 0.8667\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.3553 - accuracy: 0.8533 - val_loss: 0.3624 - val_accuracy: 0.8667\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 544us/sample - loss: 0.3550 - accuracy: 0.8533 - val_loss: 0.3621 - val_accuracy: 0.8667\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 590us/sample - loss: 0.3548 - accuracy: 0.8533 - val_loss: 0.3617 - val_accuracy: 0.8667\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 498us/sample - loss: 0.3544 - accuracy: 0.8533 - val_loss: 0.3614 - val_accuracy: 0.8667\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.3540 - accuracy: 0.8533 - val_loss: 0.3612 - val_accuracy: 0.8667\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.3537 - accuracy: 0.8533 - val_loss: 0.3611 - val_accuracy: 0.8667\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 589us/sample - loss: 0.3533 - accuracy: 0.8533 - val_loss: 0.3609 - val_accuracy: 0.8667\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.3531 - accuracy: 0.8533 - val_loss: 0.3604 - val_accuracy: 0.8667\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 499us/sample - loss: 0.3527 - accuracy: 0.8533 - val_loss: 0.3602 - val_accuracy: 0.8667\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.3524 - accuracy: 0.8533 - val_loss: 0.3597 - val_accuracy: 0.8667\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.3520 - accuracy: 0.8533 - val_loss: 0.3594 - val_accuracy: 0.8667\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 583us/sample - loss: 0.3517 - accuracy: 0.8533 - val_loss: 0.3592 - val_accuracy: 0.8667\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.3514 - accuracy: 0.8533 - val_loss: 0.3589 - val_accuracy: 0.8667\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.3511 - accuracy: 0.8533 - val_loss: 0.3586 - val_accuracy: 0.8667\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.3508 - accuracy: 0.8533 - val_loss: 0.3583 - val_accuracy: 0.8667\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3505 - accuracy: 0.8533 - val_loss: 0.3582 - val_accuracy: 0.8667\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.3501 - accuracy: 0.8533 - val_loss: 0.3580 - val_accuracy: 0.8667\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 538us/sample - loss: 0.3499 - accuracy: 0.8533 - val_loss: 0.3576 - val_accuracy: 0.8667\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.3497 - accuracy: 0.8533 - val_loss: 0.3572 - val_accuracy: 0.8667\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 509us/sample - loss: 0.3492 - accuracy: 0.8533 - val_loss: 0.3569 - val_accuracy: 0.8667\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3489 - accuracy: 0.8533 - val_loss: 0.3567 - val_accuracy: 0.8667\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.3486 - accuracy: 0.8533 - val_loss: 0.3565 - val_accuracy: 0.8667\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.3483 - accuracy: 0.8533 - val_loss: 0.3562 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.3480 - accuracy: 0.8533 - val_loss: 0.3560 - val_accuracy: 0.8667\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 0.3477 - accuracy: 0.8533 - val_loss: 0.3557 - val_accuracy: 0.8667\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.3474 - accuracy: 0.8533 - val_loss: 0.3555 - val_accuracy: 0.8667\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.3471 - accuracy: 0.8533 - val_loss: 0.3552 - val_accuracy: 0.8667\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 553us/sample - loss: 0.3467 - accuracy: 0.8533 - val_loss: 0.3550 - val_accuracy: 0.8667\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 473us/sample - loss: 0.3464 - accuracy: 0.8667 - val_loss: 0.3546 - val_accuracy: 0.8667\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.3461 - accuracy: 0.8667 - val_loss: 0.3543 - val_accuracy: 0.8667\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3458 - accuracy: 0.8667 - val_loss: 0.3541 - val_accuracy: 0.8667\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.3455 - accuracy: 0.8667 - val_loss: 0.3540 - val_accuracy: 0.8667\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.3452 - accuracy: 0.8667 - val_loss: 0.3537 - val_accuracy: 0.8667\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.3449 - accuracy: 0.8667 - val_loss: 0.3536 - val_accuracy: 0.8667\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3447 - accuracy: 0.8667 - val_loss: 0.3535 - val_accuracy: 0.8667\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.3443 - accuracy: 0.8667 - val_loss: 0.3533 - val_accuracy: 0.8667\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.3440 - accuracy: 0.8667 - val_loss: 0.3530 - val_accuracy: 0.8667\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 561us/sample - loss: 0.3437 - accuracy: 0.8667 - val_loss: 0.3527 - val_accuracy: 0.8667\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.3434 - accuracy: 0.8667 - val_loss: 0.3527 - val_accuracy: 0.8667\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.3432 - accuracy: 0.8667 - val_loss: 0.3524 - val_accuracy: 0.8667\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 0.3428 - accuracy: 0.8667 - val_loss: 0.3522 - val_accuracy: 0.8667\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.3425 - accuracy: 0.8667 - val_loss: 0.3518 - val_accuracy: 0.8667\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.3422 - accuracy: 0.8667 - val_loss: 0.3515 - val_accuracy: 0.8667\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.3419 - accuracy: 0.8667 - val_loss: 0.3513 - val_accuracy: 0.8667\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.90 - 0s 383us/sample - loss: 0.3417 - accuracy: 0.8667 - val_loss: 0.3509 - val_accuracy: 0.8667\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.3415 - accuracy: 0.8667 - val_loss: 0.3507 - val_accuracy: 0.8667\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.3412 - accuracy: 0.8667 - val_loss: 0.3504 - val_accuracy: 0.8667\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.3408 - accuracy: 0.8667 - val_loss: 0.3503 - val_accuracy: 0.8667\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.3405 - accuracy: 0.8667 - val_loss: 0.3503 - val_accuracy: 0.8667\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.3402 - accuracy: 0.8667 - val_loss: 0.3499 - val_accuracy: 0.8667\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 544us/sample - loss: 0.3398 - accuracy: 0.8667 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.3396 - accuracy: 0.8667 - val_loss: 0.3493 - val_accuracy: 0.8667\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.3393 - accuracy: 0.8667 - val_loss: 0.3491 - val_accuracy: 0.8667\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.3390 - accuracy: 0.8667 - val_loss: 0.3488 - val_accuracy: 0.8667\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 516us/sample - loss: 0.3387 - accuracy: 0.8667 - val_loss: 0.3485 - val_accuracy: 0.8667\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.3384 - accuracy: 0.8667 - val_loss: 0.3482 - val_accuracy: 0.8667\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.3381 - accuracy: 0.8667 - val_loss: 0.3478 - val_accuracy: 0.8667\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.3380 - accuracy: 0.8667 - val_loss: 0.3475 - val_accuracy: 0.8667\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.3375 - accuracy: 0.8667 - val_loss: 0.3472 - val_accuracy: 0.8667\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3373 - accuracy: 0.8667 - val_loss: 0.3470 - val_accuracy: 0.8667\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.3370 - accuracy: 0.8667 - val_loss: 0.3467 - val_accuracy: 0.8667\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.3367 - accuracy: 0.8667 - val_loss: 0.3464 - val_accuracy: 0.8667\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.3364 - accuracy: 0.8667 - val_loss: 0.3461 - val_accuracy: 0.8667\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.3361 - accuracy: 0.8667 - val_loss: 0.3460 - val_accuracy: 0.8667\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.3359 - accuracy: 0.8667 - val_loss: 0.3457 - val_accuracy: 0.8667\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.3356 - accuracy: 0.8667 - val_loss: 0.3454 - val_accuracy: 0.8667\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.3353 - accuracy: 0.8667 - val_loss: 0.3452 - val_accuracy: 0.8667\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3351 - accuracy: 0.8667 - val_loss: 0.3450 - val_accuracy: 0.8667\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.3347 - accuracy: 0.8667 - val_loss: 0.3447 - val_accuracy: 0.8667\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.3344 - accuracy: 0.8667 - val_loss: 0.3444 - val_accuracy: 0.8667\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.3341 - accuracy: 0.8667 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3339 - accuracy: 0.8667 - val_loss: 0.3440 - val_accuracy: 0.8667\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.3336 - accuracy: 0.8667 - val_loss: 0.3437 - val_accuracy: 0.8667\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3333 - accuracy: 0.8667 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.3331 - accuracy: 0.8667 - val_loss: 0.3431 - val_accuracy: 0.8667\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 501us/sample - loss: 0.3328 - accuracy: 0.8667 - val_loss: 0.3429 - val_accuracy: 0.8667\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 652us/sample - loss: 0.3325 - accuracy: 0.8667 - val_loss: 0.3428 - val_accuracy: 0.8667\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.3323 - accuracy: 0.8667 - val_loss: 0.3425 - val_accuracy: 0.8667\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 367us/sample - loss: 0.3319 - accuracy: 0.8667 - val_loss: 0.3421 - val_accuracy: 0.8667\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.3317 - accuracy: 0.8667 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.3314 - accuracy: 0.8667 - val_loss: 0.3418 - val_accuracy: 0.8667\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.3312 - accuracy: 0.8667 - val_loss: 0.3413 - val_accuracy: 0.8667\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.3309 - accuracy: 0.8667 - val_loss: 0.3412 - val_accuracy: 0.8667\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 225us/sample - loss: 0.3306 - accuracy: 0.8667 - val_loss: 0.3410 - val_accuracy: 0.8667\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.3303 - accuracy: 0.8667 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.3301 - accuracy: 0.8667 - val_loss: 0.3405 - val_accuracy: 0.8667\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.3298 - accuracy: 0.8667 - val_loss: 0.3402 - val_accuracy: 0.8667\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.3296 - accuracy: 0.8667 - val_loss: 0.3398 - val_accuracy: 0.8667\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.3293 - accuracy: 0.8667 - val_loss: 0.3397 - val_accuracy: 0.8667\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.3290 - accuracy: 0.8667 - val_loss: 0.3395 - val_accuracy: 0.8667\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3287 - accuracy: 0.8667 - val_loss: 0.3394 - val_accuracy: 0.8667\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 249us/sample - loss: 0.3285 - accuracy: 0.8667 - val_loss: 0.3391 - val_accuracy: 0.8667\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3282 - accuracy: 0.8667 - val_loss: 0.3389 - val_accuracy: 0.8667\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 209us/sample - loss: 0.3279 - accuracy: 0.8667 - val_loss: 0.3387 - val_accuracy: 0.8667\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.3278 - accuracy: 0.8667 - val_loss: 0.3384 - val_accuracy: 0.8667\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.3275 - accuracy: 0.8667 - val_loss: 0.3380 - val_accuracy: 0.8667\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 476us/sample - loss: 0.3273 - accuracy: 0.8667 - val_loss: 0.3379 - val_accuracy: 0.8667\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.3270 - accuracy: 0.8667 - val_loss: 0.3377 - val_accuracy: 0.8667\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3268 - accuracy: 0.8667 - val_loss: 0.3375 - val_accuracy: 0.8667\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.3264 - accuracy: 0.8667 - val_loss: 0.3373 - val_accuracy: 0.8667\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.3262 - accuracy: 0.8667 - val_loss: 0.3372 - val_accuracy: 0.8667\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.3260 - accuracy: 0.8667 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.3257 - accuracy: 0.8667 - val_loss: 0.3369 - val_accuracy: 0.8667\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.3254 - accuracy: 0.8667 - val_loss: 0.3367 - val_accuracy: 0.8667\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.3251 - accuracy: 0.8667 - val_loss: 0.3365 - val_accuracy: 0.8667\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.3249 - accuracy: 0.8667 - val_loss: 0.3361 - val_accuracy: 0.8667\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3246 - accuracy: 0.8667 - val_loss: 0.3360 - val_accuracy: 0.8667\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.3244 - accuracy: 0.8667 - val_loss: 0.3359 - val_accuracy: 0.8667\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3242 - accuracy: 0.8667 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.3239 - accuracy: 0.8667 - val_loss: 0.3355 - val_accuracy: 0.8667\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.3236 - accuracy: 0.8667 - val_loss: 0.3351 - val_accuracy: 0.8667\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.3234 - accuracy: 0.8667 - val_loss: 0.3348 - val_accuracy: 0.8667\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.3231 - accuracy: 0.8667 - val_loss: 0.3346 - val_accuracy: 0.8667\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 548us/sample - loss: 0.3229 - accuracy: 0.8667 - val_loss: 0.3344 - val_accuracy: 0.8667\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 527us/sample - loss: 0.3226 - accuracy: 0.8667 - val_loss: 0.3343 - val_accuracy: 0.8667\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.3224 - accuracy: 0.8667 - val_loss: 0.3341 - val_accuracy: 0.8667\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.3221 - accuracy: 0.8667 - val_loss: 0.3338 - val_accuracy: 0.8667\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3219 - accuracy: 0.8667 - val_loss: 0.3335 - val_accuracy: 0.8667\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.3216 - accuracy: 0.8667 - val_loss: 0.3333 - val_accuracy: 0.8667\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.3214 - accuracy: 0.8667 - val_loss: 0.3330 - val_accuracy: 0.8667\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.3211 - accuracy: 0.8667 - val_loss: 0.3329 - val_accuracy: 0.8667\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.3208 - accuracy: 0.8667 - val_loss: 0.3326 - val_accuracy: 0.8667\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.3206 - accuracy: 0.8667 - val_loss: 0.3323 - val_accuracy: 0.8800\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.3204 - accuracy: 0.8667 - val_loss: 0.3321 - val_accuracy: 0.8667\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.3201 - accuracy: 0.8667 - val_loss: 0.3320 - val_accuracy: 0.8667\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.3199 - accuracy: 0.8667 - val_loss: 0.3317 - val_accuracy: 0.8800\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.3196 - accuracy: 0.8667 - val_loss: 0.3314 - val_accuracy: 0.8800\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.3194 - accuracy: 0.8667 - val_loss: 0.3312 - val_accuracy: 0.8800\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3193 - accuracy: 0.8667 - val_loss: 0.3309 - val_accuracy: 0.8800\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.3189 - accuracy: 0.8667 - val_loss: 0.3307 - val_accuracy: 0.8800\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.3187 - accuracy: 0.8667 - val_loss: 0.3305 - val_accuracy: 0.8800\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.3185 - accuracy: 0.8667 - val_loss: 0.3303 - val_accuracy: 0.8800\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.3183 - accuracy: 0.8667 - val_loss: 0.3302 - val_accuracy: 0.8800\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.3180 - accuracy: 0.8667 - val_loss: 0.3299 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 484us/sample - loss: 0.3179 - accuracy: 0.8667 - val_loss: 0.3298 - val_accuracy: 0.8800\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.3176 - accuracy: 0.8667 - val_loss: 0.3295 - val_accuracy: 0.8800\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 469us/sample - loss: 0.3173 - accuracy: 0.8667 - val_loss: 0.3293 - val_accuracy: 0.8800\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.3171 - accuracy: 0.8667 - val_loss: 0.3291 - val_accuracy: 0.8800\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.3168 - accuracy: 0.8667 - val_loss: 0.3289 - val_accuracy: 0.8800\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.3166 - accuracy: 0.8667 - val_loss: 0.3287 - val_accuracy: 0.8800\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.3164 - accuracy: 0.8667 - val_loss: 0.3285 - val_accuracy: 0.8800\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.3161 - accuracy: 0.8667 - val_loss: 0.3283 - val_accuracy: 0.8800\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.3161 - accuracy: 0.8667 - val_loss: 0.3282 - val_accuracy: 0.8800\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3158 - accuracy: 0.8667 - val_loss: 0.3282 - val_accuracy: 0.8800\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.3154 - accuracy: 0.8667 - val_loss: 0.3280 - val_accuracy: 0.8800\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.3152 - accuracy: 0.8667 - val_loss: 0.3279 - val_accuracy: 0.8800\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3150 - accuracy: 0.8667 - val_loss: 0.3276 - val_accuracy: 0.8800\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.3149 - accuracy: 0.8667 - val_loss: 0.3273 - val_accuracy: 0.8800\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3145 - accuracy: 0.8667 - val_loss: 0.3270 - val_accuracy: 0.8800\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.3143 - accuracy: 0.8667 - val_loss: 0.3269 - val_accuracy: 0.8800\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.3140 - accuracy: 0.8667 - val_loss: 0.3267 - val_accuracy: 0.8800\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.3138 - accuracy: 0.8667 - val_loss: 0.3265 - val_accuracy: 0.8800\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.3136 - accuracy: 0.8667 - val_loss: 0.3263 - val_accuracy: 0.8800\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.3133 - accuracy: 0.8667 - val_loss: 0.3259 - val_accuracy: 0.8800\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.3131 - accuracy: 0.8667 - val_loss: 0.3256 - val_accuracy: 0.8800\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.3128 - accuracy: 0.8667 - val_loss: 0.3254 - val_accuracy: 0.8800\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.3126 - accuracy: 0.8667 - val_loss: 0.3252 - val_accuracy: 0.8800\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.3124 - accuracy: 0.8667 - val_loss: 0.3250 - val_accuracy: 0.8800\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3122 - accuracy: 0.8667 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.3120 - accuracy: 0.8667 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.3118 - accuracy: 0.8667 - val_loss: 0.3246 - val_accuracy: 0.8800\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.3115 - accuracy: 0.8667 - val_loss: 0.3245 - val_accuracy: 0.8800\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.3113 - accuracy: 0.8667 - val_loss: 0.3243 - val_accuracy: 0.8800\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3110 - accuracy: 0.8667 - val_loss: 0.3243 - val_accuracy: 0.8800\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.3109 - accuracy: 0.8667 - val_loss: 0.3241 - val_accuracy: 0.8800\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.3105 - accuracy: 0.8667 - val_loss: 0.3239 - val_accuracy: 0.8800\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 496us/sample - loss: 0.3103 - accuracy: 0.8667 - val_loss: 0.3238 - val_accuracy: 0.8800\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.3101 - accuracy: 0.8667 - val_loss: 0.3237 - val_accuracy: 0.8800\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.3100 - accuracy: 0.8667 - val_loss: 0.3235 - val_accuracy: 0.8800\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.3097 - accuracy: 0.8667 - val_loss: 0.3232 - val_accuracy: 0.8800\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.3095 - accuracy: 0.8667 - val_loss: 0.3231 - val_accuracy: 0.8800\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.3092 - accuracy: 0.8667 - val_loss: 0.3230 - val_accuracy: 0.8800\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.3091 - accuracy: 0.8667 - val_loss: 0.3229 - val_accuracy: 0.8667\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.3088 - accuracy: 0.8667 - val_loss: 0.3228 - val_accuracy: 0.8667\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.3086 - accuracy: 0.8667 - val_loss: 0.3225 - val_accuracy: 0.8667\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.3084 - accuracy: 0.8667 - val_loss: 0.3223 - val_accuracy: 0.8800\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3082 - accuracy: 0.8667 - val_loss: 0.3222 - val_accuracy: 0.8667\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.3079 - accuracy: 0.8800 - val_loss: 0.3220 - val_accuracy: 0.8667\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.3077 - accuracy: 0.8800 - val_loss: 0.3217 - val_accuracy: 0.8800\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3074 - accuracy: 0.8800 - val_loss: 0.3214 - val_accuracy: 0.8800\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.3072 - accuracy: 0.8800 - val_loss: 0.3212 - val_accuracy: 0.8800\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.3071 - accuracy: 0.8800 - val_loss: 0.3209 - val_accuracy: 0.8800\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.3068 - accuracy: 0.8800 - val_loss: 0.3208 - val_accuracy: 0.8800\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.3066 - accuracy: 0.8800 - val_loss: 0.3205 - val_accuracy: 0.8800\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.3065 - accuracy: 0.8800 - val_loss: 0.3202 - val_accuracy: 0.8800\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.3061 - accuracy: 0.8800 - val_loss: 0.3200 - val_accuracy: 0.8800\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.3060 - accuracy: 0.8800 - val_loss: 0.3197 - val_accuracy: 0.8800\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 502us/sample - loss: 0.3057 - accuracy: 0.8800 - val_loss: 0.3195 - val_accuracy: 0.8800\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.3055 - accuracy: 0.8800 - val_loss: 0.3193 - val_accuracy: 0.8800\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.3053 - accuracy: 0.8800 - val_loss: 0.3191 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.3051 - accuracy: 0.8800 - val_loss: 0.3189 - val_accuracy: 0.8800\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.3049 - accuracy: 0.8800 - val_loss: 0.3187 - val_accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "multinomial_log_reg_model = Sequential()\n",
    "\n",
    "\n",
    "# 3 klasser kräver 3 output neuroner, input_dim är fortfarande 4\n",
    "multinomial_log_reg_model.add(Dense(n_classes, input_dim=n_features, activation='softmax')) #activation är förändrad\n",
    "\n",
    "multinomial_log_reg_model.compile(optimizer='sgd',\n",
    "             loss='categorical_crossentropy', #Loss-funktionen är förändrad\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "multinomial_log_reg_model.summary()\n",
    "\n",
    "history = multinomial_log_reg_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " ##### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.88\n",
      "accuracy, test:  0.88\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcXHW95//Xp7d0d7bOzhJCQghLAAmhWQKoKIuIjvi7IpuMgGiGO6KMqPeGGQcR9Q7O6FW2KwaNonJBhKsEbzAGEBcWSQJhSwxZ2JosJL1kq+50ddXn98c51amu9FLdXaerq+r9fDzqUXW2qu9pQn3q813N3REREelNWb4LICIiw5+ChYiI9EnBQkRE+qRgISIifVKwEBGRPilYiIhInxQspOSZ2XQzczOryOLcK83sr0NRLpHhRMFCCoqZvWFm7WY2MWP/qvALf3p+SiZS3BQspBC9Dlya2jCz44Ca/BVneMgmMxIZKAULKUS/AD6dtn0F8PP0E8xsrJn93My2mdmbZvY1MysLj5Wb2XfNbLuZbQQ+0s21PzGzzWb2jpl9y8zKsymYmf3azLaY2Q4z+7OZHZN2rMbMvheWZ4eZ/dXMasJjZ5jZ02bWYmZvm9mV4f4nzeyzae/RpRoszKY+b2brgHXhvlvD99hpZivN7L1p55eb2f80sw1mtis8foiZ3Wlm38u4l0fM7H9kc99S/BQspBA9C4wxs6PDL/GLgV9mnHM7MBY4DHg/QXC5Kjz2OeCjwAlAPXBhxrX3AB3A4eE55wKfJTuPArOAycDzwL1px74LnAicBowH/glImtm08LrbgUnAHGBVlp8H8HHgFGB2uL08fI/xwL8Dvzaz6vDY9QRZ2fnAGOAzQCy850vTAupE4Czgvn6UQ4qZu+uhR8E8gDeAs4GvAf8HOA9YBlQADkwHyoG9wOy06/4b8GT4+gngmrRj54bXVgBTwmtr0o5fCvwxfH0l8Ncsy1oXvu9Ygh9mrcDx3Zx3A/CbHt7jSeCzadtdPj98/w/2UY7m1OcCa4ELejhvDXBO+PpaYEm+/3vrMXwequOUQvUL4M/ADDKqoICJQBXwZtq+N4GDw9cHAW9nHEs5FKgENptZal9ZxvndCrOcbwOfJMgQkmnlGQFUAxu6ufSQHvZnq0vZzOzLBJnQQQTBZExYhr4+6x7gcoLgezlw6yDKJEVG1VBSkNz9TYKG7vOB/8g4vB2IE3zxp0wD3glfbyb40kw/lvI2QWYx0d3rwscYdz+Gvl0GXECQ+YwlyHIALCxTGzCzm+ve7mE/wB6gNm37gG7O6Zw6Omyf+GfgImCcu9cBO8Iy9PVZvwQuMLPjgaOB3/ZwnpQgBQspZFcTVMHsSd/p7gngAeDbZjbazA4lqKtPtWs8AHzRzKaa2ThgQdq1m4E/AN8zszFmVmZmM83s/VmUZzRBoGkk+IL/l7T3TQKLgH81s4PChuZ5ZjaCoF3jbDO7yMwqzGyCmc0JL10F/IOZ1ZrZ4eE991WGDmAbUGFmNxJkFik/Br5pZrMs8B4zmxCWsYGgveMXwEPu3prFPUuJULCQguXuG9x9RQ+Hv0Dwq3wj8FeCht5F4bG7gaXAiwSN0JmZyacJqrFWE9T3PwgcmEWRfk5QpfVOeO2zGce/ArxM8IXcBHwHKHP3twgypC+H+1cBx4fXfB9oB7YSVBPdS++WEjSWvxaWpY2u1VT/ShAs/wDsBH5C127H9wDHEQQMkU7mrsWPRCRgZu8jyMCmh9mQCKDMQkRCZlYJXAf8WIFCMilYiAhmdjTQQlDd9oM8F0eGIVVDiYhIn5RZiIhIn4pmUN7EiRN9+vTp+S6GiEhBWbly5XZ3n9TXeUUTLKZPn86KFT31ohQRke6Y2Zt9n6VqKBERyYKChYiI9EnBQkRE+lQ0bRbdicfjNDQ00NbWlu+iDJnq6mqmTp1KZWVlvosiIkWkqINFQ0MDo0ePZvr06aRNN1203J3GxkYaGhqYMWNGvosjIkWkqKuh2tramDBhQkkECgAzY8KECSWVSYnI0CjqYAGUTKBIKbX7FZGhUdTVUCIiA/bWs1A1EratDR5DxQyO+ySMGEP7G8/w8FsjOGTzst4vGXswp3zyy5EWS8EiQo2NjZx11lkAbNmyhfLyciZNCgZKPvfcc1RVVfX5HldddRULFizgyCOPjLSsIpJh0YeCZysHT7BvscGoOezeCu+spGrLy0xIzOHU8lUkvefPX7flSILlUKKjYBGhCRMmsGrVKgBuuukmRo0axVe+8pUu56QWQy8r675G8Kc//Wnk5RSRXngCzrsFTv3Hofm8O0+FPdth+zoADrPNtB54MjX/refsYih+ShZ9m8VwtH79eo499liuueYa5s6dy+bNm5k/fz719fUcc8wx3HzzzZ3nnnHGGaxatYqOjg7q6upYsGABxx9/PPPmzePdd9/N412IFLHM2bhrxg/dZ9eOh9bmzs3pZVspHzlh6D6/ByWTWXzjkVdZvWlnTt9z9kFj+Pp/OWZA165evZqf/vSn3HXXXQDccsstjB8/no6ODj7wgQ9w4YUXMnv27C7X7Nixg/e///3ccsstXH/99SxatIgFCxZ09/YiMhjtu7tu1w5hsKgZB40buuyqGJX/YKHMIk9mzpzJSSed1Ll93333MXfuXObOncuaNWtYvXr1ftfU1NTw4Q9/GIATTzyRN954Y6iKK1JaYk1dt4c8s+j6+WVDGax6UDKZxUAzgKiMHDmy8/W6deu49dZbee6556irq+Pyyy/vdqxEeoN4eXk5HR0dQ1JWkZLTmhks6obus2vGBcHKyrruyzNlFsPAzp07GT16NGPGjGHz5s0sXbo030USKW2ZmcWQVkONh2QcEnvz8/k9KJnMYjibO3cus2fP5thjj+Wwww7j9NNPz3eRpFjE2+Dtv4VdP3Pn9e172L23eDPbsVufY1ra9l/ebgfbNiSfPWVXJUdk7hzKarAeFM0a3PX19Z65+NGaNWs4+uij81Si/CnV+5ZuPHUrLLsx36UoaHt8BMfsHbou7KeXvcy9Vf+n687P/REOnhvJ55nZSnev7+s8ZRYixWznJqgaDZc/mLO3XLt1F//zP17minnTOWLKqJy973ATrx6PJeMkqsby4MgDhu6D/VRWN52GJTtor53CEWPi1Bx0/NB9fg8ULESKWawJRk6Aaafm7C3fiW1lpbfztTmncdS0/De8FqUZ78t3CfajBm6RYtbalPP67uY9cQDG1fY9XY0UDwULkWIWa8p5T5rmWDugYFFqFCxEilkEmUVLLE6Zwehq1WKXEgULkWIWa44ks6irraKsTGunlBL9NIhQLqYoB1i0aBHnn38+BxwwhD0ySpk7dAzP1QbbO5JUllvnIleJpBNPJLs/OdlB9d4dxEfUkYjnbpxF4+526mq1xnupiTRYmNl5wK1AOfBjd78l4/g04B6gLjxngbsvMbPpwBogteLIs+5+TZRljUI2U5RnY9GiRcydO1fBYqj87kuwcnhODZ/586I8fPTmG49v5Zd/+H1Oy3HSdPWCKjWRBQszKwfuBM4BGoDlZrbY3dNnyPsa8IC7/9DMZgNLgOnhsQ3uPieq8uXbPffcw5133kl7ezunnXYad9xxB8lkkquuuopVq1bh7syfP58pU6awatUqLr74YmpqavqVkcgAbX4RJsyCEz6V75J0uuXRv3fZXvDho9i9t4M7nljPEVNGcWBdbbfXJa2CGQd8jH+uHJPT8pw2M/+zoMrQijKzOBlY7+4bAczsfuACID1YOJD6VzwW2BRZaR5dAFtezu17HnAcfPiWvs/L8Morr/Cb3/yGp59+moqKCubPn8/999/PzJkz2b59Oy+/HJSzpaWFuro6br/9du644w7mzCna2Dm8tDbB1JPgjC/luySd7vrdf3bZXnDGR9i8dRd3Lfszt7//BOYdf1CP12ryGMmFKBu4DwbeTttuCPeluwm43MwaCLKKL6Qdm2FmL5jZn8zsvd19gJnNN7MVZrZi27ahmbclFx577DGWL19OfX09c+bM4U9/+hMbNmzg8MMPZ+3atVx33XUsXbqUsWPH5ruopSnWPCzm4ulNe0eS5pjGO8jQiTKz6K6rROZEVJcCP3P375nZPOAXZnYssBmY5u6NZnYi8FszO8bdu6xe5O4LgYUQzA3Va2kGkAFExd35zGc+wze/+c39jr300ks8+uij3HbbbTz00EMsXLgwDyUsYYkO2LtjWMzy2ZuWWHvneAc1NstQiDKzaAAOSdueyv7VTFcDDwC4+zNANTDR3fe6e2O4fyWwAfafiLFQnX322TzwwANs374dCHpNvfXWW2zbtg1355Of/CTf+MY3eP755wEYPXo0u3btymeRS0dqOcthnlk0x+K0pAbHjVRmIdGLMrNYDswysxnAO8AlwGUZ57wFnAX8zMyOJggW28xsEtDk7gkzOwyYBWyMsKxD6rjjjuPrX/86Z599NslkksrKSu666y7Ky8u5+uqrcXfMjO985zsAXHXVVXz2s59VA/dQSC16MwwWm+lNc6y9sxqqrkaZhUQvsmDh7h1mdi2wlKB33yJ3f9XMbgZWuPti4MvA3Wb2JYIqqivd3c3sfcDNZtYBJIBr3L2ph48qCDfddFOX7csuu4zLLsuMnfDCCy/st++iiy7ioosuiqpoki616E3t8AkWezv2HyORqoaqKi+jtqqvzrMigxfpOAt3X0LQcJ2+78a016vpprOGuz8EPBRl2aSEJZPw4JXQ/Ob+x/aGzWJ5qIZq2tPOf793JXv2dg0OHcn9m+O+9Z9raG1PUFdb2TlATyRKGsEtpSfWCKsfhsnHwNipXY+NmgJTT4bJs4e8WK9u2sGzG5uoP3QcYzKqlg4dX8sBY6v50DEH8MhLm9iyIxhhPu8wjXeQoVH0wSJV/18qimXlw0il2iXeez0cd2F+y5Im1QZxyyeO4/DJo3s8b54GxEkeFPVEgtXV1TQ2NpbMF6i709jYSHV1db6LMrx1tksMrx5PLZ1dYdWBQYafos4spk6dSkNDA4U0YG+wqqurmTp1at8nlrLOHk/DK1ikFhVS7yYZjoo6WFRWVjJjxox8F0OGm2GaWTTH2hldXUFFeVEn/FKg9K9SSs8wzSxaYu2aukOGLQULKT2xJiivgqqR+S5JF82xOOM0dYcMU0VdDSUFakcDPPtDSOZuwZ4uXv9zkFXkoJdcMun825PradzTPuj3WrN5J0cfmNupxEVyRcFChp+Xfw3P3AEjxtD9fJQ5cMSHcvI2G7fv5rt/eI2aynIqygdf1lMOG15VYyIpChYy/MQaoaIabni773PzrCnswbTw0yfy3lmT8lwakeiozUKGnwJYTyIlNU24Gqal2ClYyPDT2jTsurX2pEVrSkiJULCQ4SfWNOynCE/RanVSKhQsZPgpoMxC04RLqVCwkOGngDKLlj1xxmqacCkB6g1VYv6+ZSevb9szoGur2rYxrvH5HJdof3Nam3l9dxWvvbw58s8arNfe3aWBdFISFCxKzKd/8hzv7to7oGtvq7yds8qfyXGJunf3K0nufzH6wJQLZx01Od9FEImcgkUJSSSdbbv38qlTpvFf5x3a7+unPXwrrR3vYcuZ342gdPt4WQVX1s3kSiuMWtJp42vzXQSRyClYlJCdrXHcYeakURx1wACmlejYCRNmMuOYU3JfOBEZ1grjp5vkROcAspEDrGMvoF5KIpJbChYlJDUmYEArsbmHvZQULERKkYJFCWkZzNQU7bshGVdmIVKiIg0WZnaema01s/VmtqCb49PM7I9m9oKZvWRm56cduyG8bq2Z5WaK0BK3b7TxAKqhYsNzwSARGRqRNXCbWTlwJ3AO0AAsN7PF7r467bSvAQ+4+w/NbDawBJgevr4EOAY4CHjMzI5w94gWOChOLbF24gkPNpIJmrc2MJEdjPMW2N3PsRZNG4JnZRYiJSnK3lAnA+vdfSOAmd0PXACkBwsHUt1yxgKbwtcXAPe7+17gdTNbH77f0HTyLwK/f2UL1/xyZef2bZW387nyZ/hcNXDHIN54pMYUiJSiKIPFwUD6ggQNQGafy5uAP5jZF4CRwNlp1z6bce3BmR9gZvOB+QDTpk3LSaGLxYZtuwH4xseOoazMOOOpRpo4kuajP8XMSQNcTnTEGDj4xByWUkQKRZTBorvJcjxj+1LgZ+7+PTObB/zCzI7N8lrcfSGwEKC+vn6/46WseU87NZXlXHHa9GDHU7th5gcZf/51eS2XiBSmKINFA3BI2vZU9lUzpVwNnAfg7s+YWTUwMctrpRfNsXjXhuzWJqgtjMn5RGT4ibI31HJglpnNMLMqggbrxRnnvAWcBWBmRwPVwLbwvEvMbISZzQBmAc9FWNai0xJr3zeeoj0GHW3qySQiAxZZZuHuHWZ2LbAUKAcWufurZnYzsMLdFwNfBu42sy8RVDNd6e4OvGpmDxA0hncAn1dPqP5pjrXvG6ndGnZ7VU8mERmgSOeGcvclBN1h0/fdmPZ6NXB6D9d+G/h2lOUrZi2xOAfW1QQbGiMhIoOkEdxFqjnWTl1NRmZRIAsKicjwo1ln82XZ12H9Y3DRz2HCzOyva9sBv/gHaG3e71BrPEHjnnbc4aFEkrq1lXBbFbSHA/BUDSUiA6RgkS9P/SB4fuf5/gWL7evgnRUw/b0wakqXQ29u2cXall0cXFeDGUycPAqqw+yidgJMPDJHhReRUqNgkW+pKqJspdofzvo6HHJSl0P//vArPNy4iRe/fG6OCiciElCbRT4k0zp2xfoZLHrp2bTf2AoRkRxRsMiHth37Xg80s+imsbrL2AoRkRxSsMiH9GxiIJmFlUF13X6HmmPtyixEJBIKFvmQnk0MJLOoroOy/f/TNe+JD2xhIxGRPihY5EMqm6idOLDMoocusKqGEpGoqDdUrm15BTa/CCd8KthubYYnvg3x1n3nNL8RPE84HLa+Cr/9PFSMgPf/M4yest9bdnrqVnjrbzB2aueu17bu4id/eZ2EO3vaE6qGEpFIKFjk2l3h7CWpYPHm07D87mDRoPK0X/1TT4I5l8Gf/18wOG/3lnDfpd2/b8deWHYjjBgLs/Z1jX3o+QZ+teJtDhpbzbTxtdRP18A7Eck9BYuotMegqnZfRnHlf8KkI/Y/78QrYNcW+N6REI/1/H6p6qpzboL6z3Tubt7TzpQxI3j6hrNyV3YRkQxqs4hKquE6FSwqa3o+N3Wso63v98uYDDAYW6F2ChGJloJFrpWPCJ5j/QgWFeGxbDKLjMbtoFFb7RQiEi0Fi1wbMSp4TmUCHVkEi/LKYOxEXJmFiAxPCha5VhUGi8zMoqKXYGEGlbVde0xl6jWzULAQkWgpWORaVUZmEW8Nqqa6GUTXRUX1viykO92sSeHutGg+KBEZAgoWuVY1Mnh+6QFwD4JFZXXf13WXWbS8DS/8EjY8EWQWFTVdqrNeeWcnHUlXm4WIRE5dZ6Py9t+gcUOQLVTW9n1+ZfX+weKxm+CVBwGDoz6yXxXUt5esBmDGxFG5KbOISA+UWeRaon3f691bgwBQkU1mUbN/sNi9NXzhsP21/Rq3d7R2MOeQOs6Z3cuobxGRHFCwyLVEHOqmBa9bm8JqqCwyi4qa/dssWpv3jfpuXA+1Xaclb4m1c/hkZRUiEr1Ig4WZnWdma81svZkt6Ob4981sVfh4zcxa0o4l0o4tjrKcOZXYC6MPDF7HmvrRZtFNZhFrCuaPAvBkN91mNSW5iAyNyNoszKwcuBM4B2gAlpvZYndfnTrH3b+Udv4XgBPS3qLV3edEVb7IJNr3rY3d2hSMys6qzaIG9mzvuq+1CaaeCO+Gf7K0Nou2eIK2eFLdZkVkSPSZWZjZtWa2/7JsfTsZWO/uG929HbgfuKCX8y8F7hvA5wwviThUjw26y6Yyi2zbLNKrodpjQaBJZRbQJbNojgVtIxqQJyJDIZtqqAMIsoIHwmoly/K9DwbeTttuCPftx8wOBWYAT6TtrjazFWb2rJl9PMvPzL+OvcF047XjgzaHeGvvo7dTKjKqoVLjKuoO3bcvLbNo3hMHUDWUiAyJPoOFu38NmAX8BLgSWGdm/2JmM/u4tLug4j2cewnwoLsn0vZNc/d64DLgB919npnNDwPKim3btvV1K0MjEQ+yiprxsKMB9u7KLlhUVkP7bmjcQEvDGra8thyArYl9DdjbEiN5ffseXt++h7VbdwKoGkpEhkRWbRbu7ma2BdgCdADjgAfNbJm7/1MPlzUAh6RtTwU29XDuJcDnMz5zU/i80cyeJGjP2JBxzkJgIUB9fX1PgWhoJdqDuZ5GTwkG00FQLdWX6jpo2wG3zyV9de1//G0Dd1XVMdlauH7JZv7yuye7XDZ5zIicFV1EpCd9Bgsz+yJwBbAd+DHwVXePm1kZsA7oKVgsB2aZ2QzgHYKAcFk3738kQfB5Jm3fOCDm7nvNbCJwOvB/+3NjeeEeBosq+Mi/QsNywOCwM/u+dt7nYfLRbG7Zwy2P/p33HTGJgydP4tMHnMnLu+YyavcbXHjAmXyibN9/srG1lcycpK6zIhK9bDKLicA/uPub6TvdPWlmH+3pInfvMLNrgaVAObDI3V81s5uBFe6e6g57KXC/u6dnBkcDPzKzJEFV2S3pvaiGrWQH4FBRBeNnBI9s1Y6H4y7krY2NPJycyCdPP4VTZ00MDx4CvD+CAouIZCebYLEEaEptmNloYLa7/83d1/R2obsvCa9P33djxvZN3Vz3NHBcFmUbXlKjt8sH3o7QHAsarjXfk4gMJ9n0hvohsDtte0+4TzJ1BouBtyO0pLrEjlTDtYgMH9kEC0uvInL3JJqAsHsdqWAx8KwglVmoS6yIDCfZBIuNZvZFM6sMH9cBG6MuWEHKQTVUS6ydqooyairLc1QoEZHByyZYXAOcRtCjqQE4BZgfZaEKVipYVAy8Gio131P2Yx9FRKLXZ3WSu79L0O1V+pIKFmUDq6V7besuHljRwBFT1B1WRIaXbMZZVANXA8cAnZMcuftnIixXYWoLRlVTPWZAl7/csAOAC0+cmqsSiYjkRDbVUL8gmB/qQ8CfCEZi74qyUAWrc53s8b2f14PU5IAX10/LVYlERHIim2BxuLv/b2CPu98DfIRCHAMxFGJhsKgdWLBoicUpMxhdrc5mIjK8ZBMs4uFzi5kdC4wFpkdWokLWmVkMZEb3ILOoq62irEyN2yIyvGTzE3ZhOFfT14DFwCjgf0daqkIVawoat0cMrM2iJRbXyG0RGZZ6DRbhZIE73b0Z+DNw2JCUqlC1NgVZxQC7vQbdZjVyW0SGn16rocLR2tcOUVkKX6xpwI3bEIze1shtERmOsqmGWmZmXwF+RTAvFADu3tTzJSWo6XVYsximzcv6kr9tbOSeZ94gNZnKG9v3cMxBA6vCEhGJUjbBIjWeIn1xIkdVUl29tjR4PuzMrC/59coGlq3eyoyJIwGYNr6WDx41OfdlExEZpGxGcPdjUYYS1toEGLzvq1lf0hJr5/DJo3n0uvdGVy4RkRzIZgT3p7vb7+4/z31xClisKVg+tSz7CQDVRiEihSKbaqiT0l5XA2cBzwMKFulam/o9GK851s7RB6iNQkSGv2yqob6Qvm1mYwmmAJF0A+gJpXEVIlIoshnBnSkGzMp1QQpePzOLZNJp0bgKESkQ2bRZPELQ+wmC4DIbeCDKQhWkWDNMOjrr03e1dZB0rbUtIoUhmzaL76a97gDedPeGiMpTeJIJePE+2LOtX5lFaoZZZRYiUgiyCRZvAZvdvQ3AzGrMbLq7vxFpyQrFphfg4XAIyqSjsr5sZ1swP+OYGmUWIjL8ZdNm8WsgmbadCPf1yczOM7O1ZrbezBZ0c/z7ZrYqfLxmZi1px64ws3Xh44psPi8v9oYLHl3+H3Bi9sWMJ4I/6YiKgTQbiYgMrWwyiwp3b09tuHu7mfVZd2Jm5cCdwDkEa3cvN7PF7r467b2+lHb+F4ATwtfjga8D9QTtJSvDa5uzu60hFG8Nnmsn9OuyvR1BsKgsV7AQkeEvm2+qbWb2sdSGmV0AbM/iupOB9e6+MQw29wMX9HL+pcB94esPAcvcvSkMEMuA87L4zKGXChaVNf27LBH0Gaiq0NoVIjL8ZZNZXAPca2Z3hNsNQLejujMcDLydtt0AnNLdiWZ2KDADeKKXaw/u5rr5wHyAadPytBTpQINFmFlUlWc/4ltEJF+yGZS3ATjVzEYB5u7Zrr/d3U9m72YfwCXAg+6e6M+17r4QWAhQX1/f03tHq6MteK7oX7BoD9ssKpVZiEgB6LMaysz+xczq3H23u+8ys3Fm9q0s3rsBOCRteyqwqYdzL2FfFVR/r82veCx47nc1lNosRKRwZPNN9WF37+ylFLYhnJ/FdcuBWWY2I2wQv4RgWdYuzOxIYBzwTNrupcC5YWAaB5wb7ht+4mFm0c9g0d5ZDaVgISLDXzZtFuVmNsLd90IwzgIY0ddF7t5hZtcSfMmXA4vc/VUzuxlY4e6pwHEpcL+7e9q1TWb2TYKAA3DzsF1sKR6D8qp+zTYL+6qhqtR1VkQKQDbB4pfA42b203D7KuCebN7c3ZcASzL23ZixfVMP1y4CFmXzOXnV0dbv9grY18CtaigRKQTZNHD/XzN7CTiboOH598ChUResYMRj/a6Cgn1dZyvL1cAtIsNftj9rtxCM4v4EwXoWayIrUaGJtw0oWKgaSkQKSY+ZhZkdQdAofSnQCPyKoOvsB4aobIVhgJlFqoG7skzBQkSGv96qof4O/AX4L+6+HsDMvtTL+aWpY2CZRTyRpKLMKCtTNZSIDH+9/az9BEH10x/N7G4zO4vuB8uVtvgAG7gTSVVBiUjB6PHbyt1/4+4XA0cBTwJfAqaY2Q/N7NwhKt/wN4hqKPWEEpFC0ee3lbvvcfd73f2jBCOpVwH7TTdesuKtUFnd78vaE65gISIFo1/fVuEssD9y9w9GVaCC07YDqsf2+7J4Iqm1LESkYOjbarBam6Am++VUU4JqKDUBiUhhULAYjPZY0BuqH2tvp8QTarMQkcKhb6vBaA2nq6oZ1+9L1RtKRAqJvq0GI5YKFv3PLPaqN5SIFBB9Ww1GKrMYYDWUpicsNKpMAAAQW0lEQVQXkUKhb6vBGERmEU+4qqFEpGDo22owBphZrNu6i5VvNqs3lIgUDAWLwYg1B8/9zCz+vG47AKcfPjHXJRIRiYSCxWC0NkHVKKio6tdlbfEEAJefqmVBRKQwKFgMRmxgA/L2xhOYoRHcIlIw9G01GK1NUNv/MRat8QTVFeWYqc1CRAqDgsVgDDCzaIsnqa7Un15ECoe+sQajtWlAYyxa4wlqKssjKJCISDQULAZjwJlFgmoFCxEpIL0tqzpoZnYecCtQDvzY3W/p5pyLgJsAB15098vC/Qng5fC0t9z9Y1GWNSvu8Pw9sPvdYLttR5+ZxeNrtvJWU4xPz5tOebiEqoKFiBSayIKFmZUDdwLnAA3AcjNb7O6r086ZBdwAnO7uzWY2Oe0tWt19TlTlG5AdDfDIdfu2rQwOOK7XS66+ZwUAxx9Sx9xpQWO42ixEpNBEmVmcDKx3940AZnY/cAGwOu2czwF3unszgLu/G2F5Bi8WDKbj4l/CkecHr8t6zhASSe983bynvfN1azxBTZUyCxEpHFH+vD0YeDttuyHcl+4I4Agze8rMng2rrVKqzWxFuP/j3X2Amc0Pz1mxbdu23Ja+O6m5oGonBkGil0ABsLM13vm6ObbvdVvYdVZEpFBEmVl0N4jAM7YrgFnAmQTre//FzI519xZgmrtvMrPDgCfM7GV339DlzdwXAgsB6uvrM98791rD6T2y7AHVHNuXTbTEumYW1cosRKSARJlZNACHpG1PBTZ1c87D7h5399eBtQTBA3ffFD5vBJ4EToiwrNnp5yyz6dlEeuDYG08qsxCRghJlsFgOzDKzGWZWBVwCLM4457fABwDMbCJBtdRGMxtnZiPS9p9O17aO/Ojnynjp2URmNVRNlRq4RaRwRFYN5e4dZnYtsJSg6+wid3/VzG4GVrj74vDYuWa2GkgAX3X3RjM7DfiRmSUJAtot6b2o8ibWBCPGQnl2f7ZUgKgqL9u/GkqZhYgUkEjHWbj7EmBJxr4b0147cH34SD/naaD3PqlRScThnZXBc6btr/VrLqhUgJgxcSRvNcV4ZkMjkMosFCxEpHBEGiwK0qp/h0e+2PPxQ8/I+q2aY+2UlxlHHDCaR17cxKV3P9t5bFxt/6Y1FxHJJwWLTDvfAQyuWEy3HbomHZX1WzXH4tTVVPKtjx/LZSdP69xfXmbMOaRu8GUVERkiChaZYk1QPRZmvG/Qb9USa6eutpKxNZXMmzkhB4UTEckPdcnJNMCZZLvTvCeu6iYRKQoKFpkGOJNsd5pj7dQpWIhIEVCwyJTDzKIlFmdcbWVO3ktEJJ8ULDLFmnOaWYwbqcxCRApfyTdwezJJItHRuV3e2oTXjCOZSHbuM7POtSiykUg67R1J9nYkqVNmISJFoOSDRfP2zYz/t9ld9v2/vzbyb396tHO7sty473OnUj+974zjZ0+9zk2PrObzH5gJaDyFiBSHkg8W1bWjeObQazq33SqYMOWjfLlqIgCxeIIfPrmBv2/ZlVWweOmdHQD8dV2w9kVdjTILESl8JR8sakeNZd5V3+my77S013s7gmCxo7Wb6T+6sSOcD2rj9j0A6g0lIkVBDdx9GFFRTm1VeZeV7nqTmop8V1vQDjJupDILESl8ChZZGFdb1WWK8d60ZJynNgsRKQYKFlmoq63sMsV4b5ozzlNvKBEpBgoWWQgyi76DRTLpXdo2aqvKGaF1K0SkCChYZCHILPquhtrZFifpcMCYagCqKvTnFZHioG+zLIyrreLt5hhX/vQ5du/t6PG8Hzy2DggWOwKoLNefV0SKg77NsvDR9xzI7APH8OTabby2dVeP5z29IRhbcf25R3D20VO4/pwjhqqIIiKRKvlxFtk45bAJ3PSxY/j//u3pXhu6m2NxLjnpEE6aPp6TshjAJyJSKJRZZCnVBbZ5T/dtF+4eLnakrrIiUnwULLLUGSx6yCz2tCeIJ1xTkotIUVKwyNLo6grKbP9BdympEd4ahCcixSjSYGFm55nZWjNbb2YLejjnIjNbbWavmtm/p+2/wszWhY8roixnNsrKjLpexlukgogG4YlIMYqsgdvMyoE7gXOABmC5mS1299Vp58wCbgBOd/dmM5sc7h8PfB2oBxxYGV7bHFV5s9HbeIuW1jCz0GJHIlKEoswsTgbWu/tGd28H7gcuyDjnc8CdqSDg7u+G+z8ELHP3pvDYMuC8CMualbqaSppj7Sx5eTO3PraOvR2JzmOpuaPUZiEixSjKrrMHA2+nbTcAp2SccwSAmT0FlAM3ufvve7j24MwPMLP5wHyAadOm5azgPRlXW8WmHW3893ufB+DkGeOZN3MCADvDaT7GVCtYiEjxiTKz6G4dUs/YrgBmAWcClwI/NrO6LK/F3Re6e72710+aNGmQxe1bXW1Vl6nK09sv2uJBllFdpbmgRKT4RBksGoBD0ranApu6Oedhd4+7++vAWoLgkc21Q25cbSVbdrZ1bqe3X6SCRU2lgoWIFJ8og8VyYJaZzTCzKuASYHHGOb8FPgBgZhMJqqU2AkuBc81snJmNA84N9+VVZuN1embRGk9QXmaaD0pEilJkbRbu3mFm1xJ8yZcDi9z9VTO7GVjh7ovZFxRWAwngq+7eCGBm3yQIOAA3u3tTVGXNVma32JYu1VBJZRUiUrQinRvK3ZcASzL23Zj22oHrw0fmtYuARVGWr78yB9ylr57XGk9QXamsQkSKk77d+iE9s6iuLMvILBJa6EhEipaCRT+kZxYzJo7qklm0xRPUqCeUiBQpBYt+SK2AB3Do+NqMrrNJVUOJSNHSehb9MG5kFU8t+CAVZcZtj6+j5Y20Nov2hBq4RaRoKVj008F1NUBQJdUSayeZdMrKjLaOBKNG6M8pIsVJ9SYDVFdbSdJhV1uwJndre4JqZRYiUqQULAYoczGkvR1JBQsRKVoKFgM0bmTQjTYVLII2C/05RaQ46dttgFJrbafmh2rrUDWUiBQvBYsBSq+GcndaYnH1hhKRoqVgMUCpRY6aY3G+v+w1AEaqN5SIFCl9uw3QmOpKzILJBF/buguAy06JfgEmEZF8UGYxQGVlxthwmdXmWJyTZ4xn4qgR+S6WiEgkFCwGYVxtFc2xODtica29LSJFTcFiEOpqK9kRi9Mca99v+nIRkWKiYDEIQWbRTkss3tmVVkSkGClYDEJdbSWbWlppTyRVDSUiRU3BYhBSbRap1yIixUrBYhDSs4nM9blFRIqJxlkMwnnHHsjarbupKi/j5Bnj810cEZHIKFgMwuGTR3H7pSfkuxgiIpFTNZSIiPQp0mBhZueZ2VozW29mC7o5fqWZbTOzVeHjs2nHEmn7F0dZThER6V1k1VBmVg7cCZwDNADLzWyxu6/OOPVX7n5tN2/R6u5zoiqfiIhkL8rM4mRgvbtvdPd24H7gggg/T0REIhJlsDgYeDttuyHcl+kTZvaSmT1oZoek7a82sxVm9qyZfby7DzCz+eE5K7Zt25bDoouISLoog4V1s88zth8Bprv7e4DHgHvSjk1z93rgMuAHZjZzvzdzX+ju9e5eP2nSpFyVW0REMkQZLBqA9ExhKrAp/QR3b3T3veHm3cCJacc2hc8bgScB9VEVEcmTKIPFcmCWmc0wsyrgEqBLryYzOzBt82PAmnD/ODMbEb6eCJwOZDaMi4jIEImsN5S7d5jZtcBSoBxY5O6vmtnNwAp3Xwx80cw+BnQATcCV4eVHAz8ysyRBQLulm15UXaxcuXK7mb05iCJPBLYP4vpCpHsuDbrn0jDQez40m5PMPbMZoTSZ2YqwjaRk6J5Lg+65NER9zxrBLSIifVKwEBGRPilY7LMw3wXIA91zadA9l4ZI71ltFiIi0idlFiIi0icFCxER6VPJB4u+plEvVGa2yMzeNbNX0vaNN7NlZrYufB4X7jczuy38G7xkZnPzV/KBM7NDzOyPZrbGzF41s+vC/UV732ZWbWbPmdmL4T1/I9w/w8z+Ft7zr8KBsZjZiHB7fXh8ej7LPxhmVm5mL5jZ78Ltor5nM3vDzF4Ol21YEe4bsn/bJR0s0qZR/zAwG7jUzGbnt1Q58zPgvIx9C4DH3X0W8Hi4DcH9zwof84EfDlEZc60D+LK7Hw2cCnw+/O9ZzPe9F/igux8PzAHOM7NTge8A3w/vuRm4Ojz/aqDZ3Q8Hvh+eV6iuI5z1IVQK9/wBd5+TNp5i6P5tu3vJPoB5wNK07RuAG/Jdrhze33TglbTttcCB4esDgbXh6x8Bl3Z3XiE/gIcJ1lMpifsGaoHngVMIRvJWhPs7/50TzKgwL3xdEZ5n+S77AO51avjl+EHgdwQTlxb7Pb8BTMzYN2T/tks6syD7adSLxRR33wwQPk8O9xfd3yGsajgB+BtFft9hdcwq4F1gGbABaHH3jvCU9PvqvOfw+A5gwtCWOCd+APwTkAy3J1D89+zAH8xspZnND/cN2b/tyOaGKhDZTKNeCorq72Bmo4CHgP/h7jvNuru94NRu9hXcfbt7AphjZnXAbwjmVtvvtPC54O/ZzD4KvOvuK83szNTubk4tmnsOne7um8xsMrDMzP7ey7k5v+dSzyz6nEa9yGxNzfQbPr8b7i+av4OZVRIEinvd/T/C3UV/3wDu3kIwnf+pQJ2ZpX4Mpt9X5z2Hx8cSTOJZSE4HPmZmbxCswPlBgkyjmO8Z37dsw7sEPwpOZgj/bZd6sOhzGvUisxi4Inx9BUGdfmr/p8MeFKcCO1KpbSGxIIX4CbDG3f817VDR3reZTQozCsysBjiboNH3j8CF4WmZ95z6W1wIPOFhpXahcPcb3H2qu08n+H/2CXf/FEV8z2Y20sxGp14D5wKvMJT/tvPdaJPvB3A+8BpBPe//ynd5cnhf9wGbgTjBr4yrCeppHwfWhc/jw3ONoFfYBuBloD7f5R/gPZ9BkGq/BKwKH+cX830D7wFeCO/5FeDGcP9hwHPAeuDXwIhwf3W4vT48fli+72GQ938m8Ltiv+fw3l4MH6+mvquG8t+2pvsQEZE+lXo1lIiIZEHBQkRE+qRgISIifVKwEBGRPilYiIhInxQsRPrBzBLhrJ+pR85mKjaz6ZY2S7DIcFLq032I9Feru8/JdyFEhpoyC5EcCNca+E64tsRzZnZ4uP9QM3s8XFPgcTObFu6fYma/CdeheNHMTgvfqtzM7g7XpvhDOCpbJO8ULET6pyajGuritGM73f1k4A6CuYoIX//c3d8D3AvcFu6/DfiTB+tQzCUYlQvB+gN3uvsxQAvwiYjvRyQrGsEt0g9mttvdR3Wz/w2CRYg2hpMZbnH3CWa2nWAdgXi4f7O7TzSzbcBUd9+b9h7TgWUeLGSDmf0zUOnu34r+zkR6p8xCJHe8h9c9ndOdvWmvE6hdUYYJBQuR3Lk47fmZ8PXTBDOjAnwK+Gv4+nHgH6Fz8aIxQ1VIkYHQrxaR/qkJV6VL+b27p7rPjjCzvxH8CLs03PdFYJGZfRXYBlwV7r8OWGhmVxNkEP9IMEuwyLCkNguRHAjbLOrdfXu+yyISBVVDiYhIn5RZiIhIn5RZiIhInxQsRESkTwoWIiLSJwULERHpk4KFiIj06f8Hcq+cemL1o+UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de nästkommande 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [2 0 2 2 0]\n",
      "\n",
      "Sannolikheter bakom prediktioner\n",
      " ['setosa' 'versicolor' 'virginica'] \n",
      " [[2.404e-03 3.040e-01 6.936e-01]\n",
      " [8.211e-01 1.749e-01 3.941e-03]\n",
      " [8.585e-04 4.914e-01 5.077e-01]\n",
      " [2.989e-03 2.626e-01 7.344e-01]\n",
      " [8.686e-01 1.282e-01 3.156e-03]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = (multinomial_log_reg_model.predict(X_test[5:10]) > 0.5).astype(\"int32\")\n",
    "\n",
    "probabilities = multinomial_log_reg_model.predict(X_test[5:10])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktioner\\n\",names,\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Neuralt nätverk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Vi har nu utvärderat likheterna mellan ett neuralt nätverk och logistisk regression\n",
    "- Neurala nätverks styrka är inte att replikera logistisk regression, utan att kunna hantera komplexare samband än en logistisk regression genom att introducera icke-linjaritet med hjälp av ett antal hidden layers, inte bara ett lager som vi använt ovan \n",
    "\n",
    "\n",
    "Skillnaden mot multinomial regression är att vi nu har flera lager (5) istället för 1: \n",
    "- Ett input lager som hanterar våra fyra features som input, har 5 noder och ReLU-aktivering\n",
    "- 3 efterföljande hidden layers med 5 noder, ReLU-aktivering\n",
    "- Det output lager som vi känner igen: softmax-aktivering som beräknar 3 värden, 0-1 hur sannolik observationen är var och en av våra 3 blomkategorier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 413\n",
      "Trainable params: 413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Skapar återigen ett tomt, sekventiellt nätverk\n",
    "neural_network_model = Sequential()\n",
    "\n",
    "\n",
    "nodes = 10 # Noder i hidden layer. TESTA ATT ÄNDRA ANTALET NODER\n",
    "\n",
    "# Input lager, n_features=4\n",
    "neural_network_model.add(Dense(nodes, input_dim=n_features, activation='relu'))\n",
    "\n",
    "#Hidden lager\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "\n",
    "\n",
    "#Output lager, n_classes=3\n",
    "neural_network_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "neural_network_model.compile(optimizer='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "neural_network_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Träning av modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 11ms/sample - loss: 1.1309 - accuracy: 0.0133 - val_loss: 1.1325 - val_accuracy: 0.0533\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 1.1279 - accuracy: 0.0133 - val_loss: 1.1297 - val_accuracy: 0.0667\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 1.1246 - accuracy: 0.0400 - val_loss: 1.1271 - val_accuracy: 0.0667\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 1.1217 - accuracy: 0.0667 - val_loss: 1.1241 - val_accuracy: 0.0667\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 1.1185 - accuracy: 0.0800 - val_loss: 1.1219 - val_accuracy: 0.1067\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 1.1153 - accuracy: 0.0933 - val_loss: 1.1193 - val_accuracy: 0.1333\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.1123 - accuracy: 0.1733 - val_loss: 1.1171 - val_accuracy: 0.1733\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 1.1097 - accuracy: 0.2000 - val_loss: 1.1148 - val_accuracy: 0.1867\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 1.1073 - accuracy: 0.2000 - val_loss: 1.1127 - val_accuracy: 0.2000\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 1.1047 - accuracy: 0.2800 - val_loss: 1.1106 - val_accuracy: 0.2000\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 1.1022 - accuracy: 0.3067 - val_loss: 1.1084 - val_accuracy: 0.2133\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 1.0997 - accuracy: 0.3333 - val_loss: 1.1061 - val_accuracy: 0.2267\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 1.0973 - accuracy: 0.2667 - val_loss: 1.1039 - val_accuracy: 0.2267\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 1.0950 - accuracy: 0.3067 - val_loss: 1.1015 - val_accuracy: 0.2000\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.0926 - accuracy: 0.3333 - val_loss: 1.0994 - val_accuracy: 0.2267\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 1.0905 - accuracy: 0.3600 - val_loss: 1.0973 - val_accuracy: 0.2933\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 1.0881 - accuracy: 0.4533 - val_loss: 1.0951 - val_accuracy: 0.3333\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 1.0860 - accuracy: 0.4667 - val_loss: 1.0933 - val_accuracy: 0.3467\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 1.0838 - accuracy: 0.4667 - val_loss: 1.0915 - val_accuracy: 0.3733\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 1.0821 - accuracy: 0.4800 - val_loss: 1.0895 - val_accuracy: 0.3467\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 1.0796 - accuracy: 0.5067 - val_loss: 1.0875 - val_accuracy: 0.3467\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 1.0772 - accuracy: 0.4533 - val_loss: 1.0855 - val_accuracy: 0.3467\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 1.0750 - accuracy: 0.4533 - val_loss: 1.0836 - val_accuracy: 0.3467\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 1.0727 - accuracy: 0.4933 - val_loss: 1.0813 - val_accuracy: 0.3467\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 1.0704 - accuracy: 0.4667 - val_loss: 1.0791 - val_accuracy: 0.3467\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 1.0682 - accuracy: 0.4667 - val_loss: 1.0771 - val_accuracy: 0.3467\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 1.0663 - accuracy: 0.4667 - val_loss: 1.0750 - val_accuracy: 0.3467\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 1.0637 - accuracy: 0.4800 - val_loss: 1.0730 - val_accuracy: 0.3467\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 1.0615 - accuracy: 0.4933 - val_loss: 1.0706 - val_accuracy: 0.3467\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 1.0590 - accuracy: 0.4667 - val_loss: 1.0680 - val_accuracy: 0.3467\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 1.0566 - accuracy: 0.4533 - val_loss: 1.0656 - val_accuracy: 0.3467\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 1.0542 - accuracy: 0.4533 - val_loss: 1.0632 - val_accuracy: 0.3467\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 1.0515 - accuracy: 0.4533 - val_loss: 1.0608 - val_accuracy: 0.3467\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 1.0490 - accuracy: 0.4533 - val_loss: 1.0586 - val_accuracy: 0.3600\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 1.0466 - accuracy: 0.4800 - val_loss: 1.0560 - val_accuracy: 0.3600\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 1.0439 - accuracy: 0.4667 - val_loss: 1.0532 - val_accuracy: 0.3600\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 1.0413 - accuracy: 0.4933 - val_loss: 1.0510 - val_accuracy: 0.3867\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.0388 - accuracy: 0.5333 - val_loss: 1.0486 - val_accuracy: 0.3867\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 1.0362 - accuracy: 0.5200 - val_loss: 1.0461 - val_accuracy: 0.3867\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 1.0336 - accuracy: 0.5333 - val_loss: 1.0436 - val_accuracy: 0.4000\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 1.0310 - accuracy: 0.5333 - val_loss: 1.0409 - val_accuracy: 0.4000\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 1.0282 - accuracy: 0.5333 - val_loss: 1.0386 - val_accuracy: 0.4267\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 1.0257 - accuracy: 0.5333 - val_loss: 1.0358 - val_accuracy: 0.4133\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 1.0230 - accuracy: 0.5333 - val_loss: 1.0328 - val_accuracy: 0.4133\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 1.0202 - accuracy: 0.5467 - val_loss: 1.0306 - val_accuracy: 0.4400\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.0176 - accuracy: 0.5467 - val_loss: 1.0281 - val_accuracy: 0.4400\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 485us/sample - loss: 1.0151 - accuracy: 0.5600 - val_loss: 1.0256 - val_accuracy: 0.4400\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 1.0127 - accuracy: 0.5600 - val_loss: 1.0233 - val_accuracy: 0.4400\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 1.0102 - accuracy: 0.5467 - val_loss: 1.0207 - val_accuracy: 0.4400\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 1.0076 - accuracy: 0.5600 - val_loss: 1.0180 - val_accuracy: 0.4400\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 1.0051 - accuracy: 0.5467 - val_loss: 1.0151 - val_accuracy: 0.4533\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 1.0023 - accuracy: 0.5467 - val_loss: 1.0122 - val_accuracy: 0.4533\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.9994 - accuracy: 0.5467 - val_loss: 1.0095 - val_accuracy: 0.4400\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.9966 - accuracy: 0.5600 - val_loss: 1.0063 - val_accuracy: 0.4533\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.9940 - accuracy: 0.5600 - val_loss: 1.0034 - val_accuracy: 0.4800\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.9908 - accuracy: 0.6000 - val_loss: 1.0003 - val_accuracy: 0.4933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.9877 - accuracy: 0.6267 - val_loss: 0.9975 - val_accuracy: 0.5333\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.9846 - accuracy: 0.6667 - val_loss: 0.9939 - val_accuracy: 0.5733\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.9812 - accuracy: 0.7600 - val_loss: 0.9901 - val_accuracy: 0.5733\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.9777 - accuracy: 0.7733 - val_loss: 0.9869 - val_accuracy: 0.6133\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.9742 - accuracy: 0.7867 - val_loss: 0.9833 - val_accuracy: 0.6667\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.9705 - accuracy: 0.8133 - val_loss: 0.9797 - val_accuracy: 0.7200\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.9669 - accuracy: 0.8267 - val_loss: 0.9758 - val_accuracy: 0.7733\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.9631 - accuracy: 0.8400 - val_loss: 0.9717 - val_accuracy: 0.7867\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 506us/sample - loss: 0.9593 - accuracy: 0.8400 - val_loss: 0.9677 - val_accuracy: 0.7867\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.9556 - accuracy: 0.8533 - val_loss: 0.9634 - val_accuracy: 0.7867\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 537us/sample - loss: 0.9515 - accuracy: 0.8533 - val_loss: 0.9592 - val_accuracy: 0.7867\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.9474 - accuracy: 0.8533 - val_loss: 0.9551 - val_accuracy: 0.7867\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.9437 - accuracy: 0.8533 - val_loss: 0.9508 - val_accuracy: 0.7867\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.9394 - accuracy: 0.8533 - val_loss: 0.9458 - val_accuracy: 0.7733\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.9347 - accuracy: 0.8267 - val_loss: 0.9415 - val_accuracy: 0.7867\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.9303 - accuracy: 0.8533 - val_loss: 0.9365 - val_accuracy: 0.7867\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.9255 - accuracy: 0.8533 - val_loss: 0.9317 - val_accuracy: 0.7867\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.9208 - accuracy: 0.8267 - val_loss: 0.9269 - val_accuracy: 0.7600\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.9162 - accuracy: 0.8400 - val_loss: 0.9213 - val_accuracy: 0.7333\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.9109 - accuracy: 0.8267 - val_loss: 0.9168 - val_accuracy: 0.7333\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.9064 - accuracy: 0.8267 - val_loss: 0.9115 - val_accuracy: 0.7333\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.9015 - accuracy: 0.8267 - val_loss: 0.9067 - val_accuracy: 0.7200\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.8968 - accuracy: 0.8133 - val_loss: 0.9020 - val_accuracy: 0.7200\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.8920 - accuracy: 0.8267 - val_loss: 0.8968 - val_accuracy: 0.7200\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.8871 - accuracy: 0.8133 - val_loss: 0.8920 - val_accuracy: 0.7200\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.8825 - accuracy: 0.8267 - val_loss: 0.8867 - val_accuracy: 0.7067\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.8774 - accuracy: 0.8133 - val_loss: 0.8818 - val_accuracy: 0.7067\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.8722 - accuracy: 0.8133 - val_loss: 0.8757 - val_accuracy: 0.7067\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.8666 - accuracy: 0.8000 - val_loss: 0.8696 - val_accuracy: 0.7067\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.8607 - accuracy: 0.8000 - val_loss: 0.8641 - val_accuracy: 0.7067\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.8553 - accuracy: 0.7867 - val_loss: 0.8570 - val_accuracy: 0.6933\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.8487 - accuracy: 0.7867 - val_loss: 0.8498 - val_accuracy: 0.6933\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.8423 - accuracy: 0.7733 - val_loss: 0.8435 - val_accuracy: 0.6933\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.8365 - accuracy: 0.7733 - val_loss: 0.8381 - val_accuracy: 0.6933\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.8311 - accuracy: 0.7733 - val_loss: 0.8325 - val_accuracy: 0.6933\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.8260 - accuracy: 0.7733 - val_loss: 0.8263 - val_accuracy: 0.6933\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.8195 - accuracy: 0.7867 - val_loss: 0.8192 - val_accuracy: 0.6933\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.8133 - accuracy: 0.7733 - val_loss: 0.8130 - val_accuracy: 0.6933\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.8075 - accuracy: 0.7733 - val_loss: 0.8059 - val_accuracy: 0.6933\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.8012 - accuracy: 0.7600 - val_loss: 0.7989 - val_accuracy: 0.6933\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.7951 - accuracy: 0.7600 - val_loss: 0.7932 - val_accuracy: 0.6933\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.7892 - accuracy: 0.7600 - val_loss: 0.7859 - val_accuracy: 0.6933\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.7829 - accuracy: 0.7600 - val_loss: 0.7796 - val_accuracy: 0.6933\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.7772 - accuracy: 0.7333 - val_loss: 0.7736 - val_accuracy: 0.6933\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.7718 - accuracy: 0.7333 - val_loss: 0.7683 - val_accuracy: 0.6933\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.7664 - accuracy: 0.7467 - val_loss: 0.7628 - val_accuracy: 0.6933\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.7609 - accuracy: 0.7467 - val_loss: 0.7566 - val_accuracy: 0.6933\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.7550 - accuracy: 0.7467 - val_loss: 0.7504 - val_accuracy: 0.6933\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.7495 - accuracy: 0.7467 - val_loss: 0.7442 - val_accuracy: 0.6933\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.7435 - accuracy: 0.7467 - val_loss: 0.7381 - val_accuracy: 0.6933\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.7379 - accuracy: 0.7467 - val_loss: 0.7322 - val_accuracy: 0.6933\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.7329 - accuracy: 0.7467 - val_loss: 0.7265 - val_accuracy: 0.6933\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.7278 - accuracy: 0.7467 - val_loss: 0.7205 - val_accuracy: 0.6933\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.7219 - accuracy: 0.7467 - val_loss: 0.7142 - val_accuracy: 0.6933\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.7163 - accuracy: 0.7467 - val_loss: 0.7087 - val_accuracy: 0.6933\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 519us/sample - loss: 0.7113 - accuracy: 0.7333 - val_loss: 0.7035 - val_accuracy: 0.6933\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 396us/sample - loss: 0.7063 - accuracy: 0.7467 - val_loss: 0.6984 - val_accuracy: 0.6933\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.7015 - accuracy: 0.7467 - val_loss: 0.6934 - val_accuracy: 0.6933\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.6968 - accuracy: 0.7467 - val_loss: 0.6879 - val_accuracy: 0.6933\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.6919 - accuracy: 0.7467 - val_loss: 0.6820 - val_accuracy: 0.6933\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.6871 - accuracy: 0.7333 - val_loss: 0.6779 - val_accuracy: 0.6933\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.6825 - accuracy: 0.7333 - val_loss: 0.6721 - val_accuracy: 0.6933\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.6777 - accuracy: 0.7333 - val_loss: 0.6665 - val_accuracy: 0.6933\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 539us/sample - loss: 0.6729 - accuracy: 0.7333 - val_loss: 0.6614 - val_accuracy: 0.6933\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 580us/sample - loss: 0.6684 - accuracy: 0.7333 - val_loss: 0.6563 - val_accuracy: 0.6933\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.6637 - accuracy: 0.7333 - val_loss: 0.6515 - val_accuracy: 0.6933\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.6595 - accuracy: 0.7333 - val_loss: 0.6475 - val_accuracy: 0.6933\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.6553 - accuracy: 0.7333 - val_loss: 0.6429 - val_accuracy: 0.6933\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.6512 - accuracy: 0.7333 - val_loss: 0.6383 - val_accuracy: 0.6933\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.6469 - accuracy: 0.7333 - val_loss: 0.6343 - val_accuracy: 0.6933\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.6429 - accuracy: 0.7333 - val_loss: 0.6308 - val_accuracy: 0.6933\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.6389 - accuracy: 0.7333 - val_loss: 0.6265 - val_accuracy: 0.6933\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 559us/sample - loss: 0.6349 - accuracy: 0.7333 - val_loss: 0.6221 - val_accuracy: 0.6933\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.6310 - accuracy: 0.7333 - val_loss: 0.6170 - val_accuracy: 0.6933\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.6269 - accuracy: 0.7467 - val_loss: 0.6129 - val_accuracy: 0.6933\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.6231 - accuracy: 0.7467 - val_loss: 0.6085 - val_accuracy: 0.6933\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 515us/sample - loss: 0.6192 - accuracy: 0.7467 - val_loss: 0.6041 - val_accuracy: 0.6933\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.6154 - accuracy: 0.7467 - val_loss: 0.6000 - val_accuracy: 0.6933\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.6116 - accuracy: 0.7467 - val_loss: 0.5962 - val_accuracy: 0.6933\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.6079 - accuracy: 0.7467 - val_loss: 0.5920 - val_accuracy: 0.6933\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.6042 - accuracy: 0.7467 - val_loss: 0.5883 - val_accuracy: 0.7067\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.6009 - accuracy: 0.7467 - val_loss: 0.5834 - val_accuracy: 0.7200\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.5971 - accuracy: 0.7467 - val_loss: 0.5804 - val_accuracy: 0.7200\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.5936 - accuracy: 0.7467 - val_loss: 0.5762 - val_accuracy: 0.7200\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.5902 - accuracy: 0.7467 - val_loss: 0.5726 - val_accuracy: 0.7200\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.5868 - accuracy: 0.7467 - val_loss: 0.5691 - val_accuracy: 0.7200\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.5833 - accuracy: 0.7600 - val_loss: 0.5658 - val_accuracy: 0.7200\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.5801 - accuracy: 0.7600 - val_loss: 0.5626 - val_accuracy: 0.7467\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 0.5766 - accuracy: 0.7600 - val_loss: 0.5591 - val_accuracy: 0.7467\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.5733 - accuracy: 0.7600 - val_loss: 0.5558 - val_accuracy: 0.7467\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 517us/sample - loss: 0.5700 - accuracy: 0.7600 - val_loss: 0.5526 - val_accuracy: 0.7600\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.5668 - accuracy: 0.7600 - val_loss: 0.5493 - val_accuracy: 0.7600\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 499us/sample - loss: 0.5636 - accuracy: 0.7600 - val_loss: 0.5461 - val_accuracy: 0.7600\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.5604 - accuracy: 0.7733 - val_loss: 0.5423 - val_accuracy: 0.7600\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 583us/sample - loss: 0.5571 - accuracy: 0.7600 - val_loss: 0.5392 - val_accuracy: 0.7600\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 0.5538 - accuracy: 0.7867 - val_loss: 0.5357 - val_accuracy: 0.7600\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 793us/sample - loss: 0.5512 - accuracy: 0.7733 - val_loss: 0.5317 - val_accuracy: 0.7600\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 495us/sample - loss: 0.5477 - accuracy: 0.7600 - val_loss: 0.5287 - val_accuracy: 0.7600\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.5447 - accuracy: 0.7600 - val_loss: 0.5255 - val_accuracy: 0.7600\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.5418 - accuracy: 0.7600 - val_loss: 0.5220 - val_accuracy: 0.7600\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.5389 - accuracy: 0.7600 - val_loss: 0.5186 - val_accuracy: 0.7600\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.5358 - accuracy: 0.7600 - val_loss: 0.5161 - val_accuracy: 0.7600\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.5330 - accuracy: 0.7867 - val_loss: 0.5129 - val_accuracy: 0.7733\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.5300 - accuracy: 0.7867 - val_loss: 0.5100 - val_accuracy: 0.7733\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 457us/sample - loss: 0.5273 - accuracy: 0.7867 - val_loss: 0.5067 - val_accuracy: 0.7733\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.5242 - accuracy: 0.7867 - val_loss: 0.5040 - val_accuracy: 0.7733\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.5213 - accuracy: 0.7867 - val_loss: 0.5013 - val_accuracy: 0.7867\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 527us/sample - loss: 0.5183 - accuracy: 0.8000 - val_loss: 0.4982 - val_accuracy: 0.7867\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 527us/sample - loss: 0.5156 - accuracy: 0.8000 - val_loss: 0.4950 - val_accuracy: 0.7733\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.5127 - accuracy: 0.8000 - val_loss: 0.4928 - val_accuracy: 0.8267\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.5100 - accuracy: 0.8000 - val_loss: 0.4895 - val_accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 490us/sample - loss: 0.5073 - accuracy: 0.8000 - val_loss: 0.4865 - val_accuracy: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.5047 - accuracy: 0.8000 - val_loss: 0.4839 - val_accuracy: 0.8267\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.5019 - accuracy: 0.8000 - val_loss: 0.4812 - val_accuracy: 0.8267\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.4994 - accuracy: 0.8000 - val_loss: 0.4795 - val_accuracy: 0.8400\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.4966 - accuracy: 0.8133 - val_loss: 0.4768 - val_accuracy: 0.8400\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 0.4941 - accuracy: 0.8267 - val_loss: 0.4745 - val_accuracy: 0.8667\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.4915 - accuracy: 0.8400 - val_loss: 0.4722 - val_accuracy: 0.8667\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.4889 - accuracy: 0.8400 - val_loss: 0.4690 - val_accuracy: 0.8667\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.4864 - accuracy: 0.8400 - val_loss: 0.4656 - val_accuracy: 0.8667\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 505us/sample - loss: 0.4836 - accuracy: 0.8400 - val_loss: 0.4632 - val_accuracy: 0.8667\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 526us/sample - loss: 0.4813 - accuracy: 0.8400 - val_loss: 0.4612 - val_accuracy: 0.8667\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.4786 - accuracy: 0.8400 - val_loss: 0.4596 - val_accuracy: 0.8800\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.4761 - accuracy: 0.8667 - val_loss: 0.4571 - val_accuracy: 0.8800\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.4737 - accuracy: 0.8533 - val_loss: 0.4535 - val_accuracy: 0.8800\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.4715 - accuracy: 0.8400 - val_loss: 0.4502 - val_accuracy: 0.8667\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.4689 - accuracy: 0.8400 - val_loss: 0.4484 - val_accuracy: 0.8800\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.4667 - accuracy: 0.8400 - val_loss: 0.4476 - val_accuracy: 0.8800\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.4636 - accuracy: 0.8667 - val_loss: 0.4444 - val_accuracy: 0.8800\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.4610 - accuracy: 0.8667 - val_loss: 0.4424 - val_accuracy: 0.8800\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 520us/sample - loss: 0.4584 - accuracy: 0.8667 - val_loss: 0.4398 - val_accuracy: 0.8800\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.4580 - accuracy: 0.8667 - val_loss: 0.4379 - val_accuracy: 0.8800\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.4534 - accuracy: 0.8667 - val_loss: 0.4353 - val_accuracy: 0.8800\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.4509 - accuracy: 0.8667 - val_loss: 0.4332 - val_accuracy: 0.8800\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.4488 - accuracy: 0.8667 - val_loss: 0.4319 - val_accuracy: 0.8667\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.4466 - accuracy: 0.8933 - val_loss: 0.4280 - val_accuracy: 0.8800\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 548us/sample - loss: 0.4439 - accuracy: 0.8800 - val_loss: 0.4250 - val_accuracy: 0.8933\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 511us/sample - loss: 0.4414 - accuracy: 0.8667 - val_loss: 0.4239 - val_accuracy: 0.8800\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 539us/sample - loss: 0.4388 - accuracy: 0.8800 - val_loss: 0.4225 - val_accuracy: 0.8800\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.4361 - accuracy: 0.9067 - val_loss: 0.4195 - val_accuracy: 0.8800\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 511us/sample - loss: 0.4337 - accuracy: 0.8933 - val_loss: 0.4177 - val_accuracy: 0.8800\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.4315 - accuracy: 0.8933 - val_loss: 0.4163 - val_accuracy: 0.8933\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.4292 - accuracy: 0.9067 - val_loss: 0.4141 - val_accuracy: 0.8933\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.4267 - accuracy: 0.9067 - val_loss: 0.4132 - val_accuracy: 0.8933\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.4238 - accuracy: 0.9200 - val_loss: 0.4102 - val_accuracy: 0.8933\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.4218 - accuracy: 0.9200 - val_loss: 0.4071 - val_accuracy: 0.8933\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.4194 - accuracy: 0.9200 - val_loss: 0.4037 - val_accuracy: 0.8933\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.4169 - accuracy: 0.9067 - val_loss: 0.4012 - val_accuracy: 0.8933\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.4149 - accuracy: 0.9067 - val_loss: 0.3985 - val_accuracy: 0.8933\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.4126 - accuracy: 0.9067 - val_loss: 0.3973 - val_accuracy: 0.8933\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.4098 - accuracy: 0.9200 - val_loss: 0.3946 - val_accuracy: 0.8933\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.4077 - accuracy: 0.9200 - val_loss: 0.3933 - val_accuracy: 0.8933\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.4051 - accuracy: 0.9200 - val_loss: 0.3908 - val_accuracy: 0.8933\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.4028 - accuracy: 0.9200 - val_loss: 0.3891 - val_accuracy: 0.8933\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.4005 - accuracy: 0.9200 - val_loss: 0.3861 - val_accuracy: 0.8933\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.3983 - accuracy: 0.9200 - val_loss: 0.3846 - val_accuracy: 0.8933\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3962 - accuracy: 0.9200 - val_loss: 0.3820 - val_accuracy: 0.8933\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.3938 - accuracy: 0.9200 - val_loss: 0.3803 - val_accuracy: 0.9067\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.3914 - accuracy: 0.9200 - val_loss: 0.3775 - val_accuracy: 0.8933\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.3894 - accuracy: 0.9200 - val_loss: 0.3746 - val_accuracy: 0.8933\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.3874 - accuracy: 0.9200 - val_loss: 0.3738 - val_accuracy: 0.9067\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.3847 - accuracy: 0.9200 - val_loss: 0.3735 - val_accuracy: 0.9067\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.3824 - accuracy: 0.9333 - val_loss: 0.3708 - val_accuracy: 0.9067\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.3803 - accuracy: 0.9200 - val_loss: 0.3704 - val_accuracy: 0.9067\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3780 - accuracy: 0.9333 - val_loss: 0.3679 - val_accuracy: 0.9067\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.3757 - accuracy: 0.9333 - val_loss: 0.3661 - val_accuracy: 0.9067\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.3736 - accuracy: 0.9333 - val_loss: 0.3627 - val_accuracy: 0.9067\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.3716 - accuracy: 0.9200 - val_loss: 0.3623 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.3692 - accuracy: 0.9333 - val_loss: 0.3608 - val_accuracy: 0.9067\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 523us/sample - loss: 0.3671 - accuracy: 0.9333 - val_loss: 0.3605 - val_accuracy: 0.9067\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.3648 - accuracy: 0.9333 - val_loss: 0.3572 - val_accuracy: 0.9200\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.3622 - accuracy: 0.9333 - val_loss: 0.3550 - val_accuracy: 0.9200\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.3599 - accuracy: 0.9333 - val_loss: 0.3535 - val_accuracy: 0.9333\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.3582 - accuracy: 0.9333 - val_loss: 0.3522 - val_accuracy: 0.9333\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.3555 - accuracy: 0.9333 - val_loss: 0.3494 - val_accuracy: 0.9333\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3535 - accuracy: 0.9333 - val_loss: 0.3491 - val_accuracy: 0.9333\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3514 - accuracy: 0.9467 - val_loss: 0.3463 - val_accuracy: 0.9333\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 211us/sample - loss: 0.3493 - accuracy: 0.9467 - val_loss: 0.3456 - val_accuracy: 0.9333\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.3483 - accuracy: 0.9467 - val_loss: 0.3442 - val_accuracy: 0.9333\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.3451 - accuracy: 0.9467 - val_loss: 0.3408 - val_accuracy: 0.9333\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.3429 - accuracy: 0.9467 - val_loss: 0.3386 - val_accuracy: 0.9333\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.3418 - accuracy: 0.9467 - val_loss: 0.3354 - val_accuracy: 0.9333\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.3385 - accuracy: 0.9467 - val_loss: 0.3323 - val_accuracy: 0.9333\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.3366 - accuracy: 0.9333 - val_loss: 0.3314 - val_accuracy: 0.9333\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.3344 - accuracy: 0.9467 - val_loss: 0.3290 - val_accuracy: 0.9333\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 234us/sample - loss: 0.3321 - accuracy: 0.9333 - val_loss: 0.3272 - val_accuracy: 0.9333\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 203us/sample - loss: 0.3303 - accuracy: 0.9467 - val_loss: 0.3266 - val_accuracy: 0.9333\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.3284 - accuracy: 0.9467 - val_loss: 0.3238 - val_accuracy: 0.9333\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 229us/sample - loss: 0.3260 - accuracy: 0.9467 - val_loss: 0.3230 - val_accuracy: 0.9333\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.3245 - accuracy: 0.9467 - val_loss: 0.3189 - val_accuracy: 0.9333\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 235us/sample - loss: 0.3228 - accuracy: 0.9333 - val_loss: 0.3206 - val_accuracy: 0.9333\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 224us/sample - loss: 0.3201 - accuracy: 0.9467 - val_loss: 0.3191 - val_accuracy: 0.9333\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.3183 - accuracy: 0.9467 - val_loss: 0.3188 - val_accuracy: 0.9333\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.3160 - accuracy: 0.9467 - val_loss: 0.3169 - val_accuracy: 0.9333\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.3140 - accuracy: 0.9467 - val_loss: 0.3130 - val_accuracy: 0.9333\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.3117 - accuracy: 0.9467 - val_loss: 0.3108 - val_accuracy: 0.9333\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3099 - accuracy: 0.9467 - val_loss: 0.3084 - val_accuracy: 0.9333\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 241us/sample - loss: 0.3078 - accuracy: 0.9467 - val_loss: 0.3066 - val_accuracy: 0.9333\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.3058 - accuracy: 0.9467 - val_loss: 0.3061 - val_accuracy: 0.9333\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 231us/sample - loss: 0.3039 - accuracy: 0.9467 - val_loss: 0.3042 - val_accuracy: 0.9333\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 228us/sample - loss: 0.3018 - accuracy: 0.9467 - val_loss: 0.3035 - val_accuracy: 0.9333\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.3000 - accuracy: 0.9467 - val_loss: 0.3024 - val_accuracy: 0.9333\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 234us/sample - loss: 0.2979 - accuracy: 0.9467 - val_loss: 0.2993 - val_accuracy: 0.9333\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.2957 - accuracy: 0.9600 - val_loss: 0.2976 - val_accuracy: 0.9333\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.2939 - accuracy: 0.9600 - val_loss: 0.2973 - val_accuracy: 0.9333\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.2925 - accuracy: 0.9600 - val_loss: 0.2953 - val_accuracy: 0.9333\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.2914 - accuracy: 0.9600 - val_loss: 0.2935 - val_accuracy: 0.9333\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.2887 - accuracy: 0.9600 - val_loss: 0.2909 - val_accuracy: 0.9333\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2862 - accuracy: 0.9600 - val_loss: 0.2913 - val_accuracy: 0.9333\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.2839 - accuracy: 0.9600 - val_loss: 0.2889 - val_accuracy: 0.9333\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.2821 - accuracy: 0.9600 - val_loss: 0.2884 - val_accuracy: 0.9333\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.2804 - accuracy: 0.9600 - val_loss: 0.2871 - val_accuracy: 0.9333\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2783 - accuracy: 0.9600 - val_loss: 0.2860 - val_accuracy: 0.9333\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.2767 - accuracy: 0.9600 - val_loss: 0.2819 - val_accuracy: 0.9333\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 213us/sample - loss: 0.2746 - accuracy: 0.9600 - val_loss: 0.2810 - val_accuracy: 0.9333\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 231us/sample - loss: 0.2729 - accuracy: 0.9600 - val_loss: 0.2815 - val_accuracy: 0.9333\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.2723 - accuracy: 0.9600 - val_loss: 0.2812 - val_accuracy: 0.9467\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.2696 - accuracy: 0.9733 - val_loss: 0.2802 - val_accuracy: 0.9467\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.2678 - accuracy: 0.9733 - val_loss: 0.2750 - val_accuracy: 0.9333\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.2655 - accuracy: 0.9600 - val_loss: 0.2740 - val_accuracy: 0.9333\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.2643 - accuracy: 0.9733 - val_loss: 0.2684 - val_accuracy: 0.9333\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.2639 - accuracy: 0.9467 - val_loss: 0.2684 - val_accuracy: 0.9333\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.2602 - accuracy: 0.9600 - val_loss: 0.2682 - val_accuracy: 0.9333\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.2583 - accuracy: 0.9733 - val_loss: 0.2688 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2566 - accuracy: 0.9733 - val_loss: 0.2679 - val_accuracy: 0.9467\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2547 - accuracy: 0.9733 - val_loss: 0.2682 - val_accuracy: 0.9467\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.2530 - accuracy: 0.9733 - val_loss: 0.2681 - val_accuracy: 0.9467\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.2521 - accuracy: 0.9733 - val_loss: 0.2655 - val_accuracy: 0.9467\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.2510 - accuracy: 0.9733 - val_loss: 0.2628 - val_accuracy: 0.9467\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.2476 - accuracy: 0.9733 - val_loss: 0.2621 - val_accuracy: 0.9467\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2473 - accuracy: 0.9733 - val_loss: 0.2582 - val_accuracy: 0.9467\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.2439 - accuracy: 0.9733 - val_loss: 0.2574 - val_accuracy: 0.9467\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.2424 - accuracy: 0.9733 - val_loss: 0.2547 - val_accuracy: 0.9467\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.2409 - accuracy: 0.9733 - val_loss: 0.2494 - val_accuracy: 0.9333\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.2391 - accuracy: 0.9733 - val_loss: 0.2490 - val_accuracy: 0.9333\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.2377 - accuracy: 0.9733 - val_loss: 0.2476 - val_accuracy: 0.9467\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.2362 - accuracy: 0.9733 - val_loss: 0.2458 - val_accuracy: 0.9333\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.2351 - accuracy: 0.9733 - val_loss: 0.2446 - val_accuracy: 0.9467\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 508us/sample - loss: 0.2327 - accuracy: 0.9733 - val_loss: 0.2417 - val_accuracy: 0.9333\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.2317 - accuracy: 0.9733 - val_loss: 0.2394 - val_accuracy: 0.9333\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.2303 - accuracy: 0.9733 - val_loss: 0.2410 - val_accuracy: 0.9467\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.2287 - accuracy: 0.9733 - val_loss: 0.2393 - val_accuracy: 0.9467\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.2262 - accuracy: 0.9733 - val_loss: 0.2399 - val_accuracy: 0.9467\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.2241 - accuracy: 0.9733 - val_loss: 0.2390 - val_accuracy: 0.9467\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.2229 - accuracy: 0.9733 - val_loss: 0.2402 - val_accuracy: 0.9467\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.2211 - accuracy: 0.9733 - val_loss: 0.2396 - val_accuracy: 0.9467\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 241us/sample - loss: 0.2202 - accuracy: 0.9733 - val_loss: 0.2436 - val_accuracy: 0.9467\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.2194 - accuracy: 0.9733 - val_loss: 0.2373 - val_accuracy: 0.9467\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.2160 - accuracy: 0.9733 - val_loss: 0.2351 - val_accuracy: 0.9467\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.2148 - accuracy: 0.9733 - val_loss: 0.2363 - val_accuracy: 0.9467\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.2143 - accuracy: 0.9733 - val_loss: 0.2318 - val_accuracy: 0.9467\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.2116 - accuracy: 0.9733 - val_loss: 0.2314 - val_accuracy: 0.9467\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 228us/sample - loss: 0.2101 - accuracy: 0.9733 - val_loss: 0.2314 - val_accuracy: 0.9467\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.2085 - accuracy: 0.9733 - val_loss: 0.2280 - val_accuracy: 0.9467\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.2081 - accuracy: 0.9733 - val_loss: 0.2248 - val_accuracy: 0.9467\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.2070 - accuracy: 0.9733 - val_loss: 0.2245 - val_accuracy: 0.9467\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.2046 - accuracy: 0.9733 - val_loss: 0.2229 - val_accuracy: 0.9467\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.2026 - accuracy: 0.9733 - val_loss: 0.2245 - val_accuracy: 0.9467\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.2018 - accuracy: 0.9733 - val_loss: 0.2296 - val_accuracy: 0.9333\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.2010 - accuracy: 0.9733 - val_loss: 0.2249 - val_accuracy: 0.9333\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.1986 - accuracy: 0.9867 - val_loss: 0.2222 - val_accuracy: 0.9600\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.1977 - accuracy: 0.9867 - val_loss: 0.2176 - val_accuracy: 0.9600\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 0.1957 - accuracy: 0.9733 - val_loss: 0.2154 - val_accuracy: 0.9600\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.1945 - accuracy: 0.9733 - val_loss: 0.2157 - val_accuracy: 0.9600\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.1927 - accuracy: 0.9733 - val_loss: 0.2143 - val_accuracy: 0.9600\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.1917 - accuracy: 0.9733 - val_loss: 0.2125 - val_accuracy: 0.9600\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.1905 - accuracy: 0.9733 - val_loss: 0.2129 - val_accuracy: 0.9600\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.1894 - accuracy: 0.9733 - val_loss: 0.2181 - val_accuracy: 0.9467\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.1880 - accuracy: 0.9867 - val_loss: 0.2167 - val_accuracy: 0.9467\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.1869 - accuracy: 0.9733 - val_loss: 0.2102 - val_accuracy: 0.9600\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.1868 - accuracy: 0.9733 - val_loss: 0.2066 - val_accuracy: 0.9600\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.1848 - accuracy: 0.9733 - val_loss: 0.2058 - val_accuracy: 0.9600\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 231us/sample - loss: 0.1826 - accuracy: 0.9733 - val_loss: 0.2090 - val_accuracy: 0.9467\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.1814 - accuracy: 0.9867 - val_loss: 0.2109 - val_accuracy: 0.9467\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.1802 - accuracy: 0.9867 - val_loss: 0.2078 - val_accuracy: 0.9467\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.1788 - accuracy: 0.9867 - val_loss: 0.2044 - val_accuracy: 0.9467\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.1784 - accuracy: 0.9867 - val_loss: 0.2018 - val_accuracy: 0.9467\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 235us/sample - loss: 0.1763 - accuracy: 0.9733 - val_loss: 0.2025 - val_accuracy: 0.9467\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.1749 - accuracy: 0.9867 - val_loss: 0.2012 - val_accuracy: 0.9467\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.1737 - accuracy: 0.9867 - val_loss: 0.1992 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.1729 - accuracy: 0.9733 - val_loss: 0.1979 - val_accuracy: 0.9467\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.1713 - accuracy: 0.9867 - val_loss: 0.1983 - val_accuracy: 0.9467\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.1714 - accuracy: 0.9867 - val_loss: 0.1990 - val_accuracy: 0.9467\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.1691 - accuracy: 0.9867 - val_loss: 0.2022 - val_accuracy: 0.9333\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.1679 - accuracy: 0.9733 - val_loss: 0.2007 - val_accuracy: 0.9333\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.1675 - accuracy: 0.9733 - val_loss: 0.2022 - val_accuracy: 0.9333\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.1662 - accuracy: 0.9733 - val_loss: 0.2043 - val_accuracy: 0.9333\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.1651 - accuracy: 0.9733 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.1640 - accuracy: 0.9733 - val_loss: 0.1921 - val_accuracy: 0.9467\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.1618 - accuracy: 0.9867 - val_loss: 0.1918 - val_accuracy: 0.9467\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.1621 - accuracy: 0.9867 - val_loss: 0.2019 - val_accuracy: 0.9333\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 552us/sample - loss: 0.1625 - accuracy: 0.9733 - val_loss: 0.1988 - val_accuracy: 0.9333\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 499us/sample - loss: 0.1595 - accuracy: 0.9733 - val_loss: 0.1958 - val_accuracy: 0.9333\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.1579 - accuracy: 0.9733 - val_loss: 0.1890 - val_accuracy: 0.9467\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.1564 - accuracy: 0.9867 - val_loss: 0.1858 - val_accuracy: 0.9467\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.1557 - accuracy: 0.9867 - val_loss: 0.1907 - val_accuracy: 0.9333\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.1554 - accuracy: 0.9733 - val_loss: 0.1848 - val_accuracy: 0.9467\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.1560 - accuracy: 0.9733 - val_loss: 0.1872 - val_accuracy: 0.9467\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.1532 - accuracy: 0.9733 - val_loss: 0.1886 - val_accuracy: 0.9333\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.1537 - accuracy: 0.9733 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.1513 - accuracy: 0.9867 - val_loss: 0.1958 - val_accuracy: 0.9200\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 249us/sample - loss: 0.1508 - accuracy: 0.9733 - val_loss: 0.1844 - val_accuracy: 0.9467\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.1484 - accuracy: 0.9733 - val_loss: 0.1794 - val_accuracy: 0.9467\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.1477 - accuracy: 0.9867 - val_loss: 0.1792 - val_accuracy: 0.9467\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.1466 - accuracy: 0.9867 - val_loss: 0.1803 - val_accuracy: 0.9467\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.1452 - accuracy: 0.9867 - val_loss: 0.1789 - val_accuracy: 0.9467\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.1447 - accuracy: 0.9733 - val_loss: 0.1745 - val_accuracy: 0.9467\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.1449 - accuracy: 0.9867 - val_loss: 0.1755 - val_accuracy: 0.9467\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.1429 - accuracy: 0.9867 - val_loss: 0.1743 - val_accuracy: 0.9467\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.1436 - accuracy: 0.9867 - val_loss: 0.1772 - val_accuracy: 0.9467\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.1407 - accuracy: 0.9733 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.1397 - accuracy: 0.9867 - val_loss: 0.1765 - val_accuracy: 0.9467\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.1387 - accuracy: 0.9867 - val_loss: 0.1755 - val_accuracy: 0.9467\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.1385 - accuracy: 0.9733 - val_loss: 0.1723 - val_accuracy: 0.9467\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.1371 - accuracy: 0.9867 - val_loss: 0.1737 - val_accuracy: 0.9467\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.1360 - accuracy: 0.9867 - val_loss: 0.1764 - val_accuracy: 0.9333\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.1352 - accuracy: 0.9733 - val_loss: 0.1733 - val_accuracy: 0.9467\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.1343 - accuracy: 0.9733 - val_loss: 0.1727 - val_accuracy: 0.9333\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.1335 - accuracy: 0.9733 - val_loss: 0.1695 - val_accuracy: 0.9467\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.1333 - accuracy: 0.9867 - val_loss: 0.1724 - val_accuracy: 0.9333\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.1323 - accuracy: 0.9733 - val_loss: 0.1675 - val_accuracy: 0.9467\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.1310 - accuracy: 0.9867 - val_loss: 0.1671 - val_accuracy: 0.9467\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.1313 - accuracy: 0.9867 - val_loss: 0.1717 - val_accuracy: 0.9333\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.1290 - accuracy: 0.9733 - val_loss: 0.1702 - val_accuracy: 0.9333\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.1283 - accuracy: 0.9867 - val_loss: 0.1687 - val_accuracy: 0.9333\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.1280 - accuracy: 0.9733 - val_loss: 0.1666 - val_accuracy: 0.9467\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.1279 - accuracy: 0.9733 - val_loss: 0.1601 - val_accuracy: 0.9467\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.1280 - accuracy: 0.9867 - val_loss: 0.1674 - val_accuracy: 0.9333\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.1253 - accuracy: 0.9867 - val_loss: 0.1717 - val_accuracy: 0.9333\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.1245 - accuracy: 0.9733 - val_loss: 0.1676 - val_accuracy: 0.9333\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.1241 - accuracy: 0.9733 - val_loss: 0.1633 - val_accuracy: 0.9467\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.1236 - accuracy: 0.9867 - val_loss: 0.1647 - val_accuracy: 0.9333\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.1231 - accuracy: 0.9733 - val_loss: 0.1639 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.1221 - accuracy: 0.9733 - val_loss: 0.1567 - val_accuracy: 0.9467\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 747us/sample - loss: 0.1225 - accuracy: 0.9867 - val_loss: 0.1599 - val_accuracy: 0.9467\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.1202 - accuracy: 0.9867 - val_loss: 0.1650 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.1198 - accuracy: 0.9733 - val_loss: 0.1622 - val_accuracy: 0.9333\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.1192 - accuracy: 0.9867 - val_loss: 0.1710 - val_accuracy: 0.9333\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.1182 - accuracy: 0.9733 - val_loss: 0.1670 - val_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.1178 - accuracy: 0.9733 - val_loss: 0.1587 - val_accuracy: 0.9467\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.1182 - accuracy: 0.9867 - val_loss: 0.1706 - val_accuracy: 0.9333\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.1177 - accuracy: 0.9733 - val_loss: 0.1742 - val_accuracy: 0.9333\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.1162 - accuracy: 0.9733 - val_loss: 0.1710 - val_accuracy: 0.9333\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.1151 - accuracy: 0.9733 - val_loss: 0.1631 - val_accuracy: 0.9333\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.1146 - accuracy: 0.9733 - val_loss: 0.1627 - val_accuracy: 0.9333\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.1128 - accuracy: 0.9733 - val_loss: 0.1606 - val_accuracy: 0.9333\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.1122 - accuracy: 0.9733 - val_loss: 0.1608 - val_accuracy: 0.9333\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.1116 - accuracy: 0.9733 - val_loss: 0.1568 - val_accuracy: 0.9333\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.1111 - accuracy: 0.9867 - val_loss: 0.1590 - val_accuracy: 0.9333\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 485us/sample - loss: 0.1110 - accuracy: 0.9733 - val_loss: 0.1544 - val_accuracy: 0.9467\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.1104 - accuracy: 0.9867 - val_loss: 0.1561 - val_accuracy: 0.9333\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.1094 - accuracy: 0.9867 - val_loss: 0.1564 - val_accuracy: 0.9333\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.1095 - accuracy: 0.9867 - val_loss: 0.1655 - val_accuracy: 0.9333\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.1090 - accuracy: 0.9733 - val_loss: 0.1688 - val_accuracy: 0.9333\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.1084 - accuracy: 0.9733 - val_loss: 0.1631 - val_accuracy: 0.9333\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.1071 - accuracy: 0.9733 - val_loss: 0.1600 - val_accuracy: 0.9333\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.1064 - accuracy: 0.9733 - val_loss: 0.1517 - val_accuracy: 0.9467\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.1055 - accuracy: 0.9867 - val_loss: 0.1494 - val_accuracy: 0.9467\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.1054 - accuracy: 0.9867 - val_loss: 0.1480 - val_accuracy: 0.9467\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.1045 - accuracy: 0.9867 - val_loss: 0.1519 - val_accuracy: 0.9333\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 509us/sample - loss: 0.1046 - accuracy: 0.9867 - val_loss: 0.1503 - val_accuracy: 0.9333\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.1042 - accuracy: 0.9733 - val_loss: 0.1512 - val_accuracy: 0.9333\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.1030 - accuracy: 0.9867 - val_loss: 0.1485 - val_accuracy: 0.9467\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.1025 - accuracy: 0.9867 - val_loss: 0.1468 - val_accuracy: 0.9467\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.1024 - accuracy: 0.9867 - val_loss: 0.1456 - val_accuracy: 0.9467\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.1014 - accuracy: 0.9867 - val_loss: 0.1527 - val_accuracy: 0.9333\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.1003 - accuracy: 0.9733 - val_loss: 0.1566 - val_accuracy: 0.9333\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.0997 - accuracy: 0.9733 - val_loss: 0.1556 - val_accuracy: 0.9333\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.1003 - accuracy: 0.9733 - val_loss: 0.1445 - val_accuracy: 0.9467\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.1015 - accuracy: 0.9733 - val_loss: 0.1438 - val_accuracy: 0.9467\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.1006 - accuracy: 0.9867 - val_loss: 0.1415 - val_accuracy: 0.9467\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.0987 - accuracy: 0.9867 - val_loss: 0.1417 - val_accuracy: 0.9467\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.0983 - accuracy: 0.9867 - val_loss: 0.1453 - val_accuracy: 0.9467\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 489us/sample - loss: 0.0967 - accuracy: 0.9867 - val_loss: 0.1507 - val_accuracy: 0.9333\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 513us/sample - loss: 0.0966 - accuracy: 0.9733 - val_loss: 0.1460 - val_accuracy: 0.9333\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.0958 - accuracy: 0.9867 - val_loss: 0.1538 - val_accuracy: 0.9333\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.0957 - accuracy: 0.9733 - val_loss: 0.1539 - val_accuracy: 0.9333\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.0952 - accuracy: 0.9733 - val_loss: 0.1437 - val_accuracy: 0.9467\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.0944 - accuracy: 0.9867 - val_loss: 0.1430 - val_accuracy: 0.9467\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.0941 - accuracy: 0.9867 - val_loss: 0.1460 - val_accuracy: 0.9333\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.0938 - accuracy: 0.9733 - val_loss: 0.1389 - val_accuracy: 0.9467\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.0940 - accuracy: 0.9867 - val_loss: 0.1399 - val_accuracy: 0.9467\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.0928 - accuracy: 0.9867 - val_loss: 0.1448 - val_accuracy: 0.9333\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.0919 - accuracy: 0.9867 - val_loss: 0.1465 - val_accuracy: 0.9333\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.0923 - accuracy: 0.9867 - val_loss: 0.1519 - val_accuracy: 0.9333\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.0914 - accuracy: 0.9733 - val_loss: 0.1432 - val_accuracy: 0.9333\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.0914 - accuracy: 0.9867 - val_loss: 0.1451 - val_accuracy: 0.9333\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.0905 - accuracy: 0.9733 - val_loss: 0.1402 - val_accuracy: 0.9467\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.0903 - accuracy: 0.9867 - val_loss: 0.1486 - val_accuracy: 0.9333\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.0905 - accuracy: 0.9733 - val_loss: 0.1447 - val_accuracy: 0.9333\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.0893 - accuracy: 0.9733 - val_loss: 0.1406 - val_accuracy: 0.9467\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.0895 - accuracy: 0.9867 - val_loss: 0.1398 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.0886 - accuracy: 0.9867 - val_loss: 0.1495 - val_accuracy: 0.9333\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 229us/sample - loss: 0.0881 - accuracy: 0.9733 - val_loss: 0.1554 - val_accuracy: 0.9333\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.0879 - accuracy: 0.9733 - val_loss: 0.1519 - val_accuracy: 0.9333\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.0884 - accuracy: 0.9733 - val_loss: 0.1621 - val_accuracy: 0.9200\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.0889 - accuracy: 0.9733 - val_loss: 0.1492 - val_accuracy: 0.9333\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.0870 - accuracy: 0.9733 - val_loss: 0.1570 - val_accuracy: 0.9200\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.0867 - accuracy: 0.9733 - val_loss: 0.1482 - val_accuracy: 0.9333\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.0872 - accuracy: 0.9733 - val_loss: 0.1400 - val_accuracy: 0.9333\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.0851 - accuracy: 0.9867 - val_loss: 0.1359 - val_accuracy: 0.9467\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 511us/sample - loss: 0.0850 - accuracy: 0.9867 - val_loss: 0.1401 - val_accuracy: 0.9333\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.0840 - accuracy: 0.9867 - val_loss: 0.1421 - val_accuracy: 0.9333\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.0849 - accuracy: 0.9733 - val_loss: 0.1393 - val_accuracy: 0.9333\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.0832 - accuracy: 0.9867 - val_loss: 0.1402 - val_accuracy: 0.9333\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 235us/sample - loss: 0.0835 - accuracy: 0.9867 - val_loss: 0.1350 - val_accuracy: 0.9467\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.0846 - accuracy: 0.9733 - val_loss: 0.1341 - val_accuracy: 0.9600\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.0826 - accuracy: 0.9867 - val_loss: 0.1387 - val_accuracy: 0.9333\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.0820 - accuracy: 0.9867 - val_loss: 0.1467 - val_accuracy: 0.9333\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.0816 - accuracy: 0.9733 - val_loss: 0.1410 - val_accuracy: 0.9333\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.0811 - accuracy: 0.9733 - val_loss: 0.1375 - val_accuracy: 0.9333\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.0821 - accuracy: 0.9867 - val_loss: 0.1514 - val_accuracy: 0.9200\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.0811 - accuracy: 0.9733 - val_loss: 0.1501 - val_accuracy: 0.9333\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.0805 - accuracy: 0.9733 - val_loss: 0.1452 - val_accuracy: 0.9333\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.0798 - accuracy: 0.9733 - val_loss: 0.1445 - val_accuracy: 0.9333\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.0796 - accuracy: 0.9733 - val_loss: 0.1477 - val_accuracy: 0.9333\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 0.0793 - accuracy: 0.9733 - val_loss: 0.1439 - val_accuracy: 0.9333\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.1408 - val_accuracy: 0.9333\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 242us/sample - loss: 0.0795 - accuracy: 0.9733 - val_loss: 0.1560 - val_accuracy: 0.9200\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 229us/sample - loss: 0.0800 - accuracy: 0.9733 - val_loss: 0.1536 - val_accuracy: 0.9200\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 237us/sample - loss: 0.0798 - accuracy: 0.9733 - val_loss: 0.1452 - val_accuracy: 0.9333\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.1414 - val_accuracy: 0.9333\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.0770 - accuracy: 0.9733 - val_loss: 0.1411 - val_accuracy: 0.9333\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.0771 - accuracy: 0.9733 - val_loss: 0.1420 - val_accuracy: 0.9333\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 0.0773 - accuracy: 0.9733 - val_loss: 0.1526 - val_accuracy: 0.9200\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 249us/sample - loss: 0.0794 - accuracy: 0.9733 - val_loss: 0.1440 - val_accuracy: 0.9333\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.0760 - accuracy: 0.9733 - val_loss: 0.1433 - val_accuracy: 0.9333\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.0757 - accuracy: 0.9733 - val_loss: 0.1400 - val_accuracy: 0.9333\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.0753 - accuracy: 0.9733 - val_loss: 0.1438 - val_accuracy: 0.9333\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.0754 - accuracy: 0.9733 - val_loss: 0.1401 - val_accuracy: 0.9333\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.0746 - accuracy: 0.9733 - val_loss: 0.1392 - val_accuracy: 0.9333\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.0742 - accuracy: 0.9733 - val_loss: 0.1402 - val_accuracy: 0.9333\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.0739 - accuracy: 0.9733 - val_loss: 0.1382 - val_accuracy: 0.9333\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 497us/sample - loss: 0.0744 - accuracy: 0.9733 - val_loss: 0.1430 - val_accuracy: 0.9333\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.0737 - accuracy: 0.9733 - val_loss: 0.1422 - val_accuracy: 0.9333\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 545us/sample - loss: 0.0749 - accuracy: 0.9733 - val_loss: 0.1400 - val_accuracy: 0.9333\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.0735 - accuracy: 0.9733 - val_loss: 0.1353 - val_accuracy: 0.9333\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 0.0732 - accuracy: 0.9733 - val_loss: 0.1395 - val_accuracy: 0.9333\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.0739 - accuracy: 0.9733 - val_loss: 0.1292 - val_accuracy: 0.9600\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.0723 - accuracy: 0.9867 - val_loss: 0.1300 - val_accuracy: 0.9467\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.0721 - accuracy: 0.9867 - val_loss: 0.1372 - val_accuracy: 0.9333\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.0715 - accuracy: 0.9733 - val_loss: 0.1360 - val_accuracy: 0.9333\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.0718 - accuracy: 0.9733 - val_loss: 0.1428 - val_accuracy: 0.9333\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.0715 - accuracy: 0.9733 - val_loss: 0.1409 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "history = neural_network_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?\n",
    " - med 5 lager och 10 noder i varje lager utom output-lagret har vi 413 träningsbara parametrar. Är det rimligt givet 75 obs i träningsdata setet?\n",
    " - Övertränar nätverket på träningsdatat?\n",
    " - Vad händer om du minskar antalet noder i vår modell, hur påverkar det accuracy för tränings och valideringsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.97333336\n",
      "accuracy, test:  0.93333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [0 0 2 0 0]\n",
      "\n",
      "Sannolikheter bakom prediktionerna\n",
      " ['setosa' 'versicolor' 'virginica'] \n",
      " [[7.740e-01 1.558e-01 7.020e-02]\n",
      " [7.740e-01 1.558e-01 7.020e-02]\n",
      " [4.100e-04 3.749e-01 6.247e-01]\n",
      " [7.740e-01 1.558e-01 7.020e-02]\n",
      " [7.740e-01 1.558e-01 7.020e-02]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category =  np.argmax(neural_network_model.predict(X_test[0:5]), axis=-1)\n",
    "\n",
    "probabilities = neural_network_model.predict(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktionerna\\n\",names,\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d. Neurala nätverk - Regularisering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi testar att köra vårat överdrivet stora neurala nätverk igen, denna gång med L1 och L2-regularisering\n",
    "\n",
    "- Vi utvärderar om introduktion av L1 och L2-regularisering kan mitigera överträning på träningsdatat\n",
    "- Testa gärna att förändra  antal_hidden_layer, antal_noder samt l1- / l2_reg_rate och utforska vad som händer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 413\n",
      "Trainable params: 413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 16ms/sample - loss: 2.2387 - accuracy: 0.3333 - val_loss: 2.2442 - val_accuracy: 0.3333\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 2.2123 - accuracy: 0.3333 - val_loss: 2.2206 - val_accuracy: 0.3333\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 2.1910 - accuracy: 0.3333 - val_loss: 2.1975 - val_accuracy: 0.3333\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 526us/sample - loss: 2.1713 - accuracy: 0.3333 - val_loss: 2.1782 - val_accuracy: 0.3333\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 2.1549 - accuracy: 0.3333 - val_loss: 2.1619 - val_accuracy: 0.3333\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 546us/sample - loss: 2.1391 - accuracy: 0.3333 - val_loss: 2.1454 - val_accuracy: 0.3333\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 2.1237 - accuracy: 0.3333 - val_loss: 2.1273 - val_accuracy: 0.3333\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 2.1078 - accuracy: 0.3333 - val_loss: 2.1113 - val_accuracy: 0.3333\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 2.0939 - accuracy: 0.3333 - val_loss: 2.0995 - val_accuracy: 0.3333\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 2.0820 - accuracy: 0.3600 - val_loss: 2.0873 - val_accuracy: 0.3333\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 2.0707 - accuracy: 0.3600 - val_loss: 2.0762 - val_accuracy: 0.3333\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 2.0596 - accuracy: 0.3600 - val_loss: 2.0649 - val_accuracy: 0.3467\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 2.0494 - accuracy: 0.3600 - val_loss: 2.0545 - val_accuracy: 0.3600\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 2.0396 - accuracy: 0.3600 - val_loss: 2.0431 - val_accuracy: 0.3600\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 2.0293 - accuracy: 0.3733 - val_loss: 2.0326 - val_accuracy: 0.3733\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 2.0194 - accuracy: 0.3733 - val_loss: 2.0230 - val_accuracy: 0.4000\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 2.0101 - accuracy: 0.3733 - val_loss: 2.0140 - val_accuracy: 0.4133\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 2.0015 - accuracy: 0.4533 - val_loss: 2.0059 - val_accuracy: 0.4667\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 1.9923 - accuracy: 0.4533 - val_loss: 1.9979 - val_accuracy: 0.4800\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.9844 - accuracy: 0.4933 - val_loss: 1.9901 - val_accuracy: 0.4800\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 1.9764 - accuracy: 0.4933 - val_loss: 1.9824 - val_accuracy: 0.4800\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 1.9691 - accuracy: 0.4933 - val_loss: 1.9751 - val_accuracy: 0.5200\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 1.9619 - accuracy: 0.5067 - val_loss: 1.9679 - val_accuracy: 0.5333\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 1.9547 - accuracy: 0.5200 - val_loss: 1.9605 - val_accuracy: 0.5600\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 1.9478 - accuracy: 0.5333 - val_loss: 1.9531 - val_accuracy: 0.6267\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 1.9411 - accuracy: 0.5600 - val_loss: 1.9466 - val_accuracy: 0.6533\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 1.9347 - accuracy: 0.5733 - val_loss: 1.9397 - val_accuracy: 0.6933\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 1.9274 - accuracy: 0.5733 - val_loss: 1.9330 - val_accuracy: 0.7067\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 1.9206 - accuracy: 0.5867 - val_loss: 1.9257 - val_accuracy: 0.7067\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 1.9139 - accuracy: 0.5867 - val_loss: 1.9190 - val_accuracy: 0.7200\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 1.9076 - accuracy: 0.6400 - val_loss: 1.9125 - val_accuracy: 0.7333\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 1.9013 - accuracy: 0.6400 - val_loss: 1.9058 - val_accuracy: 0.7200\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 1.8949 - accuracy: 0.6400 - val_loss: 1.8989 - val_accuracy: 0.7200\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 1.8883 - accuracy: 0.6533 - val_loss: 1.8925 - val_accuracy: 0.7200\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 1.8818 - accuracy: 0.6667 - val_loss: 1.8859 - val_accuracy: 0.7200\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 1.8754 - accuracy: 0.6667 - val_loss: 1.8795 - val_accuracy: 0.7467\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 1.8692 - accuracy: 0.6667 - val_loss: 1.8736 - val_accuracy: 0.7600\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 1.8628 - accuracy: 0.6800 - val_loss: 1.8668 - val_accuracy: 0.7600\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 1.8559 - accuracy: 0.6800 - val_loss: 1.8607 - val_accuracy: 0.7600\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 1.8495 - accuracy: 0.6933 - val_loss: 1.8539 - val_accuracy: 0.7600\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 1.8432 - accuracy: 0.7067 - val_loss: 1.8471 - val_accuracy: 0.7733\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 1.8368 - accuracy: 0.6933 - val_loss: 1.8418 - val_accuracy: 0.8000\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 1.8310 - accuracy: 0.7067 - val_loss: 1.8351 - val_accuracy: 0.8000\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 1.8249 - accuracy: 0.7067 - val_loss: 1.8287 - val_accuracy: 0.8000\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 1.8188 - accuracy: 0.7067 - val_loss: 1.8231 - val_accuracy: 0.8000\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 1.8125 - accuracy: 0.7467 - val_loss: 1.8173 - val_accuracy: 0.8133\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 1.8066 - accuracy: 0.7467 - val_loss: 1.8116 - val_accuracy: 0.8133\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 1.8005 - accuracy: 0.7600 - val_loss: 1.8057 - val_accuracy: 0.8133\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 1.7946 - accuracy: 0.7600 - val_loss: 1.7996 - val_accuracy: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 1.7886 - accuracy: 0.7600 - val_loss: 1.7936 - val_accuracy: 0.8133\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 1.7830 - accuracy: 0.7600 - val_loss: 1.7882 - val_accuracy: 0.8267\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 467us/sample - loss: 1.7774 - accuracy: 0.7600 - val_loss: 1.7827 - val_accuracy: 0.8267\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 1.7718 - accuracy: 0.7733 - val_loss: 1.7776 - val_accuracy: 0.8267\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 1.7663 - accuracy: 0.7733 - val_loss: 1.7722 - val_accuracy: 0.8267\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 1.7615 - accuracy: 0.7733 - val_loss: 1.7676 - val_accuracy: 0.8400\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 1.7556 - accuracy: 0.7733 - val_loss: 1.7618 - val_accuracy: 0.8400\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 1.7503 - accuracy: 0.7733 - val_loss: 1.7571 - val_accuracy: 0.8400\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 1.7449 - accuracy: 0.7733 - val_loss: 1.7518 - val_accuracy: 0.8400\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 1.7397 - accuracy: 0.7733 - val_loss: 1.7470 - val_accuracy: 0.8400\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.7344 - accuracy: 0.7867 - val_loss: 1.7421 - val_accuracy: 0.8400\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 1.7292 - accuracy: 0.7867 - val_loss: 1.7365 - val_accuracy: 0.8400\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.7235 - accuracy: 0.7867 - val_loss: 1.7316 - val_accuracy: 0.8533\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 1.7187 - accuracy: 0.7867 - val_loss: 1.7272 - val_accuracy: 0.8533\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 1.7137 - accuracy: 0.7867 - val_loss: 1.7218 - val_accuracy: 0.8533\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 1.7086 - accuracy: 0.7867 - val_loss: 1.7173 - val_accuracy: 0.8533\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 523us/sample - loss: 1.7042 - accuracy: 0.7867 - val_loss: 1.7119 - val_accuracy: 0.8533\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.6990 - accuracy: 0.7867 - val_loss: 1.7056 - val_accuracy: 0.8533\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 1.6932 - accuracy: 0.7867 - val_loss: 1.7010 - val_accuracy: 0.8533\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 1.6885 - accuracy: 0.7867 - val_loss: 1.6952 - val_accuracy: 0.8533\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 1.6835 - accuracy: 0.7867 - val_loss: 1.6894 - val_accuracy: 0.8533\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 538us/sample - loss: 1.6787 - accuracy: 0.7867 - val_loss: 1.6855 - val_accuracy: 0.8533\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 1.6738 - accuracy: 0.7867 - val_loss: 1.6802 - val_accuracy: 0.8533\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 1.6680 - accuracy: 0.7867 - val_loss: 1.6748 - val_accuracy: 0.8533\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 1.6626 - accuracy: 0.7867 - val_loss: 1.6695 - val_accuracy: 0.8533\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.6573 - accuracy: 0.7867 - val_loss: 1.6631 - val_accuracy: 0.8533\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 1.6513 - accuracy: 0.7867 - val_loss: 1.6586 - val_accuracy: 0.8533\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.6459 - accuracy: 0.7867 - val_loss: 1.6525 - val_accuracy: 0.8533\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 1.6398 - accuracy: 0.7867 - val_loss: 1.6469 - val_accuracy: 0.8533\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 1.6338 - accuracy: 0.7867 - val_loss: 1.6412 - val_accuracy: 0.8533\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 1.6276 - accuracy: 0.7867 - val_loss: 1.6354 - val_accuracy: 0.8667\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 1.6216 - accuracy: 0.7867 - val_loss: 1.6290 - val_accuracy: 0.8667\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 1.6156 - accuracy: 0.7867 - val_loss: 1.6225 - val_accuracy: 0.8667\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 1.6095 - accuracy: 0.7867 - val_loss: 1.6166 - val_accuracy: 0.8667\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 1.6034 - accuracy: 0.8000 - val_loss: 1.6101 - val_accuracy: 0.8667\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 1.5969 - accuracy: 0.8000 - val_loss: 1.6026 - val_accuracy: 0.8667\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 1.5903 - accuracy: 0.8000 - val_loss: 1.5963 - val_accuracy: 0.8667\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 1.5840 - accuracy: 0.8000 - val_loss: 1.5883 - val_accuracy: 0.8667\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 1.5770 - accuracy: 0.8000 - val_loss: 1.5805 - val_accuracy: 0.8667\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 1.5703 - accuracy: 0.8000 - val_loss: 1.5748 - val_accuracy: 0.8667\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 1.5636 - accuracy: 0.8133 - val_loss: 1.5692 - val_accuracy: 0.8667\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 1.5573 - accuracy: 0.8133 - val_loss: 1.5634 - val_accuracy: 0.8800\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 1.5526 - accuracy: 0.8133 - val_loss: 1.5572 - val_accuracy: 0.8800\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 1.5451 - accuracy: 0.8400 - val_loss: 1.5504 - val_accuracy: 0.8800\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 1.5387 - accuracy: 0.8400 - val_loss: 1.5441 - val_accuracy: 0.8800\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 1.5326 - accuracy: 0.8400 - val_loss: 1.5366 - val_accuracy: 0.8800\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 1.5265 - accuracy: 0.8400 - val_loss: 1.5301 - val_accuracy: 0.8800\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 1.5203 - accuracy: 0.8400 - val_loss: 1.5253 - val_accuracy: 0.8667\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 1.5144 - accuracy: 0.8400 - val_loss: 1.5175 - val_accuracy: 0.8800\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 1.5086 - accuracy: 0.8400 - val_loss: 1.5114 - val_accuracy: 0.8800\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 1.5028 - accuracy: 0.8400 - val_loss: 1.5058 - val_accuracy: 0.8800\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 459us/sample - loss: 1.4971 - accuracy: 0.8400 - val_loss: 1.5020 - val_accuracy: 0.8667\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 1.4914 - accuracy: 0.8400 - val_loss: 1.4962 - val_accuracy: 0.8667\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 1.4857 - accuracy: 0.8400 - val_loss: 1.4902 - val_accuracy: 0.8667\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 1.4798 - accuracy: 0.8400 - val_loss: 1.4848 - val_accuracy: 0.8667\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 1.4750 - accuracy: 0.8400 - val_loss: 1.4792 - val_accuracy: 0.8667\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 463us/sample - loss: 1.4686 - accuracy: 0.8400 - val_loss: 1.4731 - val_accuracy: 0.8667\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 1.4632 - accuracy: 0.8400 - val_loss: 1.4681 - val_accuracy: 0.8800\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 1.4585 - accuracy: 0.8533 - val_loss: 1.4615 - val_accuracy: 0.8667\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 1.4534 - accuracy: 0.8400 - val_loss: 1.4559 - val_accuracy: 0.8667\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 1.4471 - accuracy: 0.8400 - val_loss: 1.4488 - val_accuracy: 0.8667\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 1.4415 - accuracy: 0.8400 - val_loss: 1.4436 - val_accuracy: 0.8667\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 529us/sample - loss: 1.4366 - accuracy: 0.8400 - val_loss: 1.4394 - val_accuracy: 0.8800\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 618us/sample - loss: 1.4316 - accuracy: 0.8533 - val_loss: 1.4343 - val_accuracy: 0.8800\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 1.4265 - accuracy: 0.8533 - val_loss: 1.4293 - val_accuracy: 0.8800\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.4217 - accuracy: 0.8667 - val_loss: 1.4233 - val_accuracy: 0.8800\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 483us/sample - loss: 1.4169 - accuracy: 0.8400 - val_loss: 1.4172 - val_accuracy: 0.8800\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 1.4120 - accuracy: 0.8400 - val_loss: 1.4141 - val_accuracy: 0.8933\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 1.4072 - accuracy: 0.8667 - val_loss: 1.4077 - val_accuracy: 0.8800\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 1.4025 - accuracy: 0.8400 - val_loss: 1.4014 - val_accuracy: 0.8933\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 1.3979 - accuracy: 0.8400 - val_loss: 1.3967 - val_accuracy: 0.8933\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 1.3931 - accuracy: 0.8400 - val_loss: 1.3914 - val_accuracy: 0.8933\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 1.3884 - accuracy: 0.8400 - val_loss: 1.3869 - val_accuracy: 0.8800\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 1.3839 - accuracy: 0.8400 - val_loss: 1.3840 - val_accuracy: 0.8800\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 1.3790 - accuracy: 0.8667 - val_loss: 1.3790 - val_accuracy: 0.8933\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.3750 - accuracy: 0.8533 - val_loss: 1.3745 - val_accuracy: 0.8800\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 1.3701 - accuracy: 0.8667 - val_loss: 1.3705 - val_accuracy: 0.8933\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 1.3661 - accuracy: 0.8667 - val_loss: 1.3684 - val_accuracy: 0.9067\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.3615 - accuracy: 0.8933 - val_loss: 1.3646 - val_accuracy: 0.8933\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 1.3572 - accuracy: 0.8933 - val_loss: 1.3594 - val_accuracy: 0.8933\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 1.3531 - accuracy: 0.8933 - val_loss: 1.3525 - val_accuracy: 0.8800\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 1.3484 - accuracy: 0.8800 - val_loss: 1.3489 - val_accuracy: 0.8933\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 1.3437 - accuracy: 0.8933 - val_loss: 1.3432 - val_accuracy: 0.8800\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 1.3397 - accuracy: 0.8933 - val_loss: 1.3375 - val_accuracy: 0.8800\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 1.3356 - accuracy: 0.8667 - val_loss: 1.3339 - val_accuracy: 0.8800\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 489us/sample - loss: 1.3311 - accuracy: 0.8800 - val_loss: 1.3297 - val_accuracy: 0.8800\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 1.3274 - accuracy: 0.8800 - val_loss: 1.3241 - val_accuracy: 0.8933\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 1.3231 - accuracy: 0.8533 - val_loss: 1.3205 - val_accuracy: 0.8933\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 1.3198 - accuracy: 0.8667 - val_loss: 1.3159 - val_accuracy: 0.8933\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 1.3153 - accuracy: 0.8533 - val_loss: 1.3127 - val_accuracy: 0.8933\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 1.3113 - accuracy: 0.8667 - val_loss: 1.3079 - val_accuracy: 0.8933\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 1.3078 - accuracy: 0.8533 - val_loss: 1.3041 - val_accuracy: 0.8933\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 1.3042 - accuracy: 0.8667 - val_loss: 1.3015 - val_accuracy: 0.8800\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 1.2996 - accuracy: 0.8933 - val_loss: 1.2981 - val_accuracy: 0.8933\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 1.2960 - accuracy: 0.8933 - val_loss: 1.2951 - val_accuracy: 0.8933\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 1.2920 - accuracy: 0.8933 - val_loss: 1.2922 - val_accuracy: 0.9067\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 1.2883 - accuracy: 0.8933 - val_loss: 1.2896 - val_accuracy: 0.9200\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 1.2846 - accuracy: 0.8933 - val_loss: 1.2846 - val_accuracy: 0.9200\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.2809 - accuracy: 0.8933 - val_loss: 1.2817 - val_accuracy: 0.9200\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.2773 - accuracy: 0.8933 - val_loss: 1.2777 - val_accuracy: 0.9200\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 1.2739 - accuracy: 0.8933 - val_loss: 1.2728 - val_accuracy: 0.9067\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 1.2700 - accuracy: 0.8933 - val_loss: 1.2699 - val_accuracy: 0.9200\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 1.2665 - accuracy: 0.8933 - val_loss: 1.2660 - val_accuracy: 0.9200\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 1.2639 - accuracy: 0.8933 - val_loss: 1.2609 - val_accuracy: 0.9200\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 1.2598 - accuracy: 0.8933 - val_loss: 1.2569 - val_accuracy: 0.9200\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 1.2563 - accuracy: 0.8933 - val_loss: 1.2533 - val_accuracy: 0.9200\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 1.2532 - accuracy: 0.8933 - val_loss: 1.2498 - val_accuracy: 0.9200\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 1.2497 - accuracy: 0.8933 - val_loss: 1.2460 - val_accuracy: 0.9200\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 1.2462 - accuracy: 0.8933 - val_loss: 1.2436 - val_accuracy: 0.9200\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 1.2433 - accuracy: 0.8933 - val_loss: 1.2403 - val_accuracy: 0.9333\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 1.2395 - accuracy: 0.8933 - val_loss: 1.2371 - val_accuracy: 0.9333\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 1.2365 - accuracy: 0.8933 - val_loss: 1.2337 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 1.2326 - accuracy: 0.8933 - val_loss: 1.2312 - val_accuracy: 0.9333\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 1.2293 - accuracy: 0.8933 - val_loss: 1.2279 - val_accuracy: 0.9333\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 1.2261 - accuracy: 0.8933 - val_loss: 1.2243 - val_accuracy: 0.9333\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 1.2233 - accuracy: 0.8933 - val_loss: 1.2202 - val_accuracy: 0.9333\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 1.2202 - accuracy: 0.8933 - val_loss: 1.2184 - val_accuracy: 0.9333\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 1.2168 - accuracy: 0.8933 - val_loss: 1.2150 - val_accuracy: 0.9333\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 1.2135 - accuracy: 0.8933 - val_loss: 1.2125 - val_accuracy: 0.9333\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 1.2107 - accuracy: 0.8933 - val_loss: 1.2091 - val_accuracy: 0.9333\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 1.2073 - accuracy: 0.8933 - val_loss: 1.2058 - val_accuracy: 0.9333\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 1.2043 - accuracy: 0.8933 - val_loss: 1.2048 - val_accuracy: 0.9467\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 1.2012 - accuracy: 0.8933 - val_loss: 1.2020 - val_accuracy: 0.9467\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 1.1983 - accuracy: 0.8933 - val_loss: 1.1994 - val_accuracy: 0.9467\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 1.1954 - accuracy: 0.8933 - val_loss: 1.1984 - val_accuracy: 0.9467\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 1.1923 - accuracy: 0.9200 - val_loss: 1.1936 - val_accuracy: 0.9467\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 1.1900 - accuracy: 0.9200 - val_loss: 1.1888 - val_accuracy: 0.9600\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 1.1870 - accuracy: 0.8933 - val_loss: 1.1850 - val_accuracy: 0.9333\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 1.1843 - accuracy: 0.8933 - val_loss: 1.1835 - val_accuracy: 0.9600\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 1.1814 - accuracy: 0.8933 - val_loss: 1.1835 - val_accuracy: 0.9467\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 1.1784 - accuracy: 0.9200 - val_loss: 1.1795 - val_accuracy: 0.9467\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 1.1758 - accuracy: 0.9067 - val_loss: 1.1750 - val_accuracy: 0.9600\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 1.1735 - accuracy: 0.8933 - val_loss: 1.1706 - val_accuracy: 0.9333\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 1.1706 - accuracy: 0.8933 - val_loss: 1.1688 - val_accuracy: 0.9600\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 1.1683 - accuracy: 0.8933 - val_loss: 1.1688 - val_accuracy: 0.9467\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 1.1650 - accuracy: 0.9067 - val_loss: 1.1646 - val_accuracy: 0.9600\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 1.1621 - accuracy: 0.8933 - val_loss: 1.1642 - val_accuracy: 0.9467\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 1.1592 - accuracy: 0.9200 - val_loss: 1.1611 - val_accuracy: 0.9467\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 1.1614 - accuracy: 0.9200 - val_loss: 1.1597 - val_accuracy: 0.9467\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 1.1540 - accuracy: 0.9200 - val_loss: 1.1564 - val_accuracy: 0.9467\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.1515 - accuracy: 0.9200 - val_loss: 1.1539 - val_accuracy: 0.9467\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 1.1495 - accuracy: 0.9200 - val_loss: 1.1535 - val_accuracy: 0.9467\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.1471 - accuracy: 0.9200 - val_loss: 1.1483 - val_accuracy: 0.9467\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 1.1442 - accuracy: 0.9200 - val_loss: 1.1447 - val_accuracy: 0.9600\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 1.1418 - accuracy: 0.9067 - val_loss: 1.1453 - val_accuracy: 0.9467\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.1387 - accuracy: 0.9200 - val_loss: 1.1437 - val_accuracy: 0.9467\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 1.1364 - accuracy: 0.9200 - val_loss: 1.1399 - val_accuracy: 0.9467\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 1.1335 - accuracy: 0.9200 - val_loss: 1.1392 - val_accuracy: 0.9467\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 1.1318 - accuracy: 0.9200 - val_loss: 1.1402 - val_accuracy: 0.9467\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 1.1298 - accuracy: 0.9200 - val_loss: 1.1383 - val_accuracy: 0.9467\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 1.1270 - accuracy: 0.9333 - val_loss: 1.1392 - val_accuracy: 0.9333\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 1.1242 - accuracy: 0.9467 - val_loss: 1.1337 - val_accuracy: 0.9467\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 1.1227 - accuracy: 0.9333 - val_loss: 1.1289 - val_accuracy: 0.9467\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 1.1192 - accuracy: 0.9200 - val_loss: 1.1246 - val_accuracy: 0.9467\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.1164 - accuracy: 0.9200 - val_loss: 1.1207 - val_accuracy: 0.9467\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 1.1150 - accuracy: 0.9200 - val_loss: 1.1182 - val_accuracy: 0.9467\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.1121 - accuracy: 0.9200 - val_loss: 1.1192 - val_accuracy: 0.9467\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 1.1090 - accuracy: 0.9200 - val_loss: 1.1160 - val_accuracy: 0.9467\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 1.1068 - accuracy: 0.9200 - val_loss: 1.1161 - val_accuracy: 0.9467\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 1.1042 - accuracy: 0.9200 - val_loss: 1.1131 - val_accuracy: 0.9467\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 1.1020 - accuracy: 0.9200 - val_loss: 1.1117 - val_accuracy: 0.9467\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 1.1000 - accuracy: 0.9467 - val_loss: 1.1060 - val_accuracy: 0.9467\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 1.0976 - accuracy: 0.9200 - val_loss: 1.1050 - val_accuracy: 0.9467\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 1.0954 - accuracy: 0.9200 - val_loss: 1.1014 - val_accuracy: 0.9467\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 1.0933 - accuracy: 0.9200 - val_loss: 1.0998 - val_accuracy: 0.9467\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.0908 - accuracy: 0.9200 - val_loss: 1.0966 - val_accuracy: 0.9467\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 1.0885 - accuracy: 0.9200 - val_loss: 1.0946 - val_accuracy: 0.9467\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 1.0870 - accuracy: 0.9200 - val_loss: 1.0949 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 1.0841 - accuracy: 0.9333 - val_loss: 1.0967 - val_accuracy: 0.9333\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 1.0817 - accuracy: 0.9600 - val_loss: 1.0918 - val_accuracy: 0.9467\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 1.0596 - accuracy: 0.96 - 0s 375us/sample - loss: 1.0800 - accuracy: 0.9333 - val_loss: 1.0947 - val_accuracy: 0.9333\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 1.0778 - accuracy: 0.9600 - val_loss: 1.0909 - val_accuracy: 0.9333\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 1.0763 - accuracy: 0.9600 - val_loss: 1.0879 - val_accuracy: 0.9467\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 1.0730 - accuracy: 0.9600 - val_loss: 1.0827 - val_accuracy: 0.9467\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 1.0713 - accuracy: 0.9333 - val_loss: 1.0834 - val_accuracy: 0.9467\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 473us/sample - loss: 1.0687 - accuracy: 0.9467 - val_loss: 1.0828 - val_accuracy: 0.9333\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 626us/sample - loss: 1.0670 - accuracy: 0.9600 - val_loss: 1.0837 - val_accuracy: 0.9333\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 1.0650 - accuracy: 0.9467 - val_loss: 1.0789 - val_accuracy: 0.9333\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 523us/sample - loss: 1.0622 - accuracy: 0.9600 - val_loss: 1.0749 - val_accuracy: 0.9467\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 1.0599 - accuracy: 0.9600 - val_loss: 1.0726 - val_accuracy: 0.9467\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 1.0590 - accuracy: 0.9467 - val_loss: 1.0711 - val_accuracy: 0.9467\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 1.0563 - accuracy: 0.9467 - val_loss: 1.0675 - val_accuracy: 0.9467\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 1.0540 - accuracy: 0.9467 - val_loss: 1.0694 - val_accuracy: 0.9333\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 1.0518 - accuracy: 0.9600 - val_loss: 1.0655 - val_accuracy: 0.9467\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 1.0501 - accuracy: 0.9600 - val_loss: 1.0649 - val_accuracy: 0.9333\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.0488 - accuracy: 0.9600 - val_loss: 1.0629 - val_accuracy: 0.9333\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 1.0457 - accuracy: 0.9600 - val_loss: 1.0598 - val_accuracy: 0.9467\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 1.0440 - accuracy: 0.9600 - val_loss: 1.0579 - val_accuracy: 0.9467\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 1.0438 - accuracy: 0.9467 - val_loss: 1.0550 - val_accuracy: 0.9467\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 1.0403 - accuracy: 0.9467 - val_loss: 1.0506 - val_accuracy: 0.9467\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 1.0377 - accuracy: 0.9467 - val_loss: 1.0504 - val_accuracy: 0.9467\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.0357 - accuracy: 0.9467 - val_loss: 1.0483 - val_accuracy: 0.9467\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 1.0334 - accuracy: 0.9467 - val_loss: 1.0458 - val_accuracy: 0.9467\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 1.0321 - accuracy: 0.9467 - val_loss: 1.0462 - val_accuracy: 0.9467\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 1.0300 - accuracy: 0.9600 - val_loss: 1.0421 - val_accuracy: 0.9467\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 1.0278 - accuracy: 0.9467 - val_loss: 1.0416 - val_accuracy: 0.9467\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 1.0263 - accuracy: 0.9600 - val_loss: 1.0355 - val_accuracy: 0.9600\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 1.0247 - accuracy: 0.9333 - val_loss: 1.0395 - val_accuracy: 0.9467\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 1.0221 - accuracy: 0.9467 - val_loss: 1.0377 - val_accuracy: 0.9467\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 1.0203 - accuracy: 0.9600 - val_loss: 1.0376 - val_accuracy: 0.9467\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 1.0185 - accuracy: 0.9467 - val_loss: 1.0350 - val_accuracy: 0.9467\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 1.0165 - accuracy: 0.9600 - val_loss: 1.0318 - val_accuracy: 0.9467\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 1.0144 - accuracy: 0.9600 - val_loss: 1.0285 - val_accuracy: 0.9467\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 1.0124 - accuracy: 0.9467 - val_loss: 1.0267 - val_accuracy: 0.9467\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 1.0109 - accuracy: 0.9467 - val_loss: 1.0247 - val_accuracy: 0.9467\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 1.0086 - accuracy: 0.9467 - val_loss: 1.0244 - val_accuracy: 0.9467\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 1.0070 - accuracy: 0.9467 - val_loss: 1.0234 - val_accuracy: 0.9467\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.0050 - accuracy: 0.9600 - val_loss: 1.0234 - val_accuracy: 0.9467\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 1.0041 - accuracy: 0.9467 - val_loss: 1.0222 - val_accuracy: 0.9467\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 1.0020 - accuracy: 0.9600 - val_loss: 1.0189 - val_accuracy: 0.9467\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.9994 - accuracy: 0.9600 - val_loss: 1.0149 - val_accuracy: 0.9600\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 1.0050 - accuracy: 0.96 - 0s 427us/sample - loss: 0.9978 - accuracy: 0.9467 - val_loss: 1.0160 - val_accuracy: 0.9467\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.9969 - accuracy: 0.9733 - val_loss: 1.0131 - val_accuracy: 0.9467\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.9962 - accuracy: 0.9467 - val_loss: 1.0124 - val_accuracy: 0.9467\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.9941 - accuracy: 0.9467 - val_loss: 1.0095 - val_accuracy: 0.9467\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.9908 - accuracy: 0.9467 - val_loss: 1.0115 - val_accuracy: 0.9333\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.9887 - accuracy: 0.9733 - val_loss: 1.0070 - val_accuracy: 0.9467\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.9867 - accuracy: 0.9467 - val_loss: 1.0063 - val_accuracy: 0.9467\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.9853 - accuracy: 0.9467 - val_loss: 1.0048 - val_accuracy: 0.9467\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.9834 - accuracy: 0.9733 - val_loss: 1.0041 - val_accuracy: 0.9467\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.9816 - accuracy: 0.9733 - val_loss: 0.9981 - val_accuracy: 0.9600\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.9797 - accuracy: 0.9467 - val_loss: 0.9971 - val_accuracy: 0.9600\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.9776 - accuracy: 0.9467 - val_loss: 0.9977 - val_accuracy: 0.9467\n",
      "Epoch 273/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 357us/sample - loss: 0.9773 - accuracy: 0.9733 - val_loss: 0.9974 - val_accuracy: 0.9467\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.9747 - accuracy: 0.9733 - val_loss: 0.9972 - val_accuracy: 0.9333\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.9731 - accuracy: 0.9733 - val_loss: 0.9895 - val_accuracy: 0.9600\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.9706 - accuracy: 0.9467 - val_loss: 0.9881 - val_accuracy: 0.9600\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.9699 - accuracy: 0.9467 - val_loss: 0.9815 - val_accuracy: 0.9600\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.9704 - accuracy: 0.9467 - val_loss: 0.9806 - val_accuracy: 0.9600\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 568us/sample - loss: 0.9661 - accuracy: 0.9467 - val_loss: 0.9814 - val_accuracy: 0.9600\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.9640 - accuracy: 0.9467 - val_loss: 0.9817 - val_accuracy: 0.9600\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 503us/sample - loss: 0.9621 - accuracy: 0.9600 - val_loss: 0.9809 - val_accuracy: 0.9600\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.9606 - accuracy: 0.9600 - val_loss: 0.9834 - val_accuracy: 0.9467\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.9591 - accuracy: 0.9733 - val_loss: 0.9842 - val_accuracy: 0.9333\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.9585 - accuracy: 0.9733 - val_loss: 0.9805 - val_accuracy: 0.9467\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.9574 - accuracy: 0.9600 - val_loss: 0.9770 - val_accuracy: 0.9600\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.9538 - accuracy: 0.9733 - val_loss: 0.9763 - val_accuracy: 0.9600\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.9540 - accuracy: 0.9733 - val_loss: 0.9722 - val_accuracy: 0.9600\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.9501 - accuracy: 0.9600 - val_loss: 0.9715 - val_accuracy: 0.9600\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.9491 - accuracy: 0.9600 - val_loss: 0.9685 - val_accuracy: 0.9600\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.9472 - accuracy: 0.9600 - val_loss: 0.9630 - val_accuracy: 0.9600\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 512us/sample - loss: 0.9456 - accuracy: 0.9467 - val_loss: 0.9627 - val_accuracy: 0.9600\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.9439 - accuracy: 0.9600 - val_loss: 0.9623 - val_accuracy: 0.9600\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.9425 - accuracy: 0.9600 - val_loss: 0.9599 - val_accuracy: 0.9600\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.9425 - accuracy: 0.9467 - val_loss: 0.9599 - val_accuracy: 0.9600\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 459us/sample - loss: 0.9388 - accuracy: 0.9733 - val_loss: 0.9562 - val_accuracy: 0.9600\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.9376 - accuracy: 0.9733 - val_loss: 0.9536 - val_accuracy: 0.9600\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 458us/sample - loss: 0.9365 - accuracy: 0.9467 - val_loss: 0.9577 - val_accuracy: 0.9600\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 544us/sample - loss: 0.9353 - accuracy: 0.9600 - val_loss: 0.9543 - val_accuracy: 0.9600\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.9324 - accuracy: 0.9733 - val_loss: 0.9550 - val_accuracy: 0.9600\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.9303 - accuracy: 0.9600 - val_loss: 0.9528 - val_accuracy: 0.9600\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.9300 - accuracy: 0.9600 - val_loss: 0.9542 - val_accuracy: 0.9600\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.9275 - accuracy: 0.9733 - val_loss: 0.9535 - val_accuracy: 0.9600\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.9266 - accuracy: 0.9600 - val_loss: 0.9559 - val_accuracy: 0.9333\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.9259 - accuracy: 0.9733 - val_loss: 0.9493 - val_accuracy: 0.9600\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.9223 - accuracy: 0.9733 - val_loss: 0.9469 - val_accuracy: 0.9600\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.9212 - accuracy: 0.9733 - val_loss: 0.9495 - val_accuracy: 0.9467\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.9205 - accuracy: 0.9733 - val_loss: 0.9427 - val_accuracy: 0.9600\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.9180 - accuracy: 0.9600 - val_loss: 0.9435 - val_accuracy: 0.9600\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.9161 - accuracy: 0.9600 - val_loss: 0.9423 - val_accuracy: 0.9600\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.9144 - accuracy: 0.9733 - val_loss: 0.9387 - val_accuracy: 0.9600\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.9146 - accuracy: 0.9600 - val_loss: 0.9342 - val_accuracy: 0.9600\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.9121 - accuracy: 0.9600 - val_loss: 0.9347 - val_accuracy: 0.9600\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.9100 - accuracy: 0.9600 - val_loss: 0.9337 - val_accuracy: 0.9600\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.9081 - accuracy: 0.9600 - val_loss: 0.9352 - val_accuracy: 0.9600\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 476us/sample - loss: 0.9072 - accuracy: 0.9600 - val_loss: 0.9375 - val_accuracy: 0.9467\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.9060 - accuracy: 0.9733 - val_loss: 0.9307 - val_accuracy: 0.9600\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.9033 - accuracy: 0.9600 - val_loss: 0.9290 - val_accuracy: 0.9600\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.9033 - accuracy: 0.9600 - val_loss: 0.9233 - val_accuracy: 0.9600\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.9002 - accuracy: 0.9733 - val_loss: 0.9201 - val_accuracy: 0.9600\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 457us/sample - loss: 0.8992 - accuracy: 0.9733 - val_loss: 0.9204 - val_accuracy: 0.9600\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.8971 - accuracy: 0.9600 - val_loss: 0.9189 - val_accuracy: 0.9600\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.8958 - accuracy: 0.9733 - val_loss: 0.9168 - val_accuracy: 0.9600\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 521us/sample - loss: 0.8943 - accuracy: 0.9600 - val_loss: 0.9150 - val_accuracy: 0.9600\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.8932 - accuracy: 0.9733 - val_loss: 0.9203 - val_accuracy: 0.9600\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.8914 - accuracy: 0.9733 - val_loss: 0.9186 - val_accuracy: 0.9600\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.8907 - accuracy: 0.9733 - val_loss: 0.9115 - val_accuracy: 0.9600\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.8903 - accuracy: 0.9600 - val_loss: 0.9076 - val_accuracy: 0.9600\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.8874 - accuracy: 0.9733 - val_loss: 0.9058 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.8856 - accuracy: 0.9733 - val_loss: 0.9092 - val_accuracy: 0.9600\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.8840 - accuracy: 0.9600 - val_loss: 0.9100 - val_accuracy: 0.9600\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.8823 - accuracy: 0.9600 - val_loss: 0.9070 - val_accuracy: 0.9600\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.8807 - accuracy: 0.9600 - val_loss: 0.9047 - val_accuracy: 0.9600\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 610us/sample - loss: 0.8802 - accuracy: 0.9600 - val_loss: 0.9014 - val_accuracy: 0.9600\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.8780 - accuracy: 0.9733 - val_loss: 0.9023 - val_accuracy: 0.9600\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 541us/sample - loss: 0.8765 - accuracy: 0.9600 - val_loss: 0.8995 - val_accuracy: 0.9600\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 515us/sample - loss: 0.8748 - accuracy: 0.9600 - val_loss: 0.8992 - val_accuracy: 0.9600\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.8736 - accuracy: 0.9600 - val_loss: 0.8960 - val_accuracy: 0.9600\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.8719 - accuracy: 0.9600 - val_loss: 0.8951 - val_accuracy: 0.9600\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 543us/sample - loss: 0.8719 - accuracy: 0.9600 - val_loss: 0.8964 - val_accuracy: 0.9600\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 510us/sample - loss: 0.8692 - accuracy: 0.9600 - val_loss: 0.8986 - val_accuracy: 0.9600\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.8678 - accuracy: 0.9600 - val_loss: 0.8965 - val_accuracy: 0.9600\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.8670 - accuracy: 0.9600 - val_loss: 0.8962 - val_accuracy: 0.9600\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.8659 - accuracy: 0.9600 - val_loss: 0.9001 - val_accuracy: 0.9467\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.8647 - accuracy: 0.9733 - val_loss: 0.8962 - val_accuracy: 0.9600\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.8631 - accuracy: 0.9733 - val_loss: 0.8888 - val_accuracy: 0.9600\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.8602 - accuracy: 0.9600 - val_loss: 0.8872 - val_accuracy: 0.9600\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.8595 - accuracy: 0.9600 - val_loss: 0.8929 - val_accuracy: 0.9600\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.8597 - accuracy: 0.9600 - val_loss: 0.8915 - val_accuracy: 0.9600\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.8570 - accuracy: 0.9733 - val_loss: 0.8869 - val_accuracy: 0.9600\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.8548 - accuracy: 0.9733 - val_loss: 0.8812 - val_accuracy: 0.9600\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.8531 - accuracy: 0.9600 - val_loss: 0.8775 - val_accuracy: 0.9600\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.8517 - accuracy: 0.9600 - val_loss: 0.8791 - val_accuracy: 0.9600\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.8513 - accuracy: 0.9733 - val_loss: 0.8733 - val_accuracy: 0.9600\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.8519 - accuracy: 0.9600 - val_loss: 0.8733 - val_accuracy: 0.9600\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.8489 - accuracy: 0.9600 - val_loss: 0.8729 - val_accuracy: 0.9600\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.8482 - accuracy: 0.9600 - val_loss: 0.8733 - val_accuracy: 0.9600\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 0.8459 - accuracy: 0.9600 - val_loss: 0.8805 - val_accuracy: 0.9600\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.8445 - accuracy: 0.9733 - val_loss: 0.8717 - val_accuracy: 0.9600\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.8420 - accuracy: 0.9600 - val_loss: 0.8668 - val_accuracy: 0.9600\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.8403 - accuracy: 0.9600 - val_loss: 0.8655 - val_accuracy: 0.9600\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.8392 - accuracy: 0.9600 - val_loss: 0.8654 - val_accuracy: 0.9600\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 490us/sample - loss: 0.8375 - accuracy: 0.9600 - val_loss: 0.8631 - val_accuracy: 0.9600\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.8363 - accuracy: 0.9600 - val_loss: 0.8595 - val_accuracy: 0.9600\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.8356 - accuracy: 0.9600 - val_loss: 0.8588 - val_accuracy: 0.9600\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.8424 - accuracy: 0.96 - 0s 329us/sample - loss: 0.8337 - accuracy: 0.9600 - val_loss: 0.8553 - val_accuracy: 0.9600\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.8345 - accuracy: 0.9733 - val_loss: 0.8558 - val_accuracy: 0.9600\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.8312 - accuracy: 0.9600 - val_loss: 0.8537 - val_accuracy: 0.9600\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.8297 - accuracy: 0.9600 - val_loss: 0.8542 - val_accuracy: 0.9600\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.8281 - accuracy: 0.9600 - val_loss: 0.8526 - val_accuracy: 0.9600\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.8279 - accuracy: 0.9600 - val_loss: 0.8495 - val_accuracy: 0.9600\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.8257 - accuracy: 0.9600 - val_loss: 0.8511 - val_accuracy: 0.9600\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.8240 - accuracy: 0.9600 - val_loss: 0.8526 - val_accuracy: 0.9600\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.8229 - accuracy: 0.9600 - val_loss: 0.8493 - val_accuracy: 0.9600\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.8214 - accuracy: 0.9600 - val_loss: 0.8490 - val_accuracy: 0.9600\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.8199 - accuracy: 0.9600 - val_loss: 0.8461 - val_accuracy: 0.9600\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 0.8191 - accuracy: 0.9600 - val_loss: 0.8466 - val_accuracy: 0.9600\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.8176 - accuracy: 0.9600 - val_loss: 0.8437 - val_accuracy: 0.9600\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.8159 - accuracy: 0.9600 - val_loss: 0.8419 - val_accuracy: 0.9600\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.8154 - accuracy: 0.9600 - val_loss: 0.8428 - val_accuracy: 0.9600\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.8133 - accuracy: 0.9600 - val_loss: 0.8425 - val_accuracy: 0.9600\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.8121 - accuracy: 0.9600 - val_loss: 0.8390 - val_accuracy: 0.9600\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.8111 - accuracy: 0.9600 - val_loss: 0.8356 - val_accuracy: 0.9600\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.8102 - accuracy: 0.9600 - val_loss: 0.8306 - val_accuracy: 0.9600\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 326us/sample - loss: 0.8094 - accuracy: 0.9600 - val_loss: 0.8344 - val_accuracy: 0.9600\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.8071 - accuracy: 0.9600 - val_loss: 0.8372 - val_accuracy: 0.9600\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.8059 - accuracy: 0.9600 - val_loss: 0.8329 - val_accuracy: 0.9600\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.8050 - accuracy: 0.9600 - val_loss: 0.8289 - val_accuracy: 0.9600\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.8041 - accuracy: 0.9600 - val_loss: 0.8307 - val_accuracy: 0.9600\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.8023 - accuracy: 0.9600 - val_loss: 0.8286 - val_accuracy: 0.9600\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.8014 - accuracy: 0.9600 - val_loss: 0.8214 - val_accuracy: 0.9600\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.8011 - accuracy: 0.9733 - val_loss: 0.8231 - val_accuracy: 0.9600\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.7984 - accuracy: 0.9600 - val_loss: 0.8260 - val_accuracy: 0.9600\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 476us/sample - loss: 0.7972 - accuracy: 0.9600 - val_loss: 0.8221 - val_accuracy: 0.9600\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.7963 - accuracy: 0.9600 - val_loss: 0.8277 - val_accuracy: 0.9600\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.7948 - accuracy: 0.9600 - val_loss: 0.8242 - val_accuracy: 0.9600\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.7940 - accuracy: 0.9600 - val_loss: 0.8179 - val_accuracy: 0.9600\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.7934 - accuracy: 0.9600 - val_loss: 0.8233 - val_accuracy: 0.9600\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.7920 - accuracy: 0.9600 - val_loss: 0.8253 - val_accuracy: 0.9600\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.7903 - accuracy: 0.9600 - val_loss: 0.8236 - val_accuracy: 0.9600\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.7893 - accuracy: 0.9600 - val_loss: 0.8182 - val_accuracy: 0.9600\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.7886 - accuracy: 0.9600 - val_loss: 0.8175 - val_accuracy: 0.9600\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.7862 - accuracy: 0.9600 - val_loss: 0.8153 - val_accuracy: 0.9600\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.7849 - accuracy: 0.9600 - val_loss: 0.8134 - val_accuracy: 0.9600\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 0.7838 - accuracy: 0.9600 - val_loss: 0.8094 - val_accuracy: 0.9600\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.7830 - accuracy: 0.9600 - val_loss: 0.8118 - val_accuracy: 0.9600\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 526us/sample - loss: 0.7819 - accuracy: 0.9600 - val_loss: 0.8085 - val_accuracy: 0.9600\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.7813 - accuracy: 0.9600 - val_loss: 0.8082 - val_accuracy: 0.9600\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 469us/sample - loss: 0.7791 - accuracy: 0.9600 - val_loss: 0.8073 - val_accuracy: 0.9600\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.7784 - accuracy: 0.9600 - val_loss: 0.8113 - val_accuracy: 0.9600\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.7776 - accuracy: 0.9600 - val_loss: 0.8134 - val_accuracy: 0.9600\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.7762 - accuracy: 0.9600 - val_loss: 0.8090 - val_accuracy: 0.9600\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.7746 - accuracy: 0.9600 - val_loss: 0.8064 - val_accuracy: 0.9600\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.7734 - accuracy: 0.9600 - val_loss: 0.8006 - val_accuracy: 0.9600\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.7722 - accuracy: 0.9600 - val_loss: 0.7977 - val_accuracy: 0.9600\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.7709 - accuracy: 0.9600 - val_loss: 0.7965 - val_accuracy: 0.9600\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.7697 - accuracy: 0.9600 - val_loss: 0.7985 - val_accuracy: 0.9600\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.7697 - accuracy: 0.9600 - val_loss: 0.7953 - val_accuracy: 0.9600\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.7687 - accuracy: 0.9600 - val_loss: 0.7950 - val_accuracy: 0.9600\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.7668 - accuracy: 0.9600 - val_loss: 0.7910 - val_accuracy: 0.9600\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.7652 - accuracy: 0.9600 - val_loss: 0.7894 - val_accuracy: 0.9600\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.7643 - accuracy: 0.9600 - val_loss: 0.7883 - val_accuracy: 0.9600\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.7631 - accuracy: 0.9600 - val_loss: 0.7923 - val_accuracy: 0.9600\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.7617 - accuracy: 0.9600 - val_loss: 0.7936 - val_accuracy: 0.9600\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.7606 - accuracy: 0.9600 - val_loss: 0.7922 - val_accuracy: 0.9600\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 769us/sample - loss: 0.7601 - accuracy: 0.9600 - val_loss: 0.7845 - val_accuracy: 0.9600\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.7603 - accuracy: 0.9600 - val_loss: 0.7825 - val_accuracy: 0.9600\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.7587 - accuracy: 0.9600 - val_loss: 0.7803 - val_accuracy: 0.9600\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.7563 - accuracy: 0.9600 - val_loss: 0.7785 - val_accuracy: 0.9600\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.7555 - accuracy: 0.9600 - val_loss: 0.7805 - val_accuracy: 0.9600\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.7535 - accuracy: 0.9600 - val_loss: 0.7808 - val_accuracy: 0.9600\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.7527 - accuracy: 0.9600 - val_loss: 0.7771 - val_accuracy: 0.9600\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.7515 - accuracy: 0.9600 - val_loss: 0.7809 - val_accuracy: 0.9600\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.7506 - accuracy: 0.9600 - val_loss: 0.7817 - val_accuracy: 0.9600\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.7495 - accuracy: 0.9600 - val_loss: 0.7741 - val_accuracy: 0.9600\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.7481 - accuracy: 0.9600 - val_loss: 0.7728 - val_accuracy: 0.9600\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.7473 - accuracy: 0.9600 - val_loss: 0.7731 - val_accuracy: 0.9600\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.7465 - accuracy: 0.9600 - val_loss: 0.7685 - val_accuracy: 0.9600\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.7453 - accuracy: 0.9600 - val_loss: 0.7678 - val_accuracy: 0.9600\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.7439 - accuracy: 0.9600 - val_loss: 0.7693 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.7426 - accuracy: 0.9600 - val_loss: 0.7695 - val_accuracy: 0.9600\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.7426 - accuracy: 0.9600 - val_loss: 0.7726 - val_accuracy: 0.9600\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 604us/sample - loss: 0.7408 - accuracy: 0.9600 - val_loss: 0.7657 - val_accuracy: 0.9600\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.7405 - accuracy: 0.9600 - val_loss: 0.7670 - val_accuracy: 0.9600\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.7389 - accuracy: 0.9600 - val_loss: 0.7627 - val_accuracy: 0.9600\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.7376 - accuracy: 0.9600 - val_loss: 0.7659 - val_accuracy: 0.9600\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.7366 - accuracy: 0.9600 - val_loss: 0.7628 - val_accuracy: 0.9600\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.7355 - accuracy: 0.9600 - val_loss: 0.7602 - val_accuracy: 0.9600\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.7346 - accuracy: 0.9600 - val_loss: 0.7589 - val_accuracy: 0.9600\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.7332 - accuracy: 0.9600 - val_loss: 0.7622 - val_accuracy: 0.9600\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.7320 - accuracy: 0.9600 - val_loss: 0.7638 - val_accuracy: 0.9600\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 501us/sample - loss: 0.7313 - accuracy: 0.9600 - val_loss: 0.7629 - val_accuracy: 0.9600\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 534us/sample - loss: 0.7314 - accuracy: 0.9600 - val_loss: 0.7706 - val_accuracy: 0.9600\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.7312 - accuracy: 0.9600 - val_loss: 0.7634 - val_accuracy: 0.9600\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.7288 - accuracy: 0.9600 - val_loss: 0.7670 - val_accuracy: 0.9600\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.7278 - accuracy: 0.9733 - val_loss: 0.7596 - val_accuracy: 0.9600\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.7284 - accuracy: 0.9600 - val_loss: 0.7522 - val_accuracy: 0.9600\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.7251 - accuracy: 0.9600 - val_loss: 0.7479 - val_accuracy: 0.9600\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.7241 - accuracy: 0.9600 - val_loss: 0.7503 - val_accuracy: 0.9600\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.7225 - accuracy: 0.9600 - val_loss: 0.7498 - val_accuracy: 0.9600\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.7223 - accuracy: 0.9600 - val_loss: 0.7487 - val_accuracy: 0.9600\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.7204 - accuracy: 0.9600 - val_loss: 0.7498 - val_accuracy: 0.9600\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.7199 - accuracy: 0.9600 - val_loss: 0.7434 - val_accuracy: 0.9600\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.7201 - accuracy: 0.9600 - val_loss: 0.7407 - val_accuracy: 0.9600\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.7180 - accuracy: 0.9600 - val_loss: 0.7434 - val_accuracy: 0.9600\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.7164 - accuracy: 0.9600 - val_loss: 0.7457 - val_accuracy: 0.9600\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.7152 - accuracy: 0.9600 - val_loss: 0.7426 - val_accuracy: 0.9600\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 515us/sample - loss: 0.7144 - accuracy: 0.9600 - val_loss: 0.7406 - val_accuracy: 0.9600\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 550us/sample - loss: 0.7140 - accuracy: 0.9600 - val_loss: 0.7470 - val_accuracy: 0.9600\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 511us/sample - loss: 0.7131 - accuracy: 0.9600 - val_loss: 0.7488 - val_accuracy: 0.9600\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 0.7119 - accuracy: 0.9600 - val_loss: 0.7443 - val_accuracy: 0.9600\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.7104 - accuracy: 0.9600 - val_loss: 0.7439 - val_accuracy: 0.9600\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 459us/sample - loss: 0.7096 - accuracy: 0.9600 - val_loss: 0.7445 - val_accuracy: 0.9600\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 510us/sample - loss: 0.7087 - accuracy: 0.9600 - val_loss: 0.7423 - val_accuracy: 0.9600\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.7078 - accuracy: 0.9600 - val_loss: 0.7383 - val_accuracy: 0.9600\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 519us/sample - loss: 0.7071 - accuracy: 0.9600 - val_loss: 0.7454 - val_accuracy: 0.9600\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 518us/sample - loss: 0.7067 - accuracy: 0.9733 - val_loss: 0.7430 - val_accuracy: 0.9600\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.7067 - accuracy: 0.9600 - val_loss: 0.7387 - val_accuracy: 0.9600\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.7047 - accuracy: 0.9600 - val_loss: 0.7349 - val_accuracy: 0.9600\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.7024 - accuracy: 0.9600 - val_loss: 0.7346 - val_accuracy: 0.9600\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.7013 - accuracy: 0.9600 - val_loss: 0.7342 - val_accuracy: 0.9600\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 0.7013 - accuracy: 0.9600 - val_loss: 0.7405 - val_accuracy: 0.9733\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 509us/sample - loss: 0.7015 - accuracy: 0.9733 - val_loss: 0.7348 - val_accuracy: 0.9600\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 554us/sample - loss: 0.6989 - accuracy: 0.9600 - val_loss: 0.7328 - val_accuracy: 0.9600\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.6975 - accuracy: 0.9600 - val_loss: 0.7285 - val_accuracy: 0.9600\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 655us/sample - loss: 0.6965 - accuracy: 0.9600 - val_loss: 0.7308 - val_accuracy: 0.9600\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.6956 - accuracy: 0.9600 - val_loss: 0.7275 - val_accuracy: 0.9600\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.6943 - accuracy: 0.9600 - val_loss: 0.7247 - val_accuracy: 0.9600\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.6932 - accuracy: 0.9600 - val_loss: 0.7231 - val_accuracy: 0.9600\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.6922 - accuracy: 0.9600 - val_loss: 0.7204 - val_accuracy: 0.9600\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 617us/sample - loss: 0.6922 - accuracy: 0.9600 - val_loss: 0.7212 - val_accuracy: 0.9600\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.6907 - accuracy: 0.9600 - val_loss: 0.7220 - val_accuracy: 0.9600\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 571us/sample - loss: 0.6904 - accuracy: 0.9600 - val_loss: 0.7199 - val_accuracy: 0.9600\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.6900 - accuracy: 0.9600 - val_loss: 0.7154 - val_accuracy: 0.9600\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.6880 - accuracy: 0.9600 - val_loss: 0.7169 - val_accuracy: 0.9600\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.7084 - accuracy: 0.93 - 0s 429us/sample - loss: 0.6878 - accuracy: 0.9600 - val_loss: 0.7116 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.6857 - accuracy: 0.9600 - val_loss: 0.7095 - val_accuracy: 0.9600\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.6850 - accuracy: 0.9600 - val_loss: 0.7126 - val_accuracy: 0.9600\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.6836 - accuracy: 0.9600 - val_loss: 0.7119 - val_accuracy: 0.9600\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 0.6828 - accuracy: 0.9600 - val_loss: 0.7128 - val_accuracy: 0.9600\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.6819 - accuracy: 0.9600 - val_loss: 0.7119 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "# Storlek på Neuralt Nätverk\n",
    "antal_hidden_layer = 3 # Djup\n",
    "antal_noder = 10 # Bredd per lager\n",
    "\n",
    "#Regulariseringsparametrar\n",
    "l1_reg_rate = 0.01\n",
    "l2_reg_rate = 0.01\n",
    "\n",
    "# Definiera forward propagation\n",
    "neural_network_model = Sequential()\n",
    "\n",
    "# Input lager \n",
    "neural_network_model.add(Dense(antal_noder, input_dim=4, activation='relu'))\n",
    "\n",
    "#Hidden lager\n",
    "for l in range(antal_hidden_layer):\n",
    "    neural_network_model.add(Dense(antal_noder, activation='relu', kernel_regularizer=L1L2(l1=l1_reg_rate, l2=l2_reg_rate)))\n",
    "\n",
    "#Output lager\n",
    "neural_network_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "neural_network_model.compile(optimizer='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "neural_network_model.summary()\n",
    "\n",
    "history = neural_network_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?\n",
    " - Löser regularisering vårt problem med överträning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.96\n",
      "accuracy, test:  0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slutsats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- I denna övning har vi utforskat likheterna mellan neurala nätverk och logistisk regression\n",
    "\n",
    "\n",
    "- Introducerat större neurala nätverk och de komplexa samband som kan hanteras mha icke-linjaritet\n",
    "\n",
    "\n",
    "- Utforskat vad som händer om du bygger för stort neuralt nätverk relativt till träningsdata\n",
    "\n",
    "\n",
    "- Redovisat att regularisering kan öka neurala nätverkets generaliserbarhet till test-datat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
