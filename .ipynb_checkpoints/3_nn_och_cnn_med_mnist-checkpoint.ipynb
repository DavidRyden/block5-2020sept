{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Grundläggande neuralt nätverk med MNIST data setet\n",
    "\n",
    "Ett av de första fallen där Neurala nätverk visade sig effektiva och välpresterande var vid igenkänning av handskrivna Postkoder för  den Amerikanska Posten. Nätverket som kallades LeNet skapades av Yann Lecun på 1990-talet.\n",
    "\n",
    "I denna övning ska vi lära ett neuralt nätverk att klassificera handskriva siffror korrekt. Övningen är en typisk första övning inom neurala nätverk, hämtad från boken \"Deep Learning with Python\" av Francois Chollet som även byggt Keras. Rekommenderas för den som vill gräva djupare!\n",
    "\n",
    "\n",
    "Boken \"Deep Learning with Python\": https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff\n",
    "\n",
    "Github med tillhörande notebooks: https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "\n",
    "#### Urval av data från MNIST-datasetet\n",
    "![](https://www.researchgate.net/profile/Steven_Young11/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST-datasetet består av 70 000 bilder på handskrivna siffror. Namnet MNIST, Modified National Institute of Standards and Technology, kommer från institutet som skapade data setet med ett M tillagt då man modifierat det ursprungliga NIST-datasetet\n",
    "\n",
    "Bilderna består av handskrivna tal, från 0 till och med 9, i gråskala och med enbart 28x28 pixlar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hämtar data från github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/DavidRyden/block5-2020sept.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Hjälpfunktioner\n",
    "\n",
    "- Används senare för att plotta modellutvärdering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(hist):\n",
    "    \n",
    "    print(\"accuracy, train: \", hist['accuracy'][-1])\n",
    "    print(\"accuracy, validation: \", hist['val_accuracy'][-1])\n",
    "    \n",
    "    # Credd : https://janakiev.com/notebooks/keras-iris/\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(hist['accuracy'])\n",
    "    plt.plot(hist['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(hist['loss'])\n",
    "    plt.plot(hist['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import av bibliotek \n",
    "\n",
    " Vi importerar Keras, som i sin tur använder TensorFlow som backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importera data\n",
    "\n",
    "MNIST är ett standard data set, till den grad att det redan finns att hämta direkt från Keras!\n",
    "\n",
    "Vi skapar här 4 stycken arrayer:\n",
    "- train_images, träningsdata bestående av 60 000 bilder med 28x28 pixlar\n",
    "- train_labels, 60 000 träningsetiketter som berättar vilken siffra träningsdatat ska representera\n",
    "\n",
    "\n",
    "- test_images, 10 000 bilder som används för att testa modellen\n",
    "- test_labels, 10 000 etiketter fför att testa modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Träningsdatat består alltså av 60 000 bilder som alla representeras av en matris med 28 kolumner och 28 rader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_labels består av en vektor med 60 000 rader, där varje rad säger vad train_image ska representera för siffra mellan 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Första träningsbilden\n",
    "\n",
    "Tittar vi enbart på den första bilden i train_images,  train_images[0],  så får vi grepp om hur en bild representeras:\n",
    "\n",
    "- 28 kolumner och 28 rader\n",
    "- De flesta celler är 0, vilket innebär att de är svarta\n",
    "- Cellerna i mitten symboliserar i detta fall en handskriven femma, desto närmare värdet 255 desto vitare är pixeln \n",
    "\n",
    "##### Exempel på första bilden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print (train_images[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I en formaterad version, blir det tydligt vad vår 28x28-matris  representerar:\n",
    "\n",
    "![](https://github.com/DavidRyden/pics/blob/master/picture%20of%205.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### test_images och test_labels\n",
    "    \n",
    "  - test_images består av 10 000 matris-representationer av handskriva siffror på precis på samma sätt som train_images\n",
    "  \n",
    "  - test_labels ger svaren på dessa test_images\n",
    "  \n",
    "  - Nedan är de två första observationerna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image nr 0 föreställer:  7 \n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image nr 1 föreställer:  2 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.imshow(test_images[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"Test image nr 0 föreställer: \",test_labels[0] , \"\\n \\n\")\n",
    "\n",
    "plt.imshow(test_images[1], cmap='gray')\n",
    "plt.show()\n",
    "print(\"Test image nr 1 föreställer: \",test_labels[1], \"\\n \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Skapa neuralt nätverk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi använder datat till vår neurala nätverks-modell som vilken annan modell:\n",
    "\n",
    "1. Vi låter vårt neurala nätverk träna på `train_images` och `train_labels`\n",
    "2. Vi verifierar vår modells prediktioner med hjälp av `test_images` och `test_labels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grundläggande struktur\n",
    "\n",
    "Vi skapar här en grundläggande modellarkitektur, väldigt likt de vi tidigare skapat:\n",
    "\n",
    "- Sequential()\n",
    "\n",
    "\n",
    "- Ett ReLu-aktiverat lager med 512 neuroner\n",
    "\n",
    "\n",
    "- Vi anger hur vår input ser ut med \"(28 * 28,)\". Vi \"plattar\" alltså till bilderna: istället för att se bilderna som 28 kolumner och 28 rader, ser vi de som 1 kolumn med 784 (28x28) rader \n",
    "\n",
    "\n",
    "\n",
    "- I vårt sista output-lager anger vi 10 neuroner och \"softmax\" aktivering då vi vill ha prediktioner för 10 klasser \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "\n",
    "# Output-lager\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Vidare konfiguration\n",
    "\n",
    "Vi använder oss av Stochastic gradient descent (sgd), categorical_crossentropy och accuracy som tidigare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='sgd', #rmsprop\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Transformera input-data\n",
    "\n",
    "Vi såg tidigare att input data innehöll celler med värden mellan 0-255. Neurala nätverk konvergerar fortare om vi normaliserar input mellan intervallet 0 och 1. Vi transformerar därför datat genom att dividera alla celler med 255.\n",
    "\n",
    "- Nu betyder 0 fortfarande svart, men det högsta värdet är 1 vilket nu står för helt vitt\n",
    "\n",
    "Vi förändrar även data från än array med formen (60000,28,28) till (60000, 28 * 28). Vi plattar alltså ut input från att en bild bestått av 28 kolumner och 28 rader till att den blir endast en kolumn med 784 rader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformera labels\n",
    "\n",
    "* Vi behöver också transformera våra labels för att nätverket ska kunna hantera dem. Istället för att en observation visar en siffra mellan 0 och 9, blir en observation en array med 10 dummy-variabler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_labels innan transformering**\n",
    "\n",
    "- 60 000 rader och 1 kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form: (60000,)\n",
      "\n",
      "De tre första observationerna innan transformering: \n",
      "\n",
      "5\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"Form:\",train_labels.shape)\n",
    "\n",
    "print(\"\\nDe tre första observationerna innan transformering: \\n\")\n",
    "print(train_labels[0])\n",
    "print(train_labels[1])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_labels efter transformering**\n",
    "\n",
    "Vi använder funktionen inbyggda keras-funktionen \"to_categorical\" för att utföra transformationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nu har våra train_labels istället 60 000 rader och 10 kolumner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form: (60000, 10)\n",
      "\n",
      "De tre första observationerna efter transformering: \n",
      "\n",
      "kolumn-namn\n",
      "[0  1  2  3  4  5  6  7  8  9 ]\n",
      "\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Form:\",train_labels.shape)\n",
    "\n",
    "print(\"\\nDe tre första observationerna efter transformering: \\n\")\n",
    "print(\"kolumn-namn\")\n",
    "print(\"[0  1  2  3  4  5  6  7  8  9 ]\\n\")\n",
    "\n",
    "\n",
    "print(train_labels[0])\n",
    "print(train_labels[1])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Träna nätverket\n",
    "\n",
    "##### Valideringsdata\n",
    " \n",
    "I detta case har vi tillräckligt många observationer för att använda tre data set\n",
    "\n",
    "1. Train (50 000 obs),  att träna på\n",
    "2. Validation (10 000 obs), att validera och försöka generalisera på\n",
    "3. Test (10 000 obs), data vi inte är tillåtna att använda alls förens vi är klara med vår modell\n",
    "\n",
    "\n",
    "\n",
    "- Train och Test har vi redan skapat, Validation skapar vi genom funktionen \"validation_split=1/6\", som samplar 1/6 av träningsdatat\n",
    "\n",
    "- Vi är nu redo att träna modellen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 1.1508 - accuracy: 0.7455 - val_loss: 0.6346 - val_accuracy: 0.8703\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 0.5634 - accuracy: 0.8672 - val_loss: 0.4487 - val_accuracy: 0.8909\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 0.4488 - accuracy: 0.8850 - val_loss: 0.3806 - val_accuracy: 0.9029\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 0.3972 - accuracy: 0.8941 - val_loss: 0.3471 - val_accuracy: 0.9088\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.3661 - accuracy: 0.9007 - val_loss: 0.3243 - val_accuracy: 0.9132\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.3442 - accuracy: 0.9059 - val_loss: 0.3080 - val_accuracy: 0.9166\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.3274 - accuracy: 0.9100 - val_loss: 0.2950 - val_accuracy: 0.9202\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.3138 - accuracy: 0.9133 - val_loss: 0.2849 - val_accuracy: 0.9224\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.3022 - accuracy: 0.9161 - val_loss: 0.2756 - val_accuracy: 0.9247\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 0.2921 - accuracy: 0.9187 - val_loss: 0.2679 - val_accuracy: 0.9265\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.2831 - accuracy: 0.9211 - val_loss: 0.2600 - val_accuracy: 0.9285\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 0.2750 - accuracy: 0.9235 - val_loss: 0.2539 - val_accuracy: 0.9291\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.2674 - accuracy: 0.9257 - val_loss: 0.2482 - val_accuracy: 0.9317\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.2606 - accuracy: 0.9278 - val_loss: 0.2421 - val_accuracy: 0.9329\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.2541 - accuracy: 0.9295 - val_loss: 0.2373 - val_accuracy: 0.9342\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 0.2482 - accuracy: 0.9313 - val_loss: 0.2315 - val_accuracy: 0.9353\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 0.2425 - accuracy: 0.9331 - val_loss: 0.2273 - val_accuracy: 0.9361\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.2371 - accuracy: 0.9345 - val_loss: 0.2230 - val_accuracy: 0.9380\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.2319 - accuracy: 0.9358 - val_loss: 0.2183 - val_accuracy: 0.9388\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.2273 - accuracy: 0.9371 - val_loss: 0.2147 - val_accuracy: 0.9412\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.2227 - accuracy: 0.9379 - val_loss: 0.2108 - val_accuracy: 0.9424\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 0.2181 - accuracy: 0.9393 - val_loss: 0.2069 - val_accuracy: 0.9440\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.2139 - accuracy: 0.9404 - val_loss: 0.2034 - val_accuracy: 0.9442\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 0.2100 - accuracy: 0.9419 - val_loss: 0.1999 - val_accuracy: 0.9459\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 0.2061 - accuracy: 0.9425 - val_loss: 0.1973 - val_accuracy: 0.9463\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.2023 - accuracy: 0.9431 - val_loss: 0.1943 - val_accuracy: 0.9474\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 0.1987 - accuracy: 0.9442 - val_loss: 0.1913 - val_accuracy: 0.9486\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1952 - accuracy: 0.9452 - val_loss: 0.1884 - val_accuracy: 0.9501\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1920 - accuracy: 0.9458 - val_loss: 0.1854 - val_accuracy: 0.9510\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.1887 - accuracy: 0.9469 - val_loss: 0.1827 - val_accuracy: 0.9516\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1855 - accuracy: 0.9476 - val_loss: 0.1802 - val_accuracy: 0.9519\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1825 - accuracy: 0.9486 - val_loss: 0.1779 - val_accuracy: 0.9523\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1796 - accuracy: 0.9496 - val_loss: 0.1751 - val_accuracy: 0.9536\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1765 - accuracy: 0.9504 - val_loss: 0.1734 - val_accuracy: 0.9547\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1738 - accuracy: 0.9514 - val_loss: 0.1707 - val_accuracy: 0.9553\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1712 - accuracy: 0.9519 - val_loss: 0.1686 - val_accuracy: 0.9559\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1686 - accuracy: 0.9527 - val_loss: 0.1668 - val_accuracy: 0.9560\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1660 - accuracy: 0.9532 - val_loss: 0.1646 - val_accuracy: 0.9567\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1636 - accuracy: 0.9544 - val_loss: 0.1629 - val_accuracy: 0.9576\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1612 - accuracy: 0.9548 - val_loss: 0.1606 - val_accuracy: 0.9585\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1588 - accuracy: 0.9555 - val_loss: 0.1585 - val_accuracy: 0.9582\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1566 - accuracy: 0.9563 - val_loss: 0.1570 - val_accuracy: 0.9592\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 0.1544 - accuracy: 0.9570 - val_loss: 0.1548 - val_accuracy: 0.9595\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.1522 - accuracy: 0.9577 - val_loss: 0.1537 - val_accuracy: 0.9598\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1502 - accuracy: 0.9579 - val_loss: 0.1514 - val_accuracy: 0.9601\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1481 - accuracy: 0.9588 - val_loss: 0.1501 - val_accuracy: 0.9603\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1461 - accuracy: 0.9594 - val_loss: 0.1485 - val_accuracy: 0.9613\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 0.1441 - accuracy: 0.9602 - val_loss: 0.1471 - val_accuracy: 0.9611\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 0.1422 - accuracy: 0.9604 - val_loss: 0.1454 - val_accuracy: 0.9621\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 0.1404 - accuracy: 0.9613 - val_loss: 0.1441 - val_accuracy: 0.9627\n"
     ]
    }
   ],
   "source": [
    "#Proportion av data till valideringsdata (vi vill ha 10 000 observationer)\n",
    "val_prop = 1/6\n",
    "\n",
    "history = network.fit(train_images, train_labels, epochs=50, batch_size=128,  validation_split=val_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modellutvärdering\n",
    "\n",
    "- Vi utvärderar nu hur bra modellen tränar på träningsdata och generaliserar på Valideringsdata\n",
    "- Är vi inte nöjda med modellen kan man lägga till fler noder, hidden layers eller t.ex introducera regularisering\n",
    "- När vi sedan är nöjda utvärderar vi modellen en sista gång på test-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.96126\n",
      "accuracy, validation:  0.9627\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Utvärdera på test-data\n",
    "\n",
    "För att undersöka hur väl modellen generaliserar på data den inte tränar på, och vi inte heller försökt optimera generaliserbarheten, utvärderar vi modellen på test-datasetet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9569\n"
     ]
    }
   ],
   "source": [
    "#Predicerar på test-data\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slutsats\n",
    "\n",
    "På detta testdata får vi en accuracy på nästan 96-97%, alltså att modellen klassificerar 97% av bilderna korrekt.\n",
    "\n",
    "Vi har med ett fåtal rader kod skapat en modell som klassificerar handskrivna siffror korrekt, med väldigt hög träffsäkerhet.\n",
    "\n",
    "Även om detta med dagens mått inte är så imponerande längre, är det värt att komma ihåg att detta var \"state of the art\" för ett decennium sedan, och att vi enkelt kan replikera detta tack vare det open source-community som gjort detta tillgängligt för oss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Är 100% träffsäkerhet önskvärd?\n",
    "\n",
    "Även om vi inte får **100%** träffsäkerhet, kan man ha viss förståelse att modellen klassificerar fel på de observationer den gör.\n",
    "\n",
    "Nedan undersöker vi den observation där vår modell är säker på en felaktig siffra, dvs där prediktionen och sanningen skiljer sig som mest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #för matris beräkningar\n",
    "\n",
    "# Predicerar sannolikheter\n",
    "test_pred = network.predict(test_images)\n",
    "# Tar differens mellan prediktion och sanning\n",
    "test_diff = np.abs(test_pred-test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation med störst differens mellan prediktion och sanning är nr :  [1790]\n",
      "\n",
      "\n",
      "Prediktionen är siffran :  [9]  med en säkerhet på: [0.5651755]\n",
      "\n",
      "\n",
      "Sanningen är :  [2]\n",
      "Vår modell anser att sannolikheten för detta är 3.39746e-05\n",
      "\n",
      "Bilden ser ut såhär:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hämtar den observation med störst differens\n",
    "\n",
    "result = np.where(test_diff == np.amax(test_diff))\n",
    "\n",
    "predicted = np.where(test_pred[result[0]] == np.amax(test_pred[result[0]]))\n",
    "\n",
    "print('Observation med störst differens mellan prediktion och sanning är nr : ', result[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('Prediktionen är siffran : ', predicted[1],' med en säkerhet på:', test_pred[result[0],predicted[1]]  )\n",
    "print(\"\\n\")\n",
    "print('Sanningen är : ',\n",
    "      np.where(test_labels[result[0]] == np.amax(test_labels[result[0]]))[1])\n",
    "print('Vår modell anser att sannolikheten för detta är', round(1-np.amax(test_diff), 10 ))\n",
    "\n",
    "print(\"\\nBilden ser ut såhär:\")\n",
    "plt.imshow(test_images[ result[0] ].reshape(28,28), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För det mänskliga ögat är det inte uppenbart att detta att vår \"sanning\" är korrekt\n",
    "\n",
    "Skulle modellen lyckas klassificera detta korrekt krävs antingen att\n",
    "\n",
    "- Det faktiskt är väldigt vanligt i indata att man skriver såhär slarvigt \n",
    "- Man låter man modellen överträna till den grad att den på ett nytt dataset skulle felklassificera andra observationer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "##### Ett ännu bättre exempel - Rabbit vs. duck\n",
    "\n",
    "- Vad vill vi klassificera nedan bild som, kanin eller anka?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"550\"\n",
       "            src=\"https://gfycat.com/ifr/FamousGleefulChimpanzee\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x21a8c779898>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame    \n",
    "IFrame(\"https://gfycat.com/ifr/FamousGleefulChimpanzee\", width=800, height=550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Convolutional Neural Network med MNIST\n",
    "\n",
    "Vi testar nu övningen med Convolutional lager istället Dense-lager\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Laddar in mnist-data igen\n",
    "\n",
    "För CNN behöver vi skapa en 4:e dimension. 60000 syftar på våra träningsexempel. 28*28 syftar på antal pixlar i bilden (width*height). Utöver det behöver vi dessutom specificera antalet färgkanaler. Eftersom vi jobbar med svartvita bilder så har vi endast 1 färgkanal (60000, 28, 28, 1). Hade vi däreemot haft en färgbild så hade vi behövt specificera 3 input kanaler i linje med RGB formatet(red, green, blue). Då hade vi behövt skriva x_train_resized = x_train.reshape((60000, 28, 28, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#För CNN behöver vi skapa en 4:e dimension \n",
    "x_train_resized = x_train.reshape((60000, 28, 28, 1))\n",
    "x_test_resized = x_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "#Återigen skapar vi dummy-variabler för respektive siffra\n",
    "y_train_labels = to_categorical(y_train)\n",
    "y_test_labels = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Modell-arkitektur\n",
    " \n",
    " \n",
    "Vi skapar här en grundläggande modellarkitektur, likt de vi tidigare gått igenom idag:\n",
    "\n",
    "- Alternerar mellan Convolutional Neural Networks och Maxpooling-lager\n",
    "\n",
    "- \"Plattar\" slutligen till vårt nätverk och kör ett Dense-lager\n",
    "\n",
    "\n",
    "- I vårt sista output-lager anger vi 10 neuroner och \"softmax\" aktivering då vi vill ha prediktioner till våra 10 klasser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model = models.Sequential()\n",
    "CNN_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # 28*28 pixlar med 1 kanal (svartvit bild)\n",
    "CNN_model.add(layers.MaxPooling2D((2, 2)))\n",
    "CNN_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "CNN_model.add(layers.MaxPooling2D((2, 2)))\n",
    "CNN_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "CNN_model.add(layers.Flatten())\n",
    "CNN_model.add(layers.Dense(64, activation='relu'))\n",
    "CNN_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# samma kompilering som tidigare\n",
    "CNN_model.compile(optimizer='sgd',  #rmsprop\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Träna nätverket\n",
    "\n",
    "- Vi tränar återigen nätverket med 10 000 obs i validering\n",
    "\n",
    "- Eftersom CNN är mer tidskrävande kör vi bara ett fåtal epochs och testar även en förtränad modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 49s 988us/sample - loss: 2.0764 - accuracy: 0.7413 - val_loss: 0.1876 - val_accuracy: 0.9444\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 48s 959us/sample - loss: 0.1856 - accuracy: 0.9430 - val_loss: 0.1515 - val_accuracy: 0.9546\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 50s 1ms/sample - loss: 0.1229 - accuracy: 0.9609 - val_loss: 0.1258 - val_accuracy: 0.9650\n",
      "Epoch 4/5\n",
      "39168/50000 [======================>.......] - ETA: 9s - loss: 0.1176 - accuracy: 0.9633 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-dc9f620a8e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#Vi tränar väldigt kort, endast 5 epochs, addera fler om du vill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         validation_split=val_prop)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_prop=1/6\n",
    "\n",
    "history = CNN_model.fit(x_train_resized,\n",
    "                        y_train_labels,\n",
    "                        epochs=5, #Vi tränar väldigt kort, endast 5 epochs, addera fler om du vill\n",
    "                        batch_size=256,\n",
    "                        validation_split=val_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "När modeller tar längre tid att träna är det viktigt att spara ned dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.save('MNIST_CNN_V1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spara ned träningshistoriken\n",
    "import pickle\n",
    "with open('MNIST_CNN_V1_hist', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ladda in förtränad model\n",
    "\n",
    "Eftersom att vi inte hinner träna vår modell särskilt länge under vår övningsdag, kan vi här ladda in en förtränad modell och dess historik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme 'http' not implemented (file: 'http://github.com/DavidRyden/block5-2020sept/blob/master/MNIST_CNN_V1_100_epochs.h5?raw=true\\saved_model.pb')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-3b2b978072a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Ladda in förtränad model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mCNN_model_pretrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_pickle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#load_model('MNIST_CNN_V1_100_epochs.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Ladda in historiken för förtränad model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;31m# Parse the SavedModel protocol buffer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_model_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_pb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[0mfile_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_pb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mfile_exists\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPropagates\u001b[0m \u001b[0many\u001b[0m \u001b[0merrors\u001b[0m \u001b[0mreported\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mFileSystem\u001b[0m \u001b[0mAPI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m   \"\"\"\n\u001b[1;32m--> 262\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mfile_exists_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mfile_exists_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    278\u001b[0m   \"\"\"\n\u001b[0;32m    279\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileExists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'http' not implemented (file: 'http://github.com/DavidRyden/block5-2020sept/blob/master/MNIST_CNN_V1_100_epochs.h5?raw=true\\saved_model.pb')"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    " \n",
    "# Ladda in förtränad model\n",
    "CNN_model_pretrain = load_model('block5-2020sept/MNIST_CNN_V1_100_epochs.h5')\n",
    "\n",
    "# Ladda in historiken för förtränad model\n",
    "\n",
    "with open('block5-2020sept/MNIST_CNN_V1_100_epochs_hist', 'rb') as f:\n",
    "    # load using pickle de-serializer\n",
    "    history_pretrain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modellutvärdering\n",
    "\n",
    "- Vi utvärderar nu hur bra modellen tränar på träningsdata och generaliserar på Valideringsdata\n",
    "- Är vi inte nöjda med modellen kan man lägga justerar vi den och tränar återigen\n",
    "- När vi sedan är nöjda utvärderar vi modellen en sista gång på test-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_training(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historik för vårt förtränade nätverk\n",
    "\n",
    "- Med vårt förtränade nätverk når vi högre accuracy då det fått träna längre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history_pretrain )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Utvärdera på test-data\n",
    "\n",
    "För att undersöka hur väl modellen generaliserar på data den inte tränar på, och vi inte heller försökt optimera generaliserbarheten, utvärderar vi modellen på test-datasetet\n",
    "\n",
    "##### Vår egen träning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicerar på test-data\n",
    "test_loss, test_acc = CNN_model.evaluate(x_test_resized, y_test_labels, verbose=0)\n",
    "\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Förtränad modell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicerar på test-data\n",
    "test_loss_pre, test_acc_pre = CNN_model_pretrain.evaluate(x_test_resized, y_test_labels, verbose=0)\n",
    "\n",
    "print('test accuracy:', test_acc_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slutsats - Convolutional neural network\n",
    "\n",
    "- Vi uppnår högre accuracy med CNN än enkelt Dense nätverk\n",
    "- MNIST klarar sig bra med enkelt Dense nätverk, vid komplexare problem är CNN betydligt kraftfullare traditionella nätverk med enbart Dense-lager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
