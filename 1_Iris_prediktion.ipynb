{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Kort om att gå från R till Python\n",
    "\n",
    "- Ni förväntas inte kunna skriva Python-kod, men ni kommer delvis känna igen arbetssättet från R\n",
    "\n",
    "\n",
    "- Python är likt R ett populärt open source-språk inom data science, det är bra att få en inblick även i detta språk\n",
    "\n",
    "\n",
    "\n",
    "- Vi kör koden i en \"Jupyter Notebook\", även det populärt inom Data Science. Notebooks stödjer både Python och R\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Python\n",
    "- \"General-purpose\" programmeringsspråk - data science bara ett applikationsområde\n",
    "- Förlåtande för nybörjare, men därav mer risk för implicita fel, ex, \"123\" * 3\n",
    "- Tacksamt att implementera, många data engineers kan python \n",
    "- TVINGAR dig att skriva prydligt, får felmeddelande utan korrekt indentering\n",
    "\n",
    "- Python har betydligt sämre paket för klassisk statistik och regression jämfört med R, regression i populära Scikitlearn ger inte ens p-värden\n",
    "\n",
    "\n",
    "#### R\n",
    "- Fokuserat och mer utvecklat för Statistisk programmering\n",
    "- Oförlåtande för nybörjare, mindre risk för implicita fel - exempelvis mean(x, na.rm=TRUE), beräkningar kan enbart göras på tillåtna datatyper\n",
    "- bättre för visualiseringar med ggplot2\n",
    "- Trevlig app och rapport-generering med knitr och Shiny\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Snabba exempel\n",
    "\n",
    "- \"<-\" i R ersätts med \"=\" i Python \n",
    "\n",
    "(precis som i R är \"==\" det man använder som lika med-tecken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Kör denna cell med \"Shift + Enter\"\n",
    "siffra_python = 1+2 \n",
    "print(siffra_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Förlåtande\n",
    "\n",
    "- Python är förlåtande för nybörjare, men därav mer risk för implicita fel, ex, \"123\" * 3 fungerar, men är inte en matematisk operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123123123\n"
     ]
    }
   ],
   "source": [
    "#Det går att multiplicera strängen \"123\" i python, men det är inte en matematisk operation\n",
    "strang_ggr_num = \"123\"*3\n",
    "print(strang_ggr_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prydlighet\n",
    "\n",
    "Nedan fungerar, det är korrekt med indenteringen efter både for och if-satsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Slut\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2]:\n",
    "    print(i)\n",
    "    if(i==2):\n",
    "        print(\"Slut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nedan fungerar inte, vi får IndentationError då vi inte indenterat efter if-satsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-52-95df71d784a5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-52-95df71d784a5>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print(\"Slut\")\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2]:\n",
    "    print(i)\n",
    "    if(i==2):\n",
    "    print(\"Slut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Övning 1: Enkel logistisk modell\n",
    "\n",
    "I denna övning testar vi att göra en enkel logistisk modell utifrån Iris-datasetet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Importera bibliotek\n",
    "\n",
    "Vi importerar de python-bibliotek som vi behöver för att bearbeta vårt dataset\n",
    "\n",
    "- numpy används för matrisberäkningar, extremt vanligt att använda tillsammans med pandas\n",
    "- matplotlib för grafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hjälpfunktioner\n",
    "\n",
    "- Används senare för att plotta modellutvärdering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training():\n",
    "    \n",
    "    print(\"accuracy, train: \", history.history['accuracy'][-1])\n",
    "    print(\"accuracy, test: \", history.history['val_accuracy'][-1])\n",
    "    \n",
    "    # Credd : https://janakiev.com/notebooks/keras-iris/\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris-data med 2 klasser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Data import & preparering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vi importerar vid bibliotek från sklearn, ett mycket populärt bibiliotek för typiska funktioner inom data science\n",
    " \n",
    " - load_iris för att hämta iris-data\n",
    " - train_test_split för att enkelt dela upp data i train och test\n",
    " - Onehotencoder för att skapa target-variaber som är dummies\n",
    " - StandardScaler för att senare normalisera input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapreparering är importerad från : https://janakiev.com/notebooks/keras-iris/\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "#Bestämmer seed inför sampling\n",
    "seed = 444\n",
    "#Anger seed för tensorflow respektive numpy-beräkningar\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vi hämtar iris-datasetet som vi arbetat med tidigare\n",
    "\n",
    "- Vi har oberoende variablerna 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)' och 'petal width (cm)'\n",
    "- Vi vill klassificera om blomman är versicolor(Y=1) eller inte (Y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hämtar iris-data\n",
    "iris = load_iris()\n",
    "X = iris['data'][0:100] # Hämta endast 100 observationer\n",
    "y = iris['target'][0:100]\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding (= skapar dummy-varibler)\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Standardiserar data till medelvärde 0 och varians 1 \n",
    "# Standardisering av värden hjälper neurala nätverk att konvergera\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Delar upp data i training och test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features : 4\n",
      "n_classes : 2\n",
      "\n",
      " Standardiserade features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      " [[-0.894  0.002 -0.944 -1.22 ]\n",
      " [ 0.359 -0.418  0.928  0.914]\n",
      " [-0.581  0.842 -1.013 -0.864]]\n",
      "\n",
      "Y (1=Versicolor) \n",
      " [[0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Vi delar upp data test i train och test\n",
    "X_train, X_test, Y_train_, Y_test_ = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "#Vi skapar variabler för antalet features och klasser, används till neurala nätverket\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "# Anpassa format för binär klassificering (1 target variabel)\n",
    "Y_train = Y_train_[:,1].reshape(50,1)\n",
    "Y_test = Y_test_[:,1].reshape(50,1)\n",
    "\n",
    "print(\"n_features : \" + str(n_features))\n",
    "print(\"n_classes : \" + str(n_classes))\n",
    "\n",
    "\n",
    "print( \"\\n Standardiserade features: \\n\",feature_names,\"\\n\",X_train[0:3])\n",
    "print (\"\\nY (1=Versicolor)\",\"\\n\", Y_train[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistisk regression (sigmoid aktivering)\n",
    "\n",
    "Vi skapar nu en logistisk regression med ett neuralt nätverk:\n",
    "\n",
    "- Vi använder \"tensorflow\" som \"backend\" till vårt neurala nätverk\n",
    "- Paketet \"keras\" som numera finns i tensorflow används som \"frontend\"\n",
    "\n",
    "- Vi skapar ett sekventiellt neuralt nätverk (funktionen \"Sequential()\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#Sekventiellt neuralt nätverk\n",
    "logistic_regression_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I vårt tomma sekventiella nätverk lägger vi till ett \"Dense\"/\"fully connected\" hidden layer:\n",
    "\n",
    "1. Detta lager tar 4 dimensoner som input (våra oberoende variabler)\n",
    "\n",
    "2. Ger 1 dimension output på mellan 0-1, efter sannolikhet att observationen är versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.add(Dense(1, input_dim=n_features, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I kompilering anger vi övriga val:\n",
    "- Optimizer = sgd (stochastic gradient descent:    theta(t+1) = theta(t) - learning_rate * gradient)\n",
    "- Loss-funktion = binary crossentropy, då vi har binär output-variabel\n",
    "- Den metric vi optimerar för är accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.compile(optimizer='sgd',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summering av vår skapade modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Träna modell\n",
    "\n",
    "Vi tränar modellen i 500 epoker med funktion fit()\n",
    "\n",
    "För varje epok ser vi hur loss och accuracy förändras på både vårt train och validation-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 50 samples\n",
      "Epoch 1/500\n",
      "50/50 [==============================] - 1s 18ms/sample - loss: 1.0050 - accuracy: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "50/50 [==============================] - 0s 588us/sample - loss: 0.9837 - accuracy: 0.0000e+00 - val_loss: 0.9882 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.9628 - accuracy: 0.0000e+00 - val_loss: 0.9667 - val_accuracy: 0.0200\n",
      "Epoch 4/500\n",
      "50/50 [==============================] - 0s 414us/sample - loss: 0.9424 - accuracy: 0.0200 - val_loss: 0.9457 - val_accuracy: 0.0400\n",
      "Epoch 5/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.9225 - accuracy: 0.0200 - val_loss: 0.9254 - val_accuracy: 0.0400\n",
      "Epoch 6/500\n",
      "50/50 [==============================] - 0s 671us/sample - loss: 0.9032 - accuracy: 0.0600 - val_loss: 0.9055 - val_accuracy: 0.0400\n",
      "Epoch 7/500\n",
      "50/50 [==============================] - 0s 611us/sample - loss: 0.8842 - accuracy: 0.1200 - val_loss: 0.8862 - val_accuracy: 0.0600\n",
      "Epoch 8/500\n",
      "50/50 [==============================] - 0s 548us/sample - loss: 0.8659 - accuracy: 0.1400 - val_loss: 0.8676 - val_accuracy: 0.1600\n",
      "Epoch 9/500\n",
      "50/50 [==============================] - 0s 403us/sample - loss: 0.8484 - accuracy: 0.1600 - val_loss: 0.8497 - val_accuracy: 0.1800\n",
      "Epoch 10/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.8312 - accuracy: 0.2000 - val_loss: 0.8318 - val_accuracy: 0.2400\n",
      "Epoch 11/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.8144 - accuracy: 0.2200 - val_loss: 0.8148 - val_accuracy: 0.2600\n",
      "Epoch 12/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.7981 - accuracy: 0.2400 - val_loss: 0.7979 - val_accuracy: 0.2600\n",
      "Epoch 13/500\n",
      "50/50 [==============================] - 0s 373us/sample - loss: 0.7822 - accuracy: 0.2600 - val_loss: 0.7817 - val_accuracy: 0.3200\n",
      "Epoch 14/500\n",
      "50/50 [==============================] - 0s 587us/sample - loss: 0.7670 - accuracy: 0.2800 - val_loss: 0.7659 - val_accuracy: 0.3600\n",
      "Epoch 15/500\n",
      "50/50 [==============================] - 0s 432us/sample - loss: 0.7522 - accuracy: 0.2800 - val_loss: 0.7508 - val_accuracy: 0.3800\n",
      "Epoch 16/500\n",
      "50/50 [==============================] - 0s 759us/sample - loss: 0.7375 - accuracy: 0.3800 - val_loss: 0.7358 - val_accuracy: 0.4000\n",
      "Epoch 17/500\n",
      "50/50 [==============================] - 0s 578us/sample - loss: 0.7235 - accuracy: 0.4200 - val_loss: 0.7217 - val_accuracy: 0.4200\n",
      "Epoch 18/500\n",
      "50/50 [==============================] - 0s 549us/sample - loss: 0.7101 - accuracy: 0.4400 - val_loss: 0.7079 - val_accuracy: 0.4600\n",
      "Epoch 19/500\n",
      "50/50 [==============================] - 0s 465us/sample - loss: 0.6971 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.4800\n",
      "Epoch 20/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.6843 - accuracy: 0.5000 - val_loss: 0.6812 - val_accuracy: 0.5600\n",
      "Epoch 21/500\n",
      "50/50 [==============================] - 0s 441us/sample - loss: 0.6718 - accuracy: 0.5200 - val_loss: 0.6682 - val_accuracy: 0.5600\n",
      "Epoch 22/500\n",
      "50/50 [==============================] - 0s 286us/sample - loss: 0.6595 - accuracy: 0.5800 - val_loss: 0.6557 - val_accuracy: 0.5800\n",
      "Epoch 23/500\n",
      "50/50 [==============================] - 0s 471us/sample - loss: 0.6477 - accuracy: 0.5800 - val_loss: 0.6436 - val_accuracy: 0.6400\n",
      "Epoch 24/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.6363 - accuracy: 0.6400 - val_loss: 0.6319 - val_accuracy: 0.7000\n",
      "Epoch 25/500\n",
      "50/50 [==============================] - 0s 673us/sample - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6205 - val_accuracy: 0.7400\n",
      "Epoch 26/500\n",
      "50/50 [==============================] - 0s 551us/sample - loss: 0.6145 - accuracy: 0.7200 - val_loss: 0.6093 - val_accuracy: 0.7400\n",
      "Epoch 27/500\n",
      "50/50 [==============================] - 0s 735us/sample - loss: 0.6040 - accuracy: 0.7400 - val_loss: 0.5984 - val_accuracy: 0.7800\n",
      "Epoch 28/500\n",
      "50/50 [==============================] - 0s 512us/sample - loss: 0.5938 - accuracy: 0.7800 - val_loss: 0.5880 - val_accuracy: 0.8200\n",
      "Epoch 29/500\n",
      "50/50 [==============================] - 0s 596us/sample - loss: 0.5839 - accuracy: 0.8200 - val_loss: 0.5780 - val_accuracy: 0.8400\n",
      "Epoch 30/500\n",
      "50/50 [==============================] - 0s 406us/sample - loss: 0.5743 - accuracy: 0.8400 - val_loss: 0.5679 - val_accuracy: 0.8400\n",
      "Epoch 31/500\n",
      "50/50 [==============================] - 0s 598us/sample - loss: 0.5649 - accuracy: 0.8400 - val_loss: 0.5582 - val_accuracy: 0.8400\n",
      "Epoch 32/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.5557 - accuracy: 0.8400 - val_loss: 0.5488 - val_accuracy: 0.8400\n",
      "Epoch 33/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.5469 - accuracy: 0.8600 - val_loss: 0.5395 - val_accuracy: 0.8600\n",
      "Epoch 34/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.5381 - accuracy: 0.8600 - val_loss: 0.5306 - val_accuracy: 0.8800\n",
      "Epoch 35/500\n",
      "50/50 [==============================] - 0s 339us/sample - loss: 0.5297 - accuracy: 0.8800 - val_loss: 0.5218 - val_accuracy: 0.8800\n",
      "Epoch 36/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.5214 - accuracy: 0.8800 - val_loss: 0.5132 - val_accuracy: 0.8800\n",
      "Epoch 37/500\n",
      "50/50 [==============================] - 0s 445us/sample - loss: 0.5134 - accuracy: 0.9000 - val_loss: 0.5049 - val_accuracy: 0.9000\n",
      "Epoch 38/500\n",
      "50/50 [==============================] - 0s 606us/sample - loss: 0.5056 - accuracy: 0.9000 - val_loss: 0.4970 - val_accuracy: 0.9000\n",
      "Epoch 39/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.4980 - accuracy: 0.9200 - val_loss: 0.4892 - val_accuracy: 0.9000\n",
      "Epoch 40/500\n",
      "50/50 [==============================] - 0s 393us/sample - loss: 0.4907 - accuracy: 0.9200 - val_loss: 0.4815 - val_accuracy: 0.9000\n",
      "Epoch 41/500\n",
      "50/50 [==============================] - 0s 542us/sample - loss: 0.4834 - accuracy: 0.9400 - val_loss: 0.4741 - val_accuracy: 0.9200\n",
      "Epoch 42/500\n",
      "50/50 [==============================] - 0s 435us/sample - loss: 0.4765 - accuracy: 0.9400 - val_loss: 0.4669 - val_accuracy: 0.9400\n",
      "Epoch 43/500\n",
      "50/50 [==============================] - 0s 609us/sample - loss: 0.4697 - accuracy: 0.9400 - val_loss: 0.4600 - val_accuracy: 0.9400\n",
      "Epoch 44/500\n",
      "50/50 [==============================] - 0s 736us/sample - loss: 0.4630 - accuracy: 0.9400 - val_loss: 0.4531 - val_accuracy: 0.9600\n",
      "Epoch 45/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.4565 - accuracy: 0.9400 - val_loss: 0.4464 - val_accuracy: 0.9800\n",
      "Epoch 46/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.4502 - accuracy: 0.9400 - val_loss: 0.4398 - val_accuracy: 0.9800\n",
      "Epoch 47/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.4440 - accuracy: 0.9800 - val_loss: 0.4334 - val_accuracy: 0.9800\n",
      "Epoch 48/500\n",
      "50/50 [==============================] - 0s 456us/sample - loss: 0.4379 - accuracy: 0.9800 - val_loss: 0.4273 - val_accuracy: 0.9800\n",
      "Epoch 49/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.4320 - accuracy: 0.9800 - val_loss: 0.4211 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.4262 - accuracy: 0.9800 - val_loss: 0.4152 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "50/50 [==============================] - 0s 391us/sample - loss: 0.4206 - accuracy: 0.9800 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.4151 - accuracy: 0.9800 - val_loss: 0.4036 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.4097 - accuracy: 0.9800 - val_loss: 0.3981 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "50/50 [==============================] - 0s 522us/sample - loss: 0.4045 - accuracy: 0.9800 - val_loss: 0.3927 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "50/50 [==============================] - 0s 559us/sample - loss: 0.3993 - accuracy: 0.9800 - val_loss: 0.3873 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "50/50 [==============================] - 0s 456us/sample - loss: 0.3943 - accuracy: 0.9800 - val_loss: 0.3822 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.3894 - accuracy: 0.9800 - val_loss: 0.3772 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "50/50 [==============================] - 0s 453us/sample - loss: 0.3846 - accuracy: 0.9800 - val_loss: 0.3722 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "50/50 [==============================] - 0s 404us/sample - loss: 0.3798 - accuracy: 0.9800 - val_loss: 0.3674 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "50/50 [==============================] - 0s 500us/sample - loss: 0.3752 - accuracy: 0.9800 - val_loss: 0.3626 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "50/50 [==============================] - 0s 477us/sample - loss: 0.3707 - accuracy: 0.9800 - val_loss: 0.3580 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "50/50 [==============================] - 0s 483us/sample - loss: 0.3663 - accuracy: 0.9800 - val_loss: 0.3535 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.3621 - accuracy: 0.9800 - val_loss: 0.3491 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.3579 - accuracy: 0.9800 - val_loss: 0.3448 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "50/50 [==============================] - 0s 648us/sample - loss: 0.3538 - accuracy: 0.9800 - val_loss: 0.3406 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "50/50 [==============================] - 0s 599us/sample - loss: 0.3498 - accuracy: 0.9800 - val_loss: 0.3365 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "50/50 [==============================] - 0s 576us/sample - loss: 0.3459 - accuracy: 0.9800 - val_loss: 0.3325 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "50/50 [==============================] - 0s 676us/sample - loss: 0.3420 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.3383 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "50/50 [==============================] - 0s 552us/sample - loss: 0.3346 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "50/50 [==============================] - 0s 321us/sample - loss: 0.3310 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.3275 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.3240 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "50/50 [==============================] - 0s 455us/sample - loss: 0.3205 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "50/50 [==============================] - 0s 422us/sample - loss: 0.3172 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "50/50 [==============================] - 0s 330us/sample - loss: 0.3139 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.3075 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.3045 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "50/50 [==============================] - 0s 339us/sample - loss: 0.3014 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.2984 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "50/50 [==============================] - 0s 313us/sample - loss: 0.2955 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "50/50 [==============================] - 0s 565us/sample - loss: 0.2926 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "50/50 [==============================] - 0s 357us/sample - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.2870 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "50/50 [==============================] - 0s 427us/sample - loss: 0.2843 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "50/50 [==============================] - 0s 535us/sample - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "50/50 [==============================] - 0s 827us/sample - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "50/50 [==============================] - 0s 659us/sample - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "50/50 [==============================] - 0s 376us/sample - loss: 0.2739 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "50/50 [==============================] - 0s 406us/sample - loss: 0.2689 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "50/50 [==============================] - 0s 378us/sample - loss: 0.2642 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "50/50 [==============================] - 0s 489us/sample - loss: 0.2618 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.2595 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.2572 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "50/50 [==============================] - 0s 536us/sample - loss: 0.2550 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "50/50 [==============================] - 0s 412us/sample - loss: 0.2528 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "50/50 [==============================] - 0s 585us/sample - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.2486 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.2465 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.2444 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "50/50 [==============================] - 0s 342us/sample - loss: 0.2424 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "50/50 [==============================] - 0s 715us/sample - loss: 0.2405 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.2385 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "50/50 [==============================] - 0s 493us/sample - loss: 0.2366 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "50/50 [==============================] - 0s 384us/sample - loss: 0.2348 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "50/50 [==============================] - 0s 532us/sample - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.2293 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "50/50 [==============================] - 0s 508us/sample - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 334us/sample - loss: 0.2258 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "50/50 [==============================] - 0s 431us/sample - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "50/50 [==============================] - 0s 584us/sample - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "50/50 [==============================] - 0s 407us/sample - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "50/50 [==============================] - 0s 516us/sample - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "50/50 [==============================] - 0s 591us/sample - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "50/50 [==============================] - 0s 938us/sample - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "50/50 [==============================] - 0s 346us/sample - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "50/50 [==============================] - 0s 511us/sample - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "50/50 [==============================] - 0s 546us/sample - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.2068 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "50/50 [==============================] - 0s 518us/sample - loss: 0.2053 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.2039 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.2025 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "50/50 [==============================] - 0s 479us/sample - loss: 0.2011 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "50/50 [==============================] - 0s 371us/sample - loss: 0.1998 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "50/50 [==============================] - 0s 545us/sample - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "50/50 [==============================] - 0s 465us/sample - loss: 0.1971 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "50/50 [==============================] - 0s 383us/sample - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "50/50 [==============================] - 0s 483us/sample - loss: 0.1945 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "50/50 [==============================] - 0s 427us/sample - loss: 0.1932 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "50/50 [==============================] - 0s 551us/sample - loss: 0.1920 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "50/50 [==============================] - 0s 403us/sample - loss: 0.1907 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "50/50 [==============================] - 0s 384us/sample - loss: 0.1895 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "50/50 [==============================] - 0s 553us/sample - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "50/50 [==============================] - 0s 526us/sample - loss: 0.1872 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "50/50 [==============================] - 0s 381us/sample - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "50/50 [==============================] - 0s 564us/sample - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "50/50 [==============================] - 0s 456us/sample - loss: 0.1837 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "50/50 [==============================] - 0s 758us/sample - loss: 0.1825 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "50/50 [==============================] - 0s 479us/sample - loss: 0.1814 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "50/50 [==============================] - 0s 553us/sample - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "50/50 [==============================] - 0s 536us/sample - loss: 0.1781 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "50/50 [==============================] - 0s 516us/sample - loss: 0.1771 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.1760 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "50/50 [==============================] - 0s 483us/sample - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "50/50 [==============================] - 0s 569us/sample - loss: 0.1729 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "50/50 [==============================] - 0s 346us/sample - loss: 0.1719 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "50/50 [==============================] - 0s 452us/sample - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "50/50 [==============================] - 0s 548us/sample - loss: 0.1699 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.1689 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.1680 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "50/50 [==============================] - 0s 530us/sample - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.1661 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.1652 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.1642 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "50/50 [==============================] - 0s 575us/sample - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "50/50 [==============================] - 0s 571us/sample - loss: 0.1624 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.1615 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "50/50 [==============================] - 0s 536us/sample - loss: 0.1607 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "50/50 [==============================] - 0s 440us/sample - loss: 0.1598 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "50/50 [==============================] - 0s 548us/sample - loss: 0.1589 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "50/50 [==============================] - 0s 369us/sample - loss: 0.1581 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "50/50 [==============================] - 0s 593us/sample - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "50/50 [==============================] - 0s 265us/sample - loss: 0.1564 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "50/50 [==============================] - 0s 479us/sample - loss: 0.1548 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.1539 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "50/50 [==============================] - 0s 430us/sample - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "50/50 [==============================] - 0s 499us/sample - loss: 0.1523 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "50/50 [==============================] - 0s 399us/sample - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "50/50 [==============================] - 0s 471us/sample - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "50/50 [==============================] - 0s 378us/sample - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "50/50 [==============================] - 0s 327us/sample - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "50/50 [==============================] - 0s 493us/sample - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.1463 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.1455 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "50/50 [==============================] - 0s 557us/sample - loss: 0.1448 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "50/50 [==============================] - 0s 679us/sample - loss: 0.1441 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "50/50 [==============================] - 0s 549us/sample - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "50/50 [==============================] - 0s 468us/sample - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.1420 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "50/50 [==============================] - 0s 546us/sample - loss: 0.1413 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "50/50 [==============================] - 0s 368us/sample - loss: 0.1407 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "50/50 [==============================] - 0s 494us/sample - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "50/50 [==============================] - 0s 384us/sample - loss: 0.1386 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "50/50 [==============================] - 0s 529us/sample - loss: 0.1380 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "50/50 [==============================] - 0s 404us/sample - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "50/50 [==============================] - 0s 567us/sample - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.1361 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "50/50 [==============================] - 0s 636us/sample - loss: 0.1348 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "50/50 [==============================] - 0s 548us/sample - loss: 0.1342 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "50/50 [==============================] - 0s 461us/sample - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "50/50 [==============================] - 0s 576us/sample - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "50/50 [==============================] - 0s 422us/sample - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "50/50 [==============================] - 0s 481us/sample - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "50/50 [==============================] - 0s 475us/sample - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.1295 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "50/50 [==============================] - 0s 408us/sample - loss: 0.1284 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "50/50 [==============================] - 0s 524us/sample - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "50/50 [==============================] - 0s 409us/sample - loss: 0.1272 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "50/50 [==============================] - 0s 590us/sample - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "50/50 [==============================] - 0s 428us/sample - loss: 0.1262 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "50/50 [==============================] - 0s 345us/sample - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "50/50 [==============================] - 0s 395us/sample - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "50/50 [==============================] - 0s 518us/sample - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "50/50 [==============================] - 0s 453us/sample - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "50/50 [==============================] - 0s 490us/sample - loss: 0.1215 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "50/50 [==============================] - 0s 543us/sample - loss: 0.1210 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "50/50 [==============================] - 0s 545us/sample - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "50/50 [==============================] - 0s 416us/sample - loss: 0.1200 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "50/50 [==============================] - 0s 477us/sample - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "50/50 [==============================] - 0s 504us/sample - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "50/50 [==============================] - 0s 519us/sample - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "50/50 [==============================] - 0s 461us/sample - loss: 0.1172 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.1162 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "50/50 [==============================] - 0s 630us/sample - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "50/50 [==============================] - 0s 569us/sample - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "50/50 [==============================] - 0s 370us/sample - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "50/50 [==============================] - 0s 448us/sample - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "50/50 [==============================] - 0s 496us/sample - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "50/50 [==============================] - 0s 379us/sample - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "50/50 [==============================] - 0s 614us/sample - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.1118 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "50/50 [==============================] - 0s 538us/sample - loss: 0.1114 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "50/50 [==============================] - 0s 438us/sample - loss: 0.1110 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "50/50 [==============================] - 0s 420us/sample - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "50/50 [==============================] - 0s 387us/sample - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "50/50 [==============================] - 0s 482us/sample - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.1090 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "50/50 [==============================] - 0s 497us/sample - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "50/50 [==============================] - 0s 329us/sample - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "50/50 [==============================] - 0s 443us/sample - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "50/50 [==============================] - 0s 500us/sample - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "50/50 [==============================] - 0s 514us/sample - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "50/50 [==============================] - 0s 394us/sample - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "50/50 [==============================] - 0s 609us/sample - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "50/50 [==============================] - 0s 554us/sample - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "50/50 [==============================] - 0s 476us/sample - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "50/50 [==============================] - 0s 577us/sample - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "50/50 [==============================] - 0s 495us/sample - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "50/50 [==============================] - 0s 473us/sample - loss: 0.1022 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "50/50 [==============================] - 0s 479us/sample - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "50/50 [==============================] - 0s 518us/sample - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "50/50 [==============================] - 0s 492us/sample - loss: 0.1004 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "50/50 [==============================] - 0s 421us/sample - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "50/50 [==============================] - 0s 475us/sample - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "50/50 [==============================] - 0s 532us/sample - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "50/50 [==============================] - 0s 554us/sample - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "50/50 [==============================] - 0s 488us/sample - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "50/50 [==============================] - 0s 390us/sample - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "50/50 [==============================] - 0s 505us/sample - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "50/50 [==============================] - 0s 463us/sample - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "50/50 [==============================] - 0s 437us/sample - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "50/50 [==============================] - 0s 505us/sample - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "50/50 [==============================] - 0s 515us/sample - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "50/50 [==============================] - 0s 413us/sample - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "50/50 [==============================] - 0s 356us/sample - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "50/50 [==============================] - 0s 456us/sample - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 1.00 - 0s 421us/sample - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "50/50 [==============================] - 0s 506us/sample - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "50/50 [==============================] - 0s 443us/sample - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "50/50 [==============================] - 0s 499us/sample - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "50/50 [==============================] - 0s 687us/sample - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "50/50 [==============================] - 0s 518us/sample - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "50/50 [==============================] - 0s 527us/sample - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "50/50 [==============================] - 0s 633us/sample - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "50/50 [==============================] - 0s 498us/sample - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "50/50 [==============================] - 0s 500us/sample - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "50/50 [==============================] - 0s 499us/sample - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "50/50 [==============================] - 0s 511us/sample - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "50/50 [==============================] - 0s 498us/sample - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "50/50 [==============================] - 0s 497us/sample - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "50/50 [==============================] - 0s 448us/sample - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "50/50 [==============================] - 0s 494us/sample - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "50/50 [==============================] - 0s 1ms/sample - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "50/50 [==============================] - 0s 511us/sample - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "50/50 [==============================] - 0s 568us/sample - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "50/50 [==============================] - 0s 476us/sample - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "50/50 [==============================] - 0s 571us/sample - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "50/50 [==============================] - 0s 486us/sample - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "50/50 [==============================] - 0s 491us/sample - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "50/50 [==============================] - 0s 412us/sample - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "50/50 [==============================] - 0s 445us/sample - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "50/50 [==============================] - 0s 456us/sample - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "50/50 [==============================] - 0s 349us/sample - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "50/50 [==============================] - 0s 489us/sample - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "50/50 [==============================] - 0s 351us/sample - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "50/50 [==============================] - 0s 418us/sample - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "50/50 [==============================] - 0s 724us/sample - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "50/50 [==============================] - 0s 910us/sample - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "50/50 [==============================] - 0s 786us/sample - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "50/50 [==============================] - 0s 717us/sample - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "50/50 [==============================] - 0s 708us/sample - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "50/50 [==============================] - 0s 504us/sample - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "50/50 [==============================] - 0s 393us/sample - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "50/50 [==============================] - 0s 460us/sample - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "50/50 [==============================] - 0s 512us/sample - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "50/50 [==============================] - 0s 379us/sample - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "50/50 [==============================] - 0s 472us/sample - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "50/50 [==============================] - 0s 356us/sample - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "50/50 [==============================] - 0s 509us/sample - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "50/50 [==============================] - 0s 437us/sample - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "50/50 [==============================] - 0s 518us/sample - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "50/50 [==============================] - 0s 409us/sample - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "50/50 [==============================] - 0s 509us/sample - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "50/50 [==============================] - 0s 524us/sample - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "50/50 [==============================] - 0s 537us/sample - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "50/50 [==============================] - 0s 532us/sample - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "50/50 [==============================] - 0s 541us/sample - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "50/50 [==============================] - 0s 543us/sample - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "50/50 [==============================] - 0s 594us/sample - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "50/50 [==============================] - 0s 420us/sample - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "50/50 [==============================] - 0s 437us/sample - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "50/50 [==============================] - 0s 523us/sample - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "50/50 [==============================] - 0s 481us/sample - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "50/50 [==============================] - 0s 632us/sample - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "50/50 [==============================] - 0s 462us/sample - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "50/50 [==============================] - 0s 563us/sample - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "50/50 [==============================] - 0s 353us/sample - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "50/50 [==============================] - 0s 509us/sample - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "50/50 [==============================] - 0s 400us/sample - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "50/50 [==============================] - 0s 514us/sample - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "50/50 [==============================] - 0s 458us/sample - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "50/50 [==============================] - 0s 497us/sample - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "50/50 [==============================] - 0s 467us/sample - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "50/50 [==============================] - 0s 381us/sample - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "50/50 [==============================] - 0s 448us/sample - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "50/50 [==============================] - 0s 403us/sample - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "50/50 [==============================] - 0s 453us/sample - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "50/50 [==============================] - 0s 658us/sample - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "50/50 [==============================] - 0s 632us/sample - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "50/50 [==============================] - 0s 428us/sample - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "50/50 [==============================] - 0s 413us/sample - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "50/50 [==============================] - 0s 563us/sample - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "50/50 [==============================] - 0s 490us/sample - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "50/50 [==============================] - 0s 430us/sample - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "50/50 [==============================] - 0s 563us/sample - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "50/50 [==============================] - 0s 419us/sample - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "50/50 [==============================] - 0s 412us/sample - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "50/50 [==============================] - 0s 435us/sample - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "50/50 [==============================] - 0s 419us/sample - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "50/50 [==============================] - 0s 545us/sample - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "50/50 [==============================] - 0s 633us/sample - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "50/50 [==============================] - 0s 395us/sample - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "50/50 [==============================] - 0s 603us/sample - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "50/50 [==============================] - 0s 516us/sample - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "50/50 [==============================] - 0s 559us/sample - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "50/50 [==============================] - 0s 538us/sample - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "50/50 [==============================] - 0s 478us/sample - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "50/50 [==============================] - 0s 364us/sample - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "50/50 [==============================] - 0s 379us/sample - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "50/50 [==============================] - 0s 430us/sample - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "50/50 [==============================] - 0s 406us/sample - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "50/50 [==============================] - 0s 478us/sample - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "50/50 [==============================] - 0s 538us/sample - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "50/50 [==============================] - 0s 294us/sample - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "50/50 [==============================] - 0s 484us/sample - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "50/50 [==============================] - 0s 503us/sample - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "50/50 [==============================] - 0s 495us/sample - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "50/50 [==============================] - 0s 686us/sample - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "50/50 [==============================] - 0s 424us/sample - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "50/50 [==============================] - 0s 436us/sample - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "50/50 [==============================] - 0s 445us/sample - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "50/50 [==============================] - 0s 577us/sample - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "50/50 [==============================] - 0s 389us/sample - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "50/50 [==============================] - 0s 616us/sample - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "50/50 [==============================] - 0s 501us/sample - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "50/50 [==============================] - 0s 449us/sample - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "50/50 [==============================] - 0s 462us/sample - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/500\n",
      "50/50 [==============================] - 0s 445us/sample - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "50/50 [==============================] - 0s 417us/sample - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "50/50 [==============================] - 0s 531us/sample - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "50/50 [==============================] - 0s 394us/sample - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "50/50 [==============================] - 0s 544us/sample - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "50/50 [==============================] - 0s 390us/sample - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "50/50 [==============================] - 0s 452us/sample - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "50/50 [==============================] - 0s 456us/sample - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "50/50 [==============================] - 0s 606us/sample - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "50/50 [==============================] - 0s 533us/sample - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "50/50 [==============================] - 0s 509us/sample - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "50/50 [==============================] - 0s 409us/sample - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "50/50 [==============================] - 0s 521us/sample - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "50/50 [==============================] - 0s 612us/sample - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "50/50 [==============================] - 0s 517us/sample - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "50/50 [==============================] - 0s 579us/sample - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "50/50 [==============================] - 0s 480us/sample - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "50/50 [==============================] - 0s 698us/sample - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "50/50 [==============================] - 0s 465us/sample - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "50/50 [==============================] - 0s 476us/sample - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "50/50 [==============================] - 0s 630us/sample - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 1.00 - 0s 413us/sample - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "50/50 [==============================] - 0s 467us/sample - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "50/50 [==============================] - 0s 339us/sample - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "50/50 [==============================] - 0s 567us/sample - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "50/50 [==============================] - 0s 492us/sample - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "50/50 [==============================] - 0s 477us/sample - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "50/50 [==============================] - 0s 491us/sample - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "50/50 [==============================] - 0s 431us/sample - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "50/50 [==============================] - 0s 529us/sample - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "50/50 [==============================] - 0s 431us/sample - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "50/50 [==============================] - 0s 510us/sample - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "50/50 [==============================] - 0s 511us/sample - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "50/50 [==============================] - 0s 494us/sample - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "50/50 [==============================] - 0s 485us/sample - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "50/50 [==============================] - 0s 534us/sample - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# i \"history\" sparar vi träningshistoriken som används vid utvärdering av modellen\n",
    "history = logistic_regression_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utvärdera modell\n",
    "Vi utvärderar accuracy och loss i modellen:\n",
    "\n",
    "- Vad ser vi för skillnader mellan train och test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  1.0\n",
      "accuracy, test:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Sannolikheter bakom prediktioner\n",
      " Versicolor = 1 \n",
      " [[0.991]\n",
      " [0.054]\n",
      " [0.979]\n",
      " [0.032]\n",
      " [0.049]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = logistic_regression_model.predict_classes(X_test[0:5])\n",
    "\n",
    "probabilities = logistic_regression_model.predict_proba(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktioner\\n Versicolor = 1\",\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomialt problem - Iris med 3 klasser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vi utökar övningen till identifiering av alla 3 klasser: 'setosa', 'versicolor' och 'virginica'\n",
    " \n",
    "Vi förändrar input data:\n",
    "- Istället för EN dummy-variabel (1=Versicolor) är vårt Y nu 3 dummy-variabler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import & preparering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features : 4\n",
      "n_classes : 3\n",
      "\n",
      " Standardiserade features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      " [[ 0.069 -0.132  0.251  0.396]\n",
      " [ 1.038  0.098  0.535  0.396]\n",
      " [ 2.25  -0.592  1.672  1.054]]\n",
      "\n",
      "Y:  ['setosa' 'versicolor' 'virginica'] \n",
      " [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding (= skapar dummy-varibler)\n",
    "enc = OneHotEncoder(categories=\"auto\")\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Standardiserar data till medelvärde 0 och varians 1 \n",
    "# Standardisering av värden hjälper neurala nätverk att konvergera\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "print(\"n_features : \" + str(n_features))\n",
    "print(\"n_classes : \" + str(n_classes))\n",
    "\n",
    "print( \"\\n Standardiserade features: \\n\",feature_names,\"\\n\",X_train[0:3])\n",
    "print (\"\\nY: \",names,\"\\n\", Y_train[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial logistisk regression (Softmax)\n",
    "\n",
    "Till skillnad från vårt binära problem kan vi inte använda \"sigmoid\" som aktiveringsfunktion\n",
    "- Aktiveringsfunktionen \"softmax\" kan hantera problem där flera kategorier ska prediceras\n",
    "- Vi måste byta ut vår loss-funktion när vi har flera klasser, från \"binary_crossentropy\" till \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 10ms/sample - loss: 1.0086 - accuracy: 0.6267 - val_loss: 1.0195 - val_accuracy: 0.6267\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.9936 - accuracy: 0.6267 - val_loss: 1.0066 - val_accuracy: 0.6267\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.9819 - accuracy: 0.6267 - val_loss: 0.9960 - val_accuracy: 0.6267\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.9722 - accuracy: 0.6267 - val_loss: 0.9861 - val_accuracy: 0.6267\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.9635 - accuracy: 0.6267 - val_loss: 0.9782 - val_accuracy: 0.6267\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.9556 - accuracy: 0.6267 - val_loss: 0.9698 - val_accuracy: 0.6267\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.9478 - accuracy: 0.6267 - val_loss: 0.9625 - val_accuracy: 0.6267\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.9411 - accuracy: 0.6267 - val_loss: 0.9553 - val_accuracy: 0.6267\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.9342 - accuracy: 0.6267 - val_loss: 0.9476 - val_accuracy: 0.6267\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.9270 - accuracy: 0.6267 - val_loss: 0.9406 - val_accuracy: 0.6267\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.9204 - accuracy: 0.6267 - val_loss: 0.9331 - val_accuracy: 0.6267\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.9132 - accuracy: 0.6267 - val_loss: 0.9254 - val_accuracy: 0.6267\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.9059 - accuracy: 0.6267 - val_loss: 0.9183 - val_accuracy: 0.6267\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.8993 - accuracy: 0.6267 - val_loss: 0.9107 - val_accuracy: 0.6267\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.8923 - accuracy: 0.6267 - val_loss: 0.9045 - val_accuracy: 0.6267\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.8865 - accuracy: 0.6267 - val_loss: 0.8974 - val_accuracy: 0.6267\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.8797 - accuracy: 0.6267 - val_loss: 0.8906 - val_accuracy: 0.6267\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.8735 - accuracy: 0.6267 - val_loss: 0.8842 - val_accuracy: 0.6267\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.8672 - accuracy: 0.6267 - val_loss: 0.8778 - val_accuracy: 0.6267\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.8613 - accuracy: 0.6267 - val_loss: 0.8706 - val_accuracy: 0.6267\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.8543 - accuracy: 0.6267 - val_loss: 0.8635 - val_accuracy: 0.6267\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.8478 - accuracy: 0.6267 - val_loss: 0.8573 - val_accuracy: 0.6267\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.8421 - accuracy: 0.6267 - val_loss: 0.8517 - val_accuracy: 0.6400\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.8366 - accuracy: 0.6267 - val_loss: 0.8452 - val_accuracy: 0.6400\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.8306 - accuracy: 0.6267 - val_loss: 0.8394 - val_accuracy: 0.6400\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.8251 - accuracy: 0.6267 - val_loss: 0.8335 - val_accuracy: 0.6400\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.8199 - accuracy: 0.6267 - val_loss: 0.8280 - val_accuracy: 0.6400\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.8145 - accuracy: 0.6267 - val_loss: 0.8220 - val_accuracy: 0.6400\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.8085 - accuracy: 0.6267 - val_loss: 0.8149 - val_accuracy: 0.6400\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.8022 - accuracy: 0.6267 - val_loss: 0.8096 - val_accuracy: 0.6400\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.7972 - accuracy: 0.6267 - val_loss: 0.8040 - val_accuracy: 0.6400\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.7917 - accuracy: 0.6267 - val_loss: 0.7977 - val_accuracy: 0.6400\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.7858 - accuracy: 0.6267 - val_loss: 0.7921 - val_accuracy: 0.6400\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.7806 - accuracy: 0.6133 - val_loss: 0.7867 - val_accuracy: 0.6267\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.7754 - accuracy: 0.6133 - val_loss: 0.7806 - val_accuracy: 0.6267\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.7698 - accuracy: 0.6000 - val_loss: 0.7750 - val_accuracy: 0.6267\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.7646 - accuracy: 0.6000 - val_loss: 0.7699 - val_accuracy: 0.6267\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.7596 - accuracy: 0.6000 - val_loss: 0.7637 - val_accuracy: 0.6400\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.7539 - accuracy: 0.5867 - val_loss: 0.7587 - val_accuracy: 0.6400\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.7490 - accuracy: 0.5867 - val_loss: 0.7528 - val_accuracy: 0.6400\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.7435 - accuracy: 0.5867 - val_loss: 0.7472 - val_accuracy: 0.6267\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.7384 - accuracy: 0.5867 - val_loss: 0.7428 - val_accuracy: 0.6267\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.7341 - accuracy: 0.5867 - val_loss: 0.7372 - val_accuracy: 0.6267\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.7290 - accuracy: 0.5867 - val_loss: 0.7321 - val_accuracy: 0.6267\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.7243 - accuracy: 0.5867 - val_loss: 0.7273 - val_accuracy: 0.6267\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.7196 - accuracy: 0.5867 - val_loss: 0.7225 - val_accuracy: 0.6400\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.7151 - accuracy: 0.5867 - val_loss: 0.7177 - val_accuracy: 0.6400\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.7106 - accuracy: 0.5867 - val_loss: 0.7126 - val_accuracy: 0.6400\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.7058 - accuracy: 0.5733 - val_loss: 0.7075 - val_accuracy: 0.6400\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.7009 - accuracy: 0.5733 - val_loss: 0.7023 - val_accuracy: 0.6400\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 221us/sample - loss: 0.6960 - accuracy: 0.5733 - val_loss: 0.6978 - val_accuracy: 0.6400\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.6917 - accuracy: 0.5867 - val_loss: 0.6933 - val_accuracy: 0.6400\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.6876 - accuracy: 0.5733 - val_loss: 0.6892 - val_accuracy: 0.6400\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 205us/sample - loss: 0.6837 - accuracy: 0.5733 - val_loss: 0.6846 - val_accuracy: 0.6400\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.6796 - accuracy: 0.5733 - val_loss: 0.6808 - val_accuracy: 0.6400\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.6757 - accuracy: 0.5733 - val_loss: 0.6759 - val_accuracy: 0.6400\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.6714 - accuracy: 0.5733 - val_loss: 0.6719 - val_accuracy: 0.6533\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.6675 - accuracy: 0.5733 - val_loss: 0.6679 - val_accuracy: 0.6533\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.6637 - accuracy: 0.5733 - val_loss: 0.6637 - val_accuracy: 0.6533\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 237us/sample - loss: 0.6597 - accuracy: 0.5733 - val_loss: 0.6597 - val_accuracy: 0.6667\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.6560 - accuracy: 0.5867 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.6516 - accuracy: 0.5867 - val_loss: 0.6513 - val_accuracy: 0.6667\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.6481 - accuracy: 0.5867 - val_loss: 0.6476 - val_accuracy: 0.6667\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.6444 - accuracy: 0.5867 - val_loss: 0.6434 - val_accuracy: 0.6933\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.6405 - accuracy: 0.5867 - val_loss: 0.6397 - val_accuracy: 0.6933\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.6370 - accuracy: 0.5867 - val_loss: 0.6354 - val_accuracy: 0.6933\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.6332 - accuracy: 0.6000 - val_loss: 0.6309 - val_accuracy: 0.6933\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.6288 - accuracy: 0.6133 - val_loss: 0.6278 - val_accuracy: 0.6933\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.6258 - accuracy: 0.6133 - val_loss: 0.6237 - val_accuracy: 0.6933\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.6220 - accuracy: 0.6000 - val_loss: 0.6198 - val_accuracy: 0.6933\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.6186 - accuracy: 0.6000 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.6155 - accuracy: 0.6000 - val_loss: 0.6134 - val_accuracy: 0.6933\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.6122 - accuracy: 0.6133 - val_loss: 0.6096 - val_accuracy: 0.7067\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.6087 - accuracy: 0.6133 - val_loss: 0.6061 - val_accuracy: 0.7067\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.6054 - accuracy: 0.6133 - val_loss: 0.6024 - val_accuracy: 0.7333\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.6020 - accuracy: 0.6000 - val_loss: 0.5996 - val_accuracy: 0.7333\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.5992 - accuracy: 0.6000 - val_loss: 0.5957 - val_accuracy: 0.7333\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.5956 - accuracy: 0.6000 - val_loss: 0.5926 - val_accuracy: 0.7333\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.5927 - accuracy: 0.6000 - val_loss: 0.5896 - val_accuracy: 0.7333\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.5898 - accuracy: 0.6000 - val_loss: 0.5868 - val_accuracy: 0.7333\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.5871 - accuracy: 0.6000 - val_loss: 0.5836 - val_accuracy: 0.7333\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.5840 - accuracy: 0.6267 - val_loss: 0.5800 - val_accuracy: 0.7333\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.5807 - accuracy: 0.6400 - val_loss: 0.5771 - val_accuracy: 0.7333\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.5780 - accuracy: 0.6533 - val_loss: 0.5744 - val_accuracy: 0.7333\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.5753 - accuracy: 0.6533 - val_loss: 0.5707 - val_accuracy: 0.7333\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.5720 - accuracy: 0.6533 - val_loss: 0.5679 - val_accuracy: 0.7333\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.5693 - accuracy: 0.6667 - val_loss: 0.5647 - val_accuracy: 0.7467\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.5663 - accuracy: 0.6667 - val_loss: 0.5616 - val_accuracy: 0.7467\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.5636 - accuracy: 0.6533 - val_loss: 0.5596 - val_accuracy: 0.7467\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.5616 - accuracy: 0.6533 - val_loss: 0.5573 - val_accuracy: 0.7467\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.5593 - accuracy: 0.6533 - val_loss: 0.5546 - val_accuracy: 0.7467\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.71 - 0s 411us/sample - loss: 0.5570 - accuracy: 0.6533 - val_loss: 0.5523 - val_accuracy: 0.7333\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.5546 - accuracy: 0.6667 - val_loss: 0.5494 - val_accuracy: 0.7333\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.5519 - accuracy: 0.6667 - val_loss: 0.5466 - val_accuracy: 0.7333\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.5492 - accuracy: 0.6667 - val_loss: 0.5439 - val_accuracy: 0.7333\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.5468 - accuracy: 0.6667 - val_loss: 0.5414 - val_accuracy: 0.7333\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.5446 - accuracy: 0.6667 - val_loss: 0.5394 - val_accuracy: 0.7333\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.5422 - accuracy: 0.6800 - val_loss: 0.5363 - val_accuracy: 0.7333\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.5395 - accuracy: 0.6933 - val_loss: 0.5339 - val_accuracy: 0.7333\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.5376 - accuracy: 0.7200 - val_loss: 0.5316 - val_accuracy: 0.7333\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.5351 - accuracy: 0.7333 - val_loss: 0.5298 - val_accuracy: 0.7333\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.5332 - accuracy: 0.7467 - val_loss: 0.5275 - val_accuracy: 0.7467\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.5309 - accuracy: 0.7467 - val_loss: 0.5253 - val_accuracy: 0.7467\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.5287 - accuracy: 0.7467 - val_loss: 0.5232 - val_accuracy: 0.7467\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.5270 - accuracy: 0.7467 - val_loss: 0.5212 - val_accuracy: 0.7467\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.5247 - accuracy: 0.7467 - val_loss: 0.5190 - val_accuracy: 0.7467\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.5226 - accuracy: 0.7600 - val_loss: 0.5167 - val_accuracy: 0.7467\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.5204 - accuracy: 0.7600 - val_loss: 0.5142 - val_accuracy: 0.7467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.5184 - accuracy: 0.7600 - val_loss: 0.5122 - val_accuracy: 0.7467\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.5162 - accuracy: 0.7600 - val_loss: 0.5098 - val_accuracy: 0.7333\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.5138 - accuracy: 0.7600 - val_loss: 0.5075 - val_accuracy: 0.7333\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.5118 - accuracy: 0.7600 - val_loss: 0.5056 - val_accuracy: 0.7333\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.5099 - accuracy: 0.7600 - val_loss: 0.5033 - val_accuracy: 0.7333\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.5077 - accuracy: 0.7733 - val_loss: 0.5011 - val_accuracy: 0.7333\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 508us/sample - loss: 0.5055 - accuracy: 0.7733 - val_loss: 0.4988 - val_accuracy: 0.7333\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.5035 - accuracy: 0.7733 - val_loss: 0.4968 - val_accuracy: 0.7333\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.5017 - accuracy: 0.7733 - val_loss: 0.4952 - val_accuracy: 0.7333\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.4999 - accuracy: 0.7733 - val_loss: 0.4929 - val_accuracy: 0.7333\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.4979 - accuracy: 0.7733 - val_loss: 0.4908 - val_accuracy: 0.7333\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.4960 - accuracy: 0.7733 - val_loss: 0.4891 - val_accuracy: 0.7467\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.4944 - accuracy: 0.7733 - val_loss: 0.4872 - val_accuracy: 0.7467\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.4927 - accuracy: 0.7733 - val_loss: 0.4856 - val_accuracy: 0.7600\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.4912 - accuracy: 0.7733 - val_loss: 0.4844 - val_accuracy: 0.7467\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.4897 - accuracy: 0.7733 - val_loss: 0.4825 - val_accuracy: 0.7600\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.4880 - accuracy: 0.7733 - val_loss: 0.4806 - val_accuracy: 0.7733\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.4861 - accuracy: 0.7733 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.4845 - accuracy: 0.7733 - val_loss: 0.4776 - val_accuracy: 0.7733\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.4830 - accuracy: 0.7733 - val_loss: 0.4761 - val_accuracy: 0.7733\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.4815 - accuracy: 0.7733 - val_loss: 0.4745 - val_accuracy: 0.7733\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.4801 - accuracy: 0.7733 - val_loss: 0.4725 - val_accuracy: 0.7733\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.4784 - accuracy: 0.7867 - val_loss: 0.4710 - val_accuracy: 0.7733\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.4768 - accuracy: 0.7867 - val_loss: 0.4693 - val_accuracy: 0.7733\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.4752 - accuracy: 0.7867 - val_loss: 0.4674 - val_accuracy: 0.7733\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.4737 - accuracy: 0.7867 - val_loss: 0.4660 - val_accuracy: 0.7733\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.4722 - accuracy: 0.7867 - val_loss: 0.4644 - val_accuracy: 0.7733\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.4708 - accuracy: 0.8000 - val_loss: 0.4627 - val_accuracy: 0.7733\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.4692 - accuracy: 0.8000 - val_loss: 0.4614 - val_accuracy: 0.7733\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.4681 - accuracy: 0.8000 - val_loss: 0.4598 - val_accuracy: 0.7733\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.4666 - accuracy: 0.8000 - val_loss: 0.4585 - val_accuracy: 0.7733\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.4653 - accuracy: 0.8000 - val_loss: 0.4571 - val_accuracy: 0.7733\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.4641 - accuracy: 0.8000 - val_loss: 0.4556 - val_accuracy: 0.7733\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.4627 - accuracy: 0.8000 - val_loss: 0.4545 - val_accuracy: 0.7733\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 0.4614 - accuracy: 0.8000 - val_loss: 0.4531 - val_accuracy: 0.7733\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.4601 - accuracy: 0.8000 - val_loss: 0.4519 - val_accuracy: 0.7733\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.4587 - accuracy: 0.8000 - val_loss: 0.4506 - val_accuracy: 0.7733\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.4573 - accuracy: 0.8133 - val_loss: 0.4495 - val_accuracy: 0.7733\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.4562 - accuracy: 0.8133 - val_loss: 0.4479 - val_accuracy: 0.7867\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.4548 - accuracy: 0.8133 - val_loss: 0.4468 - val_accuracy: 0.7867\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.4536 - accuracy: 0.8133 - val_loss: 0.4455 - val_accuracy: 0.7867\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.4522 - accuracy: 0.8133 - val_loss: 0.4440 - val_accuracy: 0.7867\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.4508 - accuracy: 0.8133 - val_loss: 0.4428 - val_accuracy: 0.7867\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.4496 - accuracy: 0.8133 - val_loss: 0.4417 - val_accuracy: 0.8000\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.4486 - accuracy: 0.8133 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.4472 - accuracy: 0.8133 - val_loss: 0.4390 - val_accuracy: 0.8000\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.4461 - accuracy: 0.8133 - val_loss: 0.4379 - val_accuracy: 0.8000\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.4451 - accuracy: 0.8133 - val_loss: 0.4367 - val_accuracy: 0.8000\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.4439 - accuracy: 0.8133 - val_loss: 0.4354 - val_accuracy: 0.8000\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.4427 - accuracy: 0.8133 - val_loss: 0.4344 - val_accuracy: 0.8000\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.4417 - accuracy: 0.8133 - val_loss: 0.4332 - val_accuracy: 0.8000\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.4404 - accuracy: 0.8133 - val_loss: 0.4321 - val_accuracy: 0.8000\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.4394 - accuracy: 0.8133 - val_loss: 0.4310 - val_accuracy: 0.8000\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.4381 - accuracy: 0.8133 - val_loss: 0.4301 - val_accuracy: 0.8000\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.4370 - accuracy: 0.8133 - val_loss: 0.4289 - val_accuracy: 0.8000\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.4358 - accuracy: 0.8133 - val_loss: 0.4278 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.4347 - accuracy: 0.8133 - val_loss: 0.4265 - val_accuracy: 0.8000\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.4335 - accuracy: 0.8133 - val_loss: 0.4256 - val_accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.4326 - accuracy: 0.8133 - val_loss: 0.4245 - val_accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.4314 - accuracy: 0.8133 - val_loss: 0.4235 - val_accuracy: 0.8000\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.4304 - accuracy: 0.8133 - val_loss: 0.4224 - val_accuracy: 0.8000\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.4293 - accuracy: 0.8133 - val_loss: 0.4212 - val_accuracy: 0.8000\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.4283 - accuracy: 0.8133 - val_loss: 0.4205 - val_accuracy: 0.8000\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.4273 - accuracy: 0.8133 - val_loss: 0.4194 - val_accuracy: 0.8000\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.4263 - accuracy: 0.8133 - val_loss: 0.4184 - val_accuracy: 0.8000\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.4252 - accuracy: 0.8133 - val_loss: 0.4177 - val_accuracy: 0.8000\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.4243 - accuracy: 0.8133 - val_loss: 0.4166 - val_accuracy: 0.8000\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.4234 - accuracy: 0.8133 - val_loss: 0.4154 - val_accuracy: 0.8000\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.4223 - accuracy: 0.8133 - val_loss: 0.4144 - val_accuracy: 0.8000\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.4213 - accuracy: 0.8133 - val_loss: 0.4135 - val_accuracy: 0.8000\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.4203 - accuracy: 0.8133 - val_loss: 0.4128 - val_accuracy: 0.8000\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.4195 - accuracy: 0.8133 - val_loss: 0.4119 - val_accuracy: 0.8000\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.4185 - accuracy: 0.8133 - val_loss: 0.4108 - val_accuracy: 0.8000\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.4177 - accuracy: 0.8133 - val_loss: 0.4098 - val_accuracy: 0.8000\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.4167 - accuracy: 0.8133 - val_loss: 0.4091 - val_accuracy: 0.8000\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.4159 - accuracy: 0.8133 - val_loss: 0.4086 - val_accuracy: 0.8000\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.4150 - accuracy: 0.8133 - val_loss: 0.4075 - val_accuracy: 0.8000\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.4140 - accuracy: 0.8133 - val_loss: 0.4067 - val_accuracy: 0.8000\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.4131 - accuracy: 0.8133 - val_loss: 0.4058 - val_accuracy: 0.8000\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.4129 - accuracy: 0.8133 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.4115 - accuracy: 0.8133 - val_loss: 0.4044 - val_accuracy: 0.8000\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.4106 - accuracy: 0.8133 - val_loss: 0.4036 - val_accuracy: 0.8000\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.4099 - accuracy: 0.8133 - val_loss: 0.4029 - val_accuracy: 0.8000\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.4090 - accuracy: 0.8133 - val_loss: 0.4019 - val_accuracy: 0.8000\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.4081 - accuracy: 0.8133 - val_loss: 0.4009 - val_accuracy: 0.8000\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.4073 - accuracy: 0.8133 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.4064 - accuracy: 0.8133 - val_loss: 0.3996 - val_accuracy: 0.8000\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.4055 - accuracy: 0.8133 - val_loss: 0.3988 - val_accuracy: 0.8000\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.4046 - accuracy: 0.8133 - val_loss: 0.3981 - val_accuracy: 0.8133\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.4039 - accuracy: 0.8133 - val_loss: 0.3976 - val_accuracy: 0.8133\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.4031 - accuracy: 0.8133 - val_loss: 0.3968 - val_accuracy: 0.8133\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.4023 - accuracy: 0.8133 - val_loss: 0.3964 - val_accuracy: 0.8133\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.4014 - accuracy: 0.8133 - val_loss: 0.3955 - val_accuracy: 0.8133\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.4010 - accuracy: 0.8133 - val_loss: 0.3947 - val_accuracy: 0.8133\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.4000 - accuracy: 0.8133 - val_loss: 0.3938 - val_accuracy: 0.8133\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3992 - accuracy: 0.8133 - val_loss: 0.3929 - val_accuracy: 0.8133\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.3985 - accuracy: 0.8133 - val_loss: 0.3921 - val_accuracy: 0.8133\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.3977 - accuracy: 0.8133 - val_loss: 0.3916 - val_accuracy: 0.8133\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.3969 - accuracy: 0.8133 - val_loss: 0.3909 - val_accuracy: 0.8133\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.3963 - accuracy: 0.8133 - val_loss: 0.3904 - val_accuracy: 0.8267\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.3954 - accuracy: 0.8133 - val_loss: 0.3898 - val_accuracy: 0.8267\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3947 - accuracy: 0.8133 - val_loss: 0.3892 - val_accuracy: 0.8267\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.3940 - accuracy: 0.8133 - val_loss: 0.3883 - val_accuracy: 0.8267\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.3931 - accuracy: 0.8133 - val_loss: 0.3876 - val_accuracy: 0.8267\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.3924 - accuracy: 0.8133 - val_loss: 0.3869 - val_accuracy: 0.8267\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.3917 - accuracy: 0.8133 - val_loss: 0.3863 - val_accuracy: 0.8267\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3909 - accuracy: 0.8133 - val_loss: 0.3854 - val_accuracy: 0.8267\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.3902 - accuracy: 0.8133 - val_loss: 0.3847 - val_accuracy: 0.8267\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.3895 - accuracy: 0.8133 - val_loss: 0.3842 - val_accuracy: 0.8267\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.3887 - accuracy: 0.8133 - val_loss: 0.3838 - val_accuracy: 0.8267\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.3879 - accuracy: 0.8133 - val_loss: 0.3830 - val_accuracy: 0.8267\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.3872 - accuracy: 0.8133 - val_loss: 0.3826 - val_accuracy: 0.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.3865 - accuracy: 0.8133 - val_loss: 0.3819 - val_accuracy: 0.8267\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.3859 - accuracy: 0.8133 - val_loss: 0.3813 - val_accuracy: 0.8267\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.3851 - accuracy: 0.8133 - val_loss: 0.3805 - val_accuracy: 0.8267\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.3845 - accuracy: 0.8133 - val_loss: 0.3800 - val_accuracy: 0.8267\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.3838 - accuracy: 0.8133 - val_loss: 0.3794 - val_accuracy: 0.8267\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.3831 - accuracy: 0.8133 - val_loss: 0.3789 - val_accuracy: 0.8267\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.3825 - accuracy: 0.8133 - val_loss: 0.3783 - val_accuracy: 0.8267\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.3816 - accuracy: 0.8133 - val_loss: 0.3776 - val_accuracy: 0.8267\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.3809 - accuracy: 0.8133 - val_loss: 0.3769 - val_accuracy: 0.8267\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.3803 - accuracy: 0.8133 - val_loss: 0.3763 - val_accuracy: 0.8267\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.3795 - accuracy: 0.8133 - val_loss: 0.3756 - val_accuracy: 0.8267\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.3788 - accuracy: 0.8133 - val_loss: 0.3751 - val_accuracy: 0.8267\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.3780 - accuracy: 0.8133 - val_loss: 0.3746 - val_accuracy: 0.8267\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.3773 - accuracy: 0.8133 - val_loss: 0.3741 - val_accuracy: 0.8267\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.3768 - accuracy: 0.8133 - val_loss: 0.3735 - val_accuracy: 0.8267\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 0.3760 - accuracy: 0.8133 - val_loss: 0.3730 - val_accuracy: 0.8267\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.3753 - accuracy: 0.8133 - val_loss: 0.3724 - val_accuracy: 0.8267\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.3748 - accuracy: 0.8133 - val_loss: 0.3716 - val_accuracy: 0.8267\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3741 - accuracy: 0.8133 - val_loss: 0.3708 - val_accuracy: 0.8267\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.3734 - accuracy: 0.8133 - val_loss: 0.3704 - val_accuracy: 0.8267\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.3727 - accuracy: 0.8133 - val_loss: 0.3697 - val_accuracy: 0.8267\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.3721 - accuracy: 0.8133 - val_loss: 0.3691 - val_accuracy: 0.8267\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3715 - accuracy: 0.8133 - val_loss: 0.3685 - val_accuracy: 0.8267\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 478us/sample - loss: 0.3709 - accuracy: 0.8133 - val_loss: 0.3679 - val_accuracy: 0.8267\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.3702 - accuracy: 0.8133 - val_loss: 0.3673 - val_accuracy: 0.8267\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3696 - accuracy: 0.8133 - val_loss: 0.3665 - val_accuracy: 0.8267\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.3689 - accuracy: 0.8133 - val_loss: 0.3661 - val_accuracy: 0.8267\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3683 - accuracy: 0.8133 - val_loss: 0.3657 - val_accuracy: 0.8267\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.3676 - accuracy: 0.8133 - val_loss: 0.3652 - val_accuracy: 0.8267\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.3670 - accuracy: 0.8133 - val_loss: 0.3647 - val_accuracy: 0.8267\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 0.3664 - accuracy: 0.8133 - val_loss: 0.3641 - val_accuracy: 0.8267\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.3656 - accuracy: 0.8133 - val_loss: 0.3633 - val_accuracy: 0.8267\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.3649 - accuracy: 0.8133 - val_loss: 0.3628 - val_accuracy: 0.8267\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.3643 - accuracy: 0.8133 - val_loss: 0.3621 - val_accuracy: 0.8267\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.3635 - accuracy: 0.8133 - val_loss: 0.3615 - val_accuracy: 0.8267\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3627 - accuracy: 0.8133 - val_loss: 0.3609 - val_accuracy: 0.8267\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.3620 - accuracy: 0.8133 - val_loss: 0.3604 - val_accuracy: 0.8267\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.3614 - accuracy: 0.8133 - val_loss: 0.3599 - val_accuracy: 0.8267\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.3607 - accuracy: 0.8133 - val_loss: 0.3592 - val_accuracy: 0.8267\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.3600 - accuracy: 0.8133 - val_loss: 0.3584 - val_accuracy: 0.8267\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3594 - accuracy: 0.8133 - val_loss: 0.3578 - val_accuracy: 0.8267\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.3588 - accuracy: 0.8133 - val_loss: 0.3572 - val_accuracy: 0.8267\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3582 - accuracy: 0.8133 - val_loss: 0.3568 - val_accuracy: 0.8400\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.3575 - accuracy: 0.8133 - val_loss: 0.3561 - val_accuracy: 0.8400\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.3569 - accuracy: 0.8133 - val_loss: 0.3557 - val_accuracy: 0.8400\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.3562 - accuracy: 0.8133 - val_loss: 0.3550 - val_accuracy: 0.8400\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.3556 - accuracy: 0.8133 - val_loss: 0.3545 - val_accuracy: 0.8400\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.3551 - accuracy: 0.8133 - val_loss: 0.3540 - val_accuracy: 0.8400\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.3545 - accuracy: 0.8267 - val_loss: 0.3536 - val_accuracy: 0.8400\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.3538 - accuracy: 0.8133 - val_loss: 0.3529 - val_accuracy: 0.8400\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 495us/sample - loss: 0.3533 - accuracy: 0.8267 - val_loss: 0.3525 - val_accuracy: 0.8400\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.3526 - accuracy: 0.8267 - val_loss: 0.3521 - val_accuracy: 0.8400\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3521 - accuracy: 0.8267 - val_loss: 0.3516 - val_accuracy: 0.8400\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.3515 - accuracy: 0.8267 - val_loss: 0.3513 - val_accuracy: 0.8533\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.3510 - accuracy: 0.8267 - val_loss: 0.3506 - val_accuracy: 0.8400\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.3504 - accuracy: 0.8267 - val_loss: 0.3501 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.3499 - accuracy: 0.8267 - val_loss: 0.3494 - val_accuracy: 0.8400\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.3496 - accuracy: 0.8267 - val_loss: 0.3489 - val_accuracy: 0.8400\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.3488 - accuracy: 0.8267 - val_loss: 0.3486 - val_accuracy: 0.8533\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.3483 - accuracy: 0.8267 - val_loss: 0.3482 - val_accuracy: 0.8533\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.3477 - accuracy: 0.8267 - val_loss: 0.3477 - val_accuracy: 0.8533\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.3472 - accuracy: 0.8267 - val_loss: 0.3475 - val_accuracy: 0.8533\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3465 - accuracy: 0.8267 - val_loss: 0.3472 - val_accuracy: 0.8533\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.3461 - accuracy: 0.8267 - val_loss: 0.3468 - val_accuracy: 0.8533\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.3454 - accuracy: 0.8267 - val_loss: 0.3461 - val_accuracy: 0.8533\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3448 - accuracy: 0.8267 - val_loss: 0.3458 - val_accuracy: 0.8533\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.3446 - accuracy: 0.8267 - val_loss: 0.3452 - val_accuracy: 0.8533\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.3437 - accuracy: 0.8267 - val_loss: 0.3447 - val_accuracy: 0.8533\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.3432 - accuracy: 0.8267 - val_loss: 0.3440 - val_accuracy: 0.8533\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 0.3427 - accuracy: 0.8267 - val_loss: 0.3433 - val_accuracy: 0.8533\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.3421 - accuracy: 0.8267 - val_loss: 0.3427 - val_accuracy: 0.8533\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.3416 - accuracy: 0.8267 - val_loss: 0.3421 - val_accuracy: 0.8533\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.3410 - accuracy: 0.8267 - val_loss: 0.3415 - val_accuracy: 0.8533\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.3405 - accuracy: 0.8267 - val_loss: 0.3412 - val_accuracy: 0.8533\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.3399 - accuracy: 0.8267 - val_loss: 0.3405 - val_accuracy: 0.8533\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3394 - accuracy: 0.8267 - val_loss: 0.3399 - val_accuracy: 0.8533\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.3389 - accuracy: 0.8267 - val_loss: 0.3394 - val_accuracy: 0.8533\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3385 - accuracy: 0.8267 - val_loss: 0.3391 - val_accuracy: 0.8533\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 238us/sample - loss: 0.3378 - accuracy: 0.8267 - val_loss: 0.3388 - val_accuracy: 0.8533\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.3373 - accuracy: 0.8267 - val_loss: 0.3383 - val_accuracy: 0.8533\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.3370 - accuracy: 0.8400 - val_loss: 0.3380 - val_accuracy: 0.8533\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.3364 - accuracy: 0.8400 - val_loss: 0.3378 - val_accuracy: 0.8533\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.3359 - accuracy: 0.8400 - val_loss: 0.3374 - val_accuracy: 0.8533\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3353 - accuracy: 0.8533 - val_loss: 0.3369 - val_accuracy: 0.8533\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.3347 - accuracy: 0.8533 - val_loss: 0.3362 - val_accuracy: 0.8533\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.3343 - accuracy: 0.8533 - val_loss: 0.3359 - val_accuracy: 0.8533\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.3338 - accuracy: 0.8533 - val_loss: 0.3352 - val_accuracy: 0.8533\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.3332 - accuracy: 0.8533 - val_loss: 0.3348 - val_accuracy: 0.8533\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.3327 - accuracy: 0.8533 - val_loss: 0.3344 - val_accuracy: 0.8533\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.3322 - accuracy: 0.8533 - val_loss: 0.3338 - val_accuracy: 0.8533\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.3318 - accuracy: 0.8533 - val_loss: 0.3331 - val_accuracy: 0.8533\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.3312 - accuracy: 0.8533 - val_loss: 0.3326 - val_accuracy: 0.8533\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.3306 - accuracy: 0.8533 - val_loss: 0.3321 - val_accuracy: 0.8533\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3300 - accuracy: 0.8533 - val_loss: 0.3319 - val_accuracy: 0.8533\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.3295 - accuracy: 0.8533 - val_loss: 0.3316 - val_accuracy: 0.8533\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.3292 - accuracy: 0.8533 - val_loss: 0.3308 - val_accuracy: 0.8533\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.3286 - accuracy: 0.8533 - val_loss: 0.3304 - val_accuracy: 0.8533\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.3283 - accuracy: 0.8533 - val_loss: 0.3297 - val_accuracy: 0.8533\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.3276 - accuracy: 0.8533 - val_loss: 0.3291 - val_accuracy: 0.8667\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.3271 - accuracy: 0.8533 - val_loss: 0.3288 - val_accuracy: 0.8533\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.3266 - accuracy: 0.8533 - val_loss: 0.3283 - val_accuracy: 0.8533\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3262 - accuracy: 0.8533 - val_loss: 0.3279 - val_accuracy: 0.8667\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.3257 - accuracy: 0.8533 - val_loss: 0.3274 - val_accuracy: 0.8667\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.3253 - accuracy: 0.8533 - val_loss: 0.3272 - val_accuracy: 0.8533\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.3246 - accuracy: 0.8533 - val_loss: 0.3268 - val_accuracy: 0.8533\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.3242 - accuracy: 0.8533 - val_loss: 0.3261 - val_accuracy: 0.8667\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3240 - accuracy: 0.8533 - val_loss: 0.3256 - val_accuracy: 0.8667\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3232 - accuracy: 0.8533 - val_loss: 0.3251 - val_accuracy: 0.8667\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.3227 - accuracy: 0.8533 - val_loss: 0.3248 - val_accuracy: 0.8667\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.3222 - accuracy: 0.8533 - val_loss: 0.3244 - val_accuracy: 0.8667\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.3218 - accuracy: 0.8533 - val_loss: 0.3239 - val_accuracy: 0.8667\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.3213 - accuracy: 0.8533 - val_loss: 0.3236 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.3208 - accuracy: 0.8533 - val_loss: 0.3231 - val_accuracy: 0.8800\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3203 - accuracy: 0.8533 - val_loss: 0.3228 - val_accuracy: 0.8800\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.3197 - accuracy: 0.8533 - val_loss: 0.3222 - val_accuracy: 0.8800\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.3191 - accuracy: 0.8533 - val_loss: 0.3218 - val_accuracy: 0.8800\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.3186 - accuracy: 0.8533 - val_loss: 0.3210 - val_accuracy: 0.8800\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.3180 - accuracy: 0.8533 - val_loss: 0.3205 - val_accuracy: 0.8800\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 542us/sample - loss: 0.3175 - accuracy: 0.8533 - val_loss: 0.3201 - val_accuracy: 0.8800\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 536us/sample - loss: 0.3169 - accuracy: 0.8533 - val_loss: 0.3199 - val_accuracy: 0.8800\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.3164 - accuracy: 0.8533 - val_loss: 0.3195 - val_accuracy: 0.8800\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.3159 - accuracy: 0.8533 - val_loss: 0.3192 - val_accuracy: 0.8800\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 544us/sample - loss: 0.3155 - accuracy: 0.8667 - val_loss: 0.3190 - val_accuracy: 0.8667\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.3148 - accuracy: 0.8667 - val_loss: 0.3186 - val_accuracy: 0.8667\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.3144 - accuracy: 0.8667 - val_loss: 0.3180 - val_accuracy: 0.8800\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.3139 - accuracy: 0.8667 - val_loss: 0.3176 - val_accuracy: 0.8800\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.3135 - accuracy: 0.8667 - val_loss: 0.3175 - val_accuracy: 0.8667\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.3132 - accuracy: 0.8667 - val_loss: 0.3171 - val_accuracy: 0.8667\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.3126 - accuracy: 0.8667 - val_loss: 0.3166 - val_accuracy: 0.8667\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.3120 - accuracy: 0.8667 - val_loss: 0.3160 - val_accuracy: 0.8667\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3115 - accuracy: 0.8667 - val_loss: 0.3153 - val_accuracy: 0.8800\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.3110 - accuracy: 0.8667 - val_loss: 0.3150 - val_accuracy: 0.8800\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3107 - accuracy: 0.8667 - val_loss: 0.3144 - val_accuracy: 0.8800\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.3104 - accuracy: 0.8667 - val_loss: 0.3139 - val_accuracy: 0.8800\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.3099 - accuracy: 0.8667 - val_loss: 0.3135 - val_accuracy: 0.8800\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3094 - accuracy: 0.8667 - val_loss: 0.3133 - val_accuracy: 0.8800\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.3090 - accuracy: 0.8667 - val_loss: 0.3132 - val_accuracy: 0.8800\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.3085 - accuracy: 0.8667 - val_loss: 0.3126 - val_accuracy: 0.8800\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.3080 - accuracy: 0.8667 - val_loss: 0.3122 - val_accuracy: 0.8800\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.3076 - accuracy: 0.8667 - val_loss: 0.3116 - val_accuracy: 0.8800\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.3071 - accuracy: 0.8667 - val_loss: 0.3112 - val_accuracy: 0.8800\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.3067 - accuracy: 0.8667 - val_loss: 0.3107 - val_accuracy: 0.8800\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.3061 - accuracy: 0.8667 - val_loss: 0.3102 - val_accuracy: 0.8800\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.3057 - accuracy: 0.8667 - val_loss: 0.3095 - val_accuracy: 0.8800\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3051 - accuracy: 0.8667 - val_loss: 0.3089 - val_accuracy: 0.8933\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.3049 - accuracy: 0.8800 - val_loss: 0.3084 - val_accuracy: 0.8933\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.3043 - accuracy: 0.8800 - val_loss: 0.3080 - val_accuracy: 0.8933\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.3039 - accuracy: 0.8800 - val_loss: 0.3076 - val_accuracy: 0.8933\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.3033 - accuracy: 0.8800 - val_loss: 0.3072 - val_accuracy: 0.8933\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.3030 - accuracy: 0.8800 - val_loss: 0.3066 - val_accuracy: 0.8933\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.3024 - accuracy: 0.8933 - val_loss: 0.3062 - val_accuracy: 0.8933\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.3019 - accuracy: 0.8800 - val_loss: 0.3059 - val_accuracy: 0.8933\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.3014 - accuracy: 0.8800 - val_loss: 0.3053 - val_accuracy: 0.8933\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.3009 - accuracy: 0.8933 - val_loss: 0.3049 - val_accuracy: 0.8933\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.3004 - accuracy: 0.8800 - val_loss: 0.3044 - val_accuracy: 0.8933\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.3000 - accuracy: 0.8933 - val_loss: 0.3040 - val_accuracy: 0.8933\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.2994 - accuracy: 0.8933 - val_loss: 0.3036 - val_accuracy: 0.8933\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.2989 - accuracy: 0.8933 - val_loss: 0.3029 - val_accuracy: 0.8933\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.2984 - accuracy: 0.8933 - val_loss: 0.3025 - val_accuracy: 0.8933\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.2979 - accuracy: 0.8933 - val_loss: 0.3021 - val_accuracy: 0.8933\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.2974 - accuracy: 0.8933 - val_loss: 0.3014 - val_accuracy: 0.8933\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.2969 - accuracy: 0.8933 - val_loss: 0.3009 - val_accuracy: 0.8933\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.2964 - accuracy: 0.8933 - val_loss: 0.3002 - val_accuracy: 0.8933\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.2959 - accuracy: 0.8933 - val_loss: 0.3000 - val_accuracy: 0.8933\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.2953 - accuracy: 0.8933 - val_loss: 0.2997 - val_accuracy: 0.8933\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.2950 - accuracy: 0.8933 - val_loss: 0.2992 - val_accuracy: 0.8933\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.2944 - accuracy: 0.8933 - val_loss: 0.2987 - val_accuracy: 0.8933\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.2940 - accuracy: 0.8933 - val_loss: 0.2984 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.2935 - accuracy: 0.8933 - val_loss: 0.2979 - val_accuracy: 0.8933\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2931 - accuracy: 0.8933 - val_loss: 0.2973 - val_accuracy: 0.8933\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.2927 - accuracy: 0.8933 - val_loss: 0.2970 - val_accuracy: 0.8933\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.2923 - accuracy: 0.8933 - val_loss: 0.2967 - val_accuracy: 0.8933\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.2918 - accuracy: 0.8933 - val_loss: 0.2962 - val_accuracy: 0.8933\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.93 - 0s 401us/sample - loss: 0.2915 - accuracy: 0.8933 - val_loss: 0.2960 - val_accuracy: 0.8933\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.2910 - accuracy: 0.8933 - val_loss: 0.2954 - val_accuracy: 0.8933\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.2907 - accuracy: 0.8933 - val_loss: 0.2948 - val_accuracy: 0.8933\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.2903 - accuracy: 0.8933 - val_loss: 0.2946 - val_accuracy: 0.8933\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.2898 - accuracy: 0.8933 - val_loss: 0.2944 - val_accuracy: 0.8933\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.2893 - accuracy: 0.8933 - val_loss: 0.2941 - val_accuracy: 0.8933\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.2889 - accuracy: 0.8933 - val_loss: 0.2936 - val_accuracy: 0.8933\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.2886 - accuracy: 0.8933 - val_loss: 0.2933 - val_accuracy: 0.8933\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 492us/sample - loss: 0.2881 - accuracy: 0.8933 - val_loss: 0.2929 - val_accuracy: 0.8933\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2878 - accuracy: 0.8933 - val_loss: 0.2925 - val_accuracy: 0.8933\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.2874 - accuracy: 0.8933 - val_loss: 0.2919 - val_accuracy: 0.8933\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.2870 - accuracy: 0.8933 - val_loss: 0.2917 - val_accuracy: 0.8933\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 215us/sample - loss: 0.2866 - accuracy: 0.8933 - val_loss: 0.2913 - val_accuracy: 0.8933\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.2863 - accuracy: 0.8933 - val_loss: 0.2908 - val_accuracy: 0.8933\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.2857 - accuracy: 0.8933 - val_loss: 0.2905 - val_accuracy: 0.8933\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.2854 - accuracy: 0.8933 - val_loss: 0.2903 - val_accuracy: 0.8933\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.2850 - accuracy: 0.8933 - val_loss: 0.2901 - val_accuracy: 0.8933\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.2845 - accuracy: 0.8933 - val_loss: 0.2899 - val_accuracy: 0.8933\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.2841 - accuracy: 0.8933 - val_loss: 0.2896 - val_accuracy: 0.8933\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.2836 - accuracy: 0.8933 - val_loss: 0.2890 - val_accuracy: 0.8933\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.2833 - accuracy: 0.8933 - val_loss: 0.2884 - val_accuracy: 0.8933\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.2827 - accuracy: 0.8933 - val_loss: 0.2880 - val_accuracy: 0.8933\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.2823 - accuracy: 0.8933 - val_loss: 0.2878 - val_accuracy: 0.8933\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.2820 - accuracy: 0.8933 - val_loss: 0.2872 - val_accuracy: 0.8933\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.2816 - accuracy: 0.8933 - val_loss: 0.2871 - val_accuracy: 0.8933\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.2811 - accuracy: 0.8933 - val_loss: 0.2865 - val_accuracy: 0.8933\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.2808 - accuracy: 0.8933 - val_loss: 0.2859 - val_accuracy: 0.8933\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.2803 - accuracy: 0.8933 - val_loss: 0.2854 - val_accuracy: 0.8933\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.2799 - accuracy: 0.8933 - val_loss: 0.2852 - val_accuracy: 0.8933\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.2795 - accuracy: 0.8933 - val_loss: 0.2849 - val_accuracy: 0.8933\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.2791 - accuracy: 0.8933 - val_loss: 0.2846 - val_accuracy: 0.8933\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.2787 - accuracy: 0.8933 - val_loss: 0.2840 - val_accuracy: 0.8933\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.2785 - accuracy: 0.8933 - val_loss: 0.2835 - val_accuracy: 0.8933\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.2780 - accuracy: 0.8933 - val_loss: 0.2831 - val_accuracy: 0.8933\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.2775 - accuracy: 0.9067 - val_loss: 0.2826 - val_accuracy: 0.8933\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 0.2772 - accuracy: 0.8933 - val_loss: 0.2824 - val_accuracy: 0.8933\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.2767 - accuracy: 0.9067 - val_loss: 0.2819 - val_accuracy: 0.8933\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.2763 - accuracy: 0.9067 - val_loss: 0.2813 - val_accuracy: 0.8933\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.2759 - accuracy: 0.9067 - val_loss: 0.2811 - val_accuracy: 0.8933\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.2755 - accuracy: 0.9067 - val_loss: 0.2808 - val_accuracy: 0.8933\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.2750 - accuracy: 0.9067 - val_loss: 0.2803 - val_accuracy: 0.9067\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 751us/sample - loss: 0.2746 - accuracy: 0.9067 - val_loss: 0.2798 - val_accuracy: 0.9067\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.2743 - accuracy: 0.9067 - val_loss: 0.2796 - val_accuracy: 0.9067\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 1ms/sample - loss: 0.2741 - accuracy: 0.9067 - val_loss: 0.2790 - val_accuracy: 0.9067\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 846us/sample - loss: 0.2735 - accuracy: 0.9067 - val_loss: 0.2786 - val_accuracy: 0.9067\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 458us/sample - loss: 0.2731 - accuracy: 0.9067 - val_loss: 0.2784 - val_accuracy: 0.9067\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 511us/sample - loss: 0.2727 - accuracy: 0.9067 - val_loss: 0.2780 - val_accuracy: 0.9067\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.2725 - accuracy: 0.9067 - val_loss: 0.2779 - val_accuracy: 0.9067\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.2719 - accuracy: 0.9067 - val_loss: 0.2773 - val_accuracy: 0.9067\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.2717 - accuracy: 0.9067 - val_loss: 0.2771 - val_accuracy: 0.9067\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.2713 - accuracy: 0.9067 - val_loss: 0.2766 - val_accuracy: 0.9067\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.2708 - accuracy: 0.9067 - val_loss: 0.2764 - val_accuracy: 0.9067\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.2705 - accuracy: 0.9067 - val_loss: 0.2760 - val_accuracy: 0.9067\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.2701 - accuracy: 0.9067 - val_loss: 0.2757 - val_accuracy: 0.9067\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2697 - accuracy: 0.9067 - val_loss: 0.2752 - val_accuracy: 0.9067\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.2693 - accuracy: 0.9067 - val_loss: 0.2750 - val_accuracy: 0.9067\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.2688 - accuracy: 0.9067 - val_loss: 0.2746 - val_accuracy: 0.9067\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.2688 - accuracy: 0.9067 - val_loss: 0.2744 - val_accuracy: 0.9067\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.2682 - accuracy: 0.9067 - val_loss: 0.2744 - val_accuracy: 0.9067\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.2677 - accuracy: 0.9067 - val_loss: 0.2742 - val_accuracy: 0.9067\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.2675 - accuracy: 0.9067 - val_loss: 0.2740 - val_accuracy: 0.9067\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2671 - accuracy: 0.9067 - val_loss: 0.2734 - val_accuracy: 0.9067\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.2670 - accuracy: 0.9067 - val_loss: 0.2730 - val_accuracy: 0.9067\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.2665 - accuracy: 0.9067 - val_loss: 0.2725 - val_accuracy: 0.9067\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.2662 - accuracy: 0.9067 - val_loss: 0.2724 - val_accuracy: 0.9067\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.2659 - accuracy: 0.9067 - val_loss: 0.2721 - val_accuracy: 0.9067\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.2655 - accuracy: 0.9067 - val_loss: 0.2717 - val_accuracy: 0.9067\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.2652 - accuracy: 0.9067 - val_loss: 0.2714 - val_accuracy: 0.9067\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.2649 - accuracy: 0.9067 - val_loss: 0.2708 - val_accuracy: 0.9067\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.2645 - accuracy: 0.9067 - val_loss: 0.2704 - val_accuracy: 0.9067\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.2642 - accuracy: 0.9067 - val_loss: 0.2702 - val_accuracy: 0.9067\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.2640 - accuracy: 0.9067 - val_loss: 0.2699 - val_accuracy: 0.9067\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 484us/sample - loss: 0.2636 - accuracy: 0.9067 - val_loss: 0.2696 - val_accuracy: 0.9067\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.2633 - accuracy: 0.9067 - val_loss: 0.2691 - val_accuracy: 0.9067\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.2630 - accuracy: 0.9067 - val_loss: 0.2690 - val_accuracy: 0.9067\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.2627 - accuracy: 0.9067 - val_loss: 0.2689 - val_accuracy: 0.9067\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.2622 - accuracy: 0.9067 - val_loss: 0.2686 - val_accuracy: 0.9067\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.2619 - accuracy: 0.9067 - val_loss: 0.2684 - val_accuracy: 0.9067\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.2616 - accuracy: 0.9067 - val_loss: 0.2683 - val_accuracy: 0.9067\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.2614 - accuracy: 0.9067 - val_loss: 0.2680 - val_accuracy: 0.9067\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.2610 - accuracy: 0.9067 - val_loss: 0.2677 - val_accuracy: 0.9067\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.2606 - accuracy: 0.9067 - val_loss: 0.2677 - val_accuracy: 0.9067\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.2603 - accuracy: 0.9067 - val_loss: 0.2674 - val_accuracy: 0.9067\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.2602 - accuracy: 0.9067 - val_loss: 0.2671 - val_accuracy: 0.9067\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2598 - accuracy: 0.9067 - val_loss: 0.2667 - val_accuracy: 0.9067\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.2594 - accuracy: 0.9067 - val_loss: 0.2665 - val_accuracy: 0.9067\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.2590 - accuracy: 0.9067 - val_loss: 0.2663 - val_accuracy: 0.9067\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.2588 - accuracy: 0.9067 - val_loss: 0.2661 - val_accuracy: 0.9067\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2583 - accuracy: 0.9067 - val_loss: 0.2658 - val_accuracy: 0.9067\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.2581 - accuracy: 0.9067 - val_loss: 0.2654 - val_accuracy: 0.9067\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.2577 - accuracy: 0.9067 - val_loss: 0.2650 - val_accuracy: 0.9067\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2574 - accuracy: 0.9067 - val_loss: 0.2646 - val_accuracy: 0.9067\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.2570 - accuracy: 0.9067 - val_loss: 0.2642 - val_accuracy: 0.9067\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2566 - accuracy: 0.9067 - val_loss: 0.2638 - val_accuracy: 0.9067\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.2563 - accuracy: 0.9067 - val_loss: 0.2632 - val_accuracy: 0.9067\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.2560 - accuracy: 0.9067 - val_loss: 0.2628 - val_accuracy: 0.9067\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.2558 - accuracy: 0.9067 - val_loss: 0.2623 - val_accuracy: 0.9067\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.2554 - accuracy: 0.9067 - val_loss: 0.2622 - val_accuracy: 0.9067\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.2551 - accuracy: 0.9067 - val_loss: 0.2618 - val_accuracy: 0.9067\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.2549 - accuracy: 0.9067 - val_loss: 0.2613 - val_accuracy: 0.9067\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.2544 - accuracy: 0.9067 - val_loss: 0.2609 - val_accuracy: 0.9067\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.2542 - accuracy: 0.9067 - val_loss: 0.2604 - val_accuracy: 0.9067\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.2538 - accuracy: 0.9067 - val_loss: 0.2600 - val_accuracy: 0.9067\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.2534 - accuracy: 0.9067 - val_loss: 0.2598 - val_accuracy: 0.9067\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.2530 - accuracy: 0.9067 - val_loss: 0.2594 - val_accuracy: 0.9067\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.2527 - accuracy: 0.9067 - val_loss: 0.2590 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 529us/sample - loss: 0.2523 - accuracy: 0.9067 - val_loss: 0.2588 - val_accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "multinomial_log_reg_model = Sequential()\n",
    "\n",
    "\n",
    "# 3 klasser kräver 3 output neuroner, input_dim är fortfarande 4\n",
    "multinomial_log_reg_model.add(Dense(n_classes, input_dim=n_features, activation='softmax')) #activation är förändrad\n",
    "\n",
    "multinomial_log_reg_model.compile(optimizers='sgd',\n",
    "             loss='categorical_crossentropy', #Loss-funktionen är förändrad\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "multinomial_log_reg_model.summary()\n",
    "\n",
    "history = multinomial_log_reg_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " ##### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.9066667\n",
      "accuracy, test:  0.9066667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VeW5///3vXdmkhAgYUyYQQmjEAcc6qxorbZVq1i1TqXtqdVzWvv76um5amtPW+1gnWgtKk511tqq1WPrXJyYZB5khgAhIZCRzLl/f+xNjDFAgOzsZOfzuq59Za+1nqx9PxjzyVrPWs8yd0dERAQgEO0CRESk81AoiIhIE4WCiIg0USiIiEgThYKIiDRRKIiISBOFgkgbmNlQM3Mzi2tD26vMbM7h7kckGhQKEnPMbKOZ1ZpZZov1i8K/kIdGpzKRzk+hILFqAzB974KZjQeSo1eOSNegUJBY9ThwZbPlbwGPNW9gZj3N7DEzKzKzTWb2P2YWCG8LmtnvzGynma0HvtzK9z5kZtvNbKuZ/a+ZBQ+2SDMbaGYvmdkuM1trZt9utu0YM5tvZmVmtsPM7gyvTzKzv5hZsZmVmNk8M+t3sJ8t0hqFgsSqj4B0MxsT/mV9CfCXFm3uBXoCw4GTCYXI1eFt3wbOA44C8oCLWnzvo0A9MDLc5izgukOo8ykgHxgY/oxfmdnp4W13A3e7ezowAng2vP5b4bpzgD7Ad4GqQ/hskS9QKEgs23u0cCawCti6d0OzoLjF3cvdfSPwe+CKcJNvAHe5+xZ33wX8utn39gPOAf7T3SvdvRD4A3DpwRRnZjnAicD/c/dqd18EPNishjpgpJllunuFu3/UbH0fYKS7N7j7AncvO5jPFtkXhYLEsseBy4CraHHqCMgEEoBNzdZtAgaF3w8EtrTYttcQIB7YHj59UwL8Geh7kPUNBHa5e/k+argWGA2sCp8iOq9Zv14HnjazbWb2GzOLP8jPFmmVQkFilrtvIjTgfC7w1xabdxL6i3tIs3WD+exoYjuh0zPNt+21BagBMt09I/xKd/exB1niNqC3maW1VoO7r3H36YTC5g7geTPr4e517v5zd88Fjid0mutKRNqBQkFi3bXAae5e2XyluzcQOkf/SzNLM7MhwA/5bNzhWeAGM8s2s17Azc2+dzvwT+D3ZpZuZgEzG2FmJx9MYe6+BfgA+HV48HhCuN4nAMzscjPLcvdGoCT8bQ1mdqqZjQ+fAisjFG4NB/PZIvuiUJCY5u7r3H3+Pjb/AKgE1gNzgCeB2eFtDxA6RbMYWMgXjzSuJHT6aQWwG3geGHAIJU4HhhI6angRuNXd/xXeNg1YbmYVhAadL3X3aqB/+PPKgJXAu3xxEF3kkJgesiMiInvpSEFERJooFEREpIlCQUREmigURESkSZebvjczM9OHDh0a7TJERLqUBQsW7HT3rAO163KhMHToUObP39cVhiIi0hoz23TgVjp9JCIizSgURESkiUJBRESadLkxhdbU1dWRn59PdXV1tEvpMElJSWRnZxMfr8kxRaT9xEQo5Ofnk5aWxtChQzGzaJcTce5OcXEx+fn5DBs2LNrliEgMiYnTR9XV1fTp06dbBAKAmdGnT59udWQkIh0jJkIB6DaBsFd366+IdIyYCYUDqqmAsm2gWWFFRPap+4RCXRVU7ICGunbfdXFxMZMmTWLSpEn079+fQYMGNS3X1ta2aR9XX301q1evbvfaREQORkwMNLdJQkroa90eiEto11336dOHRYsWAfCzn/2M1NRUbrrpps+1cXfcnUCg9Rx++OGH27UmEZFDEbEjBTObbWaFZrZsH9vNzO4xs7VmtsTMJkeqFoDS+jgc8Lo9kfyYz1m7di3jxo3ju9/9LpMnT2b79u3MmDGDvLw8xo4dy2233dbU9sQTT2TRokXU19eTkZHBzTffzMSJE5k6dSqFhYUdVrOIdG+RPFJ4BLgPeGwf288BRoVfxwJ/Cn89LD9/eTkrtpV9YX19QyOBhioCthvi2zQFSJPcgenc+pWDfSZ7yIoVK3j44Ye5//77Abj99tvp3bs39fX1nHrqqVx00UXk5uZ+7ntKS0s5+eSTuf322/nhD3/I7Nmzufnmm1vbvYhIu4rYkYK7vwfs2k+TC4DHPOQjIMPMDuUZt21iAaORAHhjpD6iVSNGjODoo49uWn7qqaeYPHkykydPZuXKlaxYseIL35OcnMw555wDwJQpU9i4cWNHlSsi3Vw0xxQGAVuaLeeH121v2dDMZgAzAAYPHrzfne7rL/r6hkZ2FOQzyIqh79h2H1fYlx49ejS9X7NmDXfffTdz584lIyODyy+/vNV7DRISPqstGAxSX1/fIbWKiETz6qPWLrRv9XpRd5/l7nnunpeVdcDpwFsVDBg1lhRaqKs8pH0crrKyMtLS0khPT2f79u28/vrrUalDRGRfonmkkA/kNFvOBrZF6sPMDOKTaawzArUVkNwrUh+1T5MnTyY3N5dx48YxfPhwTjjhhA6vQURkf8wjeDOXmQ0FXnH3ca1s+zJwPXAuoQHme9z9mAPtMy8vz1s+ZGflypWMGTPmgPUUlFaRWrGJHvGO9T1w+86urf0WETGzBe6ed6B2ETtSMLOngFOATDPLB24F4gHc/X7gVUKBsBbYA1wdqVr2SkmIo5xkUut3QX1th40riIh0FRELBXeffoDtDnw/Up/fmpSEINs9hQG2C2pKIe7QxidERGJV95nmAogLBiAukTqLh6rSaJcjItLpdKtQgNAppFJPwWsroFGXeoqINNftQiEtKY7SxhQMh5ryaJcjItKpdLtQSE2MYw9JNBCEap1CEhFprtuFQlwwQHJCHJWWAtVl7TLtRXtMnQ0we/ZsCgoKDrseEZFD1X2mzm4mLSmOXeUppFs51FZCYtph7a8tU2e3xezZs5k8eTL9+/c/rHpERA5VtwyF9KQ4isqScTOsuvSwQ2F/Hn30UWbOnEltbS3HH3889913H42NjVx99dUsWrQId2fGjBn069ePRYsWcckll5CcnMzcuXM/NweSiEhHiL1QeO1mKFi63yZJOMNrG2iklqA5xKfQ+lRMYf3Hwzm3H3Qpy5Yt48UXX+SDDz4gLi6OGTNm8PTTTzNixAh27tzJ0qWhOktKSsjIyODee+/lvvvuY9KkSQf9WSIi7SH2QqENDCMYNOobggS9NjSuYMF2/5w33niDefPmkZcXurO8qqqKnJwczj77bFavXs2NN97Iueeey1lnndXuny0icihiLxTa+Bd9Q209GwrLyA1swlL7QfrAdi/F3bnmmmv4xS9+8YVtS5Ys4bXXXuOee+7hhRdeYNasWe3++SIiB6vbXX20V3J8kGBcHFWWAlUlEIGJAc844wyeffZZdu7cCYSuUtq8eTNFRUW4OxdffDE///nPWbhwIQBpaWmUl+veCRGJntg7UmgjMyMjOZ7dFSmk+E6or4b45Hb9jPHjx3Prrbdyxhln0NjYSHx8PPfffz/BYJBrr70Wd8fMuOOOOwC4+uqrue666zTQLCJRE9GpsyPhcKbObqmqroENO0oYE9iMpfWHtIg9DTQiNHW2iLRVW6fO7ranjyB0CikuPoFqS9IEeSIidPNQAEKnkBpToL4K6muiXY6ISFTFTCgc6mmwninxlHmP0EIXmgupq532E5GuISZCISkpieLi4kP6RZkYFyQuIZEaEqC6JALVtT93p7i4mKSkpGiXIiIxJqJXH5nZNOBuIAg86O63t9g+BJgNZAG7gMvdPf9gPyc7O5v8/HyKiooOqc7y6nqKq0tJpxJ21ECg81+UlZSURHZ2drTLEJEYE8lnNAeBmcCZQD4wz8xecvcVzZr9DnjM3R81s9OAXwNXHOxnxcfHM2zYsEOudUdZNZfe/hfeTvgRnPkLOOGGQ96XiEhXFsnTR8cAa919vbvXAk8DF7Rokwu8GX7/divbO0S/9CT6DR3LqsAofOmz0ShBRKRTiGQoDAK2NFvOD69rbjFwYfj914A0M+vTckdmNsPM5pvZ/EM9RXQg508cxDM1x2EFS6FwVUQ+Q0Sks4tkKLQ27WjLkeCbgJPN7BPgZGAr8IUHJ7v7LHfPc/e8rKys9q8UOGdcf17z42kkAEufi8hniIh0dpEMhXwgp9lyNrCteQN33+buX3f3o4CfhNdF5brQXj0SGDNqJPMCE/Clz0VkLiQRkc4ukqEwDxhlZsPMLAG4FHipeQMzyzSzvTXcQuhKpKg5f9JAnqk+DivZBFvmRrMUEZGoiFgouHs9cD3wOrASeNbdl5vZbWZ2frjZKcBqM/sU6Af8MlL1tMWZuf15J3AsdZYAGnAWkW4oohfku/urwKst1v202fvngecjWcPBSE2MY2ruUN5ek8eZy1/Ept0OwfholyUi0mFi4o7m9nTR5GyerZmK7SmGdW9FuxwRkQ6lUGjhpFGZLE85mopAGizRKSQR6V4UCi3EBQN8ZfJQXqo7Bl/1KtRURLskEZEOo1BoxYWTs3mx/gSsfg+s+ke0yxER6TAKhVYc0T+NmgFHUxjI0lVIItKtKBT24cK8wTxTewK+7i0o3RrtckREOoRCYR8umDSQv/mpmDfCJ3+JdjkiIh1CobAPGSkJjBk7gY8Yjy98DBobol2SiEjEKRT24xt5OTxWeypWlq97FkSkW1Ao7MeJIzNZ2fNESgM9YcEj0S5HRCTiFAr7EQgY06eO5KnaL+GrX4OybQf+JhGRLkyhcADfyMvhBTsd8wZY+Hi0yxERiSiFwgFkpCQwZdIU5vgEGhc8Ag1feAaQiEjMUCi0wZVTh/J43ekEyrfBmtejXY6ISMQoFNogd2A6pTlnUGS98XlRfQ6QiEhEKRTa6IoTRvBE3Smw7k3YtSHa5YiIRIRCoY3OGtuPN5On4RgsfDTa5YiIREREQ8HMppnZajNba2Y3t7J9sJm9bWafmNkSMzs3kvUcjvhggLOOm8wbDUfRsOAxqK+NdkkiIu0uYqFgZkFgJnAOkAtMN7PcFs3+h9Czm48CLgX+GKl62sPFeTk82XAGwapiWPVytMsREWl3kTxSOAZY6+7r3b0WeBq4oEUbB9LD73sCnfrusP49k7CRp7GNvjRqwFlEYlAkQ2EQsKXZcn54XXM/Ay43s3zgVeAHre3IzGaY2Xwzm19UVBSJWtvsmpNG8HjdaQQ2zYGiT6Nai4hIe4tkKFgr67zF8nTgEXfPBs4FHjezL9Tk7rPcPc/d87KysiJQatudODKTT/qcSx1x+PyHolqLiEh7i2Qo5AM5zZaz+eLpoWuBZwHc/UMgCciMYE2Hzcy46OQp/F9DHg2fPAm1e6JdkohIu4lkKMwDRpnZMDNLIDSQ/FKLNpuB0wHMbAyhUIju+aE2OG/CAF6Kn0ZcbRksfzHa5YiItJuIhYK71wPXA68DKwldZbTczG4zs/PDzX4EfNvMFgNPAVe5e8tTTJ1OUnyQ0cdMY23jQGo+ejDa5YiItJu4SO7c3V8lNIDcfN1Pm71fAZwQyRoi5Yqpw3jw/TP4nx2PwfbFMGBitEsSETlsuqP5EPXvmUTt2Euo9niqP9KAs4jEBoXCYbjytIm83DCVwLLnoKY82uWIiBw2hcJhGNk3jU9zvkFCwx5qFz4V7XJERA6bQuEwnX3WuSxrHMqeOX+Czj9GLiKyXwqFw5Q3rA/vZHydjMr1NKx9O9rliIgcFoVCOxhz5tXs9HSK3rw72qWIiBwWhUI7OHVsDq8lTqNvwbu4HsAjIl2YQqEdBAJGxknfod4DFLx6R7TLERE5ZAqFdnLW1KP4W/As+q59Bko2R7scEZFDolBoJ4lxQeqOvR53KHrz3miXIyJySBQK7egrJx/LPzmO1OVPQHVZtMsRETloCoV2lJ4UT+G460hurGT3vx+IdjkiIgdNodDOzjn7y3zQOI64j2dCXVW0yxEROSgKhXbWLz2JZSO+TVp9MWUfPBztckREDopCIQLOOe9iFjaOonHOXdBQF+1yRETaTKEQATl9erB8xAwy6naw68PHo12OiEibRTQUzGyama02s7VmdnMr2/9gZovCr0/NrCSS9XSks756BSt8KA3v/R4aG6JdjohIm0QsFMwsCMwEzgFygelmltu8jbv/l7tPcvdJwL3AXyNVT0fr1zOZlSOuI6s2n4IPn452OSIibRLJI4VjgLXuvt7da4GngQv20346oec0x4xTvnot63wgje/+Fhobo12OiMgBRTIUBgFbmi3nh9d9gZkNAYYBb0Wwng7XJz2FVaO+w8DaDWz56PlolyMickCRDAVrZd2+nkJzKfC8u7d68t3MZpjZfDObX1RU1G4FdoQTv/YdNjKAwNv/Cw310S5HRGS/IhkK+UBOs+VsYNs+2l7Kfk4dufssd89z97ysrKx2LDHyevZIZkXufzGobhOb39JdziLSuUUyFOYBo8xsmJklEPrF/1LLRmZ2BNAL+DCCtUTVyedfwyKOIO3D3+A1FdEuR0RknyIWCu5eD1wPvA6sBJ519+VmdpuZnd+s6XTgaffYfcBxj6R4Co79Cb0ad7H6b7+OdjkiIvtkXe13cV5ens+fPz/aZRy0hkbno9vP5ajahfgPFtKjT6tj7iIiEWFmC9w970DtdEdzBwkGjF5f+SXxXsfqp38S7XJERFqlUOhAueMnMy/zAiYU/p2NK7ve0Y6IxD6FQgcbc+mv2GPJlL/4I1w3tIlIJ9OmUDCzEWaWGH5/ipndYGYZkS0tNvXKGsDq3BsZX7uIea89Eu1yREQ+p61HCi8ADWY2EniI0N3HT0asqhg3+es/ZENwGDnzfkl5eWm0yxERadLWUGgMX2L6NeAud/8vYEDkyoptwbh4GqfdwQB28smTt0a7HBGRJm0NhTozmw58C3glvC4+MiV1DyOOPpvFGWdw7La/sO7TpdEuR0QEaHsoXA1MBX7p7hvMbBjwl8iV1T0MnX4nDRZg1ws30dXuFxGR2NSmUHD3Fe5+g7s/ZWa9gDR3vz3CtcW8nv2GsObI73F0zUd88LqeuSAi0dfWq4/eMbN0M+sNLAYeNrM7I1ta9zD+67ewLTiQ7I9uo7S8MtrliEg319bTRz3dvQz4OvCwu08BzohcWd1HICGJujN/zRC2Mecvt0W7HBHp5toaCnFmNgD4Bp8NNEs7GXLcV1nb6yROLniEBUuXR7scEenG2hoKtxGa7XSdu88zs+HAmsiV1f3kTL+LeGug7OVbqK3Xnc4iEh1tHWh+zt0nuPv3wsvr3f3CyJbWvST2HcmWI6/j1Np3eeaFZ6Jdjoh0U20daM42sxfNrNDMdpjZC2aWHeniupuRX/8pJfF9yVv+Kz7Z2LUeOyoisaGtp48eJvTUtIHAIODl8DppTwkpJJ73G8YENrPsif+mskbPdBaRjtXWUMhy94fdvT78egToWg9L7iKSJ36NwhEX883a53jkSd0fKCIdq62hsNPMLjezYPh1OVB8oG8ys2lmttrM1prZzfto8w0zW2Fmy81Mk+wBfS+5m7LkQZy74Ve8umBdtMsRkW6kraFwDaHLUQuA7cBFhKa+2CczCwIzgXOAXGC6meW2aDMKuAU4wd3HAv95UNXHqoQepF38R4YFdrDj5Z+xvbQq2hWJSDfR1quPNrv7+e6e5e593f2rhG5k259jgLXhK5VqgaeBC1q0+TYw0913hz+n8CDrj1nBESdTPvZyrvSXeeDRh6lr0GWqIhJ5h/PktR8eYPsgYEuz5fzwuuZGA6PN7H0z+8jMprW2IzObYWbzzWx+UVH3uSon7Su/pjJ9BN8rvp27XtbjO0Uk8g4nFOwQtrecCjQOGAWcAkwHHmztiW7uPsvd89w9LyurG41vJ6WTfukD9LEyRi+4lbdWFkS7IhGJcYcTCgea6zkfyGm2nA1sa6XN3929zt03AKsJhYTsNWgyDSf/NxcEP2DeM79mw05NmicikbPfUDCzcjMra+VVTuiehf2ZB4wys2FmlgBcSuheh+b+Bpwa/qxMQqeT1h9ST2JY/Mk3UTXsbH7I49wz+xHKq+uiXZKIxKj9hoK7p7l7eiuvNHePO8D31gPXE5ozaSXwrLsvN7PbzOz8cLPXgWIzWwG8DfzY3Q94qWu3EwiQfMkD1Kfl8N+Vd/CzJ96gsVEP5RGR9mdd7YlfeXl5Pn9+Nx10LVxJ3Z9PZUldNu9OfYQfnjMu2hWJSBdhZgvcPe9A7Q5nTEE6Wt8xxH3tj0wJrKHP+z/jlSUth2hERA6PQqGLsXFfp/647/OtuH8x5/l7Wb6tNNoliUgMUSh0QXFn3kZtzgn8PPAgv33kOYoraqJdkojECIVCVxSMI+GSRwmk9OYXNXdww+y32F1ZG+2qRCQGKBS6qtQs4i97gkHB3fxg521ccf877CirjnZVItLFKRS6suw8Al/9E8cGVnJL2S+44s/vUVCqYBCRQ6dQ6OomXIxdMJPjbSk/rvgtl836QEcMInLIFAqx4KhvYmf/ijNtLpdWPMr0WR8pGETkkCgUYsVx34MpVzHD/saXyl5m+qyPKFQwiMhBUijECjM493cw6ixuDTzEsWWvc+kDCgYROTgKhVgSjIdvPI4NP5lfBe/nqNI3mf7ARxSWKxhEpG0UCrEmPgkufRIbPJXfBWcyufQNps/6SFcliUibKBRiUUIPuOwZbPBx/DZwL+eWPsPX//g+a3aUR7syEenkFAqxKjENrngRxn6dHwWe5Dt1j3Hhn95n7oZd0a5MRDqx/T4TQbq4uES48EFIzuBb82fTK76KKx9q4M5LJnPu+AHRrk5EOiGFQqwLBOHLd0JSBufPuZPePaq5+slrKfjyBK45cVi0qxORTkah0B2YwRm3QlJPTnzjVv6aUc3Fr3yXgrJqbp52JIGARbtCEekkIjqmYGbTzGy1ma01s5tb2X6VmRWZ2aLw67pI1tPtnfifcN5djKuay//1uYun3lvGjc8soqa+IdqViUgnEbFQMLMgMBM4B8gFpptZbitNn3H3SeHXg5GqR8LyrsYueoghVct5K/N3vL94FVfNnqept0UEiOyRwjHAWndf7+61wNPABRH8PGmrcRdi058mq3oT72bewdZNazjv3jks2lIS7cpEJMoiGQqDgC3NlvPD61q60MyWmNnzZpbT2o7MbIaZzTez+UVFRZGotfsZdSZc8VfS6op5M/3njG1czcX3f8BjH27E3aNdnYhESSRDobXRy5a/bV4Ghrr7BOAN4NHWduTus9w9z93zsrKy2rnMbmzI8XDtP4lPSuXPDT/llv4L+enfl3P9k5/oEZ8i3VQkQyEfaP6XfzawrXkDdy92972/fR4ApkSwHmlN3zHw7bewwVO5pvi3vDzi77yzYgtn/uE9Xlu6PdrViUgHi2QozANGmdkwM0sALgVeat7AzJrfQXU+sDKC9ci+pPSGy/8Kx32f8VufYWHf/+XM1A1874mF/OTFpVTU1Ee7QhHpIBELBXevB64HXif0y/5Zd19uZreZ2fnhZjeY2XIzWwzcAFwVqXrkAIJxMO1XcNmzJHoNt5ffwgOjP+bJuZs4+w/v8fbqwmhXKCIdwLraoGJeXp7Pnz8/2mXEtupS+Nt/wKpXqOibx42VV/FmcW++OmkgP/3KWHr3SIh2hSJykMxsgbvnHaidJsSTL0rqCZf8Bc6/j9SKDTxYcxOzcz/hH0u3ccad7/L3RVt1hZJIjFIoSOvMYPIV8B8fYUNP4rT1v+WTEQ8xLqOGG59exBUPzWVtoabiFok1CgXZv9S+8M3n4JzfkLp1Do9W3cBjR29iSf5upt31b279+zJdvioSQxQKcmBmcOx34DvvYhlD+NLSW5g/9E98d0KAv3y8mVN++w4z315LdZ3mUBLp6hQK0nZ9x8B1b8A5vyFh23xuWnsVc09axAlD0/jt66s59Xfv8PyCfBobNd4g0lUpFOTgBIKho4bvz4WRp9Pn4zu4v+Q7vHFGAf1T47jpucV8+d45vPeppiMR6YoUCnJoeg6CS5+AK1+C5J6MnPND/mo/5tmTi6moruXK2XO54qGPNcmeSBejUJDDM/xkmPEeXPwIhnPMxz/g3azfc89J9SzbWspXZ77PFQ99zPtrd+oyVpEuQDevSftpqIMFj8C7d0BlEfWjz+W5nlfz+08C7KyoYfygnnz35BFMG9efoJ72JtKh2nrzmkJB2l9NBXz0J3j/bqirpH78pbzS+yrumreHjcV7GNonhW9/aTgXTs4mKT4Y7WpFugWFgkRfZTHMuRPmzgKgceJlvJc1nTsX1LMkv5TM1ESuPmEolx83hJ7J8VEuViS2KRSk8yjZAv/+PSx6Ehpq8dzzWTr4W/xuRRrvfVpEamIclx07mGtOGEb/nknRrlYkJikUpPMp3wFz/wzzHgxNujfkBDaNuY471w/h5aUFBAPG144axDUnDuPI/unRrlYkpigUpPOqKYeFj8OHM6EsH7KOZNfE73Bf0USeWFBITX0jE3MymH50DudNHEhqYly0Kxbp8hQK0vk11MHyF0MD0juWQWJPqnMv5LWEs/jjyhTWFFbQIyHIVyYO5JKjc5iUk4GZrloSORQKBek63GHT+7DgUVjxd2iowQcexeYhF/FgyWSeX1ZGVV0DR/ZP45KjczhxZCaj+qVFu2qRLkWhIF1T1W5Y8mwoIAqXQ3wKdUd+lbd7TGPmml4s3hqarvtLo7P46qSBnJnbj7QkXbkkciCdIhTMbBpwNxAEHnT32/fR7iLgOeBod9/vb3yFQjfhDlsXwsJHYdkLUFsB6dmUDDuH1/147lndk62l1STEBThldBZfmTiQ08f0JSVB4w8irYl6KJhZEPgUOBPIB+YB0919RYt2acA/gATgeoWCfEFNOaz6Byz7K6x7Cxrr8PRsCnOm8XL9Mcxa15vCilqS44OcPqYv500YyClHZOnGOJFmOkMoTAV+5u5nh5dvAXD3X7dodxfwBnATcJNCQfarqgRWvwYr/gZr32wKiO3ZZ/Nq7SRmrc+kcI+TmhjHWbn9OG/iAE4cmUVCnKb5ku6traEQyWPtQcCWZsv5wLHNG5jZUUCOu79iZjfta0dmNgOYATB48OAIlCpdRnIGTJoeeoUDwlb8jYGrHuO6xoe4Nr4Hu0ZY5PzCAAAQ7klEQVQcy5scw70rR/HXT7aSlhjHqUf25ayx/TjliL66xFVkPyL5f0dr1w42HZaYWQD4A3DVgXbk7rOAWRA6Umin+qSrax4Q1aWw4d/Y+rfp8+k/+UbpW1xsQXYPPpr3A1N4Zk0ONyzOJi4uji+NyuKssf049Yi+ZKUlRrsXIp1K1E4fmVlPYB1QEf6W/sAu4Pz9nULS6SM5IHfYvhhWvgQrX4adnwJQm9yXxakn8tzu0fyjYhSVJDMxuyenHdmP08f0ZezAdN0HITGrM4wpxBEaaD4d2EpooPkyd1++j/bvoDEFiYSy7bBxTmgcYt3bUFeJB+LZljaBd+rH8rfdQ1ncOIKMtFROO7Ivpx7ZlxNHZtJDp5kkhkQ9FMJFnAvcReiS1Nnu/kszuw2Y7+4vtWj7DgoFibT6GtjycWiQet2bULA0tDqQxNqkXP5ZOZp3a49gVWAUU0b047Qjsjh9TD9yeqdEuXCRw9MpQiESFArSriqLYfOHoSOJjXNgRygkagNJLLEjeat6NB815rIncwInjxnIaUf2ZcqQXsQFdTWTdC0KBZFDsWdXaMqNDf8OhURh6GxntSUxt2E0HzbksiR+PL1GHsPUUf04aWQWg/voKEI6P4WCSHuo3NkUEg0b/k1w56rQapKY23AEHzXmsiF1Mlmjj+bE0f05YVQm6Zp2QzohhYJIJFQUwaY5+IY51K17l4Tda0KrPZmFjSP50MdRPOAkRo07jjPG9mdYZo8oFywSolAQ6QgVhbAxdBRRs+59UkpCl78WeTofNeayJuUoEkaewtjxR3Hs8D6am0miRqEgEg1l22DdW1Suegvb+B4pNUVAKCQW+pHsyDiKpBHHM3TscUwYovmZpOMoFESizR2K11G37l12rfo3Cds+plfNNgD2eCJLfTiFabkEB02i/xHHceS4SaQkJkS5aIlVCgWRzqhsGxVr/s2uVXMIbptPVuUaEqgDoMKT2JQwgopeY0keMoWcsVPpNXgcBHQ0IYdPoSDSFTTUUbF1OVuWfcCeTQtJ3bWMwbXrSLZaAKpIZFviCGr7TqDXEcfTd8LZBNL7R7lo6YoUCiJdVE1tLWtXfkLhqo+hYDG9S1cwomE9qVYNwNb4IezqM5nEwVMYOOYYUgeMgaT0KFctnZ1CQSSGbCwsY82SD6hf+zaZO+dyRN0q0m1P0/byYC+q04cRl30UPUceRyAnD3oNA03wJ2EKBZEYVl5Vw+qVy9ixZj57tq8mWLKRnMYtjLVNpFgNAFVxPdmTNYmUYceQPPgoGDAJeg6KcuUSLQoFkW7E3dmws5JPNu5k25qFNOYvoH/5MibYOkZbPkEL/X9emjKEhoF5pA+bQtygidBvXOi5FBLzFAoi3VxlTT2L80tYvmErO9cvJrlgPuPqljAxsJ4sK/2sXcog6D+elJyJWP8J0H8c9BwMAU36F0sUCiLyOe7O9tJqPtlcwtr1a6nYtIik4uWM9g2Msc0MD2wnEH44Yn1cD+ibS9zwkyA7D/qMhF5DIU5PquuqFAoickD1DY18uqMidESxcTtlm5aQUrKaI2wz4wMbmBRYSxyNALgFIGMw1mdkKCT6jAwFRr/xENT0HZ2dQkFEDklFTT1L80tZnF/Cyo3bKN2ynJ57NjE8UMCIQAFj4neQ7dtIbKwCwON7YAMmQJ8RkNofBkwMhUX6wCj3RJrrFKFgZtOAuwk9ee1Bd7+9xfbvAt8HGgg9q3mGu6/Y3z4VCiIdy93J313FJ1tKWLa1lCX5JSzfWkpazQ6mBD7l2LhPmZiwjSFsI7WhlIA3hL4xPRsGHwuDp4ZCom+uTj9FUdRDwcyChJ7RfCaQT+gZzdOb/9I3s3R3Lwu/Px/4D3eftr/9KhREoq+x0dlYXMnSraUszS9l9Y5yVhWUU1peQa5tYkpwDSclbWASq8moD00K6IE4LOvI0JFE/wkwYAL0Hw+JaVHuTffQ1lCI5InAY4C17r4+XNDTwAVAUyjsDYSwHkDXOpcl0k0FAsbwrFSGZ6VywaTP7n3YUVbN0vxSlm4t5fGtpfw4v4TEmnwm2HrGBjZy9M4tHLnzVdIXPfHZznqPCAfEhFBgDJgIPTKj0CuByIbCIGBLs+V84NiWjczs+8APgQTgtAjWIyIR1i89iX65SZyR269pXcmeWlZsL+OTzSU8lF/C0i0l1FcWMDawkXGBjRxbtoXc8g/pvfzFz3aUNjAcEBOg39jPBrZ1+iniIhkKrd1f/4UjAXefCcw0s8uA/wG+9YUdmc0AZgAMHjy4ncsUkUjKSEng+BGZHD/is7/+i8prWLq1hMVbSnkov4Ql+aXUVe9ibGAT44ObOL42nzGbVpL16esEwlc/EZccCoq0/pAx+LPTUH1GaCbZdhTJMYWpwM/c/ezw8i0A7v7rfbQPALvdvef+9qsxBZHY4+5sLaliSfiqp6X5obGKuppKRtpWhgcK+FLyRibEbSbTSulZs41gY2jKcYKJ0HsY9MwOXf3UexjsHbvoma35n8I6w5jCPGCUmQ0DtgKXApc1b2Bmo9x9TXjxy8AaRKTbMTOye6WQ3SuFc8cPAD4bzP50RzmrCyp4a0cZfyooZ2PxHqyxjlG2lYnBjeQlFjK6qpD+VVvpWb+ExOrCz3ackBqaGLDfWBg4CfqOCd2ElzFEYbEPEQsFd683s+uB1wldkjrb3Zeb2W3AfHd/CbjezM4A6oDdtHLqSES6p+aD2dPGfba+uq6B9UWhsFhVUM4/Csr4w44KtpaE7pvoQRUTEgs4NW0rY5OKGNywnX5r3iJhydOf7SSlDwyaEjqiyBwFfcdC1hGQmNrBvex8dPOaiMSEsuo6Pi0oZ/WOclYXhF87yinZEzrN1JfdTO5RxNFpu5kcXMewmpWkV20h0FD72U72HlVkjgodUex9pWd3+bu2o36fQqQoFESkrdydwvKaz4XE6oJy1hZWUFXXQIBGcqyQqT0KOKbHDsYEtpBdu57UPfmY13+2o0BcaHA7czT0Hg5pA0KvnoNCV0X1yOr0p6M6w5iCiEhUmVnoMtn0JL40OqtpfWNjaGB7TWHoFNSnBeU8sKOCdYUV1DY0EqCRARQzKa2Uo1J3c0RCMYPZTmbhBlLWv4vVV33+gxJ7QuZI6DMq9DVzdOj+ix6ZkJQB8Ukd3PNDpyMFEZGw+oZGNhbvYc2OctYVVbCuqJK1hRWsK6pgT214+g6c/kl1TOlVw4S0Mo6IKyCncStZNVvoUb6eYMX2L+44PgVS+4Xmg9r7ShsYujqq1xDIPALiEiLaNx0piIgcpLhggJF9UxnZ9/MDzu5OQVk16worWVtYzrqiStYVVfDIjkoKygbhPqWpbVZCHcf23M3ElF3kJFXRP7GarOAeMhqKSanagW2ZC+XboflYRiA+NOjdf1zowUe9h4VOS/UeDsH4juo+oCMFEZHDUlPfQP7uKjYX72FTcSUbi/eweVfo/ZZdVdQ2NDa1jQ+GLr0d3CuZsT1rObJHGSODOxhUs4600lUECpZBRcFnOw/Ehwa9M0eFBsFzL4BBkw+pTh0piIh0gMS4ICOyUhmR9cXLWRsbQ0cYG4srQ6Gxaw+bi/ewsbiSxzbvoaIGoB/Qj/jgCeT0SmFsdh3je5RwZFwBQxo3k1W1nuQdK7BVr4bC4RBDoa0UCiIiERIIGAMzkhmYkczxIz6/zd3ZWVHLxuJKNuwMvTYX72F9cSVvbU6jsjYFGA6cQsAgJyOBH/lIzo9wzQoFEZEoMDOy0hLJSkvk6KG9P7fN3SmurA2djtr52WmpPumRn2ZcoSAi0smYGZmpiWSmJjJlSO8Df0M7CnTop4mISKemUBARkSYKBRERaaJQEBGRJgoFERFpolAQEZEmCgUREWmiUBARkSZdbkI8MysCNh3it2cCO9uxnK5Afe4e1Ofu4XD6PMTdsw7UqMuFwuEws/ltmSUwlqjP3YP63D10RJ91+khERJooFEREpEl3C4VZ0S4gCtTn7kF97h4i3uduNaYgIiL7192OFEREZD8UCiIi0qTbhIKZTTOz1Wa21sxujnY97cXMZptZoZkta7aut5n9y8zWhL/2Cq83M7sn/G+wxMwi+7DXCDGzHDN728xWmtlyM7sxvD5m+21mSWY218wWh/v88/D6YWb2cbjPz5hZQnh9Ynh5bXj70GjWf6jMLGhmn5jZK+HlmO4vgJltNLOlZrbIzOaH13XYz3a3CAUzCwIzgXOAXGC6meVGt6p28wgwrcW6m4E33X0U8GZ4GUL9HxV+zQD+1EE1trd64EfuPgY4Dvh++L9nLPe7BjjN3ScCk4BpZnYccAfwh3CfdwPXhttfC+x295HAH8LtuqIbgZXNlmO9v3ud6u6Tmt2T0HE/2+4e8y9gKvB6s+VbgFuiXVc79m8osKzZ8mpgQPj9AGB1+P2fgemttevKL+DvwJndpd9ACrAQOJbQ3a1x4fVNP+fA68DU8Pu4cDuLdu0H2c/s8C/A04BXAIvl/jbr90Ygs8W6DvvZ7hZHCsAgYEuz5fzwuljVz923A4S/9g2vj7l/h/BpgqOAj4nxfodPpSwCCoF/AeuAEnevDzdp3q+mPoe3lwJ9Orbiw3YX8P8BjeHlPsR2f/dy4J9mtsDMZoTXddjPdtzhfHMXYq2s647X4sbUv4OZpQIvAP/p7mVmrXUv1LSVdV2u3+7eAEwyswzgRWBMa83CX7t0n83sPKDQ3ReY2Sl7V7fSNCb628IJ7r7NzPoC/zKzVftp2+797i5HCvlATrPlbGBblGrpCDvMbABA+GtheH3M/DuYWTyhQHjC3f8aXh3z/QZw9xLgHULjKRlmtvePu+b9aupzeHtPYFfHVnpYTgDON7ONwNOETiHdRez2t4m7bwt/LSQU/sfQgT/b3SUU5gGjwlcuJACXAi9FuaZIegn4Vvj9twidc9+7/srwFQvHAaV7D0m7EgsdEjwErHT3O5ttitl+m1lW+AgBM0sGziA0APs2cFG4Wcs+7/23uAh4y8MnnbsCd7/F3bPdfSih/1/fcvdvEqP93cvMephZ2t73wFnAMjryZzvagyodOHhzLvApofOwP4l2Pe3Yr6eA7UAdob8ariV0LvVNYE34a+9wWyN0FdY6YCmQF+36D7HPJxI6RF4CLAq/zo3lfgMTgE/CfV4G/DS8fjgwF1gLPAckhtcnhZfXhrcPj3YfDqPvpwCvdIf+hvu3OPxavvd3VUf+bGuaCxERadJdTh+JiEgbKBRERKSJQkFERJooFEREpIlCQUREmigURFows4bwDJV7X+02q66ZDbVmM9qKdDbdZZoLkYNR5e6Tol2ESDToSEGkjcLz3N8Rfq7BXDMbGV4/xMzeDM9n/6aZDQ6v72dmL4afgbDYzI4P7ypoZg+En4vwz/AdyiKdgkJB5IuSW5w+uqTZtjJ3Pwa4j9BcPITfP+buE4AngHvC6+8B3vXQMxAmE7pDFUJz389097FACXBhhPsj0ma6o1mkBTOrcPfUVtZvJPSgm/XhCfkK3L2Pme0kNId9XXj9dnfPNLMiINvda5rtYyjwLw89LAUz+39AvLv/b+R7JnJgOlIQOTi+j/f7atOammbvG9DYnnQiCgWRg3NJs68fht9/QGgmT4BvAnPC798EvgdND8hJ76giRQ6V/kIR+aLk8BPO9vo/d997WWqimX1M6A+q6eF1NwCzzezHQBFwdXj9jcAsM7uW0BHB9wjNaCvSaWlMQaSNwmMKee6+M9q1iESKTh+JiEgTHSmIiEgTHSmIiEgThYKIiDRRKIiISBOFgoiINFEoiIhIk/8f0qaesa7zrxUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [0 0 2 0 0]\n",
      "\n",
      "Sannolikheter bakom prediktioner\n",
      " ['setosa' 'versicolor' 'virginica'] \n",
      " [[9.987e-01 1.265e-03 2.613e-05]\n",
      " [9.905e-01 9.407e-03 9.295e-05]\n",
      " [4.073e-04 4.495e-01 5.501e-01]\n",
      " [9.702e-01 2.962e-02 2.095e-04]\n",
      " [9.975e-01 2.448e-03 4.536e-05]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = multinomial_log_reg_model.predict_classes(X_test[0:5])\n",
    "\n",
    "probabilities = multinomial_log_reg_model.predict_proba(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktioner\\n\",names,\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuralt nätverk\n",
    "\n",
    "- Vi har nu utvärderat likheterna mellan ett neuralt nätverk och logistisk regression\n",
    "- Neurala nätverks styrka är inte att replikera logistisk regression, utan att kunna hantera komplexare samband än en logistisk regression genom att introducera icke-linjaritet med hjälp av ett antal hidden layers, inte bara ett lager som vi använt ovan \n",
    "\n",
    "\n",
    "Skillnaden mot multinomial regression är att vi nu har flera lager (5) istället för 1: \n",
    "- Ett input lager som hanterar våra fyra features som input, har 5 noder och ReLU-aktivering\n",
    "- 3 efterföljande hidden layers med 5 noder, ReLU-aktivering\n",
    "- Det output lager som vi känner igen: softmax-aktivering som beräknar 3 värden, 0-1 hur sannolik observationen är var och en av våra 3 blomkategorier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Skapar återigen ett tomt, sekventiellt nätverk\n",
    "neural_network_model = Sequential()\n",
    "\n",
    "\n",
    "nodes = 5 # Noder i hidden layer. TESTA ATT ÄNDRA ANTALET NODER\n",
    "\n",
    "# Input lager, n_features=4\n",
    "neural_network_model.add(Dense(nodes, input_dim=n_features, activation='relu'))\n",
    "\n",
    "#Hidden lager\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "\n",
    "\n",
    "#Output lager, n_classes=3\n",
    "neural_network_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "neural_network_model.compile(optimizers='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "neural_network_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Träning av modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 2s 20ms/sample - loss: 1.1969 - accuracy: 0.2933 - val_loss: 1.2276 - val_accuracy: 0.2400\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 542us/sample - loss: 1.1764 - accuracy: 0.2667 - val_loss: 1.2118 - val_accuracy: 0.2133\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 1.1640 - accuracy: 0.2667 - val_loss: 1.1974 - val_accuracy: 0.2000\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 1.1544 - accuracy: 0.2533 - val_loss: 1.1862 - val_accuracy: 0.2000\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 1.1465 - accuracy: 0.2400 - val_loss: 1.1790 - val_accuracy: 0.1867\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 1.1404 - accuracy: 0.2533 - val_loss: 1.1707 - val_accuracy: 0.1600\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 1.1341 - accuracy: 0.2400 - val_loss: 1.1616 - val_accuracy: 0.1600\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 1.1281 - accuracy: 0.2267 - val_loss: 1.1558 - val_accuracy: 0.1600\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 1.1238 - accuracy: 0.2133 - val_loss: 1.1515 - val_accuracy: 0.1600\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 1.1198 - accuracy: 0.2133 - val_loss: 1.1469 - val_accuracy: 0.1600\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 1.1159 - accuracy: 0.2400 - val_loss: 1.1418 - val_accuracy: 0.1733\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 1.1117 - accuracy: 0.2267 - val_loss: 1.1347 - val_accuracy: 0.2000\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 1.1072 - accuracy: 0.2400 - val_loss: 1.1294 - val_accuracy: 0.2133\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 1.1033 - accuracy: 0.2267 - val_loss: 1.1231 - val_accuracy: 0.2267\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 1.0990 - accuracy: 0.2400 - val_loss: 1.1180 - val_accuracy: 0.2267\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.0951 - accuracy: 0.2667 - val_loss: 1.1141 - val_accuracy: 0.2133\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 1.0920 - accuracy: 0.2667 - val_loss: 1.1096 - val_accuracy: 0.2133\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 1.0889 - accuracy: 0.2933 - val_loss: 1.1065 - val_accuracy: 0.2267\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 1.0863 - accuracy: 0.2933 - val_loss: 1.1039 - val_accuracy: 0.2000\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.0841 - accuracy: 0.2933 - val_loss: 1.1012 - val_accuracy: 0.2000\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 1.0816 - accuracy: 0.2933 - val_loss: 1.0977 - val_accuracy: 0.2133\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 1.0790 - accuracy: 0.3067 - val_loss: 1.0944 - val_accuracy: 0.2133\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 1.0762 - accuracy: 0.3067 - val_loss: 1.0911 - val_accuracy: 0.2267\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.0735 - accuracy: 0.3200 - val_loss: 1.0873 - val_accuracy: 0.2400\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 1.0706 - accuracy: 0.3200 - val_loss: 1.0832 - val_accuracy: 0.3200\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 1.0674 - accuracy: 0.3600 - val_loss: 1.0804 - val_accuracy: 0.3467\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 1.0652 - accuracy: 0.3867 - val_loss: 1.0766 - val_accuracy: 0.3733\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 1.0620 - accuracy: 0.4133 - val_loss: 1.0735 - val_accuracy: 0.4133\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 1.0589 - accuracy: 0.4133 - val_loss: 1.0707 - val_accuracy: 0.4267\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 1.0559 - accuracy: 0.4400 - val_loss: 1.0672 - val_accuracy: 0.4400\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 1.0527 - accuracy: 0.4400 - val_loss: 1.0638 - val_accuracy: 0.4400\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 1.0495 - accuracy: 0.4667 - val_loss: 1.0617 - val_accuracy: 0.4667\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 1.0458 - accuracy: 0.5067 - val_loss: 1.0583 - val_accuracy: 0.4667\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 493us/sample - loss: 1.0419 - accuracy: 0.5200 - val_loss: 1.0553 - val_accuracy: 0.4800\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 1.0382 - accuracy: 0.5333 - val_loss: 1.0525 - val_accuracy: 0.4800\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 1.0344 - accuracy: 0.5467 - val_loss: 1.0487 - val_accuracy: 0.4800\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 1.0304 - accuracy: 0.5733 - val_loss: 1.0459 - val_accuracy: 0.5067\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 1.0266 - accuracy: 0.5733 - val_loss: 1.0431 - val_accuracy: 0.5333\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.0224 - accuracy: 0.6000 - val_loss: 1.0397 - val_accuracy: 0.5467\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 1.0184 - accuracy: 0.6133 - val_loss: 1.0360 - val_accuracy: 0.5467\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 485us/sample - loss: 1.0144 - accuracy: 0.6133 - val_loss: 1.0312 - val_accuracy: 0.5600\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 1.0099 - accuracy: 0.6267 - val_loss: 1.0276 - val_accuracy: 0.5867\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 1.0059 - accuracy: 0.6400 - val_loss: 1.0236 - val_accuracy: 0.5867\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 1.0020 - accuracy: 0.6400 - val_loss: 1.0201 - val_accuracy: 0.6000\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.9977 - accuracy: 0.6400 - val_loss: 1.0165 - val_accuracy: 0.6133\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.9933 - accuracy: 0.6400 - val_loss: 1.0128 - val_accuracy: 0.6267\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.9893 - accuracy: 0.6400 - val_loss: 1.0086 - val_accuracy: 0.6267\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.9847 - accuracy: 0.6400 - val_loss: 1.0043 - val_accuracy: 0.6267\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.9802 - accuracy: 0.6400 - val_loss: 1.0003 - val_accuracy: 0.6267\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 545us/sample - loss: 0.9755 - accuracy: 0.6400 - val_loss: 0.9962 - val_accuracy: 0.6400\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 513us/sample - loss: 0.9715 - accuracy: 0.6400 - val_loss: 0.9922 - val_accuracy: 0.6400\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.9666 - accuracy: 0.6400 - val_loss: 0.9881 - val_accuracy: 0.6400\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.9623 - accuracy: 0.6400 - val_loss: 0.9842 - val_accuracy: 0.6400\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.9576 - accuracy: 0.6400 - val_loss: 0.9802 - val_accuracy: 0.6400\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.9539 - accuracy: 0.6533 - val_loss: 0.9756 - val_accuracy: 0.6400\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.9485 - accuracy: 0.6533 - val_loss: 0.9717 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.9440 - accuracy: 0.6533 - val_loss: 0.9682 - val_accuracy: 0.6400\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.9395 - accuracy: 0.6533 - val_loss: 0.9633 - val_accuracy: 0.6400\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.9346 - accuracy: 0.6533 - val_loss: 0.9589 - val_accuracy: 0.6400\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.9298 - accuracy: 0.6533 - val_loss: 0.9540 - val_accuracy: 0.6533\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.9252 - accuracy: 0.6533 - val_loss: 0.9496 - val_accuracy: 0.6533\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.9199 - accuracy: 0.6533 - val_loss: 0.9452 - val_accuracy: 0.6533\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.9150 - accuracy: 0.6533 - val_loss: 0.9404 - val_accuracy: 0.6533\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.9098 - accuracy: 0.6533 - val_loss: 0.9358 - val_accuracy: 0.6533\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 480us/sample - loss: 0.9048 - accuracy: 0.6533 - val_loss: 0.9304 - val_accuracy: 0.6533\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.8996 - accuracy: 0.6533 - val_loss: 0.9251 - val_accuracy: 0.6533\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.8946 - accuracy: 0.6533 - val_loss: 0.9203 - val_accuracy: 0.6533\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 0.8893 - accuracy: 0.6533 - val_loss: 0.9149 - val_accuracy: 0.6533\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.8841 - accuracy: 0.6533 - val_loss: 0.9101 - val_accuracy: 0.6533\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 469us/sample - loss: 0.8790 - accuracy: 0.6533 - val_loss: 0.9039 - val_accuracy: 0.6533\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.8738 - accuracy: 0.6533 - val_loss: 0.8998 - val_accuracy: 0.6533\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.8685 - accuracy: 0.6533 - val_loss: 0.8942 - val_accuracy: 0.6533\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.8624 - accuracy: 0.6533 - val_loss: 0.8884 - val_accuracy: 0.6533\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.8567 - accuracy: 0.6533 - val_loss: 0.8829 - val_accuracy: 0.6533\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.8514 - accuracy: 0.6533 - val_loss: 0.8767 - val_accuracy: 0.6533\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.8452 - accuracy: 0.6533 - val_loss: 0.8704 - val_accuracy: 0.6533\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 573us/sample - loss: 0.8396 - accuracy: 0.6533 - val_loss: 0.8641 - val_accuracy: 0.6533\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.8335 - accuracy: 0.6667 - val_loss: 0.8587 - val_accuracy: 0.6533\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 493us/sample - loss: 0.8277 - accuracy: 0.6667 - val_loss: 0.8529 - val_accuracy: 0.6533\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.8215 - accuracy: 0.6667 - val_loss: 0.8472 - val_accuracy: 0.6533\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 0.8153 - accuracy: 0.6667 - val_loss: 0.8412 - val_accuracy: 0.6533\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.8094 - accuracy: 0.6667 - val_loss: 0.8358 - val_accuracy: 0.6533\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.8034 - accuracy: 0.6667 - val_loss: 0.8298 - val_accuracy: 0.6533\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.7971 - accuracy: 0.6667 - val_loss: 0.8230 - val_accuracy: 0.6533\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.7903 - accuracy: 0.6667 - val_loss: 0.8157 - val_accuracy: 0.6533\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.7837 - accuracy: 0.6667 - val_loss: 0.8105 - val_accuracy: 0.6533\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.7770 - accuracy: 0.6667 - val_loss: 0.8026 - val_accuracy: 0.6533\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.7701 - accuracy: 0.6667 - val_loss: 0.7947 - val_accuracy: 0.6533\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.7634 - accuracy: 0.6667 - val_loss: 0.7885 - val_accuracy: 0.6533\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.7568 - accuracy: 0.6667 - val_loss: 0.7832 - val_accuracy: 0.6533\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.7506 - accuracy: 0.6667 - val_loss: 0.7768 - val_accuracy: 0.6533\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.7445 - accuracy: 0.6667 - val_loss: 0.7700 - val_accuracy: 0.6533\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.7374 - accuracy: 0.6667 - val_loss: 0.7630 - val_accuracy: 0.6533\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.7307 - accuracy: 0.6667 - val_loss: 0.7560 - val_accuracy: 0.6533\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.7236 - accuracy: 0.6667 - val_loss: 0.7476 - val_accuracy: 0.6800\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.7163 - accuracy: 0.7200 - val_loss: 0.7401 - val_accuracy: 0.7733\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.7089 - accuracy: 0.8000 - val_loss: 0.7335 - val_accuracy: 0.7600\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.7018 - accuracy: 0.7600 - val_loss: 0.7251 - val_accuracy: 0.8133\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.6947 - accuracy: 0.8000 - val_loss: 0.7171 - val_accuracy: 0.8000\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.6872 - accuracy: 0.8267 - val_loss: 0.7109 - val_accuracy: 0.8000\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.6799 - accuracy: 0.8400 - val_loss: 0.7042 - val_accuracy: 0.8000\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.6732 - accuracy: 0.8400 - val_loss: 0.6971 - val_accuracy: 0.8000\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.6660 - accuracy: 0.8267 - val_loss: 0.6869 - val_accuracy: 0.8133\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.6587 - accuracy: 0.8133 - val_loss: 0.6799 - val_accuracy: 0.8133\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.6517 - accuracy: 0.7867 - val_loss: 0.6724 - val_accuracy: 0.8400\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.6437 - accuracy: 0.8000 - val_loss: 0.6648 - val_accuracy: 0.8400\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.6363 - accuracy: 0.8000 - val_loss: 0.6578 - val_accuracy: 0.8400\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.6296 - accuracy: 0.8000 - val_loss: 0.6504 - val_accuracy: 0.8400\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.6226 - accuracy: 0.8000 - val_loss: 0.6410 - val_accuracy: 0.8267\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.6142 - accuracy: 0.8133 - val_loss: 0.6326 - val_accuracy: 0.8133\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.6064 - accuracy: 0.8267 - val_loss: 0.6262 - val_accuracy: 0.8133\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.5997 - accuracy: 0.8267 - val_loss: 0.6186 - val_accuracy: 0.8133\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 417us/sample - loss: 0.5924 - accuracy: 0.8267 - val_loss: 0.6110 - val_accuracy: 0.8133\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.5846 - accuracy: 0.8267 - val_loss: 0.6035 - val_accuracy: 0.8133\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.5774 - accuracy: 0.8267 - val_loss: 0.5947 - val_accuracy: 0.8133\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.5699 - accuracy: 0.8133 - val_loss: 0.5851 - val_accuracy: 0.8267\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.5627 - accuracy: 0.8267 - val_loss: 0.5798 - val_accuracy: 0.8267\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.5555 - accuracy: 0.8133 - val_loss: 0.5711 - val_accuracy: 0.8267\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.5483 - accuracy: 0.8267 - val_loss: 0.5606 - val_accuracy: 0.8267\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.5413 - accuracy: 0.8267 - val_loss: 0.5539 - val_accuracy: 0.8267\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.5343 - accuracy: 0.8267 - val_loss: 0.5470 - val_accuracy: 0.8267\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.5268 - accuracy: 0.8400 - val_loss: 0.5405 - val_accuracy: 0.8267\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.5200 - accuracy: 0.8267 - val_loss: 0.5346 - val_accuracy: 0.8267\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.5130 - accuracy: 0.8267 - val_loss: 0.5278 - val_accuracy: 0.8267\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.5067 - accuracy: 0.8267 - val_loss: 0.5189 - val_accuracy: 0.8267\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.4998 - accuracy: 0.8400 - val_loss: 0.5138 - val_accuracy: 0.8267\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.4936 - accuracy: 0.8400 - val_loss: 0.5076 - val_accuracy: 0.8267\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.4873 - accuracy: 0.8400 - val_loss: 0.5020 - val_accuracy: 0.8267\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.4811 - accuracy: 0.8400 - val_loss: 0.4948 - val_accuracy: 0.8267\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.4745 - accuracy: 0.8400 - val_loss: 0.4859 - val_accuracy: 0.8133\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.4678 - accuracy: 0.8000 - val_loss: 0.4825 - val_accuracy: 0.8133\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.4618 - accuracy: 0.8267 - val_loss: 0.4731 - val_accuracy: 0.8133\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.4558 - accuracy: 0.8133 - val_loss: 0.4678 - val_accuracy: 0.8133\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.4503 - accuracy: 0.8000 - val_loss: 0.4627 - val_accuracy: 0.8133\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.4445 - accuracy: 0.8133 - val_loss: 0.4563 - val_accuracy: 0.8133\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.4391 - accuracy: 0.8000 - val_loss: 0.4504 - val_accuracy: 0.8267\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.4334 - accuracy: 0.8000 - val_loss: 0.4450 - val_accuracy: 0.8267\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.4292 - accuracy: 0.8133 - val_loss: 0.4423 - val_accuracy: 0.8267\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 0.4237 - accuracy: 0.8000 - val_loss: 0.4364 - val_accuracy: 0.8267\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.4189 - accuracy: 0.8000 - val_loss: 0.4306 - val_accuracy: 0.8267\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.4147 - accuracy: 0.8000 - val_loss: 0.4266 - val_accuracy: 0.8267\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.4098 - accuracy: 0.8000 - val_loss: 0.4250 - val_accuracy: 0.8267\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.4052 - accuracy: 0.8133 - val_loss: 0.4211 - val_accuracy: 0.8267\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 496us/sample - loss: 0.4007 - accuracy: 0.8133 - val_loss: 0.4162 - val_accuracy: 0.8267\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.3962 - accuracy: 0.8133 - val_loss: 0.4142 - val_accuracy: 0.8400\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.3919 - accuracy: 0.8267 - val_loss: 0.4118 - val_accuracy: 0.8267\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.3881 - accuracy: 0.8400 - val_loss: 0.4080 - val_accuracy: 0.8400\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.3837 - accuracy: 0.8400 - val_loss: 0.4041 - val_accuracy: 0.8267\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.3805 - accuracy: 0.8400 - val_loss: 0.4016 - val_accuracy: 0.8267\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.3761 - accuracy: 0.8400 - val_loss: 0.3979 - val_accuracy: 0.8400\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.3724 - accuracy: 0.8400 - val_loss: 0.3968 - val_accuracy: 0.8400\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.3692 - accuracy: 0.8400 - val_loss: 0.3937 - val_accuracy: 0.8267\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.3666 - accuracy: 0.8400 - val_loss: 0.3915 - val_accuracy: 0.8400\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.3628 - accuracy: 0.8400 - val_loss: 0.3863 - val_accuracy: 0.8400\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 502us/sample - loss: 0.3595 - accuracy: 0.8400 - val_loss: 0.3844 - val_accuracy: 0.8400\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.3570 - accuracy: 0.8400 - val_loss: 0.3806 - val_accuracy: 0.8400\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.3543 - accuracy: 0.8400 - val_loss: 0.3791 - val_accuracy: 0.8400\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 567us/sample - loss: 0.3514 - accuracy: 0.8400 - val_loss: 0.3776 - val_accuracy: 0.8400\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 495us/sample - loss: 0.3497 - accuracy: 0.8400 - val_loss: 0.3788 - val_accuracy: 0.8400\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 0.3464 - accuracy: 0.8400 - val_loss: 0.3793 - val_accuracy: 0.8400\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.3444 - accuracy: 0.8400 - val_loss: 0.3774 - val_accuracy: 0.8400\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.3418 - accuracy: 0.8400 - val_loss: 0.3778 - val_accuracy: 0.8400\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.3396 - accuracy: 0.8400 - val_loss: 0.3777 - val_accuracy: 0.8400\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 602us/sample - loss: 0.3372 - accuracy: 0.8400 - val_loss: 0.3756 - val_accuracy: 0.8400\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.3354 - accuracy: 0.8400 - val_loss: 0.3745 - val_accuracy: 0.8400\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.3334 - accuracy: 0.8400 - val_loss: 0.3740 - val_accuracy: 0.8533\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.3317 - accuracy: 0.8400 - val_loss: 0.3724 - val_accuracy: 0.8533\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.3301 - accuracy: 0.8400 - val_loss: 0.3760 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.3287 - accuracy: 0.8400 - val_loss: 0.3727 - val_accuracy: 0.8533\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.3269 - accuracy: 0.8400 - val_loss: 0.3699 - val_accuracy: 0.8533\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.3255 - accuracy: 0.8400 - val_loss: 0.3747 - val_accuracy: 0.8533\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.3244 - accuracy: 0.8400 - val_loss: 0.3731 - val_accuracy: 0.8533\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 556us/sample - loss: 0.3230 - accuracy: 0.8400 - val_loss: 0.3764 - val_accuracy: 0.8400\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 467us/sample - loss: 0.3214 - accuracy: 0.8400 - val_loss: 0.3796 - val_accuracy: 0.8400\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.3204 - accuracy: 0.8400 - val_loss: 0.3757 - val_accuracy: 0.8400\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.3192 - accuracy: 0.8400 - val_loss: 0.3757 - val_accuracy: 0.8533\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 478us/sample - loss: 0.3179 - accuracy: 0.8400 - val_loss: 0.3756 - val_accuracy: 0.8533\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.3162 - accuracy: 0.8400 - val_loss: 0.3780 - val_accuracy: 0.8533\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 525us/sample - loss: 0.3154 - accuracy: 0.8400 - val_loss: 0.3816 - val_accuracy: 0.8533\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.3144 - accuracy: 0.8400 - val_loss: 0.3810 - val_accuracy: 0.8533\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.3129 - accuracy: 0.8400 - val_loss: 0.3806 - val_accuracy: 0.8533\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.3120 - accuracy: 0.8400 - val_loss: 0.3795 - val_accuracy: 0.8533\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 457us/sample - loss: 0.3109 - accuracy: 0.8400 - val_loss: 0.3849 - val_accuracy: 0.8533\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3099 - accuracy: 0.8400 - val_loss: 0.3879 - val_accuracy: 0.8533\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3089 - accuracy: 0.8400 - val_loss: 0.3868 - val_accuracy: 0.8533\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.3074 - accuracy: 0.8400 - val_loss: 0.3932 - val_accuracy: 0.8533\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.3058 - accuracy: 0.8400 - val_loss: 0.3906 - val_accuracy: 0.8533\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.3076 - accuracy: 0.8400 - val_loss: 0.3916 - val_accuracy: 0.8533\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.3036 - accuracy: 0.8533 - val_loss: 0.3932 - val_accuracy: 0.8533\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.3029 - accuracy: 0.8533 - val_loss: 0.3974 - val_accuracy: 0.8533\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.3019 - accuracy: 0.8400 - val_loss: 0.4045 - val_accuracy: 0.8400\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.3010 - accuracy: 0.8533 - val_loss: 0.4025 - val_accuracy: 0.8533\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.2998 - accuracy: 0.8400 - val_loss: 0.4037 - val_accuracy: 0.8533\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.2987 - accuracy: 0.8400 - val_loss: 0.4086 - val_accuracy: 0.8400\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.2972 - accuracy: 0.8533 - val_loss: 0.4073 - val_accuracy: 0.8400\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.2967 - accuracy: 0.8533 - val_loss: 0.4072 - val_accuracy: 0.8533\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.2952 - accuracy: 0.8533 - val_loss: 0.4108 - val_accuracy: 0.8400\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.2946 - accuracy: 0.8533 - val_loss: 0.4225 - val_accuracy: 0.8400\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.2944 - accuracy: 0.8400 - val_loss: 0.4257 - val_accuracy: 0.8400\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 626us/sample - loss: 0.2931 - accuracy: 0.8400 - val_loss: 0.4275 - val_accuracy: 0.8267\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.2922 - accuracy: 0.8400 - val_loss: 0.4231 - val_accuracy: 0.8400\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2928 - accuracy: 0.8400 - val_loss: 0.4210 - val_accuracy: 0.8400\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.2903 - accuracy: 0.8533 - val_loss: 0.4263 - val_accuracy: 0.8400\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.2893 - accuracy: 0.8533 - val_loss: 0.4233 - val_accuracy: 0.8400\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.2894 - accuracy: 0.8533 - val_loss: 0.4272 - val_accuracy: 0.8400\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.2881 - accuracy: 0.8533 - val_loss: 0.4347 - val_accuracy: 0.8400\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.2868 - accuracy: 0.8533 - val_loss: 0.4336 - val_accuracy: 0.8400\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.2863 - accuracy: 0.8533 - val_loss: 0.4409 - val_accuracy: 0.8400\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.2853 - accuracy: 0.8533 - val_loss: 0.4413 - val_accuracy: 0.8400\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.2847 - accuracy: 0.8533 - val_loss: 0.4443 - val_accuracy: 0.8400\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.2848 - accuracy: 0.8400 - val_loss: 0.4414 - val_accuracy: 0.8400\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.2828 - accuracy: 0.8533 - val_loss: 0.4461 - val_accuracy: 0.8400\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.2820 - accuracy: 0.8533 - val_loss: 0.4448 - val_accuracy: 0.8400\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.2816 - accuracy: 0.8533 - val_loss: 0.4483 - val_accuracy: 0.8400\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.2807 - accuracy: 0.8533 - val_loss: 0.4464 - val_accuracy: 0.8400\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.2805 - accuracy: 0.8533 - val_loss: 0.4505 - val_accuracy: 0.8400\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.2803 - accuracy: 0.8533 - val_loss: 0.4566 - val_accuracy: 0.8400\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2788 - accuracy: 0.8533 - val_loss: 0.4628 - val_accuracy: 0.8400\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.2780 - accuracy: 0.8533 - val_loss: 0.4598 - val_accuracy: 0.8400\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.2775 - accuracy: 0.8533 - val_loss: 0.4697 - val_accuracy: 0.8400\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.2766 - accuracy: 0.8533 - val_loss: 0.4641 - val_accuracy: 0.8400\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.2771 - accuracy: 0.8533 - val_loss: 0.4644 - val_accuracy: 0.8400\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.2754 - accuracy: 0.8533 - val_loss: 0.4635 - val_accuracy: 0.8400\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.2755 - accuracy: 0.8533 - val_loss: 0.4730 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.2743 - accuracy: 0.8533 - val_loss: 0.4696 - val_accuracy: 0.8400\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 0.2736 - accuracy: 0.8533 - val_loss: 0.4771 - val_accuracy: 0.8533\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.2734 - accuracy: 0.8400 - val_loss: 0.4787 - val_accuracy: 0.8400\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.2723 - accuracy: 0.8533 - val_loss: 0.4767 - val_accuracy: 0.8400\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.2719 - accuracy: 0.8533 - val_loss: 0.4818 - val_accuracy: 0.8400\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.2727 - accuracy: 0.8533 - val_loss: 0.4808 - val_accuracy: 0.8400\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.2715 - accuracy: 0.8533 - val_loss: 0.4801 - val_accuracy: 0.8400\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.2710 - accuracy: 0.8533 - val_loss: 0.4837 - val_accuracy: 0.8400\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.2696 - accuracy: 0.8533 - val_loss: 0.4874 - val_accuracy: 0.8400\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.2696 - accuracy: 0.8533 - val_loss: 0.4922 - val_accuracy: 0.8400\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.2693 - accuracy: 0.8533 - val_loss: 0.4960 - val_accuracy: 0.8400\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.2685 - accuracy: 0.8533 - val_loss: 0.4997 - val_accuracy: 0.8400\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.2677 - accuracy: 0.8533 - val_loss: 0.5020 - val_accuracy: 0.8400\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.2686 - accuracy: 0.8533 - val_loss: 0.5003 - val_accuracy: 0.8400\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.2676 - accuracy: 0.8533 - val_loss: 0.4952 - val_accuracy: 0.8400\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.2659 - accuracy: 0.8533 - val_loss: 0.4979 - val_accuracy: 0.8400\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2651 - accuracy: 0.8533 - val_loss: 0.5025 - val_accuracy: 0.8400\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.2651 - accuracy: 0.8533 - val_loss: 0.5042 - val_accuracy: 0.8400\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.2648 - accuracy: 0.8533 - val_loss: 0.5139 - val_accuracy: 0.8533\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 513us/sample - loss: 0.2637 - accuracy: 0.8533 - val_loss: 0.5131 - val_accuracy: 0.8400\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.2632 - accuracy: 0.8533 - val_loss: 0.5165 - val_accuracy: 0.8400\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.2631 - accuracy: 0.8533 - val_loss: 0.5114 - val_accuracy: 0.8400\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.2623 - accuracy: 0.8533 - val_loss: 0.5188 - val_accuracy: 0.8533\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 460us/sample - loss: 0.2617 - accuracy: 0.8533 - val_loss: 0.5228 - val_accuracy: 0.8533\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.2613 - accuracy: 0.8533 - val_loss: 0.5197 - val_accuracy: 0.8533\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.2609 - accuracy: 0.8533 - val_loss: 0.5181 - val_accuracy: 0.8533\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 469us/sample - loss: 0.2599 - accuracy: 0.8533 - val_loss: 0.5226 - val_accuracy: 0.8533\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.2594 - accuracy: 0.8533 - val_loss: 0.5173 - val_accuracy: 0.8533\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.2584 - accuracy: 0.8533 - val_loss: 0.5231 - val_accuracy: 0.8533\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 0.2582 - accuracy: 0.8533 - val_loss: 0.5202 - val_accuracy: 0.8533\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.2575 - accuracy: 0.8533 - val_loss: 0.5245 - val_accuracy: 0.8533\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.2568 - accuracy: 0.8533 - val_loss: 0.5349 - val_accuracy: 0.8533\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.2560 - accuracy: 0.8533 - val_loss: 0.5416 - val_accuracy: 0.8533\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.2572 - accuracy: 0.8533 - val_loss: 0.5430 - val_accuracy: 0.8533\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 539us/sample - loss: 0.2558 - accuracy: 0.8533 - val_loss: 0.5441 - val_accuracy: 0.8533\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 580us/sample - loss: 0.2541 - accuracy: 0.8533 - val_loss: 0.5422 - val_accuracy: 0.8533\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.2540 - accuracy: 0.8533 - val_loss: 0.5517 - val_accuracy: 0.8533\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.2535 - accuracy: 0.8533 - val_loss: 0.5581 - val_accuracy: 0.8533\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.2537 - accuracy: 0.8533 - val_loss: 0.5586 - val_accuracy: 0.8533\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.2532 - accuracy: 0.8533 - val_loss: 0.5613 - val_accuracy: 0.8533\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.2519 - accuracy: 0.8533 - val_loss: 0.5651 - val_accuracy: 0.8533\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.2509 - accuracy: 0.8533 - val_loss: 0.5623 - val_accuracy: 0.8533\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.2501 - accuracy: 0.8533 - val_loss: 0.5711 - val_accuracy: 0.8533\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.2497 - accuracy: 0.8533 - val_loss: 0.5701 - val_accuracy: 0.8533\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2501 - accuracy: 0.8533 - val_loss: 0.5849 - val_accuracy: 0.8667\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.2486 - accuracy: 0.8533 - val_loss: 0.5791 - val_accuracy: 0.8533\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.2479 - accuracy: 0.8533 - val_loss: 0.5824 - val_accuracy: 0.8533\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.2466 - accuracy: 0.8533 - val_loss: 0.5941 - val_accuracy: 0.8533\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.2466 - accuracy: 0.8533 - val_loss: 0.5961 - val_accuracy: 0.8533\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.2463 - accuracy: 0.8533 - val_loss: 0.5991 - val_accuracy: 0.8533\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2453 - accuracy: 0.8533 - val_loss: 0.5891 - val_accuracy: 0.8533\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.2438 - accuracy: 0.8533 - val_loss: 0.5884 - val_accuracy: 0.8667\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.2437 - accuracy: 0.8533 - val_loss: 0.5856 - val_accuracy: 0.8667\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.2445 - accuracy: 0.8667 - val_loss: 0.5933 - val_accuracy: 0.8667\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.2420 - accuracy: 0.8667 - val_loss: 0.6082 - val_accuracy: 0.8667\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.2413 - accuracy: 0.8667 - val_loss: 0.6183 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.2403 - accuracy: 0.8533 - val_loss: 0.6180 - val_accuracy: 0.8667\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.2399 - accuracy: 0.8667 - val_loss: 0.6273 - val_accuracy: 0.8533\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.2389 - accuracy: 0.8533 - val_loss: 0.6234 - val_accuracy: 0.8667\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.2391 - accuracy: 0.8533 - val_loss: 0.6234 - val_accuracy: 0.8667\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.2387 - accuracy: 0.8667 - val_loss: 0.6264 - val_accuracy: 0.8667\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.2369 - accuracy: 0.8667 - val_loss: 0.6285 - val_accuracy: 0.8667\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.2401 - accuracy: 0.8667 - val_loss: 0.6277 - val_accuracy: 0.8667\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 541us/sample - loss: 0.2357 - accuracy: 0.8667 - val_loss: 0.6350 - val_accuracy: 0.8667\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.2358 - accuracy: 0.8667 - val_loss: 0.6355 - val_accuracy: 0.8667\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.2352 - accuracy: 0.8667 - val_loss: 0.6347 - val_accuracy: 0.8667\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.2342 - accuracy: 0.8800 - val_loss: 0.6441 - val_accuracy: 0.8667\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2343 - accuracy: 0.8667 - val_loss: 0.6476 - val_accuracy: 0.8667\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.2336 - accuracy: 0.8800 - val_loss: 0.6466 - val_accuracy: 0.8667\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.2340 - accuracy: 0.8800 - val_loss: 0.6549 - val_accuracy: 0.8667\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.2315 - accuracy: 0.8800 - val_loss: 0.6520 - val_accuracy: 0.8667\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2320 - accuracy: 0.8800 - val_loss: 0.6590 - val_accuracy: 0.8667\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.2323 - accuracy: 0.8800 - val_loss: 0.6649 - val_accuracy: 0.8667\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.2321 - accuracy: 0.8667 - val_loss: 0.6662 - val_accuracy: 0.8667\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.2298 - accuracy: 0.8800 - val_loss: 0.6648 - val_accuracy: 0.8667\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.2291 - accuracy: 0.8800 - val_loss: 0.6789 - val_accuracy: 0.8800\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.2304 - accuracy: 0.8667 - val_loss: 0.6746 - val_accuracy: 0.8800\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.2288 - accuracy: 0.8667 - val_loss: 0.6846 - val_accuracy: 0.8800\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.2289 - accuracy: 0.8667 - val_loss: 0.6812 - val_accuracy: 0.8800\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.2280 - accuracy: 0.8667 - val_loss: 0.6853 - val_accuracy: 0.8800\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.2270 - accuracy: 0.8667 - val_loss: 0.6920 - val_accuracy: 0.8800\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.2277 - accuracy: 0.8800 - val_loss: 0.6939 - val_accuracy: 0.8800\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.2269 - accuracy: 0.8667 - val_loss: 0.6854 - val_accuracy: 0.8800\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.2263 - accuracy: 0.8800 - val_loss: 0.6884 - val_accuracy: 0.8800\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.2257 - accuracy: 0.8800 - val_loss: 0.6961 - val_accuracy: 0.8800\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.2252 - accuracy: 0.8667 - val_loss: 0.7002 - val_accuracy: 0.8800\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.2251 - accuracy: 0.8800 - val_loss: 0.6855 - val_accuracy: 0.8800\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.2247 - accuracy: 0.8800 - val_loss: 0.6985 - val_accuracy: 0.8800\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.2241 - accuracy: 0.8800 - val_loss: 0.7048 - val_accuracy: 0.8800\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.2238 - accuracy: 0.8800 - val_loss: 0.7133 - val_accuracy: 0.8800\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.2233 - accuracy: 0.8667 - val_loss: 0.7152 - val_accuracy: 0.8800\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.2228 - accuracy: 0.8667 - val_loss: 0.7006 - val_accuracy: 0.8800\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.2218 - accuracy: 0.8800 - val_loss: 0.7083 - val_accuracy: 0.8800\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 492us/sample - loss: 0.2230 - accuracy: 0.8800 - val_loss: 0.7043 - val_accuracy: 0.8800\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.2210 - accuracy: 0.8800 - val_loss: 0.7022 - val_accuracy: 0.8800\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 473us/sample - loss: 0.2210 - accuracy: 0.8800 - val_loss: 0.7005 - val_accuracy: 0.8800\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.2207 - accuracy: 0.8800 - val_loss: 0.7004 - val_accuracy: 0.8800\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.2202 - accuracy: 0.8800 - val_loss: 0.6959 - val_accuracy: 0.8800\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.2197 - accuracy: 0.8800 - val_loss: 0.6888 - val_accuracy: 0.8800\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.2204 - accuracy: 0.8800 - val_loss: 0.7040 - val_accuracy: 0.8800\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.2188 - accuracy: 0.8800 - val_loss: 0.7089 - val_accuracy: 0.8800\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.2193 - accuracy: 0.8800 - val_loss: 0.6981 - val_accuracy: 0.8800\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.2197 - accuracy: 0.8800 - val_loss: 0.6990 - val_accuracy: 0.8800\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.2178 - accuracy: 0.8800 - val_loss: 0.7036 - val_accuracy: 0.8800\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2173 - accuracy: 0.8800 - val_loss: 0.7190 - val_accuracy: 0.8800\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.2178 - accuracy: 0.8800 - val_loss: 0.7202 - val_accuracy: 0.8800\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 525us/sample - loss: 0.2172 - accuracy: 0.8800 - val_loss: 0.7123 - val_accuracy: 0.8800\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 593us/sample - loss: 0.2165 - accuracy: 0.8800 - val_loss: 0.7188 - val_accuracy: 0.8800\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.2166 - accuracy: 0.8800 - val_loss: 0.7078 - val_accuracy: 0.8800\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.2161 - accuracy: 0.8800 - val_loss: 0.7221 - val_accuracy: 0.8800\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.2151 - accuracy: 0.8800 - val_loss: 0.7280 - val_accuracy: 0.8800\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.2152 - accuracy: 0.8800 - val_loss: 0.7362 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.2144 - accuracy: 0.8800 - val_loss: 0.7367 - val_accuracy: 0.8800\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.2141 - accuracy: 0.8800 - val_loss: 0.7464 - val_accuracy: 0.8800\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.2140 - accuracy: 0.8800 - val_loss: 0.7496 - val_accuracy: 0.8800\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 459us/sample - loss: 0.2130 - accuracy: 0.8800 - val_loss: 0.7636 - val_accuracy: 0.8800\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.2132 - accuracy: 0.8800 - val_loss: 0.7563 - val_accuracy: 0.8800\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.2126 - accuracy: 0.8800 - val_loss: 0.7636 - val_accuracy: 0.8800\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.2128 - accuracy: 0.8800 - val_loss: 0.7609 - val_accuracy: 0.8800\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 692us/sample - loss: 0.2120 - accuracy: 0.8800 - val_loss: 0.7673 - val_accuracy: 0.8800\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.2119 - accuracy: 0.8667 - val_loss: 0.7588 - val_accuracy: 0.8800\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.2113 - accuracy: 0.8800 - val_loss: 0.7580 - val_accuracy: 0.8800\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.2104 - accuracy: 0.8800 - val_loss: 0.7711 - val_accuracy: 0.8800\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.2108 - accuracy: 0.8800 - val_loss: 0.7996 - val_accuracy: 0.8933\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.2098 - accuracy: 0.8800 - val_loss: 0.7873 - val_accuracy: 0.8933\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.2079 - accuracy: 0.8933 - val_loss: 0.7803 - val_accuracy: 0.8933\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.2070 - accuracy: 0.8933 - val_loss: 0.7728 - val_accuracy: 0.8933\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.2073 - accuracy: 0.8933 - val_loss: 0.7827 - val_accuracy: 0.8933\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.2070 - accuracy: 0.8933 - val_loss: 0.7653 - val_accuracy: 0.8800\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.2072 - accuracy: 0.8933 - val_loss: 0.7628 - val_accuracy: 0.8800\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.2066 - accuracy: 0.8933 - val_loss: 0.7702 - val_accuracy: 0.8800\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.2057 - accuracy: 0.8933 - val_loss: 0.7944 - val_accuracy: 0.8933\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2052 - accuracy: 0.8933 - val_loss: 0.8086 - val_accuracy: 0.8933\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.2045 - accuracy: 0.8933 - val_loss: 0.7952 - val_accuracy: 0.8933\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.2027 - accuracy: 0.8933 - val_loss: 0.7980 - val_accuracy: 0.8933\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.2022 - accuracy: 0.8933 - val_loss: 0.7975 - val_accuracy: 0.8933\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.2018 - accuracy: 0.8933 - val_loss: 0.7837 - val_accuracy: 0.8933\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.2010 - accuracy: 0.8933 - val_loss: 0.7890 - val_accuracy: 0.8933\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.2005 - accuracy: 0.8933 - val_loss: 0.8044 - val_accuracy: 0.8933\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.2002 - accuracy: 0.8933 - val_loss: 0.8014 - val_accuracy: 0.8933\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.2006 - accuracy: 0.8933 - val_loss: 0.7800 - val_accuracy: 0.8933\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.2024 - accuracy: 0.8933 - val_loss: 0.7862 - val_accuracy: 0.8933\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.1998 - accuracy: 0.8933 - val_loss: 0.8034 - val_accuracy: 0.8933\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.1992 - accuracy: 0.8933 - val_loss: 0.8012 - val_accuracy: 0.8933\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 585us/sample - loss: 0.1981 - accuracy: 0.8933 - val_loss: 0.8122 - val_accuracy: 0.9067\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 531us/sample - loss: 0.1980 - accuracy: 0.8933 - val_loss: 0.7982 - val_accuracy: 0.8933\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.1978 - accuracy: 0.8933 - val_loss: 0.8066 - val_accuracy: 0.9067\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.1966 - accuracy: 0.8933 - val_loss: 0.8198 - val_accuracy: 0.9067\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.1967 - accuracy: 0.8933 - val_loss: 0.8175 - val_accuracy: 0.9067\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.1961 - accuracy: 0.8933 - val_loss: 0.8059 - val_accuracy: 0.9067\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.1949 - accuracy: 0.8933 - val_loss: 0.8155 - val_accuracy: 0.9067\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.1951 - accuracy: 0.8933 - val_loss: 0.8325 - val_accuracy: 0.9067\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.1951 - accuracy: 0.8933 - val_loss: 0.8279 - val_accuracy: 0.9067\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.1939 - accuracy: 0.8933 - val_loss: 0.8240 - val_accuracy: 0.9067\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.1933 - accuracy: 0.8933 - val_loss: 0.8411 - val_accuracy: 0.9067\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.1934 - accuracy: 0.8933 - val_loss: 0.8347 - val_accuracy: 0.9067\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.1923 - accuracy: 0.8933 - val_loss: 0.8195 - val_accuracy: 0.9067\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.1920 - accuracy: 0.8933 - val_loss: 0.8322 - val_accuracy: 0.9067\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.1917 - accuracy: 0.8933 - val_loss: 0.8393 - val_accuracy: 0.9067\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.1907 - accuracy: 0.8933 - val_loss: 0.8539 - val_accuracy: 0.9067\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.1901 - accuracy: 0.8933 - val_loss: 0.8783 - val_accuracy: 0.9067\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.1912 - accuracy: 0.8933 - val_loss: 0.8401 - val_accuracy: 0.9067\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.1895 - accuracy: 0.8933 - val_loss: 0.8425 - val_accuracy: 0.9067\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.1897 - accuracy: 0.8933 - val_loss: 0.8494 - val_accuracy: 0.9067\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.1882 - accuracy: 0.8933 - val_loss: 0.8514 - val_accuracy: 0.9067\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.1889 - accuracy: 0.8933 - val_loss: 0.8213 - val_accuracy: 0.9067\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.1886 - accuracy: 0.8933 - val_loss: 0.8302 - val_accuracy: 0.9067\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.1880 - accuracy: 0.8933 - val_loss: 0.8470 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 535us/sample - loss: 0.1873 - accuracy: 0.8933 - val_loss: 0.8444 - val_accuracy: 0.9067\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.1870 - accuracy: 0.8933 - val_loss: 0.8578 - val_accuracy: 0.9067\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.1871 - accuracy: 0.8933 - val_loss: 0.8476 - val_accuracy: 0.9067\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.1865 - accuracy: 0.8933 - val_loss: 0.8495 - val_accuracy: 0.9067\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.1861 - accuracy: 0.8933 - val_loss: 0.8551 - val_accuracy: 0.9067\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.1855 - accuracy: 0.8933 - val_loss: 0.8469 - val_accuracy: 0.9067\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 456us/sample - loss: 0.1847 - accuracy: 0.8933 - val_loss: 0.8591 - val_accuracy: 0.9067\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.1847 - accuracy: 0.8933 - val_loss: 0.8599 - val_accuracy: 0.9067\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.1857 - accuracy: 0.8933 - val_loss: 0.8538 - val_accuracy: 0.9067\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.1837 - accuracy: 0.8933 - val_loss: 0.8611 - val_accuracy: 0.9067\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.1847 - accuracy: 0.8933 - val_loss: 0.8257 - val_accuracy: 0.9200\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 577us/sample - loss: 0.1840 - accuracy: 0.8933 - val_loss: 0.8299 - val_accuracy: 0.9200\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.1838 - accuracy: 0.8933 - val_loss: 0.8512 - val_accuracy: 0.9067\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.1823 - accuracy: 0.8933 - val_loss: 0.8599 - val_accuracy: 0.9067\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 0.1827 - accuracy: 0.8933 - val_loss: 0.8755 - val_accuracy: 0.9067\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.1808 - accuracy: 0.8933 - val_loss: 0.8744 - val_accuracy: 0.9067\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 0.1795 - accuracy: 0.9067 - val_loss: 0.8658 - val_accuracy: 0.9067\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.1792 - accuracy: 0.9067 - val_loss: 0.8833 - val_accuracy: 0.9067\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.1787 - accuracy: 0.9067 - val_loss: 0.8719 - val_accuracy: 0.9067\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.1767 - accuracy: 0.9067 - val_loss: 0.8665 - val_accuracy: 0.9067\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.1759 - accuracy: 0.9067 - val_loss: 0.8516 - val_accuracy: 0.9200\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.1764 - accuracy: 0.9067 - val_loss: 0.8580 - val_accuracy: 0.9200\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.1732 - accuracy: 0.9067 - val_loss: 0.8654 - val_accuracy: 0.9200\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.1704 - accuracy: 0.9067 - val_loss: 0.8834 - val_accuracy: 0.9067\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.1692 - accuracy: 0.9200 - val_loss: 0.8915 - val_accuracy: 0.9067\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.1674 - accuracy: 0.9200 - val_loss: 0.8855 - val_accuracy: 0.9067\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.1625 - accuracy: 0.9200 - val_loss: 0.8737 - val_accuracy: 0.9200\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.1605 - accuracy: 0.9333 - val_loss: 0.8864 - val_accuracy: 0.9200\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.1589 - accuracy: 0.9200 - val_loss: 0.8685 - val_accuracy: 0.9333\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.1567 - accuracy: 0.9333 - val_loss: 0.8830 - val_accuracy: 0.9200\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.1562 - accuracy: 0.9333 - val_loss: 0.8965 - val_accuracy: 0.9200\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.1543 - accuracy: 0.9200 - val_loss: 0.8952 - val_accuracy: 0.9200\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.8658 - val_accuracy: 0.9333\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.1531 - accuracy: 0.9333 - val_loss: 0.8706 - val_accuracy: 0.9200\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.1522 - accuracy: 0.9333 - val_loss: 0.8605 - val_accuracy: 0.9333\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.1501 - accuracy: 0.9333 - val_loss: 0.8620 - val_accuracy: 0.9333\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.1488 - accuracy: 0.9333 - val_loss: 0.8727 - val_accuracy: 0.9200\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.1477 - accuracy: 0.9467 - val_loss: 0.8694 - val_accuracy: 0.9200\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.1467 - accuracy: 0.9333 - val_loss: 0.8710 - val_accuracy: 0.9200\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.1457 - accuracy: 0.9333 - val_loss: 0.8832 - val_accuracy: 0.9200\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.1444 - accuracy: 0.9333 - val_loss: 0.8980 - val_accuracy: 0.9200\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.1441 - accuracy: 0.9333 - val_loss: 0.8682 - val_accuracy: 0.9200\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.1423 - accuracy: 0.9467 - val_loss: 0.8724 - val_accuracy: 0.9200\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.1405 - accuracy: 0.9467 - val_loss: 0.8818 - val_accuracy: 0.9200\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.1406 - accuracy: 0.9600 - val_loss: 0.8647 - val_accuracy: 0.9200\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 0.1392 - accuracy: 0.9467 - val_loss: 0.8762 - val_accuracy: 0.9200\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.1377 - accuracy: 0.9467 - val_loss: 0.8830 - val_accuracy: 0.9200\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.1363 - accuracy: 0.9467 - val_loss: 0.9010 - val_accuracy: 0.9200\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.1345 - accuracy: 0.9467 - val_loss: 0.9119 - val_accuracy: 0.9200\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.1318 - accuracy: 0.9333 - val_loss: 0.8788 - val_accuracy: 0.9200\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.1316 - accuracy: 0.9600 - val_loss: 0.8894 - val_accuracy: 0.9200\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.1291 - accuracy: 0.9600 - val_loss: 0.8887 - val_accuracy: 0.9200\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.1271 - accuracy: 0.9600 - val_loss: 0.9014 - val_accuracy: 0.9200\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.1256 - accuracy: 0.9467 - val_loss: 0.8988 - val_accuracy: 0.9200\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.1249 - accuracy: 0.9600 - val_loss: 0.8813 - val_accuracy: 0.9200\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.1233 - accuracy: 0.9600 - val_loss: 0.8952 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.1201 - accuracy: 0.9600 - val_loss: 0.9069 - val_accuracy: 0.9200\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.1185 - accuracy: 0.9600 - val_loss: 0.9210 - val_accuracy: 0.9200\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 512us/sample - loss: 0.1195 - accuracy: 0.9467 - val_loss: 0.9435 - val_accuracy: 0.9200\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.1160 - accuracy: 0.9333 - val_loss: 0.9570 - val_accuracy: 0.9200\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.1116 - accuracy: 0.9467 - val_loss: 0.9408 - val_accuracy: 0.9200\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.1101 - accuracy: 0.9467 - val_loss: 0.9627 - val_accuracy: 0.9200\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.1091 - accuracy: 0.9467 - val_loss: 0.9705 - val_accuracy: 0.9200\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.9532 - val_accuracy: 0.9200\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.1048 - accuracy: 0.9467 - val_loss: 0.9475 - val_accuracy: 0.9200\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.1029 - accuracy: 0.9600 - val_loss: 0.9672 - val_accuracy: 0.9200\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.1017 - accuracy: 0.9600 - val_loss: 0.9574 - val_accuracy: 0.9200\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.1007 - accuracy: 0.9600 - val_loss: 0.9768 - val_accuracy: 0.9200\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.1000 - accuracy: 0.9600 - val_loss: 1.0016 - val_accuracy: 0.9200\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.0978 - accuracy: 0.9600 - val_loss: 0.9883 - val_accuracy: 0.9200\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.0956 - accuracy: 0.9733 - val_loss: 0.9889 - val_accuracy: 0.9200\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.0939 - accuracy: 0.9733 - val_loss: 0.9980 - val_accuracy: 0.9200\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.0931 - accuracy: 0.9733 - val_loss: 1.0149 - val_accuracy: 0.9200\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.0922 - accuracy: 0.9733 - val_loss: 0.9862 - val_accuracy: 0.9200\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 473us/sample - loss: 0.0904 - accuracy: 0.9867 - val_loss: 1.0107 - val_accuracy: 0.9200\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.0882 - accuracy: 0.9733 - val_loss: 1.0260 - val_accuracy: 0.9200\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.0881 - accuracy: 0.9733 - val_loss: 1.0531 - val_accuracy: 0.9200\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.0864 - accuracy: 0.9733 - val_loss: 1.0441 - val_accuracy: 0.9200\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.0848 - accuracy: 0.9733 - val_loss: 1.0572 - val_accuracy: 0.9200\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.0846 - accuracy: 0.9733 - val_loss: 1.0730 - val_accuracy: 0.9200\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.0847 - accuracy: 0.9733 - val_loss: 1.0894 - val_accuracy: 0.9067\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.0837 - accuracy: 0.9467 - val_loss: 1.0690 - val_accuracy: 0.9200\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.0809 - accuracy: 0.9733 - val_loss: 1.0911 - val_accuracy: 0.9200\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.0812 - accuracy: 0.9733 - val_loss: 1.0962 - val_accuracy: 0.9200\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.0802 - accuracy: 0.9733 - val_loss: 1.0989 - val_accuracy: 0.9200\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.0767 - accuracy: 0.9733 - val_loss: 1.0997 - val_accuracy: 0.9200\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.0762 - accuracy: 0.9733 - val_loss: 1.0990 - val_accuracy: 0.9200\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 458us/sample - loss: 0.0745 - accuracy: 0.9733 - val_loss: 1.1012 - val_accuracy: 0.9200\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.0749 - accuracy: 0.9867 - val_loss: 1.1383 - val_accuracy: 0.9067\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.0723 - accuracy: 0.9733 - val_loss: 1.1342 - val_accuracy: 0.9200\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 0.0709 - accuracy: 0.9733 - val_loss: 1.1304 - val_accuracy: 0.9200\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.0690 - accuracy: 0.9733 - val_loss: 1.1329 - val_accuracy: 0.9333\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.0678 - accuracy: 0.9733 - val_loss: 1.1448 - val_accuracy: 0.9333\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.0675 - accuracy: 0.9733 - val_loss: 1.1410 - val_accuracy: 0.9333\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.0653 - accuracy: 0.9733 - val_loss: 1.1366 - val_accuracy: 0.9333\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.0637 - accuracy: 0.9867 - val_loss: 1.1596 - val_accuracy: 0.9333\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.0622 - accuracy: 0.9867 - val_loss: 1.1676 - val_accuracy: 0.9333\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.0628 - accuracy: 0.9867 - val_loss: 1.1839 - val_accuracy: 0.9333\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.0631 - accuracy: 0.9733 - val_loss: 1.2004 - val_accuracy: 0.9333\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.0587 - accuracy: 0.9867 - val_loss: 1.2062 - val_accuracy: 0.9333\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.0644 - accuracy: 0.9867 - val_loss: 1.2008 - val_accuracy: 0.9333\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.0585 - accuracy: 0.9867 - val_loss: 1.2284 - val_accuracy: 0.9333\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.0565 - accuracy: 0.9867 - val_loss: 1.2162 - val_accuracy: 0.9333\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.0551 - accuracy: 0.9867 - val_loss: 1.2176 - val_accuracy: 0.9333\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.0546 - accuracy: 0.9867 - val_loss: 1.2587 - val_accuracy: 0.9333\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.0531 - accuracy: 0.9867 - val_loss: 1.2662 - val_accuracy: 0.9333\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.0522 - accuracy: 0.9867 - val_loss: 1.2644 - val_accuracy: 0.9333\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 0.0508 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "history = neural_network_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?\n",
    " - med 5 lager och 5 noder i varje lager utom output-lagret har vi 133 träningsbara parametrar. Är det rimligt givet 75 obs i träningsdata setet?\n",
    " - Övertränar nätverket på träningsdatat?\n",
    " - Vad händer om du förändrar antalet noder i vår modell, hur påverkar det accuracy för tränings och valideringsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  1.0\n",
      "accuracy, test:  0.93333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [0 0 2 0 0]\n",
      "\n",
      "Sannolikheter bakom prediktionerna\n",
      " ['setosa' 'versicolor' 'virginica'] \n",
      " [[1.000e+00 4.480e-19 3.169e-09]\n",
      " [1.000e+00 8.022e-18 1.220e-08]\n",
      " [5.663e-06 3.077e-01 6.923e-01]\n",
      " [1.000e+00 1.676e-16 3.796e-08]\n",
      " [1.000e+00 8.291e-18 1.184e-08]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = neural_network_model.predict_classes(X_test[0:5])\n",
    "\n",
    "probabilities = neural_network_model.predict_proba(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktionerna\\n\",names,\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurala nätverk - Regularisering\n",
    "\n",
    "Vi testar att köra vårat överdrivet stora neurala nätverk igen, denna gång med L1 och L2-regularisering\n",
    "- Vi utvärderar om introduktion av L1 och L2-regularisering kan mitigera överträning på träningsdatat\n",
    "- Testa gärna att förändra  antal_hidden_layer, antal_noder samt l1- / l2_reg_rate och utforska vad som händer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 2s 24ms/sample - loss: 1.6258 - accuracy: 0.2667 - val_loss: 1.6331 - val_accuracy: 0.2267\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 508us/sample - loss: 1.5878 - accuracy: 0.2667 - val_loss: 1.6081 - val_accuracy: 0.2400\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 1.5668 - accuracy: 0.2533 - val_loss: 1.5874 - val_accuracy: 0.2400\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 1.5503 - accuracy: 0.2800 - val_loss: 1.5717 - val_accuracy: 0.2933\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 1.5373 - accuracy: 0.2400 - val_loss: 1.5600 - val_accuracy: 0.2933\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 1.5265 - accuracy: 0.3067 - val_loss: 1.5484 - val_accuracy: 0.2933\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 1.5168 - accuracy: 0.3067 - val_loss: 1.5358 - val_accuracy: 0.2800\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 1.5067 - accuracy: 0.3333 - val_loss: 1.5246 - val_accuracy: 0.2667\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 1.4970 - accuracy: 0.3600 - val_loss: 1.5162 - val_accuracy: 0.2933\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 460us/sample - loss: 1.4886 - accuracy: 0.4133 - val_loss: 1.5074 - val_accuracy: 0.2933\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 1.4800 - accuracy: 0.4133 - val_loss: 1.4981 - val_accuracy: 0.3200\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 1.4712 - accuracy: 0.4133 - val_loss: 1.4881 - val_accuracy: 0.3200\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 1.4626 - accuracy: 0.4267 - val_loss: 1.4787 - val_accuracy: 0.3467\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 1.4542 - accuracy: 0.4133 - val_loss: 1.4679 - val_accuracy: 0.3600\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 1.4455 - accuracy: 0.4400 - val_loss: 1.4592 - val_accuracy: 0.3733\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 373us/sample - loss: 1.4379 - accuracy: 0.4400 - val_loss: 1.4516 - val_accuracy: 0.4133\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 1.4307 - accuracy: 0.4667 - val_loss: 1.4446 - val_accuracy: 0.4000\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 1.4242 - accuracy: 0.4533 - val_loss: 1.4375 - val_accuracy: 0.4000\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 1.4167 - accuracy: 0.4400 - val_loss: 1.4305 - val_accuracy: 0.4267\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.4100 - accuracy: 0.4267 - val_loss: 1.4239 - val_accuracy: 0.4133\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 1.4030 - accuracy: 0.4400 - val_loss: 1.4169 - val_accuracy: 0.4267\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 1.3961 - accuracy: 0.4400 - val_loss: 1.4105 - val_accuracy: 0.4400\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 1.3891 - accuracy: 0.4933 - val_loss: 1.4044 - val_accuracy: 0.4400\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 1.3825 - accuracy: 0.5067 - val_loss: 1.3979 - val_accuracy: 0.4533\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 1.3756 - accuracy: 0.4933 - val_loss: 1.3911 - val_accuracy: 0.4533\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 1.3690 - accuracy: 0.5200 - val_loss: 1.3850 - val_accuracy: 0.4400\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 1.3628 - accuracy: 0.5067 - val_loss: 1.3781 - val_accuracy: 0.4400\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 1.3555 - accuracy: 0.5600 - val_loss: 1.3712 - val_accuracy: 0.4267\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 1.3488 - accuracy: 0.5467 - val_loss: 1.3637 - val_accuracy: 0.4267\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 1.3419 - accuracy: 0.5200 - val_loss: 1.3565 - val_accuracy: 0.4533\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 1.3355 - accuracy: 0.5467 - val_loss: 1.3494 - val_accuracy: 0.4533\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.3286 - accuracy: 0.5333 - val_loss: 1.3422 - val_accuracy: 0.4400\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 1.3217 - accuracy: 0.5333 - val_loss: 1.3350 - val_accuracy: 0.4400\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.3151 - accuracy: 0.5467 - val_loss: 1.3284 - val_accuracy: 0.4267\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 1.3088 - accuracy: 0.5333 - val_loss: 1.3218 - val_accuracy: 0.4267\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 1.3024 - accuracy: 0.5467 - val_loss: 1.3156 - val_accuracy: 0.4267\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 528us/sample - loss: 1.2962 - accuracy: 0.5333 - val_loss: 1.3091 - val_accuracy: 0.4267\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 1.2896 - accuracy: 0.5467 - val_loss: 1.3021 - val_accuracy: 0.4133\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 1.2832 - accuracy: 0.5333 - val_loss: 1.2960 - val_accuracy: 0.4133\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 1.2767 - accuracy: 0.5200 - val_loss: 1.2888 - val_accuracy: 0.4133\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 1.2703 - accuracy: 0.5200 - val_loss: 1.2814 - val_accuracy: 0.4400\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 1.2638 - accuracy: 0.5200 - val_loss: 1.2756 - val_accuracy: 0.4267\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 1.2575 - accuracy: 0.5067 - val_loss: 1.2684 - val_accuracy: 0.4400\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 1.2513 - accuracy: 0.4933 - val_loss: 1.2614 - val_accuracy: 0.4533\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 1.2450 - accuracy: 0.5200 - val_loss: 1.2550 - val_accuracy: 0.4267\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 1.2384 - accuracy: 0.4800 - val_loss: 1.2486 - val_accuracy: 0.4000\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 1.2320 - accuracy: 0.4800 - val_loss: 1.2422 - val_accuracy: 0.4000\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.2255 - accuracy: 0.4800 - val_loss: 1.2353 - val_accuracy: 0.4000\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 1.2190 - accuracy: 0.4400 - val_loss: 1.2285 - val_accuracy: 0.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 1.2125 - accuracy: 0.4400 - val_loss: 1.2218 - val_accuracy: 0.4267\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 1.2063 - accuracy: 0.4400 - val_loss: 1.2155 - val_accuracy: 0.4400\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 1.1998 - accuracy: 0.4400 - val_loss: 1.2091 - val_accuracy: 0.4400\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 1.1933 - accuracy: 0.4533 - val_loss: 1.2032 - val_accuracy: 0.4267\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 1.1870 - accuracy: 0.4533 - val_loss: 1.1969 - val_accuracy: 0.4533\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 1.1816 - accuracy: 0.4533 - val_loss: 1.1914 - val_accuracy: 0.4400\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 1.1750 - accuracy: 0.4667 - val_loss: 1.1847 - val_accuracy: 0.4667\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 1.1691 - accuracy: 0.4933 - val_loss: 1.1794 - val_accuracy: 0.4667\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 1.1635 - accuracy: 0.4667 - val_loss: 1.1739 - val_accuracy: 0.4667\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 467us/sample - loss: 1.1581 - accuracy: 0.5067 - val_loss: 1.1690 - val_accuracy: 0.4800\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 609us/sample - loss: 1.1526 - accuracy: 0.4933 - val_loss: 1.1636 - val_accuracy: 0.5067\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 1.1473 - accuracy: 0.5200 - val_loss: 1.1574 - val_accuracy: 0.5467\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 527us/sample - loss: 1.1412 - accuracy: 0.5467 - val_loss: 1.1513 - val_accuracy: 0.6000\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 529us/sample - loss: 1.1360 - accuracy: 0.5867 - val_loss: 1.1466 - val_accuracy: 0.6000\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 497us/sample - loss: 1.1305 - accuracy: 0.5867 - val_loss: 1.1405 - val_accuracy: 0.6533\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 1.1249 - accuracy: 0.5867 - val_loss: 1.1358 - val_accuracy: 0.6133\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 1.1201 - accuracy: 0.6000 - val_loss: 1.1292 - val_accuracy: 0.7067\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 547us/sample - loss: 1.1144 - accuracy: 0.6133 - val_loss: 1.1228 - val_accuracy: 0.6933\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 1.1085 - accuracy: 0.6400 - val_loss: 1.1175 - val_accuracy: 0.6933\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 1.1035 - accuracy: 0.6400 - val_loss: 1.1115 - val_accuracy: 0.7333\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 1.0984 - accuracy: 0.6267 - val_loss: 1.1057 - val_accuracy: 0.7200\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 1.0934 - accuracy: 0.6533 - val_loss: 1.1017 - val_accuracy: 0.7467\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 1.0885 - accuracy: 0.6667 - val_loss: 1.0965 - val_accuracy: 0.7600\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 1.0832 - accuracy: 0.6667 - val_loss: 1.0911 - val_accuracy: 0.7733\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 1.0782 - accuracy: 0.6933 - val_loss: 1.0858 - val_accuracy: 0.7867\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 1.0738 - accuracy: 0.6933 - val_loss: 1.0791 - val_accuracy: 0.7733\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 1.0681 - accuracy: 0.6933 - val_loss: 1.0752 - val_accuracy: 0.7733\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 1.0636 - accuracy: 0.7200 - val_loss: 1.0695 - val_accuracy: 0.7867\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 1.0583 - accuracy: 0.6933 - val_loss: 1.0654 - val_accuracy: 0.7733\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 1.0539 - accuracy: 0.7200 - val_loss: 1.0608 - val_accuracy: 0.8000\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 1.0493 - accuracy: 0.7200 - val_loss: 1.0560 - val_accuracy: 0.8000\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 1.0441 - accuracy: 0.7200 - val_loss: 1.0507 - val_accuracy: 0.8000\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 1.0395 - accuracy: 0.7333 - val_loss: 1.0455 - val_accuracy: 0.8000\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 1.0345 - accuracy: 0.7200 - val_loss: 1.0412 - val_accuracy: 0.8000\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 1.0300 - accuracy: 0.7333 - val_loss: 1.0367 - val_accuracy: 0.8133\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.0250 - accuracy: 0.8000 - val_loss: 1.0307 - val_accuracy: 0.8000\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 1.0200 - accuracy: 0.7333 - val_loss: 1.0260 - val_accuracy: 0.8000\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 1.0154 - accuracy: 0.7333 - val_loss: 1.0197 - val_accuracy: 0.8000\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 1.0108 - accuracy: 0.7333 - val_loss: 1.0139 - val_accuracy: 0.8000\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 1.0060 - accuracy: 0.7200 - val_loss: 1.0101 - val_accuracy: 0.8133\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 1.0016 - accuracy: 0.7333 - val_loss: 1.0064 - val_accuracy: 0.8133\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.9970 - accuracy: 0.7867 - val_loss: 1.0025 - val_accuracy: 0.8267\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.9940 - accuracy: 0.7733 - val_loss: 0.9989 - val_accuracy: 0.8400\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.9889 - accuracy: 0.8133 - val_loss: 0.9936 - val_accuracy: 0.8267\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.9840 - accuracy: 0.8133 - val_loss: 0.9884 - val_accuracy: 0.8267\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.9799 - accuracy: 0.8133 - val_loss: 0.9830 - val_accuracy: 0.8267\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.9757 - accuracy: 0.8133 - val_loss: 0.9784 - val_accuracy: 0.8267\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.9711 - accuracy: 0.8000 - val_loss: 0.9750 - val_accuracy: 0.8400\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.9664 - accuracy: 0.8133 - val_loss: 0.9688 - val_accuracy: 0.8267\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.9624 - accuracy: 0.8000 - val_loss: 0.9642 - val_accuracy: 0.8267\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.9584 - accuracy: 0.7867 - val_loss: 0.9606 - val_accuracy: 0.8400\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.9537 - accuracy: 0.8000 - val_loss: 0.9578 - val_accuracy: 0.8400\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.9497 - accuracy: 0.8133 - val_loss: 0.9533 - val_accuracy: 0.8533\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.9454 - accuracy: 0.8133 - val_loss: 0.9484 - val_accuracy: 0.8533\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.9412 - accuracy: 0.8133 - val_loss: 0.9444 - val_accuracy: 0.8533\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.9379 - accuracy: 0.8133 - val_loss: 0.9405 - val_accuracy: 0.8800\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 371us/sample - loss: 0.9327 - accuracy: 0.8267 - val_loss: 0.9356 - val_accuracy: 0.8800\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.9287 - accuracy: 0.8267 - val_loss: 0.9310 - val_accuracy: 0.8667\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.9229 - accuracy: 0.75 - 0s 445us/sample - loss: 0.9249 - accuracy: 0.8133 - val_loss: 0.9265 - val_accuracy: 0.8667\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.9210 - accuracy: 0.8267 - val_loss: 0.9217 - val_accuracy: 0.8800\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.9161 - accuracy: 0.8267 - val_loss: 0.9155 - val_accuracy: 0.8533\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.9110 - accuracy: 0.8133 - val_loss: 0.9111 - val_accuracy: 0.8533\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.9075 - accuracy: 0.8133 - val_loss: 0.9071 - val_accuracy: 0.8533\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.9030 - accuracy: 0.8267 - val_loss: 0.9026 - val_accuracy: 0.8800\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.8984 - accuracy: 0.8267 - val_loss: 0.8984 - val_accuracy: 0.8800\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.8942 - accuracy: 0.8400 - val_loss: 0.8922 - val_accuracy: 0.8533\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.8900 - accuracy: 0.8133 - val_loss: 0.8862 - val_accuracy: 0.8533\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.8857 - accuracy: 0.8133 - val_loss: 0.8835 - val_accuracy: 0.8800\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.8812 - accuracy: 0.8267 - val_loss: 0.8769 - val_accuracy: 0.8533\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.8774 - accuracy: 0.8133 - val_loss: 0.8712 - val_accuracy: 0.8533\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.8732 - accuracy: 0.8133 - val_loss: 0.8666 - val_accuracy: 0.8533\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.8685 - accuracy: 0.8133 - val_loss: 0.8611 - val_accuracy: 0.8533\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.8638 - accuracy: 0.8000 - val_loss: 0.8563 - val_accuracy: 0.8533\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.8594 - accuracy: 0.8133 - val_loss: 0.8529 - val_accuracy: 0.8800\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.8546 - accuracy: 0.8400 - val_loss: 0.8481 - val_accuracy: 0.8800\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.8508 - accuracy: 0.8267 - val_loss: 0.8421 - val_accuracy: 0.8667\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.8458 - accuracy: 0.8400 - val_loss: 0.8379 - val_accuracy: 0.8800\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.8418 - accuracy: 0.8400 - val_loss: 0.8347 - val_accuracy: 0.9067\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 539us/sample - loss: 0.8369 - accuracy: 0.8533 - val_loss: 0.8297 - val_accuracy: 0.9067\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.8326 - accuracy: 0.8400 - val_loss: 0.8236 - val_accuracy: 0.9067\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.8284 - accuracy: 0.8400 - val_loss: 0.8169 - val_accuracy: 0.8933\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.8232 - accuracy: 0.8400 - val_loss: 0.8125 - val_accuracy: 0.8933\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.8186 - accuracy: 0.8400 - val_loss: 0.8053 - val_accuracy: 0.8933\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.8142 - accuracy: 0.8400 - val_loss: 0.7998 - val_accuracy: 0.8800\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.8100 - accuracy: 0.8400 - val_loss: 0.7954 - val_accuracy: 0.8933\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.8046 - accuracy: 0.8400 - val_loss: 0.7894 - val_accuracy: 0.8933\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.8004 - accuracy: 0.8400 - val_loss: 0.7830 - val_accuracy: 0.8800\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.7951 - accuracy: 0.8400 - val_loss: 0.7789 - val_accuracy: 0.9200\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.7912 - accuracy: 0.8533 - val_loss: 0.7729 - val_accuracy: 0.9067\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 502us/sample - loss: 0.7851 - accuracy: 0.8400 - val_loss: 0.7682 - val_accuracy: 0.9200\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.7802 - accuracy: 0.8400 - val_loss: 0.7615 - val_accuracy: 0.9200\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.7757 - accuracy: 0.8267 - val_loss: 0.7564 - val_accuracy: 0.9200\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.7707 - accuracy: 0.8400 - val_loss: 0.7520 - val_accuracy: 0.9200\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.7645 - accuracy: 0.8400 - val_loss: 0.7466 - val_accuracy: 0.9200\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.7599 - accuracy: 0.8400 - val_loss: 0.7412 - val_accuracy: 0.9200\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.7543 - accuracy: 0.8267 - val_loss: 0.7366 - val_accuracy: 0.9200\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.7498 - accuracy: 0.8400 - val_loss: 0.7320 - val_accuracy: 0.9200\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.7443 - accuracy: 0.8400 - val_loss: 0.7255 - val_accuracy: 0.9200\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.7397 - accuracy: 0.8400 - val_loss: 0.7212 - val_accuracy: 0.9200\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.7348 - accuracy: 0.8400 - val_loss: 0.7143 - val_accuracy: 0.9200\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.7302 - accuracy: 0.8400 - val_loss: 0.7078 - val_accuracy: 0.9200\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.7245 - accuracy: 0.8400 - val_loss: 0.7034 - val_accuracy: 0.9200\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.7199 - accuracy: 0.8400 - val_loss: 0.6984 - val_accuracy: 0.9200\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.7164 - accuracy: 0.8133 - val_loss: 0.6919 - val_accuracy: 0.9200\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.7104 - accuracy: 0.8400 - val_loss: 0.6859 - val_accuracy: 0.9200\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.7052 - accuracy: 0.8400 - val_loss: 0.6808 - val_accuracy: 0.9200\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.7011 - accuracy: 0.8400 - val_loss: 0.6750 - val_accuracy: 0.9200\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.6961 - accuracy: 0.8400 - val_loss: 0.6700 - val_accuracy: 0.9200\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.6909 - accuracy: 0.8400 - val_loss: 0.6658 - val_accuracy: 0.9200\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.6869 - accuracy: 0.8267 - val_loss: 0.6609 - val_accuracy: 0.9333\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.6817 - accuracy: 0.8400 - val_loss: 0.6565 - val_accuracy: 0.9200\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.6779 - accuracy: 0.8400 - val_loss: 0.6511 - val_accuracy: 0.9200\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.6719 - accuracy: 0.8400 - val_loss: 0.6472 - val_accuracy: 0.9200\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.6673 - accuracy: 0.8400 - val_loss: 0.6418 - val_accuracy: 0.9200\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.6633 - accuracy: 0.8400 - val_loss: 0.6360 - val_accuracy: 0.9200\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.6593 - accuracy: 0.8267 - val_loss: 0.6304 - val_accuracy: 0.9200\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.90 - 0s 451us/sample - loss: 0.6546 - accuracy: 0.8400 - val_loss: 0.6284 - val_accuracy: 0.9333\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.6497 - accuracy: 0.8667 - val_loss: 0.6233 - val_accuracy: 0.9200\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.6456 - accuracy: 0.8533 - val_loss: 0.6197 - val_accuracy: 0.9333\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.6421 - accuracy: 0.8667 - val_loss: 0.6137 - val_accuracy: 0.9200\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.6372 - accuracy: 0.8533 - val_loss: 0.6087 - val_accuracy: 0.9200\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.6332 - accuracy: 0.8533 - val_loss: 0.6075 - val_accuracy: 0.9333\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.6295 - accuracy: 0.8533 - val_loss: 0.6036 - val_accuracy: 0.9333\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.6258 - accuracy: 0.8533 - val_loss: 0.6003 - val_accuracy: 0.9333\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.6219 - accuracy: 0.8667 - val_loss: 0.5990 - val_accuracy: 0.8933\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.6184 - accuracy: 0.8533 - val_loss: 0.5923 - val_accuracy: 0.9333\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.6151 - accuracy: 0.8667 - val_loss: 0.5860 - val_accuracy: 0.9333\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.6110 - accuracy: 0.8667 - val_loss: 0.5810 - val_accuracy: 0.9333\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 623us/sample - loss: 0.6074 - accuracy: 0.8667 - val_loss: 0.5783 - val_accuracy: 0.9333\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.6040 - accuracy: 0.8667 - val_loss: 0.5774 - val_accuracy: 0.9333\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.6003 - accuracy: 0.8667 - val_loss: 0.5723 - val_accuracy: 0.9333\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.5968 - accuracy: 0.8667 - val_loss: 0.5672 - val_accuracy: 0.9333\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.5944 - accuracy: 0.8800 - val_loss: 0.5628 - val_accuracy: 0.9333\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.5905 - accuracy: 0.8800 - val_loss: 0.5600 - val_accuracy: 0.9333\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.5882 - accuracy: 0.8667 - val_loss: 0.5601 - val_accuracy: 0.9333\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.5838 - accuracy: 0.8667 - val_loss: 0.5552 - val_accuracy: 0.9333\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.5808 - accuracy: 0.8667 - val_loss: 0.5545 - val_accuracy: 0.9333\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.5777 - accuracy: 0.8533 - val_loss: 0.5501 - val_accuracy: 0.9333\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.5805 - accuracy: 0.8533 - val_loss: 0.5489 - val_accuracy: 0.9333\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 475us/sample - loss: 0.5719 - accuracy: 0.8667 - val_loss: 0.5453 - val_accuracy: 0.9333\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 536us/sample - loss: 0.5693 - accuracy: 0.8667 - val_loss: 0.5417 - val_accuracy: 0.9333\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.5670 - accuracy: 0.8800 - val_loss: 0.5413 - val_accuracy: 0.9200\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.5654 - accuracy: 0.8533 - val_loss: 0.5355 - val_accuracy: 0.9333\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.5616 - accuracy: 0.8800 - val_loss: 0.5321 - val_accuracy: 0.9333\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 0.5593 - accuracy: 0.8800 - val_loss: 0.5326 - val_accuracy: 0.9333\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.5566 - accuracy: 0.8667 - val_loss: 0.5316 - val_accuracy: 0.9333\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.5538 - accuracy: 0.8533 - val_loss: 0.5272 - val_accuracy: 0.9467\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.5511 - accuracy: 0.8667 - val_loss: 0.5263 - val_accuracy: 0.9333\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.5493 - accuracy: 0.8667 - val_loss: 0.5273 - val_accuracy: 0.9067\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.5475 - accuracy: 0.8800 - val_loss: 0.5259 - val_accuracy: 0.9067\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.5453 - accuracy: 0.8933 - val_loss: 0.5263 - val_accuracy: 0.8933\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.5422 - accuracy: 0.8933 - val_loss: 0.5204 - val_accuracy: 0.9067\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.5413 - accuracy: 0.8800 - val_loss: 0.5165 - val_accuracy: 0.9200\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 0.5372 - accuracy: 0.8800 - val_loss: 0.5125 - val_accuracy: 0.9467\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.5347 - accuracy: 0.8800 - val_loss: 0.5097 - val_accuracy: 0.9467\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.5337 - accuracy: 0.8667 - val_loss: 0.5073 - val_accuracy: 0.9467\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.5313 - accuracy: 0.8800 - val_loss: 0.5092 - val_accuracy: 0.9333\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 484us/sample - loss: 0.5280 - accuracy: 0.8667 - val_loss: 0.5057 - val_accuracy: 0.9467\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.5261 - accuracy: 0.8800 - val_loss: 0.5062 - val_accuracy: 0.9200\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 0.5236 - accuracy: 0.8933 - val_loss: 0.5034 - val_accuracy: 0.9467\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.5215 - accuracy: 0.8800 - val_loss: 0.5026 - val_accuracy: 0.9200\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.5199 - accuracy: 0.9067 - val_loss: 0.4968 - val_accuracy: 0.9467\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.5178 - accuracy: 0.8933 - val_loss: 0.4958 - val_accuracy: 0.9467\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 594us/sample - loss: 0.5156 - accuracy: 0.8800 - val_loss: 0.4931 - val_accuracy: 0.9467\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.5139 - accuracy: 0.8933 - val_loss: 0.4936 - val_accuracy: 0.9467\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.5112 - accuracy: 0.9067 - val_loss: 0.4899 - val_accuracy: 0.9467\n",
      "Epoch 216/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 385us/sample - loss: 0.5092 - accuracy: 0.9067 - val_loss: 0.4884 - val_accuracy: 0.9467\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.5084 - accuracy: 0.8933 - val_loss: 0.4898 - val_accuracy: 0.9467\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.5052 - accuracy: 0.9067 - val_loss: 0.4925 - val_accuracy: 0.9067\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.5029 - accuracy: 0.9067 - val_loss: 0.4872 - val_accuracy: 0.9467\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 493us/sample - loss: 0.5016 - accuracy: 0.9067 - val_loss: 0.4905 - val_accuracy: 0.9067\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.4992 - accuracy: 0.9200 - val_loss: 0.4883 - val_accuracy: 0.9067\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 556us/sample - loss: 0.4985 - accuracy: 0.9200 - val_loss: 0.4867 - val_accuracy: 0.9067\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.4957 - accuracy: 0.9067 - val_loss: 0.4818 - val_accuracy: 0.9467\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.4943 - accuracy: 0.9200 - val_loss: 0.4830 - val_accuracy: 0.9200\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.4917 - accuracy: 0.9067 - val_loss: 0.4831 - val_accuracy: 0.9067\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.4902 - accuracy: 0.9333 - val_loss: 0.4844 - val_accuracy: 0.9067\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.4888 - accuracy: 0.9200 - val_loss: 0.4799 - val_accuracy: 0.9333\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.4857 - accuracy: 0.9333 - val_loss: 0.4765 - val_accuracy: 0.9333\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.4838 - accuracy: 0.9200 - val_loss: 0.4770 - val_accuracy: 0.9333\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.4834 - accuracy: 0.9467 - val_loss: 0.4768 - val_accuracy: 0.9067\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.4812 - accuracy: 0.9200 - val_loss: 0.4730 - val_accuracy: 0.9333\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.4788 - accuracy: 0.9467 - val_loss: 0.4770 - val_accuracy: 0.9067\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.4765 - accuracy: 0.9200 - val_loss: 0.4731 - val_accuracy: 0.9200\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.4751 - accuracy: 0.9333 - val_loss: 0.4738 - val_accuracy: 0.9067\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 535us/sample - loss: 0.4744 - accuracy: 0.9200 - val_loss: 0.4721 - val_accuracy: 0.9067\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.4711 - accuracy: 0.9200 - val_loss: 0.4679 - val_accuracy: 0.9333\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.4695 - accuracy: 0.9600 - val_loss: 0.4681 - val_accuracy: 0.9333\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.4699 - accuracy: 0.9200 - val_loss: 0.4662 - val_accuracy: 0.9333\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.4665 - accuracy: 0.9467 - val_loss: 0.4627 - val_accuracy: 0.9467\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.4638 - accuracy: 0.9467 - val_loss: 0.4644 - val_accuracy: 0.9333\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.4617 - accuracy: 0.9333 - val_loss: 0.4636 - val_accuracy: 0.9333\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.4603 - accuracy: 0.9333 - val_loss: 0.4617 - val_accuracy: 0.9333\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.4596 - accuracy: 0.9333 - val_loss: 0.4629 - val_accuracy: 0.9333\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.4574 - accuracy: 0.9467 - val_loss: 0.4594 - val_accuracy: 0.9333\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.4547 - accuracy: 0.9467 - val_loss: 0.4602 - val_accuracy: 0.9333\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.4540 - accuracy: 0.9467 - val_loss: 0.4547 - val_accuracy: 0.9333\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.4518 - accuracy: 0.9467 - val_loss: 0.4598 - val_accuracy: 0.9333\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.4494 - accuracy: 0.9600 - val_loss: 0.4589 - val_accuracy: 0.9333\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 489us/sample - loss: 0.4477 - accuracy: 0.9600 - val_loss: 0.4600 - val_accuracy: 0.9200\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.4466 - accuracy: 0.9467 - val_loss: 0.4579 - val_accuracy: 0.9200\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.4442 - accuracy: 0.9600 - val_loss: 0.4544 - val_accuracy: 0.9333\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 524us/sample - loss: 0.4426 - accuracy: 0.9600 - val_loss: 0.4532 - val_accuracy: 0.9333\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.4403 - accuracy: 0.9733 - val_loss: 0.4519 - val_accuracy: 0.9333\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.4391 - accuracy: 0.9600 - val_loss: 0.4511 - val_accuracy: 0.9333\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.4365 - accuracy: 0.9733 - val_loss: 0.4557 - val_accuracy: 0.9200\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.4351 - accuracy: 0.9600 - val_loss: 0.4559 - val_accuracy: 0.9200\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.4333 - accuracy: 0.9467 - val_loss: 0.4575 - val_accuracy: 0.9200\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.4331 - accuracy: 0.9600 - val_loss: 0.4570 - val_accuracy: 0.9200\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.4309 - accuracy: 0.9733 - val_loss: 0.4517 - val_accuracy: 0.9200\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.4275 - accuracy: 0.9733 - val_loss: 0.4478 - val_accuracy: 0.9333\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.4265 - accuracy: 0.9733 - val_loss: 0.4529 - val_accuracy: 0.9200\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.4264 - accuracy: 0.9600 - val_loss: 0.4509 - val_accuracy: 0.9200\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.4257 - accuracy: 0.9733 - val_loss: 0.4506 - val_accuracy: 0.9200\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.4231 - accuracy: 0.9467 - val_loss: 0.4493 - val_accuracy: 0.9200\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.4196 - accuracy: 0.9733 - val_loss: 0.4532 - val_accuracy: 0.9200\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.4175 - accuracy: 0.9733 - val_loss: 0.4475 - val_accuracy: 0.9200\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.4157 - accuracy: 0.9733 - val_loss: 0.4497 - val_accuracy: 0.9200\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.4147 - accuracy: 0.9733 - val_loss: 0.4515 - val_accuracy: 0.9200\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.4132 - accuracy: 0.9733 - val_loss: 0.4510 - val_accuracy: 0.9200\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.4116 - accuracy: 0.9733 - val_loss: 0.4425 - val_accuracy: 0.9333\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.4091 - accuracy: 0.9867 - val_loss: 0.4444 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.4075 - accuracy: 0.9867 - val_loss: 0.4471 - val_accuracy: 0.9200\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.4089 - accuracy: 0.9867 - val_loss: 0.4488 - val_accuracy: 0.9200\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.4060 - accuracy: 0.9733 - val_loss: 0.4524 - val_accuracy: 0.9200\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.4043 - accuracy: 0.9600 - val_loss: 0.4404 - val_accuracy: 0.9333\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.4014 - accuracy: 0.9867 - val_loss: 0.4411 - val_accuracy: 0.9200\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.4013 - accuracy: 0.9867 - val_loss: 0.4347 - val_accuracy: 0.9333\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.4012 - accuracy: 0.9600 - val_loss: 0.4362 - val_accuracy: 0.9333\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.3972 - accuracy: 0.9867 - val_loss: 0.4388 - val_accuracy: 0.9333\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.3955 - accuracy: 0.9867 - val_loss: 0.4417 - val_accuracy: 0.9200\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 484us/sample - loss: 0.3941 - accuracy: 0.9867 - val_loss: 0.4444 - val_accuracy: 0.9200\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.3929 - accuracy: 0.9867 - val_loss: 0.4468 - val_accuracy: 0.9333\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.3919 - accuracy: 0.9867 - val_loss: 0.4500 - val_accuracy: 0.9333\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.3914 - accuracy: 0.9867 - val_loss: 0.4443 - val_accuracy: 0.9333\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.3920 - accuracy: 0.9867 - val_loss: 0.4402 - val_accuracy: 0.9200\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3867 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9200\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.3885 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9333\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.3841 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9333\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.3839 - accuracy: 0.9867 - val_loss: 0.4342 - val_accuracy: 0.9333\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.3819 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9333\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.3805 - accuracy: 0.9733 - val_loss: 0.4314 - val_accuracy: 0.9333\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.3788 - accuracy: 0.9867 - val_loss: 0.4331 - val_accuracy: 0.9333\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.3781 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9333\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.3790 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9333\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.3748 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9333\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.3749 - accuracy: 0.9867 - val_loss: 0.4254 - val_accuracy: 0.9333\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.3739 - accuracy: 0.9600 - val_loss: 0.4358 - val_accuracy: 0.9333\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 482us/sample - loss: 0.3726 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9333\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.3707 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9333\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 0.3688 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9333\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3686 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9200\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3671 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9333\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.3666 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9200\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9333\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.3630 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9333\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.3621 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9333\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 444us/sample - loss: 0.3624 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9333\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.3600 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9333\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 1.00 - 0s 345us/sample - loss: 0.3592 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9333\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3579 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9333\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.3587 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9333\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.3571 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9333\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 519us/sample - loss: 0.3552 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9333\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.3531 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9333\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3535 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9333\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.3525 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9333\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 393us/sample - loss: 0.3504 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9333\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.3514 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9333\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3489 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.9333\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.3483 - accuracy: 0.9733 - val_loss: 0.4262 - val_accuracy: 0.9333\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.3469 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9333\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3461 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9333\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.3456 - accuracy: 0.9867 - val_loss: 0.4239 - val_accuracy: 0.9333\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.3452 - accuracy: 0.9733 - val_loss: 0.4378 - val_accuracy: 0.9333\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.3438 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9333\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.3438 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9333\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.3435 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9333\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.3419 - accuracy: 0.9733 - val_loss: 0.4196 - val_accuracy: 0.9333\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3405 - accuracy: 0.9733 - val_loss: 0.4286 - val_accuracy: 0.9333\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.3401 - accuracy: 0.9867 - val_loss: 0.4350 - val_accuracy: 0.9333\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.3390 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9333\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.3382 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9333\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.3381 - accuracy: 0.9867 - val_loss: 0.4178 - val_accuracy: 0.9333\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.3370 - accuracy: 0.9733 - val_loss: 0.4283 - val_accuracy: 0.9333\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.3360 - accuracy: 0.9867 - val_loss: 0.4286 - val_accuracy: 0.9333\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.3349 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9333\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 484us/sample - loss: 0.3348 - accuracy: 0.9867 - val_loss: 0.4241 - val_accuracy: 0.9333\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.3332 - accuracy: 0.9733 - val_loss: 0.4266 - val_accuracy: 0.9333\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.3349 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9333\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.3322 - accuracy: 0.9867 - val_loss: 0.4390 - val_accuracy: 0.9333\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.3318 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9333\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.3325 - accuracy: 0.9733 - val_loss: 0.4403 - val_accuracy: 0.9333\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3315 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9333\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 459us/sample - loss: 0.3315 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9333\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.3304 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9333\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3280 - accuracy: 0.9867 - val_loss: 0.4278 - val_accuracy: 0.9333\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.3283 - accuracy: 0.9733 - val_loss: 0.4400 - val_accuracy: 0.9333\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3290 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9333\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.3270 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9333\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.3258 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9333\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.3251 - accuracy: 0.9867 - val_loss: 0.4203 - val_accuracy: 0.9333\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.3248 - accuracy: 0.9733 - val_loss: 0.4320 - val_accuracy: 0.9333\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.3250 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9333\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 510us/sample - loss: 0.3265 - accuracy: 0.9733 - val_loss: 0.4213 - val_accuracy: 0.9333\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.3241 - accuracy: 0.9733 - val_loss: 0.4240 - val_accuracy: 0.9333\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.3241 - accuracy: 0.9867 - val_loss: 0.4247 - val_accuracy: 0.9333\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3233 - accuracy: 0.9733 - val_loss: 0.4372 - val_accuracy: 0.9333\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 0.3222 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9333\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.3211 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9333\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 0.3211 - accuracy: 0.9733 - val_loss: 0.4233 - val_accuracy: 0.9333\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.3204 - accuracy: 0.9733 - val_loss: 0.4262 - val_accuracy: 0.9333\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3195 - accuracy: 0.9867 - val_loss: 0.4264 - val_accuracy: 0.9333\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 0.3191 - accuracy: 0.9867 - val_loss: 0.4181 - val_accuracy: 0.9333\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.3196 - accuracy: 0.9733 - val_loss: 0.4215 - val_accuracy: 0.9333\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.3186 - accuracy: 0.9733 - val_loss: 0.4159 - val_accuracy: 0.9333\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.3204 - accuracy: 0.9733 - val_loss: 0.4206 - val_accuracy: 0.9333\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.3175 - accuracy: 0.9733 - val_loss: 0.4186 - val_accuracy: 0.9333\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.3166 - accuracy: 0.9733 - val_loss: 0.4235 - val_accuracy: 0.9333\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.3159 - accuracy: 0.9867 - val_loss: 0.4187 - val_accuracy: 0.9333\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.3171 - accuracy: 0.9733 - val_loss: 0.4124 - val_accuracy: 0.9333\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.3157 - accuracy: 0.9733 - val_loss: 0.4202 - val_accuracy: 0.9333\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.3144 - accuracy: 0.9733 - val_loss: 0.4301 - val_accuracy: 0.9333\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 464us/sample - loss: 0.3143 - accuracy: 0.9867 - val_loss: 0.4193 - val_accuracy: 0.9333\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.3135 - accuracy: 0.9733 - val_loss: 0.4219 - val_accuracy: 0.9333\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.3129 - accuracy: 0.9867 - val_loss: 0.4177 - val_accuracy: 0.9333\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.3135 - accuracy: 0.9733 - val_loss: 0.4305 - val_accuracy: 0.9333\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.3128 - accuracy: 0.9867 - val_loss: 0.4193 - val_accuracy: 0.9333\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.3114 - accuracy: 0.9733 - val_loss: 0.4206 - val_accuracy: 0.9333\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.3126 - accuracy: 0.9733 - val_loss: 0.4301 - val_accuracy: 0.9333\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.3102 - accuracy: 0.9867 - val_loss: 0.4299 - val_accuracy: 0.9333\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.3098 - accuracy: 0.9867 - val_loss: 0.4235 - val_accuracy: 0.9333\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3098 - accuracy: 0.9867 - val_loss: 0.4205 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.3113 - accuracy: 0.9733 - val_loss: 0.4135 - val_accuracy: 0.9333\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.3099 - accuracy: 0.9733 - val_loss: 0.4252 - val_accuracy: 0.9333\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.96 - 0s 397us/sample - loss: 0.3082 - accuracy: 0.9733 - val_loss: 0.4337 - val_accuracy: 0.9333\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 232us/sample - loss: 0.3077 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9333\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.3080 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9333\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.3077 - accuracy: 0.9867 - val_loss: 0.4254 - val_accuracy: 0.9333\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.3074 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 553us/sample - loss: 0.3073 - accuracy: 0.9867 - val_loss: 0.4117 - val_accuracy: 0.9333\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.3078 - accuracy: 0.9733 - val_loss: 0.4190 - val_accuracy: 0.9333\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.3058 - accuracy: 0.9733 - val_loss: 0.4275 - val_accuracy: 0.9333\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.3060 - accuracy: 0.9733 - val_loss: 0.4214 - val_accuracy: 0.9333\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.3054 - accuracy: 0.9733 - val_loss: 0.4352 - val_accuracy: 0.9333\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.3045 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.3050 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9333\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.3049 - accuracy: 0.9733 - val_loss: 0.4345 - val_accuracy: 0.9333\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3043 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9333\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.3034 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9333\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.3027 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9333\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.3030 - accuracy: 0.9867 - val_loss: 0.4240 - val_accuracy: 0.9333\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.3017 - accuracy: 0.9867 - val_loss: 0.4228 - val_accuracy: 0.9333\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.3016 - accuracy: 0.9867 - val_loss: 0.4291 - val_accuracy: 0.9333\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.3012 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9333\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.3013 - accuracy: 0.9867 - val_loss: 0.4279 - val_accuracy: 0.9333\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 473us/sample - loss: 0.3010 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9333\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 577us/sample - loss: 0.3013 - accuracy: 0.9733 - val_loss: 0.4230 - val_accuracy: 0.9333\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 470us/sample - loss: 0.2997 - accuracy: 0.9867 - val_loss: 0.4178 - val_accuracy: 0.9333\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3004 - accuracy: 0.9733 - val_loss: 0.4312 - val_accuracy: 0.9333\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.2991 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9333\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 442us/sample - loss: 0.2987 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9333\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.2980 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9333\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.2979 - accuracy: 0.9867 - val_loss: 0.4111 - val_accuracy: 0.9333\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.2977 - accuracy: 0.9733 - val_loss: 0.4126 - val_accuracy: 0.9333\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.2972 - accuracy: 0.9867 - val_loss: 0.4093 - val_accuracy: 0.9333\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.2968 - accuracy: 0.9733 - val_loss: 0.4201 - val_accuracy: 0.9333\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.2973 - accuracy: 0.9733 - val_loss: 0.4135 - val_accuracy: 0.9333\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 435us/sample - loss: 0.2974 - accuracy: 0.9733 - val_loss: 0.4145 - val_accuracy: 0.9333\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2968 - accuracy: 0.9733 - val_loss: 0.4115 - val_accuracy: 0.9333\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.2951 - accuracy: 0.9733 - val_loss: 0.4107 - val_accuracy: 0.9333\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.2950 - accuracy: 0.9733 - val_loss: 0.4100 - val_accuracy: 0.9333\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.2943 - accuracy: 0.9733 - val_loss: 0.4255 - val_accuracy: 0.9333\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.2938 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9333\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.2939 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9333\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.2943 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9333\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.2947 - accuracy: 0.9733 - val_loss: 0.4114 - val_accuracy: 0.9333\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.2949 - accuracy: 0.9733 - val_loss: 0.4089 - val_accuracy: 0.9333\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.2925 - accuracy: 0.9733 - val_loss: 0.4085 - val_accuracy: 0.9333\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2921 - accuracy: 0.9733 - val_loss: 0.4141 - val_accuracy: 0.9333\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.2911 - accuracy: 0.9867 - val_loss: 0.4227 - val_accuracy: 0.9333\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.2911 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9333\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.2906 - accuracy: 0.9733 - val_loss: 0.4289 - val_accuracy: 0.9333\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.2908 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9333\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.2906 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9333\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.2895 - accuracy: 0.9867 - val_loss: 0.4136 - val_accuracy: 0.9333\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.2893 - accuracy: 0.9867 - val_loss: 0.4157 - val_accuracy: 0.9333\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.2889 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9333\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.2890 - accuracy: 0.9733 - val_loss: 0.4108 - val_accuracy: 0.9333\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.2880 - accuracy: 0.9733 - val_loss: 0.4161 - val_accuracy: 0.9333\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.2877 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9333\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.2879 - accuracy: 0.9733 - val_loss: 0.4257 - val_accuracy: 0.9333\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.2871 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9333\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 446us/sample - loss: 0.2871 - accuracy: 0.9733 - val_loss: 0.4169 - val_accuracy: 0.9333\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2871 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9333\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.2861 - accuracy: 0.9733 - val_loss: 0.4199 - val_accuracy: 0.9333\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.2862 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9333\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.2853 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9333\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2859 - accuracy: 0.9733 - val_loss: 0.4124 - val_accuracy: 0.9333\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.2843 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9333\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2844 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9333\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.2843 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9333\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 0.2851 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9333\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 432us/sample - loss: 0.2850 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9333\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.2831 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9333\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.2830 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9333\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9333\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.2823 - accuracy: 0.9867 - val_loss: 0.4023 - val_accuracy: 0.9333\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.2821 - accuracy: 0.9733 - val_loss: 0.4115 - val_accuracy: 0.9333\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.2810 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9333\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.2825 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9333\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.2805 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.9333\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.2807 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9333\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.2821 - accuracy: 0.9733 - val_loss: 0.3988 - val_accuracy: 0.9333\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.2802 - accuracy: 0.9733 - val_loss: 0.4116 - val_accuracy: 0.9333\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.2794 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.9333\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9333\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9333\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.2792 - accuracy: 0.9867 - val_loss: 0.4264 - val_accuracy: 0.9333\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 417us/sample - loss: 0.2787 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9333\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 437us/sample - loss: 0.2782 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9333\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2772 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9333\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 397us/sample - loss: 0.2770 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9333\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.2771 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9333\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.2772 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9333\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 391us/sample - loss: 0.2770 - accuracy: 0.9867 - val_loss: 0.4244 - val_accuracy: 0.9333\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 389us/sample - loss: 0.2762 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9333\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9333\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.2758 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9333\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.2746 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9333\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.2742 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9333\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 443us/sample - loss: 0.2748 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9333\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.2761 - accuracy: 0.9867 - val_loss: 0.4126 - val_accuracy: 0.9333\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.2732 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9333\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.2728 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9333\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2725 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9333\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.2724 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9333\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9333\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9333\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.2709 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9333\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.2727 - accuracy: 0.9867 - val_loss: 0.4146 - val_accuracy: 0.9333\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9333\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.2726 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9333\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.2713 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.2700 - accuracy: 0.9867 - val_loss: 0.4116 - val_accuracy: 0.9333\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.2702 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9333\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9333\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.2686 - accuracy: 0.9867 - val_loss: 0.4088 - val_accuracy: 0.9333\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.2681 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9333\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.2681 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9333\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.2681 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Storlek på Neuralt Nätverk\n",
    "antal_hidden_layer = 3 # Djup\n",
    "antal_noder = 5 # Bredd per lager\n",
    "\n",
    "#Regulariseringsparametrar\n",
    "l1_reg_rate = 0.01\n",
    "l2_reg_rate = 0.01\n",
    "\n",
    "# Definiera forward propagation\n",
    "neural_network_model = Sequential()\n",
    "\n",
    "# Input lager \n",
    "neural_network_model.add(Dense(antal_noder, input_dim=4, activation='relu'))\n",
    "\n",
    "#Hidden lager\n",
    "for l in range(antal_hidden_layer):\n",
    "    neural_network_model.add(Dense(antal_noder, activation='relu', kernel_regularizer=L1L2(l1=l1_reg_rate, l2=l2_reg_rate)))\n",
    "\n",
    "#Output lager\n",
    "neural_network_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "neural_network_model.compile(optimizers='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "neural_network_model.summary()\n",
    "\n",
    "history = neural_network_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?\n",
    " - Löser regularisering vårt problem med överträning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  1.0\n",
      "accuracy, test:  0.93333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slutsats\n",
    "\n",
    "- I denna övning har vi utforskat likheterna mellan neurala nätverk och logistisk regression\n",
    "\n",
    "\n",
    "- Introducerat större neurala nätverk och de komplexa samband som kan hanteras mha icke-linjaritet\n",
    "\n",
    "\n",
    "- Utforskat vad som händer om du bygger för stort neuralt nätverk relativt till träningsdata\n",
    "\n",
    "\n",
    "- Redovisat att regularisering kan öka neurala nätverkets generaliserbarhet till test-datat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
