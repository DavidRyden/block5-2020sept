{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Kort om att gå från R till Python\n",
    "\n",
    "- Ni förväntas inte kunna skriva Python-kod, men ni kommer delvis känna igen arbetssättet från R\n",
    "\n",
    "\n",
    "- Python är likt R ett populärt open source-språk inom data science, det är bra att få en inblick även i detta språk\n",
    "\n",
    "\n",
    "\n",
    "- Vi kör koden i en \"Jupyter Notebook\", även det populärt inom Data Science. Notebooks stödjer både Python och R\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Python\n",
    "- \"General-purpose\" programmeringsspråk - data science bara ett applikationsområde\n",
    "- Förlåtande för nybörjare, men därav mer risk för implicita fel, ex, \"123\" * 3\n",
    "- Tacksamt att implementera, många data engineers kan python \n",
    "- TVINGAR dig att skriva prydligt, får felmeddelande utan korrekt indentering\n",
    "\n",
    "- Python har betydligt sämre paket för klassisk statistik och regression jämfört med R, regression i populära Scikitlearn ger inte ens p-värden\n",
    "\n",
    "\n",
    "#### R\n",
    "- Fokuserat och mer utvecklat för Statistisk programmering\n",
    "- Oförlåtande för nybörjare, mindre risk för implicita fel - exempelvis mean(x, na.rm=TRUE), beräkningar kan enbart göras på tillåtna datatyper\n",
    "- bättre för visualiseringar med ggplot2\n",
    "- Trevlig app och rapport-generering med knitr och Shiny\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Snabba exempel\n",
    "\n",
    "- \"<-\" i R ersätts med \"=\" i Python \n",
    "\n",
    "(precis som i R är \"==\" det man använder som lika med-tecken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Kör denna cell med \"Shift + Enter\"\n",
    "siffra_python = 1+2 \n",
    "print(siffra_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Förlåtande\n",
    "\n",
    "- Python är förlåtande för nybörjare, men därav mer risk för implicita fel, ex, \"123\" * 3 fungerar, men är inte en matematisk operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123123123\n"
     ]
    }
   ],
   "source": [
    "#Det går att multiplicera strängen \"123\" i python, men det är inte en matematisk operation\n",
    "strang_ggr_num = \"123\"*3\n",
    "print(strang_ggr_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prydlighet\n",
    "\n",
    "Nedan fungerar, det är korrekt med indenteringen efter både for och if-satsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Slut\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2]:\n",
    "    print(i)\n",
    "    if(i==2):\n",
    "        print(\"Slut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nedan fungerar inte, vi får IndentationError då vi inte indenterat efter if-satsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-4-95df71d784a5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-95df71d784a5>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print(\"Slut\")\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2]:\n",
    "    print(i)\n",
    "    if(i==2):\n",
    "    print(\"Slut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dokumentation av funktioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-874923e39036>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-874923e39036>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    strang_ggr_num.\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "strang_ggr_num = \"123\"*3\n",
    "\n",
    "#Placera markören efter punkten nedan, tryck sedan på tab-tangenten\n",
    "#Du ser nu vad för funktioner du kan använda\n",
    "strang_ggr_num.\n",
    "\n",
    "#Placera markören inne i parentesen, tryck \"shift + tab\"\n",
    "#Du ser nu dokumentation av funktionen\n",
    "strang_ggr_num.isdigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Övning 1: Enkel logistisk modell\n",
    "\n",
    "I denna övning testar vi att göra en enkel logistisk modell utifrån Iris-datasetet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importera bibliotek\n",
    "\n",
    "Vi importerar de python-bibliotek som vi behöver för att bearbeta vårt dataset\n",
    "\n",
    "- numpy används för matrisberäkningar, extremt vanligt att använda tillsammans med pandas\n",
    "- matplotlib för grafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hjälpfunktioner\n",
    "\n",
    "- Används senare för att plotta modellutvärdering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training():\n",
    "    \n",
    "    print(\"accuracy, train: \", history.history['accuracy'][-1])\n",
    "    print(\"accuracy, test: \", history.history['val_accuracy'][-1])\n",
    "    \n",
    "    # Credd : https://janakiev.com/notebooks/keras-iris/\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris-data med 2 klasser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import & preparering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vi importerar vid bibliotek från sklearn, ett mycket populärt bibiliotek för typiska funktioner inom data science\n",
    " \n",
    " - load_iris för att hämta iris-data\n",
    " - train_test_split för att enkelt dela upp data i train och test\n",
    " - Onehotencoder för att skapa target-variaber som är dummies\n",
    " - StandardScaler för att senare normalisera input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapreparering är importerad från : https://janakiev.com/notebooks/keras-iris/\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "#Bestämmer seed inför sampling\n",
    "seed = 444\n",
    "#Anger seed för tensorflow respektive numpy-beräkningar\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vi hämtar iris-datasetet som vi arbetat med tidigare\n",
    "\n",
    "- Vi har oberoende variablerna 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)' och 'petal width (cm)'\n",
    "- Vi vill klassificera om blomman är versicolor(Y=1) eller inte (Y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DavidRyden\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Hämtar iris-data\n",
    "iris = load_iris()\n",
    "X = iris['data'][0:100] # Hämta endast 100 observationer\n",
    "y = iris['target'][0:100]\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding (= skapar dummy-varibler)\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Standardiserar data till medelvärde 0 och varians 1 \n",
    "# Standardisering av värden hjälper neurala nätverk att konvergera\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Delar upp data i training och test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features : 4\n",
      "n_classes : 2\n",
      "\n",
      " Standardiserade features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      " [[-0.89430898  0.00209934 -0.94364311 -1.21994552]\n",
      " [ 0.35866332 -0.41776955  0.92838951  0.91406997]\n",
      " [-0.5810659   0.84183714 -1.01297765 -0.86427627]]\n",
      "\n",
      "Y (1=Versicolor) \n",
      " [[0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Vi delar upp data test i train och test\n",
    "X_train, X_test, Y_train_, Y_test_ = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "#Vi skapar variabler för antalet features och klasser, används till neurala nätverket\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "# Anpassa format för binär klassificering (1 target variabel)\n",
    "Y_train = Y_train_[:,1].reshape(50,1)\n",
    "Y_test = Y_test_[:,1].reshape(50,1)\n",
    "\n",
    "print(\"n_features : \" + str(n_features))\n",
    "print(\"n_classes : \" + str(n_classes))\n",
    "\n",
    "\n",
    "print( \"\\n Standardiserade features: \\n\",feature_names,\"\\n\",X_train[0:3])\n",
    "print (\"\\nY (1=Versicolor)\",\"\\n\", Y_train[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistisk regression (sigmoid aktivering)\n",
    "\n",
    "Vi skapar nu en logistisk regression med ett neuralt nätverk:\n",
    "\n",
    "- Vi använder \"tensorflow\" som \"backend\" till vårt neurala nätverk\n",
    "- Paketet \"keras\" som numera finns i tensorflow används som \"frontend\"\n",
    "\n",
    "- Vi skapar ett sekventiellt neuralt nätverk (funktionen \"Sequential()\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#Sekventiellt neuralt nätverk\n",
    "logistic_regression_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I vårt tomma sekventiella nätverk lägger vi till ett \"Dense\"/\"fully connected\" hidden layer:\n",
    "\n",
    "1. Detta lager tar 4 dimensoner som input (våra oberoende variabler)\n",
    "\n",
    "2. Ger 1 dimension output på mellan 0-1, efter sannolikhet att observationen är versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.add(Dense(1, input_dim=n_features, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I kompilering anger vi övriga val:\n",
    "- Optimizer = sgd (stochastic gradient descent:    theta(t+1) = theta(t) - learning_rate * gradient)\n",
    "- Loss-funktion = binary crossentropy, då vi har binär output-variabel\n",
    "- Den metric vi optimerar för är accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.compile(optimizers='sgd',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summering av vår skapade modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Träna modell\n",
    "\n",
    "Vi tränar modellen i 500 epoker med funktion fit()\n",
    "\n",
    "För varje epok ser vi hur loss och accuracy förändras på både vårt train och validation-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 50 samples\n",
      "Epoch 1/500\n",
      "50/50 [==============================] - 3s 56ms/sample - loss: 1.0067 - accuracy: 0.0000e+00 - val_loss: 1.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "50/50 [==============================] - 0s 369us/sample - loss: 0.9963 - accuracy: 0.0000e+00 - val_loss: 1.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "50/50 [==============================] - 0s 330us/sample - loss: 0.9891 - accuracy: 0.0000e+00 - val_loss: 1.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "50/50 [==============================] - 0s 427us/sample - loss: 0.9829 - accuracy: 0.0000e+00 - val_loss: 1.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "50/50 [==============================] - 0s 407us/sample - loss: 0.9774 - accuracy: 0.0000e+00 - val_loss: 0.9962 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "50/50 [==============================] - 0s 397us/sample - loss: 0.9724 - accuracy: 0.0000e+00 - val_loss: 0.9912 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "50/50 [==============================] - 0s 350us/sample - loss: 0.9674 - accuracy: 0.0000e+00 - val_loss: 0.9865 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "50/50 [==============================] - 0s 547us/sample - loss: 0.9629 - accuracy: 0.0000e+00 - val_loss: 0.9820 - val_accuracy: 0.0200\n",
      "Epoch 9/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.9584 - accuracy: 0.0200 - val_loss: 0.9775 - val_accuracy: 0.0200\n",
      "Epoch 10/500\n",
      "50/50 [==============================] - 0s 342us/sample - loss: 0.9540 - accuracy: 0.0200 - val_loss: 0.9731 - val_accuracy: 0.0200\n",
      "Epoch 11/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.9497 - accuracy: 0.0200 - val_loss: 0.9689 - val_accuracy: 0.0200\n",
      "Epoch 12/500\n",
      "50/50 [==============================] - 0s 324us/sample - loss: 0.9456 - accuracy: 0.0200 - val_loss: 0.9646 - val_accuracy: 0.0200\n",
      "Epoch 13/500\n",
      "50/50 [==============================] - 0s 351us/sample - loss: 0.9414 - accuracy: 0.0200 - val_loss: 0.9605 - val_accuracy: 0.0200\n",
      "Epoch 14/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.9373 - accuracy: 0.0200 - val_loss: 0.9564 - val_accuracy: 0.0200\n",
      "Epoch 15/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.9334 - accuracy: 0.0200 - val_loss: 0.9523 - val_accuracy: 0.0400\n",
      "Epoch 16/500\n",
      "50/50 [==============================] - 0s 330us/sample - loss: 0.9292 - accuracy: 0.0200 - val_loss: 0.9482 - val_accuracy: 0.0400\n",
      "Epoch 17/500\n",
      "50/50 [==============================] - 0s 358us/sample - loss: 0.9253 - accuracy: 0.0400 - val_loss: 0.9443 - val_accuracy: 0.0400\n",
      "Epoch 18/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.9214 - accuracy: 0.0400 - val_loss: 0.9404 - val_accuracy: 0.0400\n",
      "Epoch 19/500\n",
      "50/50 [==============================] - 0s 439us/sample - loss: 0.9176 - accuracy: 0.0400 - val_loss: 0.9363 - val_accuracy: 0.0400\n",
      "Epoch 20/500\n",
      "50/50 [==============================] - 0s 324us/sample - loss: 0.9137 - accuracy: 0.0400 - val_loss: 0.9324 - val_accuracy: 0.0400\n",
      "Epoch 21/500\n",
      "50/50 [==============================] - 0s 340us/sample - loss: 0.9098 - accuracy: 0.0400 - val_loss: 0.9284 - val_accuracy: 0.0400\n",
      "Epoch 22/500\n",
      "50/50 [==============================] - 0s 336us/sample - loss: 0.9059 - accuracy: 0.0400 - val_loss: 0.9244 - val_accuracy: 0.0400\n",
      "Epoch 23/500\n",
      "50/50 [==============================] - 0s 414us/sample - loss: 0.9020 - accuracy: 0.0400 - val_loss: 0.9205 - val_accuracy: 0.0400\n",
      "Epoch 24/500\n",
      "50/50 [==============================] - 0s 377us/sample - loss: 0.8982 - accuracy: 0.0400 - val_loss: 0.9166 - val_accuracy: 0.0400\n",
      "Epoch 25/500\n",
      "50/50 [==============================] - 0s 344us/sample - loss: 0.8944 - accuracy: 0.0600 - val_loss: 0.9128 - val_accuracy: 0.0400\n",
      "Epoch 26/500\n",
      "50/50 [==============================] - 0s 301us/sample - loss: 0.8906 - accuracy: 0.0800 - val_loss: 0.9089 - val_accuracy: 0.0600\n",
      "Epoch 27/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.8869 - accuracy: 0.1000 - val_loss: 0.9049 - val_accuracy: 0.0600\n",
      "Epoch 28/500\n",
      "50/50 [==============================] - 0s 323us/sample - loss: 0.8830 - accuracy: 0.1000 - val_loss: 0.9011 - val_accuracy: 0.0800\n",
      "Epoch 29/500\n",
      "50/50 [==============================] - 0s 383us/sample - loss: 0.8793 - accuracy: 0.1000 - val_loss: 0.8973 - val_accuracy: 0.0800\n",
      "Epoch 30/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.8755 - accuracy: 0.1000 - val_loss: 0.8934 - val_accuracy: 0.0800\n",
      "Epoch 31/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.8717 - accuracy: 0.1000 - val_loss: 0.8896 - val_accuracy: 0.0800\n",
      "Epoch 32/500\n",
      "50/50 [==============================] - 0s 323us/sample - loss: 0.8680 - accuracy: 0.1000 - val_loss: 0.8858 - val_accuracy: 0.1000\n",
      "Epoch 33/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.8645 - accuracy: 0.1400 - val_loss: 0.8819 - val_accuracy: 0.1000\n",
      "Epoch 34/500\n",
      "50/50 [==============================] - 0s 477us/sample - loss: 0.8607 - accuracy: 0.1600 - val_loss: 0.8781 - val_accuracy: 0.1000\n",
      "Epoch 35/500\n",
      "50/50 [==============================] - 0s 307us/sample - loss: 0.8570 - accuracy: 0.1600 - val_loss: 0.8743 - val_accuracy: 0.1000\n",
      "Epoch 36/500\n",
      "50/50 [==============================] - 0s 373us/sample - loss: 0.8533 - accuracy: 0.1800 - val_loss: 0.8704 - val_accuracy: 0.1000\n",
      "Epoch 37/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.8496 - accuracy: 0.1800 - val_loss: 0.8666 - val_accuracy: 0.1600\n",
      "Epoch 38/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.8460 - accuracy: 0.1800 - val_loss: 0.8629 - val_accuracy: 0.1800\n",
      "Epoch 39/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.8423 - accuracy: 0.1800 - val_loss: 0.8592 - val_accuracy: 0.2000\n",
      "Epoch 40/500\n",
      "50/50 [==============================] - 0s 301us/sample - loss: 0.8388 - accuracy: 0.2000 - val_loss: 0.8554 - val_accuracy: 0.2000\n",
      "Epoch 41/500\n",
      "50/50 [==============================] - 0s 368us/sample - loss: 0.8351 - accuracy: 0.2000 - val_loss: 0.8517 - val_accuracy: 0.2000\n",
      "Epoch 42/500\n",
      "50/50 [==============================] - 0s 317us/sample - loss: 0.8315 - accuracy: 0.2000 - val_loss: 0.8480 - val_accuracy: 0.2000\n",
      "Epoch 43/500\n",
      "50/50 [==============================] - 0s 331us/sample - loss: 0.8280 - accuracy: 0.2200 - val_loss: 0.8445 - val_accuracy: 0.2000\n",
      "Epoch 44/500\n",
      "50/50 [==============================] - 0s 302us/sample - loss: 0.8244 - accuracy: 0.2200 - val_loss: 0.8407 - val_accuracy: 0.2000\n",
      "Epoch 45/500\n",
      "50/50 [==============================] - 0s 390us/sample - loss: 0.8208 - accuracy: 0.2200 - val_loss: 0.8371 - val_accuracy: 0.2000\n",
      "Epoch 46/500\n",
      "50/50 [==============================] - 0s 331us/sample - loss: 0.8172 - accuracy: 0.2200 - val_loss: 0.8335 - val_accuracy: 0.2200\n",
      "Epoch 47/500\n",
      "50/50 [==============================] - 0s 437us/sample - loss: 0.8137 - accuracy: 0.2200 - val_loss: 0.8299 - val_accuracy: 0.2400\n",
      "Epoch 48/500\n",
      "50/50 [==============================] - 0s 549us/sample - loss: 0.8102 - accuracy: 0.2400 - val_loss: 0.8264 - val_accuracy: 0.2600\n",
      "Epoch 49/500\n",
      "50/50 [==============================] - 0s 430us/sample - loss: 0.8066 - accuracy: 0.2600 - val_loss: 0.8227 - val_accuracy: 0.2800\n",
      "Epoch 50/500\n",
      "50/50 [==============================] - 0s 438us/sample - loss: 0.8031 - accuracy: 0.2600 - val_loss: 0.8191 - val_accuracy: 0.2800\n",
      "Epoch 51/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.7996 - accuracy: 0.2600 - val_loss: 0.8154 - val_accuracy: 0.2800\n",
      "Epoch 52/500\n",
      "50/50 [==============================] - 0s 345us/sample - loss: 0.7961 - accuracy: 0.2600 - val_loss: 0.8118 - val_accuracy: 0.2800\n",
      "Epoch 53/500\n",
      "50/50 [==============================] - 0s 326us/sample - loss: 0.7926 - accuracy: 0.2600 - val_loss: 0.8083 - val_accuracy: 0.2800\n",
      "Epoch 54/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.7891 - accuracy: 0.2600 - val_loss: 0.8048 - val_accuracy: 0.2800\n",
      "Epoch 55/500\n",
      "50/50 [==============================] - 0s 327us/sample - loss: 0.7856 - accuracy: 0.2600 - val_loss: 0.8012 - val_accuracy: 0.2800\n",
      "Epoch 56/500\n",
      "50/50 [==============================] - 0s 337us/sample - loss: 0.7823 - accuracy: 0.2600 - val_loss: 0.7978 - val_accuracy: 0.2800\n",
      "Epoch 57/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.7789 - accuracy: 0.2600 - val_loss: 0.7944 - val_accuracy: 0.2800\n",
      "Epoch 58/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.7754 - accuracy: 0.2600 - val_loss: 0.7908 - val_accuracy: 0.2800\n",
      "Epoch 59/500\n",
      "50/50 [==============================] - 0s 466us/sample - loss: 0.7720 - accuracy: 0.2600 - val_loss: 0.7874 - val_accuracy: 0.3000\n",
      "Epoch 60/500\n",
      "50/50 [==============================] - 0s 327us/sample - loss: 0.7686 - accuracy: 0.2800 - val_loss: 0.7839 - val_accuracy: 0.3000\n",
      "Epoch 61/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.7652 - accuracy: 0.2800 - val_loss: 0.7804 - val_accuracy: 0.3000\n",
      "Epoch 62/500\n",
      "50/50 [==============================] - 0s 340us/sample - loss: 0.7618 - accuracy: 0.3000 - val_loss: 0.7770 - val_accuracy: 0.3200\n",
      "Epoch 63/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.7586 - accuracy: 0.3200 - val_loss: 0.7735 - val_accuracy: 0.3400\n",
      "Epoch 64/500\n",
      "50/50 [==============================] - 0s 328us/sample - loss: 0.7551 - accuracy: 0.3200 - val_loss: 0.7700 - val_accuracy: 0.3400\n",
      "Epoch 65/500\n",
      "50/50 [==============================] - 0s 337us/sample - loss: 0.7518 - accuracy: 0.3200 - val_loss: 0.7667 - val_accuracy: 0.3600\n",
      "Epoch 66/500\n",
      "50/50 [==============================] - 0s 373us/sample - loss: 0.7485 - accuracy: 0.3200 - val_loss: 0.7633 - val_accuracy: 0.3600\n",
      "Epoch 67/500\n",
      "50/50 [==============================] - 0s 339us/sample - loss: 0.7452 - accuracy: 0.3200 - val_loss: 0.7599 - val_accuracy: 0.3800\n",
      "Epoch 68/500\n",
      "50/50 [==============================] - 0s 327us/sample - loss: 0.7419 - accuracy: 0.3200 - val_loss: 0.7565 - val_accuracy: 0.3800\n",
      "Epoch 69/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.7387 - accuracy: 0.3400 - val_loss: 0.7531 - val_accuracy: 0.3800\n",
      "Epoch 70/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.7354 - accuracy: 0.3400 - val_loss: 0.7497 - val_accuracy: 0.3800\n",
      "Epoch 71/500\n",
      "50/50 [==============================] - 0s 411us/sample - loss: 0.7322 - accuracy: 0.3600 - val_loss: 0.7463 - val_accuracy: 0.3800\n",
      "Epoch 72/500\n",
      "50/50 [==============================] - 0s 296us/sample - loss: 0.7290 - accuracy: 0.3600 - val_loss: 0.7430 - val_accuracy: 0.4000\n",
      "Epoch 73/500\n",
      "50/50 [==============================] - 0s 329us/sample - loss: 0.7257 - accuracy: 0.3600 - val_loss: 0.7395 - val_accuracy: 0.4000\n",
      "Epoch 74/500\n",
      "50/50 [==============================] - 0s 302us/sample - loss: 0.7223 - accuracy: 0.3600 - val_loss: 0.7361 - val_accuracy: 0.4200\n",
      "Epoch 75/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.7191 - accuracy: 0.3600 - val_loss: 0.7328 - val_accuracy: 0.4200\n",
      "Epoch 76/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.7159 - accuracy: 0.3800 - val_loss: 0.7295 - val_accuracy: 0.4200\n",
      "Epoch 77/500\n",
      "50/50 [==============================] - 0s 381us/sample - loss: 0.7128 - accuracy: 0.3800 - val_loss: 0.7262 - val_accuracy: 0.4200\n",
      "Epoch 78/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.7095 - accuracy: 0.3800 - val_loss: 0.7229 - val_accuracy: 0.4600\n",
      "Epoch 79/500\n",
      "50/50 [==============================] - 0s 364us/sample - loss: 0.7065 - accuracy: 0.3800 - val_loss: 0.7195 - val_accuracy: 0.4600\n",
      "Epoch 80/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.7032 - accuracy: 0.4000 - val_loss: 0.7163 - val_accuracy: 0.4800\n",
      "Epoch 81/500\n",
      "50/50 [==============================] - 0s 315us/sample - loss: 0.7001 - accuracy: 0.4200 - val_loss: 0.7130 - val_accuracy: 0.4800\n",
      "Epoch 82/500\n",
      "50/50 [==============================] - 0s 373us/sample - loss: 0.6970 - accuracy: 0.4200 - val_loss: 0.7097 - val_accuracy: 0.4800\n",
      "Epoch 83/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.6939 - accuracy: 0.4200 - val_loss: 0.7066 - val_accuracy: 0.4800\n",
      "Epoch 84/500\n",
      "50/50 [==============================] - 0s 567us/sample - loss: 0.6908 - accuracy: 0.4400 - val_loss: 0.7033 - val_accuracy: 0.4800\n",
      "Epoch 85/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.6878 - accuracy: 0.4400 - val_loss: 0.7000 - val_accuracy: 0.4800\n",
      "Epoch 86/500\n",
      "50/50 [==============================] - 0s 294us/sample - loss: 0.6846 - accuracy: 0.4400 - val_loss: 0.6967 - val_accuracy: 0.4800\n",
      "Epoch 87/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.6815 - accuracy: 0.4400 - val_loss: 0.6936 - val_accuracy: 0.4800\n",
      "Epoch 88/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.6785 - accuracy: 0.4600 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 89/500\n",
      "50/50 [==============================] - 0s 307us/sample - loss: 0.6755 - accuracy: 0.4800 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 90/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.6724 - accuracy: 0.5200 - val_loss: 0.6842 - val_accuracy: 0.5000\n",
      "Epoch 91/500\n",
      "50/50 [==============================] - 0s 442us/sample - loss: 0.6694 - accuracy: 0.5200 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
      "Epoch 92/500\n",
      "50/50 [==============================] - 0s 435us/sample - loss: 0.6664 - accuracy: 0.5600 - val_loss: 0.6780 - val_accuracy: 0.5400\n",
      "Epoch 93/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.6634 - accuracy: 0.5800 - val_loss: 0.6749 - val_accuracy: 0.5400\n",
      "Epoch 94/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.6604 - accuracy: 0.5800 - val_loss: 0.6718 - val_accuracy: 0.5600\n",
      "Epoch 95/500\n",
      "50/50 [==============================] - 0s 392us/sample - loss: 0.6574 - accuracy: 0.5800 - val_loss: 0.6687 - val_accuracy: 0.5600\n",
      "Epoch 96/500\n",
      "50/50 [==============================] - 0s 321us/sample - loss: 0.6544 - accuracy: 0.5800 - val_loss: 0.6657 - val_accuracy: 0.5600\n",
      "Epoch 97/500\n",
      "50/50 [==============================] - 0s 336us/sample - loss: 0.6514 - accuracy: 0.5800 - val_loss: 0.6626 - val_accuracy: 0.5800\n",
      "Epoch 98/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.6485 - accuracy: 0.5800 - val_loss: 0.6595 - val_accuracy: 0.5800\n",
      "Epoch 99/500\n",
      "50/50 [==============================] - 0s 440us/sample - loss: 0.6456 - accuracy: 0.6000 - val_loss: 0.6566 - val_accuracy: 0.5800\n",
      "Epoch 100/500\n",
      "50/50 [==============================] - 0s 377us/sample - loss: 0.6426 - accuracy: 0.6200 - val_loss: 0.6535 - val_accuracy: 0.6200\n",
      "Epoch 101/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.6397 - accuracy: 0.6200 - val_loss: 0.6505 - val_accuracy: 0.6200\n",
      "Epoch 102/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.6368 - accuracy: 0.6400 - val_loss: 0.6476 - val_accuracy: 0.6200\n",
      "Epoch 103/500\n",
      "50/50 [==============================] - 0s 328us/sample - loss: 0.6340 - accuracy: 0.6400 - val_loss: 0.6447 - val_accuracy: 0.6200\n",
      "Epoch 104/500\n",
      "50/50 [==============================] - 0s 299us/sample - loss: 0.6311 - accuracy: 0.6400 - val_loss: 0.6416 - val_accuracy: 0.6200\n",
      "Epoch 105/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.6282 - accuracy: 0.6400 - val_loss: 0.6387 - val_accuracy: 0.6200\n",
      "Epoch 106/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.6253 - accuracy: 0.6400 - val_loss: 0.6357 - val_accuracy: 0.6200\n",
      "Epoch 107/500\n",
      "50/50 [==============================] - 0s 384us/sample - loss: 0.6224 - accuracy: 0.6800 - val_loss: 0.6328 - val_accuracy: 0.6200\n",
      "Epoch 108/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.6196 - accuracy: 0.7000 - val_loss: 0.6299 - val_accuracy: 0.6400\n",
      "Epoch 109/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.6167 - accuracy: 0.7000 - val_loss: 0.6270 - val_accuracy: 0.6600\n",
      "Epoch 110/500\n",
      "50/50 [==============================] - 0s 373us/sample - loss: 0.6139 - accuracy: 0.7000 - val_loss: 0.6240 - val_accuracy: 0.7000\n",
      "Epoch 111/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.6111 - accuracy: 0.7400 - val_loss: 0.6210 - val_accuracy: 0.7000\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 389us/sample - loss: 0.6082 - accuracy: 0.7400 - val_loss: 0.6182 - val_accuracy: 0.7000\n",
      "Epoch 113/500\n",
      "50/50 [==============================] - 0s 544us/sample - loss: 0.6055 - accuracy: 0.7400 - val_loss: 0.6153 - val_accuracy: 0.7000\n",
      "Epoch 114/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.6027 - accuracy: 0.7600 - val_loss: 0.6125 - val_accuracy: 0.7000\n",
      "Epoch 115/500\n",
      "50/50 [==============================] - 0s 412us/sample - loss: 0.6000 - accuracy: 0.7600 - val_loss: 0.6097 - val_accuracy: 0.7000\n",
      "Epoch 116/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.5972 - accuracy: 0.7600 - val_loss: 0.6068 - val_accuracy: 0.7000\n",
      "Epoch 117/500\n",
      "50/50 [==============================] - 0s 487us/sample - loss: 0.5944 - accuracy: 0.7600 - val_loss: 0.6041 - val_accuracy: 0.7000\n",
      "Epoch 118/500\n",
      "50/50 [==============================] - 0s 390us/sample - loss: 0.5917 - accuracy: 0.7600 - val_loss: 0.6012 - val_accuracy: 0.7000\n",
      "Epoch 119/500\n",
      "50/50 [==============================] - 0s 371us/sample - loss: 0.5890 - accuracy: 0.7600 - val_loss: 0.5983 - val_accuracy: 0.7200\n",
      "Epoch 120/500\n",
      "50/50 [==============================] - 0s 347us/sample - loss: 0.5862 - accuracy: 0.7800 - val_loss: 0.5954 - val_accuracy: 0.7200\n",
      "Epoch 121/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.5835 - accuracy: 0.7800 - val_loss: 0.5926 - val_accuracy: 0.7400\n",
      "Epoch 122/500\n",
      "50/50 [==============================] - 0s 349us/sample - loss: 0.5809 - accuracy: 0.8000 - val_loss: 0.5899 - val_accuracy: 0.7400\n",
      "Epoch 123/500\n",
      "50/50 [==============================] - 0s 303us/sample - loss: 0.5781 - accuracy: 0.8000 - val_loss: 0.5870 - val_accuracy: 0.7400\n",
      "Epoch 124/500\n",
      "50/50 [==============================] - 0s 354us/sample - loss: 0.5754 - accuracy: 0.8200 - val_loss: 0.5842 - val_accuracy: 0.7400\n",
      "Epoch 125/500\n",
      "50/50 [==============================] - 0s 326us/sample - loss: 0.5728 - accuracy: 0.8200 - val_loss: 0.5815 - val_accuracy: 0.7600\n",
      "Epoch 126/500\n",
      "50/50 [==============================] - 0s 368us/sample - loss: 0.5702 - accuracy: 0.8400 - val_loss: 0.5789 - val_accuracy: 0.7800\n",
      "Epoch 127/500\n",
      "50/50 [==============================] - 0s 394us/sample - loss: 0.5675 - accuracy: 0.8400 - val_loss: 0.5761 - val_accuracy: 0.7800\n",
      "Epoch 128/500\n",
      "50/50 [==============================] - 0s 419us/sample - loss: 0.5649 - accuracy: 0.8400 - val_loss: 0.5732 - val_accuracy: 0.7800\n",
      "Epoch 129/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.5623 - accuracy: 0.8400 - val_loss: 0.5704 - val_accuracy: 0.8000\n",
      "Epoch 130/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.5596 - accuracy: 0.8400 - val_loss: 0.5676 - val_accuracy: 0.8000\n",
      "Epoch 131/500\n",
      "50/50 [==============================] - 0s 302us/sample - loss: 0.5570 - accuracy: 0.8400 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 132/500\n",
      "50/50 [==============================] - 0s 298us/sample - loss: 0.5544 - accuracy: 0.8400 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 133/500\n",
      "50/50 [==============================] - 0s 323us/sample - loss: 0.5518 - accuracy: 0.8400 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 134/500\n",
      "50/50 [==============================] - 0s 424us/sample - loss: 0.5493 - accuracy: 0.8400 - val_loss: 0.5566 - val_accuracy: 0.8400\n",
      "Epoch 135/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.5467 - accuracy: 0.8400 - val_loss: 0.5540 - val_accuracy: 0.8400\n",
      "Epoch 136/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.5442 - accuracy: 0.8400 - val_loss: 0.5515 - val_accuracy: 0.8400\n",
      "Epoch 137/500\n",
      "50/50 [==============================] - 0s 341us/sample - loss: 0.5417 - accuracy: 0.8600 - val_loss: 0.5489 - val_accuracy: 0.8600\n",
      "Epoch 138/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.5392 - accuracy: 0.8600 - val_loss: 0.5463 - val_accuracy: 0.8600\n",
      "Epoch 139/500\n",
      "50/50 [==============================] - 0s 321us/sample - loss: 0.5367 - accuracy: 0.8600 - val_loss: 0.5437 - val_accuracy: 0.9000\n",
      "Epoch 140/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.5342 - accuracy: 0.8600 - val_loss: 0.5410 - val_accuracy: 0.9000\n",
      "Epoch 141/500\n",
      "50/50 [==============================] - 0s 340us/sample - loss: 0.5317 - accuracy: 0.8600 - val_loss: 0.5385 - val_accuracy: 0.9000\n",
      "Epoch 142/500\n",
      "50/50 [==============================] - 0s 395us/sample - loss: 0.5292 - accuracy: 0.8600 - val_loss: 0.5359 - val_accuracy: 0.9000\n",
      "Epoch 143/500\n",
      "50/50 [==============================] - 0s 481us/sample - loss: 0.5267 - accuracy: 0.8600 - val_loss: 0.5333 - val_accuracy: 0.9000\n",
      "Epoch 144/500\n",
      "50/50 [==============================] - 0s 404us/sample - loss: 0.5242 - accuracy: 0.8600 - val_loss: 0.5308 - val_accuracy: 0.9000\n",
      "Epoch 145/500\n",
      "50/50 [==============================] - 0s 324us/sample - loss: 0.5218 - accuracy: 0.8600 - val_loss: 0.5281 - val_accuracy: 0.9000\n",
      "Epoch 146/500\n",
      "50/50 [==============================] - 0s 357us/sample - loss: 0.5193 - accuracy: 0.8600 - val_loss: 0.5256 - val_accuracy: 0.9000\n",
      "Epoch 147/500\n",
      "50/50 [==============================] - 0s 400us/sample - loss: 0.5169 - accuracy: 0.8800 - val_loss: 0.5231 - val_accuracy: 0.9000\n",
      "Epoch 148/500\n",
      "50/50 [==============================] - 0s 346us/sample - loss: 0.5145 - accuracy: 0.9200 - val_loss: 0.5206 - val_accuracy: 0.9000\n",
      "Epoch 149/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.5121 - accuracy: 0.9200 - val_loss: 0.5181 - val_accuracy: 0.9000\n",
      "Epoch 150/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.5098 - accuracy: 0.9200 - val_loss: 0.5157 - val_accuracy: 0.9000\n",
      "Epoch 151/500\n",
      "50/50 [==============================] - 0s 423us/sample - loss: 0.5074 - accuracy: 0.9200 - val_loss: 0.5132 - val_accuracy: 0.9000\n",
      "Epoch 152/500\n",
      "50/50 [==============================] - 0s 545us/sample - loss: 0.5050 - accuracy: 0.9200 - val_loss: 0.5107 - val_accuracy: 0.9000\n",
      "Epoch 153/500\n",
      "50/50 [==============================] - 0s 387us/sample - loss: 0.5026 - accuracy: 0.9200 - val_loss: 0.5081 - val_accuracy: 0.9000\n",
      "Epoch 154/500\n",
      "50/50 [==============================] - 0s 369us/sample - loss: 0.5002 - accuracy: 0.9400 - val_loss: 0.5056 - val_accuracy: 0.9000\n",
      "Epoch 155/500\n",
      "50/50 [==============================] - 0s 321us/sample - loss: 0.4978 - accuracy: 0.9600 - val_loss: 0.5031 - val_accuracy: 0.9000\n",
      "Epoch 156/500\n",
      "50/50 [==============================] - 0s 399us/sample - loss: 0.4955 - accuracy: 0.9600 - val_loss: 0.5006 - val_accuracy: 0.9000\n",
      "Epoch 157/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.4931 - accuracy: 0.9600 - val_loss: 0.4982 - val_accuracy: 0.9000\n",
      "Epoch 158/500\n",
      "50/50 [==============================] - 0s 336us/sample - loss: 0.4908 - accuracy: 0.9600 - val_loss: 0.4958 - val_accuracy: 0.9000\n",
      "Epoch 159/500\n",
      "50/50 [==============================] - 0s 324us/sample - loss: 0.4885 - accuracy: 0.9600 - val_loss: 0.4934 - val_accuracy: 0.9000\n",
      "Epoch 160/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.4862 - accuracy: 0.9600 - val_loss: 0.4911 - val_accuracy: 0.9000\n",
      "Epoch 161/500\n",
      "50/50 [==============================] - 0s 371us/sample - loss: 0.4840 - accuracy: 0.9600 - val_loss: 0.4888 - val_accuracy: 0.9000\n",
      "Epoch 162/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.4817 - accuracy: 0.9600 - val_loss: 0.4864 - val_accuracy: 0.9200\n",
      "Epoch 163/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.4794 - accuracy: 0.9600 - val_loss: 0.4841 - val_accuracy: 0.9200\n",
      "Epoch 164/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.4771 - accuracy: 0.9600 - val_loss: 0.4816 - val_accuracy: 0.9200\n",
      "Epoch 165/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.4748 - accuracy: 0.9600 - val_loss: 0.4793 - val_accuracy: 0.9200\n",
      "Epoch 166/500\n",
      "50/50 [==============================] - 0s 428us/sample - loss: 0.4726 - accuracy: 0.9600 - val_loss: 0.4770 - val_accuracy: 0.9200\n",
      "Epoch 167/500\n",
      "50/50 [==============================] - 0s 393us/sample - loss: 0.4705 - accuracy: 0.9600 - val_loss: 0.4747 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "50/50 [==============================] - 0s 330us/sample - loss: 0.4681 - accuracy: 0.9600 - val_loss: 0.4723 - val_accuracy: 0.9200\n",
      "Epoch 169/500\n",
      "50/50 [==============================] - 0s 337us/sample - loss: 0.4659 - accuracy: 0.9600 - val_loss: 0.4699 - val_accuracy: 0.9200\n",
      "Epoch 170/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.4637 - accuracy: 0.9600 - val_loss: 0.4676 - val_accuracy: 0.9200\n",
      "Epoch 171/500\n",
      "50/50 [==============================] - 0s 378us/sample - loss: 0.4616 - accuracy: 0.9600 - val_loss: 0.4652 - val_accuracy: 0.9200\n",
      "Epoch 172/500\n",
      "50/50 [==============================] - 0s 398us/sample - loss: 0.4593 - accuracy: 0.9600 - val_loss: 0.4628 - val_accuracy: 0.9200\n",
      "Epoch 173/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.4572 - accuracy: 0.9600 - val_loss: 0.4606 - val_accuracy: 0.9200\n",
      "Epoch 174/500\n",
      "50/50 [==============================] - 0s 369us/sample - loss: 0.4550 - accuracy: 0.9600 - val_loss: 0.4583 - val_accuracy: 0.9200\n",
      "Epoch 175/500\n",
      "50/50 [==============================] - 0s 432us/sample - loss: 0.4529 - accuracy: 0.9600 - val_loss: 0.4561 - val_accuracy: 0.9400\n",
      "Epoch 176/500\n",
      "50/50 [==============================] - 0s 356us/sample - loss: 0.4507 - accuracy: 0.9600 - val_loss: 0.4538 - val_accuracy: 0.9400\n",
      "Epoch 177/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.4487 - accuracy: 0.9600 - val_loss: 0.4516 - val_accuracy: 0.9400\n",
      "Epoch 178/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.4465 - accuracy: 0.9600 - val_loss: 0.4494 - val_accuracy: 0.9400\n",
      "Epoch 179/500\n",
      "50/50 [==============================] - 0s 422us/sample - loss: 0.4443 - accuracy: 0.9600 - val_loss: 0.4471 - val_accuracy: 0.9400\n",
      "Epoch 180/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.4423 - accuracy: 0.9600 - val_loss: 0.4450 - val_accuracy: 0.9400\n",
      "Epoch 181/500\n",
      "50/50 [==============================] - 0s 427us/sample - loss: 0.4401 - accuracy: 0.9600 - val_loss: 0.4428 - val_accuracy: 0.9400\n",
      "Epoch 182/500\n",
      "50/50 [==============================] - 0s 447us/sample - loss: 0.4381 - accuracy: 0.9600 - val_loss: 0.4406 - val_accuracy: 0.9400\n",
      "Epoch 183/500\n",
      "50/50 [==============================] - 0s 384us/sample - loss: 0.4360 - accuracy: 0.9600 - val_loss: 0.4385 - val_accuracy: 0.9400\n",
      "Epoch 184/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.4339 - accuracy: 0.9600 - val_loss: 0.4364 - val_accuracy: 0.9400\n",
      "Epoch 185/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.4319 - accuracy: 0.9600 - val_loss: 0.4342 - val_accuracy: 0.9400\n",
      "Epoch 186/500\n",
      "50/50 [==============================] - 0s 319us/sample - loss: 0.4298 - accuracy: 0.9600 - val_loss: 0.4320 - val_accuracy: 0.9400\n",
      "Epoch 187/500\n",
      "50/50 [==============================] - 0s 381us/sample - loss: 0.4278 - accuracy: 0.9600 - val_loss: 0.4299 - val_accuracy: 0.9400\n",
      "Epoch 188/500\n",
      "50/50 [==============================] - 0s 460us/sample - loss: 0.4257 - accuracy: 0.9600 - val_loss: 0.4279 - val_accuracy: 0.9400\n",
      "Epoch 189/500\n",
      "50/50 [==============================] - 0s 310us/sample - loss: 0.4237 - accuracy: 0.9600 - val_loss: 0.4257 - val_accuracy: 0.9400\n",
      "Epoch 190/500\n",
      "50/50 [==============================] - 0s 364us/sample - loss: 0.4217 - accuracy: 0.9600 - val_loss: 0.4235 - val_accuracy: 0.9400\n",
      "Epoch 191/500\n",
      "50/50 [==============================] - 0s 305us/sample - loss: 0.4196 - accuracy: 0.9600 - val_loss: 0.4214 - val_accuracy: 0.9400\n",
      "Epoch 192/500\n",
      "50/50 [==============================] - 0s 358us/sample - loss: 0.4177 - accuracy: 0.9600 - val_loss: 0.4194 - val_accuracy: 0.9400\n",
      "Epoch 193/500\n",
      "50/50 [==============================] - 0s 377us/sample - loss: 0.4157 - accuracy: 0.9600 - val_loss: 0.4172 - val_accuracy: 0.9600\n",
      "Epoch 194/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.4136 - accuracy: 0.9600 - val_loss: 0.4151 - val_accuracy: 0.9600\n",
      "Epoch 195/500\n",
      "50/50 [==============================] - 0s 354us/sample - loss: 0.4116 - accuracy: 0.9600 - val_loss: 0.4129 - val_accuracy: 0.9600\n",
      "Epoch 196/500\n",
      "50/50 [==============================] - 0s 393us/sample - loss: 0.4097 - accuracy: 0.9600 - val_loss: 0.4109 - val_accuracy: 0.9600\n",
      "Epoch 197/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.4078 - accuracy: 0.9600 - val_loss: 0.4088 - val_accuracy: 0.9600\n",
      "Epoch 198/500\n",
      "50/50 [==============================] - 0s 354us/sample - loss: 0.4058 - accuracy: 0.9600 - val_loss: 0.4067 - val_accuracy: 0.9600\n",
      "Epoch 199/500\n",
      "50/50 [==============================] - 0s 325us/sample - loss: 0.4039 - accuracy: 0.9600 - val_loss: 0.4047 - val_accuracy: 0.9600\n",
      "Epoch 200/500\n",
      "50/50 [==============================] - 0s 463us/sample - loss: 0.4020 - accuracy: 0.9600 - val_loss: 0.4027 - val_accuracy: 0.9600\n",
      "Epoch 201/500\n",
      "50/50 [==============================] - 0s 443us/sample - loss: 0.4000 - accuracy: 0.9600 - val_loss: 0.4007 - val_accuracy: 0.9600\n",
      "Epoch 202/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.3981 - accuracy: 0.9600 - val_loss: 0.3987 - val_accuracy: 0.9600\n",
      "Epoch 203/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.3962 - accuracy: 0.9800 - val_loss: 0.3967 - val_accuracy: 0.9800\n",
      "Epoch 204/500\n",
      "50/50 [==============================] - 0s 357us/sample - loss: 0.3943 - accuracy: 0.9800 - val_loss: 0.3946 - val_accuracy: 0.9800\n",
      "Epoch 205/500\n",
      "50/50 [==============================] - 0s 678us/sample - loss: 0.3924 - accuracy: 0.9800 - val_loss: 0.3926 - val_accuracy: 0.9800\n",
      "Epoch 206/500\n",
      "50/50 [==============================] - 0s 477us/sample - loss: 0.3906 - accuracy: 0.9800 - val_loss: 0.3906 - val_accuracy: 0.9800\n",
      "Epoch 207/500\n",
      "50/50 [==============================] - 0s 356us/sample - loss: 0.3887 - accuracy: 0.9800 - val_loss: 0.3887 - val_accuracy: 0.9800\n",
      "Epoch 208/500\n",
      "50/50 [==============================] - 0s 328us/sample - loss: 0.3868 - accuracy: 0.9800 - val_loss: 0.3867 - val_accuracy: 0.9800\n",
      "Epoch 209/500\n",
      "50/50 [==============================] - 0s 349us/sample - loss: 0.3850 - accuracy: 0.9800 - val_loss: 0.3848 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "50/50 [==============================] - 0s 330us/sample - loss: 0.3831 - accuracy: 0.9800 - val_loss: 0.3828 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "50/50 [==============================] - 0s 350us/sample - loss: 0.3813 - accuracy: 0.9800 - val_loss: 0.3809 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "50/50 [==============================] - 0s 325us/sample - loss: 0.3795 - accuracy: 0.9800 - val_loss: 0.3790 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "50/50 [==============================] - 0s 577us/sample - loss: 0.3776 - accuracy: 0.9800 - val_loss: 0.3771 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.3758 - accuracy: 0.9800 - val_loss: 0.3753 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.3740 - accuracy: 0.9800 - val_loss: 0.3733 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.3722 - accuracy: 0.9800 - val_loss: 0.3714 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.3704 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "50/50 [==============================] - 0s 308us/sample - loss: 0.3686 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "50/50 [==============================] - 0s 347us/sample - loss: 0.3669 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "50/50 [==============================] - 0s 441us/sample - loss: 0.3650 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.3633 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.3616 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "50/50 [==============================] - 0s 337us/sample - loss: 0.3599 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "50/50 [==============================] - 0s 485us/sample - loss: 0.3581 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.3563 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "50/50 [==============================] - 0s 326us/sample - loss: 0.3529 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.3513 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.3495 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "50/50 [==============================] - 0s 322us/sample - loss: 0.3478 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "50/50 [==============================] - 0s 299us/sample - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.3445 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.3428 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "50/50 [==============================] - 0s 336us/sample - loss: 0.3411 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.3395 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.3378 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "50/50 [==============================] - 0s 325us/sample - loss: 0.3362 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "50/50 [==============================] - 0s 321us/sample - loss: 0.3346 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "50/50 [==============================] - 0s 361us/sample - loss: 0.3330 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.3314 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 1.00 - 0s 330us/sample - loss: 0.3298 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "50/50 [==============================] - 0s 391us/sample - loss: 0.3282 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "50/50 [==============================] - 0s 361us/sample - loss: 0.3266 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "50/50 [==============================] - 0s 399us/sample - loss: 0.3250 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.3234 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.3219 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "50/50 [==============================] - 0s 379us/sample - loss: 0.3203 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.3188 - accuracy: 1.0000 - val_loss: 0.3148 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.3173 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "50/50 [==============================] - 0s 406us/sample - loss: 0.3157 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "50/50 [==============================] - 0s 315us/sample - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.3127 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "50/50 [==============================] - 0s 317us/sample - loss: 0.3112 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "50/50 [==============================] - 0s 415us/sample - loss: 0.3081 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "50/50 [==============================] - 0s 312us/sample - loss: 0.3066 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.3051 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.3037 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.3022 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "50/50 [==============================] - 0s 399us/sample - loss: 0.3007 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "50/50 [==============================] - 0s 392us/sample - loss: 0.2993 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "50/50 [==============================] - 0s 377us/sample - loss: 0.2979 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "50/50 [==============================] - 0s 503us/sample - loss: 0.2964 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "50/50 [==============================] - 0s 404us/sample - loss: 0.2950 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "50/50 [==============================] - 0s 452us/sample - loss: 0.2935 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.2921 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "50/50 [==============================] - 0s 395us/sample - loss: 0.2907 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "50/50 [==============================] - 0s 364us/sample - loss: 0.2892 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "50/50 [==============================] - 0s 361us/sample - loss: 0.2878 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.2864 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.2851 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "50/50 [==============================] - 0s 377us/sample - loss: 0.2837 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "50/50 [==============================] - 0s 350us/sample - loss: 0.2823 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "50/50 [==============================] - 0s 389us/sample - loss: 0.2809 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "50/50 [==============================] - 0s 425us/sample - loss: 0.2795 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "50/50 [==============================] - 0s 307us/sample - loss: 0.2782 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.2755 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "50/50 [==============================] - 0s 438us/sample - loss: 0.2741 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.2728 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "50/50 [==============================] - 0s 344us/sample - loss: 0.2715 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "50/50 [==============================] - 0s 323us/sample - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "50/50 [==============================] - 0s 451us/sample - loss: 0.2688 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.2675 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "50/50 [==============================] - 0s 432us/sample - loss: 0.2662 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "50/50 [==============================] - 0s 402us/sample - loss: 0.2649 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.2636 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "50/50 [==============================] - 0s 349us/sample - loss: 0.2623 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "50/50 [==============================] - 0s 540us/sample - loss: 0.2610 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "50/50 [==============================] - 0s 353us/sample - loss: 0.2598 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.2585 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "50/50 [==============================] - 0s 383us/sample - loss: 0.2573 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "50/50 [==============================] - 0s 381us/sample - loss: 0.2560 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "50/50 [==============================] - 0s 309us/sample - loss: 0.2548 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.2535 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.2523 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.2511 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.2499 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "50/50 [==============================] - 0s 325us/sample - loss: 0.2487 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "50/50 [==============================] - 0s 368us/sample - loss: 0.2474 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "50/50 [==============================] - 0s 298us/sample - loss: 0.2462 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "50/50 [==============================] - 0s 350us/sample - loss: 0.2450 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "50/50 [==============================] - 0s 371us/sample - loss: 0.2438 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.2426 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "50/50 [==============================] - 0s 394us/sample - loss: 0.2415 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "50/50 [==============================] - 0s 329us/sample - loss: 0.2403 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "50/50 [==============================] - 0s 336us/sample - loss: 0.2391 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "50/50 [==============================] - 0s 426us/sample - loss: 0.2379 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "50/50 [==============================] - 0s 315us/sample - loss: 0.2368 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.2356 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "50/50 [==============================] - 0s 326us/sample - loss: 0.2345 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "50/50 [==============================] - 0s 407us/sample - loss: 0.2334 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "50/50 [==============================] - 0s 324us/sample - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "50/50 [==============================] - 0s 329us/sample - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "50/50 [==============================] - 0s 342us/sample - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "50/50 [==============================] - 0s 347us/sample - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "50/50 [==============================] - 0s 339us/sample - loss: 0.2278 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "50/50 [==============================] - 0s 683us/sample - loss: 0.2267 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.2256 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.2245 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "50/50 [==============================] - 0s 307us/sample - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "50/50 [==============================] - 0s 323us/sample - loss: 0.2223 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "50/50 [==============================] - 0s 364us/sample - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "50/50 [==============================] - 0s 331us/sample - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "50/50 [==============================] - 0s 331us/sample - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "50/50 [==============================] - 0s 342us/sample - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "50/50 [==============================] - 0s 392us/sample - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "50/50 [==============================] - 0s 454us/sample - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "50/50 [==============================] - 0s 432us/sample - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/500\n",
      "50/50 [==============================] - 0s 370us/sample - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "50/50 [==============================] - 0s 372us/sample - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "50/50 [==============================] - 0s 362us/sample - loss: 0.2066 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "50/50 [==============================] - 0s 326us/sample - loss: 0.2056 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "50/50 [==============================] - 0s 305us/sample - loss: 0.2046 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "50/50 [==============================] - 0s 391us/sample - loss: 0.2036 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.2026 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "50/50 [==============================] - 0s 316us/sample - loss: 0.2016 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "50/50 [==============================] - 0s 298us/sample - loss: 0.2006 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "50/50 [==============================] - 0s 333us/sample - loss: 0.1997 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "50/50 [==============================] - 0s 395us/sample - loss: 0.1987 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "50/50 [==============================] - 0s 320us/sample - loss: 0.1978 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "50/50 [==============================] - 0s 469us/sample - loss: 0.1968 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.1959 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "50/50 [==============================] - 0s 376us/sample - loss: 0.1949 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "50/50 [==============================] - 0s 320us/sample - loss: 0.1940 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "50/50 [==============================] - 0s 499us/sample - loss: 0.1930 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "50/50 [==============================] - 0s 420us/sample - loss: 0.1921 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "50/50 [==============================] - 0s 342us/sample - loss: 0.1912 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "50/50 [==============================] - 0s 397us/sample - loss: 0.1903 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "50/50 [==============================] - 0s 396us/sample - loss: 0.1894 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.1885 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "50/50 [==============================] - 0s 444us/sample - loss: 0.1875 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.1866 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.1857 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "50/50 [==============================] - 0s 319us/sample - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "50/50 [==============================] - 0s 333us/sample - loss: 0.1839 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "50/50 [==============================] - 0s 291us/sample - loss: 0.1830 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.1821 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.1812 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "50/50 [==============================] - 0s 330us/sample - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "50/50 [==============================] - 0s 388us/sample - loss: 0.1795 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "50/50 [==============================] - 0s 353us/sample - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "50/50 [==============================] - 0s 350us/sample - loss: 0.1777 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "50/50 [==============================] - 0s 410us/sample - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "50/50 [==============================] - 0s 477us/sample - loss: 0.1759 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "50/50 [==============================] - 0s 465us/sample - loss: 0.1751 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "50/50 [==============================] - 0s 307us/sample - loss: 0.1742 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "50/50 [==============================] - 0s 405us/sample - loss: 0.1734 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "50/50 [==============================] - 0s 354us/sample - loss: 0.1726 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "50/50 [==============================] - 0s 331us/sample - loss: 0.1701 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.1692 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.1684 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "50/50 [==============================] - 0s 338us/sample - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "50/50 [==============================] - 0s 325us/sample - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "50/50 [==============================] - 0s 318us/sample - loss: 0.1660 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "50/50 [==============================] - 0s 370us/sample - loss: 0.1652 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "50/50 [==============================] - 0s 298us/sample - loss: 0.1644 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "50/50 [==============================] - 0s 324us/sample - loss: 0.1637 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.1629 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "50/50 [==============================] - 0s 365us/sample - loss: 0.1621 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "50/50 [==============================] - 0s 355us/sample - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "50/50 [==============================] - 0s 354us/sample - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "50/50 [==============================] - 0s 407us/sample - loss: 0.1597 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.1590 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "50/50 [==============================] - 0s 350us/sample - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.1574 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "50/50 [==============================] - 0s 420us/sample - loss: 0.1567 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "50/50 [==============================] - 0s 423us/sample - loss: 0.1559 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "50/50 [==============================] - 0s 334us/sample - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "50/50 [==============================] - 0s 340us/sample - loss: 0.1544 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "50/50 [==============================] - 0s 370us/sample - loss: 0.1537 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "50/50 [==============================] - 0s 340us/sample - loss: 0.1529 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "50/50 [==============================] - 0s 339us/sample - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "50/50 [==============================] - 0s 513us/sample - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "50/50 [==============================] - 0s 393us/sample - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "50/50 [==============================] - 0s 359us/sample - loss: 0.1499 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "50/50 [==============================] - 0s 411us/sample - loss: 0.1492 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "50/50 [==============================] - 0s 305us/sample - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "50/50 [==============================] - 0s 379us/sample - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "50/50 [==============================] - 0s 391us/sample - loss: 0.1471 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "50/50 [==============================] - 0s 398us/sample - loss: 0.1464 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "50/50 [==============================] - 0s 333us/sample - loss: 0.1457 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "50/50 [==============================] - 0s 319us/sample - loss: 0.1450 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "50/50 [==============================] - 0s 378us/sample - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.1436 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.1429 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "50/50 [==============================] - 0s 336us/sample - loss: 0.1423 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "50/50 [==============================] - 0s 409us/sample - loss: 0.1416 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "50/50 [==============================] - 0s 391us/sample - loss: 0.1409 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "50/50 [==============================] - 0s 318us/sample - loss: 0.1402 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.1395 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "50/50 [==============================] - 0s 314us/sample - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "50/50 [==============================] - 0s 309us/sample - loss: 0.1382 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "50/50 [==============================] - 0s 323us/sample - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.1369 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.1362 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.1356 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "50/50 [==============================] - 0s 455us/sample - loss: 0.1349 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "50/50 [==============================] - 0s 349us/sample - loss: 0.1343 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "50/50 [==============================] - 0s 305us/sample - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "50/50 [==============================] - 0s 296us/sample - loss: 0.1317 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "50/50 [==============================] - 0s 338us/sample - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "50/50 [==============================] - 0s 357us/sample - loss: 0.1298 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "50/50 [==============================] - 0s 375us/sample - loss: 0.1292 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "50/50 [==============================] - 0s 383us/sample - loss: 0.1286 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "50/50 [==============================] - 0s 405us/sample - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "50/50 [==============================] - 0s 409us/sample - loss: 0.1274 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "50/50 [==============================] - 0s 734us/sample - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "50/50 [==============================] - 0s 446us/sample - loss: 0.1261 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "50/50 [==============================] - 0s 491us/sample - loss: 0.1249 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "50/50 [==============================] - 0s 416us/sample - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "50/50 [==============================] - 0s 378us/sample - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "50/50 [==============================] - 0s 367us/sample - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "50/50 [==============================] - 0s 403us/sample - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.1214 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "50/50 [==============================] - 0s 360us/sample - loss: 0.1208 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "50/50 [==============================] - 0s 354us/sample - loss: 0.1202 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "50/50 [==============================] - 0s 374us/sample - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "50/50 [==============================] - 0s 394us/sample - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "50/50 [==============================] - 0s 306us/sample - loss: 0.1185 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "50/50 [==============================] - 0s 316us/sample - loss: 0.1174 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "50/50 [==============================] - 0s 391us/sample - loss: 0.1168 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "50/50 [==============================] - 0s 492us/sample - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "50/50 [==============================] - 0s 399us/sample - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "50/50 [==============================] - 0s 363us/sample - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "50/50 [==============================] - 0s 322us/sample - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "50/50 [==============================] - 0s 383us/sample - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "50/50 [==============================] - 0s 312us/sample - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "50/50 [==============================] - 0s 358us/sample - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "50/50 [==============================] - 0s 284us/sample - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "50/50 [==============================] - 0s 434us/sample - loss: 0.1120 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "50/50 [==============================] - 0s 370us/sample - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "50/50 [==============================] - 0s 460us/sample - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "50/50 [==============================] - 0s 428us/sample - loss: 0.1104 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "50/50 [==============================] - 0s 397us/sample - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "50/50 [==============================] - 0s 404us/sample - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "50/50 [==============================] - 0s 366us/sample - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "50/50 [==============================] - 0s 348us/sample - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "50/50 [==============================] - 0s 316us/sample - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "50/50 [==============================] - 0s 385us/sample - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "50/50 [==============================] - 0s 356us/sample - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "50/50 [==============================] - 0s 373us/sample - loss: 0.1063 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "50/50 [==============================] - 0s 352us/sample - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "50/50 [==============================] - 0s 379us/sample - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "50/50 [==============================] - 0s 386us/sample - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "50/50 [==============================] - 0s 461us/sample - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "50/50 [==============================] - 0s 335us/sample - loss: 0.1033 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "50/50 [==============================] - 0s 571us/sample - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "50/50 [==============================] - 0s 424us/sample - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "50/50 [==============================] - 0s 474us/sample - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "50/50 [==============================] - 0s 431us/sample - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "50/50 [==============================] - 0s 343us/sample - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "50/50 [==============================] - 0s 382us/sample - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "50/50 [==============================] - 0s 384us/sample - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "50/50 [==============================] - 0s 347us/sample - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "50/50 [==============================] - 0s 399us/sample - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "50/50 [==============================] - 0s 368us/sample - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "50/50 [==============================] - 0s 372us/sample - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "50/50 [==============================] - 0s 405us/sample - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "50/50 [==============================] - 0s 389us/sample - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "50/50 [==============================] - 0s 459us/sample - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "50/50 [==============================] - 0s 380us/sample - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "50/50 [==============================] - 0s 429us/sample - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "50/50 [==============================] - 0s 471us/sample - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# i \"history\" sparar vi treäningshistoriken som används vid utvärdering av modellen\n",
    "history = logistic_regression_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utvärdera modell\n",
    "Vi utvärderar accuracy och loss i modellen:\n",
    "\n",
    "- Vad ser vi för skillnader mellan train och test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  1.0\n",
      "accuracy, test:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "Sannolikheter bakom prediktioner\n",
      " Versicolor = 1 \n",
      " [[0.807]\n",
      " [0.268]\n",
      " [0.887]\n",
      " [0.472]\n",
      " [0.516]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = logistic_regression_model.predict_classes(X_test[0:5])\n",
    "\n",
    "probabilities = logistic_regression_model.predict_proba(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktioner\\n Versicolor = 1\",\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomialt problem - Iris med 3 klasser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vi utökar övningen till identifiering av alla 3 klasser: 'setosa', 'versicolor' och 'virginica'\n",
    " \n",
    "Vi förändrar input data:\n",
    "- Istället för EN dummy-variabel (1=Versicolor) är vårt Y nu 3 dummy-variabler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import & preparering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features : 4\n",
      "n_classes : 3\n",
      "\n",
      " Standardiserade features: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      " [[ 0.069 -0.132  0.251  0.396]\n",
      " [ 1.038  0.098  0.535  0.396]\n",
      " [ 2.25  -0.592  1.672  1.054]]\n",
      "\n",
      "Y:  ['setosa' 'versicolor' 'virginica'] \n",
      " [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding (= skapar dummy-varibler)\n",
    "enc = OneHotEncoder(categories=\"auto\")\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Standardiserar data till medelvärde 0 och varians 1 \n",
    "# Standardisering av värden hjälper neurala nätverk att konvergera\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "print(\"n_features : \" + str(n_features))\n",
    "print(\"n_classes : \" + str(n_classes))\n",
    "\n",
    "print( \"\\n Standardiserade features: \\n\",feature_names,\"\\n\",X_train[0:3])\n",
    "print (\"\\nY: \",names,\"\\n\", Y_train[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial logistisk regression (Softmax)\n",
    "\n",
    "Till skillnad från vårt binära problem kan vi inte använda \"sigmoid\" som aktiveringsfunktion\n",
    "- Aktiveringsfunktionen \"softmax\" kan hantera problem där flera kategorier ska prediceras\n",
    "- Vi måste byta ut vår loss-funktion när vi har flera klasser, från \"binary_crossentropy\" till \"categorical_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 10ms/sample - loss: 0.5921 - accuracy: 0.7200 - val_loss: 0.5000 - val_accuracy: 0.7733\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.5852 - accuracy: 0.7333 - val_loss: 0.4965 - val_accuracy: 0.8000\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.5808 - accuracy: 0.7333 - val_loss: 0.4936 - val_accuracy: 0.8000\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.5774 - accuracy: 0.7467 - val_loss: 0.4912 - val_accuracy: 0.8000\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.5744 - accuracy: 0.7467 - val_loss: 0.4888 - val_accuracy: 0.8000\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.5710 - accuracy: 0.7600 - val_loss: 0.4865 - val_accuracy: 0.8000\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.5683 - accuracy: 0.7600 - val_loss: 0.4844 - val_accuracy: 0.8000\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.5654 - accuracy: 0.7600 - val_loss: 0.4823 - val_accuracy: 0.8133\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.5625 - accuracy: 0.7600 - val_loss: 0.4802 - val_accuracy: 0.8267\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.5596 - accuracy: 0.7600 - val_loss: 0.4782 - val_accuracy: 0.8267\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.5571 - accuracy: 0.7600 - val_loss: 0.4763 - val_accuracy: 0.8267\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.5545 - accuracy: 0.7600 - val_loss: 0.4745 - val_accuracy: 0.8267\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 0.5522 - accuracy: 0.7600 - val_loss: 0.4726 - val_accuracy: 0.8267\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.5497 - accuracy: 0.7600 - val_loss: 0.4708 - val_accuracy: 0.8267\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.5475 - accuracy: 0.7600 - val_loss: 0.4689 - val_accuracy: 0.8267\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.5450 - accuracy: 0.7600 - val_loss: 0.4672 - val_accuracy: 0.8267\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.5427 - accuracy: 0.7600 - val_loss: 0.4654 - val_accuracy: 0.8400\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.5405 - accuracy: 0.7600 - val_loss: 0.4634 - val_accuracy: 0.8400\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.5377 - accuracy: 0.7600 - val_loss: 0.4616 - val_accuracy: 0.8400\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.5353 - accuracy: 0.7600 - val_loss: 0.4600 - val_accuracy: 0.8400\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.5332 - accuracy: 0.7600 - val_loss: 0.4585 - val_accuracy: 0.8400\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.5310 - accuracy: 0.7600 - val_loss: 0.4567 - val_accuracy: 0.8400\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.5285 - accuracy: 0.7733 - val_loss: 0.4549 - val_accuracy: 0.8400\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.5260 - accuracy: 0.7867 - val_loss: 0.4533 - val_accuracy: 0.8400\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.5240 - accuracy: 0.7867 - val_loss: 0.4517 - val_accuracy: 0.8400\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.5217 - accuracy: 0.7867 - val_loss: 0.4499 - val_accuracy: 0.8400\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.5197 - accuracy: 0.7867 - val_loss: 0.4483 - val_accuracy: 0.8400\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.5172 - accuracy: 0.7867 - val_loss: 0.4467 - val_accuracy: 0.8400\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.5150 - accuracy: 0.7867 - val_loss: 0.4453 - val_accuracy: 0.8400\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.5132 - accuracy: 0.7733 - val_loss: 0.4438 - val_accuracy: 0.8533\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.5113 - accuracy: 0.7733 - val_loss: 0.4424 - val_accuracy: 0.8533\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.5093 - accuracy: 0.7733 - val_loss: 0.4409 - val_accuracy: 0.8533\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.5073 - accuracy: 0.7733 - val_loss: 0.4393 - val_accuracy: 0.8533\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.5051 - accuracy: 0.7733 - val_loss: 0.4376 - val_accuracy: 0.8533\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.5029 - accuracy: 0.7733 - val_loss: 0.4361 - val_accuracy: 0.8533\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 235us/sample - loss: 0.5010 - accuracy: 0.7733 - val_loss: 0.4345 - val_accuracy: 0.8533\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.4989 - accuracy: 0.7733 - val_loss: 0.4330 - val_accuracy: 0.8533\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.4967 - accuracy: 0.7733 - val_loss: 0.4315 - val_accuracy: 0.8533\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 471us/sample - loss: 0.4948 - accuracy: 0.7733 - val_loss: 0.4301 - val_accuracy: 0.8533\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.4928 - accuracy: 0.7733 - val_loss: 0.4286 - val_accuracy: 0.8533\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.4909 - accuracy: 0.7733 - val_loss: 0.4273 - val_accuracy: 0.8533\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.4890 - accuracy: 0.7733 - val_loss: 0.4258 - val_accuracy: 0.8533\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.4870 - accuracy: 0.7733 - val_loss: 0.4245 - val_accuracy: 0.8533\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.4854 - accuracy: 0.7733 - val_loss: 0.4232 - val_accuracy: 0.8533\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.4834 - accuracy: 0.7733 - val_loss: 0.4218 - val_accuracy: 0.8533\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.4812 - accuracy: 0.7867 - val_loss: 0.4204 - val_accuracy: 0.8533\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.4793 - accuracy: 0.7867 - val_loss: 0.4190 - val_accuracy: 0.8533\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.4773 - accuracy: 0.7867 - val_loss: 0.4176 - val_accuracy: 0.8533\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.4756 - accuracy: 0.7867 - val_loss: 0.4163 - val_accuracy: 0.8533\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.4739 - accuracy: 0.7867 - val_loss: 0.4150 - val_accuracy: 0.8533\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.4722 - accuracy: 0.7867 - val_loss: 0.4137 - val_accuracy: 0.8533\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.4703 - accuracy: 0.7867 - val_loss: 0.4124 - val_accuracy: 0.8533\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.4686 - accuracy: 0.7867 - val_loss: 0.4113 - val_accuracy: 0.8533\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 495us/sample - loss: 0.4667 - accuracy: 0.8000 - val_loss: 0.4100 - val_accuracy: 0.8533\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.4650 - accuracy: 0.8000 - val_loss: 0.4088 - val_accuracy: 0.8533\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.4631 - accuracy: 0.8000 - val_loss: 0.4076 - val_accuracy: 0.8533\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.4616 - accuracy: 0.8000 - val_loss: 0.4065 - val_accuracy: 0.8533\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.4598 - accuracy: 0.8000 - val_loss: 0.4052 - val_accuracy: 0.8533\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.4580 - accuracy: 0.8000 - val_loss: 0.4041 - val_accuracy: 0.8533\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.4564 - accuracy: 0.8000 - val_loss: 0.4030 - val_accuracy: 0.8533\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.4547 - accuracy: 0.8000 - val_loss: 0.4017 - val_accuracy: 0.8533\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.4532 - accuracy: 0.8000 - val_loss: 0.4006 - val_accuracy: 0.8533\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.4515 - accuracy: 0.8000 - val_loss: 0.3996 - val_accuracy: 0.8533\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.4499 - accuracy: 0.8000 - val_loss: 0.3984 - val_accuracy: 0.8400\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 241us/sample - loss: 0.4484 - accuracy: 0.8000 - val_loss: 0.3973 - val_accuracy: 0.8400\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.4469 - accuracy: 0.8000 - val_loss: 0.3962 - val_accuracy: 0.8400\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.4455 - accuracy: 0.8000 - val_loss: 0.3951 - val_accuracy: 0.8400\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.4440 - accuracy: 0.8000 - val_loss: 0.3941 - val_accuracy: 0.8400\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 372us/sample - loss: 0.4426 - accuracy: 0.8000 - val_loss: 0.3930 - val_accuracy: 0.8400\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.4414 - accuracy: 0.8000 - val_loss: 0.3920 - val_accuracy: 0.8400\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.4401 - accuracy: 0.8000 - val_loss: 0.3911 - val_accuracy: 0.8533\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.4385 - accuracy: 0.8000 - val_loss: 0.3901 - val_accuracy: 0.8533\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.4371 - accuracy: 0.8000 - val_loss: 0.3890 - val_accuracy: 0.8533\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.4357 - accuracy: 0.8000 - val_loss: 0.3879 - val_accuracy: 0.8533\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.4343 - accuracy: 0.8000 - val_loss: 0.3870 - val_accuracy: 0.8533\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.4330 - accuracy: 0.8000 - val_loss: 0.3860 - val_accuracy: 0.8533\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.4315 - accuracy: 0.8000 - val_loss: 0.3850 - val_accuracy: 0.8533\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.4301 - accuracy: 0.8133 - val_loss: 0.3839 - val_accuracy: 0.8400\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.4286 - accuracy: 0.8133 - val_loss: 0.3829 - val_accuracy: 0.8533\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.4271 - accuracy: 0.8133 - val_loss: 0.3820 - val_accuracy: 0.8533\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.4258 - accuracy: 0.8133 - val_loss: 0.3810 - val_accuracy: 0.8533\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.4245 - accuracy: 0.8133 - val_loss: 0.3799 - val_accuracy: 0.8533\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.4232 - accuracy: 0.8133 - val_loss: 0.3788 - val_accuracy: 0.8533\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.4217 - accuracy: 0.8133 - val_loss: 0.3778 - val_accuracy: 0.8400\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.4202 - accuracy: 0.8000 - val_loss: 0.3768 - val_accuracy: 0.8400\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.4190 - accuracy: 0.8000 - val_loss: 0.3757 - val_accuracy: 0.8400\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.4176 - accuracy: 0.8000 - val_loss: 0.3747 - val_accuracy: 0.8400\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.4164 - accuracy: 0.8000 - val_loss: 0.3736 - val_accuracy: 0.8400\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.4152 - accuracy: 0.8000 - val_loss: 0.3729 - val_accuracy: 0.8400\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 234us/sample - loss: 0.4138 - accuracy: 0.8000 - val_loss: 0.3722 - val_accuracy: 0.8400\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.4125 - accuracy: 0.8133 - val_loss: 0.3712 - val_accuracy: 0.8533\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.4116 - accuracy: 0.8133 - val_loss: 0.3704 - val_accuracy: 0.8533\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.4101 - accuracy: 0.8133 - val_loss: 0.3696 - val_accuracy: 0.8533\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.4089 - accuracy: 0.8133 - val_loss: 0.3687 - val_accuracy: 0.8533\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.4077 - accuracy: 0.8133 - val_loss: 0.3677 - val_accuracy: 0.8533\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.4066 - accuracy: 0.8133 - val_loss: 0.3668 - val_accuracy: 0.8667\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 242us/sample - loss: 0.4053 - accuracy: 0.8133 - val_loss: 0.3660 - val_accuracy: 0.8667\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.4041 - accuracy: 0.8400 - val_loss: 0.3651 - val_accuracy: 0.8667\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.4030 - accuracy: 0.8400 - val_loss: 0.3642 - val_accuracy: 0.8667\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.4019 - accuracy: 0.8400 - val_loss: 0.3633 - val_accuracy: 0.8667\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.4006 - accuracy: 0.8400 - val_loss: 0.3627 - val_accuracy: 0.8800\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.3993 - accuracy: 0.8400 - val_loss: 0.3618 - val_accuracy: 0.8667\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.3981 - accuracy: 0.8400 - val_loss: 0.3611 - val_accuracy: 0.8667\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3970 - accuracy: 0.8400 - val_loss: 0.3604 - val_accuracy: 0.8667\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.3960 - accuracy: 0.8400 - val_loss: 0.3597 - val_accuracy: 0.8667\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.3947 - accuracy: 0.8400 - val_loss: 0.3589 - val_accuracy: 0.8667\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.3936 - accuracy: 0.8400 - val_loss: 0.3581 - val_accuracy: 0.8667\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.3925 - accuracy: 0.8400 - val_loss: 0.3571 - val_accuracy: 0.8667\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 302us/sample - loss: 0.3915 - accuracy: 0.8400 - val_loss: 0.3564 - val_accuracy: 0.8667\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.3902 - accuracy: 0.8400 - val_loss: 0.3555 - val_accuracy: 0.8667\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.3892 - accuracy: 0.8400 - val_loss: 0.3547 - val_accuracy: 0.8667\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.3882 - accuracy: 0.8400 - val_loss: 0.3540 - val_accuracy: 0.8667\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.3871 - accuracy: 0.8400 - val_loss: 0.3532 - val_accuracy: 0.8667\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 235us/sample - loss: 0.3858 - accuracy: 0.8400 - val_loss: 0.3523 - val_accuracy: 0.8667\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 249us/sample - loss: 0.3847 - accuracy: 0.8400 - val_loss: 0.3514 - val_accuracy: 0.8667\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.3837 - accuracy: 0.8400 - val_loss: 0.3505 - val_accuracy: 0.8667\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.3826 - accuracy: 0.8400 - val_loss: 0.3498 - val_accuracy: 0.8667\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 241us/sample - loss: 0.3814 - accuracy: 0.8533 - val_loss: 0.3490 - val_accuracy: 0.8667\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.3805 - accuracy: 0.8533 - val_loss: 0.3481 - val_accuracy: 0.8667\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.3796 - accuracy: 0.8533 - val_loss: 0.3474 - val_accuracy: 0.8667\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.3786 - accuracy: 0.8533 - val_loss: 0.3466 - val_accuracy: 0.8667\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.3776 - accuracy: 0.8533 - val_loss: 0.3459 - val_accuracy: 0.8667\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.3766 - accuracy: 0.8533 - val_loss: 0.3453 - val_accuracy: 0.8667\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.3755 - accuracy: 0.8533 - val_loss: 0.3445 - val_accuracy: 0.8667\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.3745 - accuracy: 0.8533 - val_loss: 0.3438 - val_accuracy: 0.8667\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.3734 - accuracy: 0.8533 - val_loss: 0.3430 - val_accuracy: 0.8667\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.3724 - accuracy: 0.8533 - val_loss: 0.3425 - val_accuracy: 0.8667\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.3713 - accuracy: 0.8533 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.3706 - accuracy: 0.8533 - val_loss: 0.3413 - val_accuracy: 0.8667\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3697 - accuracy: 0.8533 - val_loss: 0.3405 - val_accuracy: 0.8667\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.3689 - accuracy: 0.8533 - val_loss: 0.3398 - val_accuracy: 0.8667\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.3679 - accuracy: 0.8533 - val_loss: 0.3390 - val_accuracy: 0.8800\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3672 - accuracy: 0.8533 - val_loss: 0.3382 - val_accuracy: 0.8800\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.3664 - accuracy: 0.8533 - val_loss: 0.3376 - val_accuracy: 0.8800\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.3654 - accuracy: 0.8533 - val_loss: 0.3370 - val_accuracy: 0.8800\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.3645 - accuracy: 0.8533 - val_loss: 0.3362 - val_accuracy: 0.8800\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.3637 - accuracy: 0.8533 - val_loss: 0.3355 - val_accuracy: 0.8800\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.3630 - accuracy: 0.8533 - val_loss: 0.3347 - val_accuracy: 0.8800\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.3620 - accuracy: 0.8533 - val_loss: 0.3341 - val_accuracy: 0.8800\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.3611 - accuracy: 0.8533 - val_loss: 0.3333 - val_accuracy: 0.8800\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 238us/sample - loss: 0.3605 - accuracy: 0.8533 - val_loss: 0.3325 - val_accuracy: 0.8800\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.3596 - accuracy: 0.8533 - val_loss: 0.3320 - val_accuracy: 0.8800\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 237us/sample - loss: 0.3586 - accuracy: 0.8533 - val_loss: 0.3314 - val_accuracy: 0.8800\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3578 - accuracy: 0.8533 - val_loss: 0.3308 - val_accuracy: 0.8800\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.3568 - accuracy: 0.8533 - val_loss: 0.3302 - val_accuracy: 0.8800\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 234us/sample - loss: 0.3559 - accuracy: 0.8533 - val_loss: 0.3297 - val_accuracy: 0.8800\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.3551 - accuracy: 0.8533 - val_loss: 0.3289 - val_accuracy: 0.8800\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.3543 - accuracy: 0.8533 - val_loss: 0.3283 - val_accuracy: 0.8800\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.3534 - accuracy: 0.8533 - val_loss: 0.3276 - val_accuracy: 0.8800\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3525 - accuracy: 0.8533 - val_loss: 0.3269 - val_accuracy: 0.8800\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.3516 - accuracy: 0.8533 - val_loss: 0.3262 - val_accuracy: 0.8800\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.3507 - accuracy: 0.8533 - val_loss: 0.3256 - val_accuracy: 0.8800\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.3501 - accuracy: 0.8533 - val_loss: 0.3248 - val_accuracy: 0.8800\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.3492 - accuracy: 0.8533 - val_loss: 0.3242 - val_accuracy: 0.8800\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.3485 - accuracy: 0.8533 - val_loss: 0.3235 - val_accuracy: 0.8800\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.3478 - accuracy: 0.8533 - val_loss: 0.3229 - val_accuracy: 0.8800\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.3470 - accuracy: 0.8533 - val_loss: 0.3222 - val_accuracy: 0.8800\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.3462 - accuracy: 0.8533 - val_loss: 0.3216 - val_accuracy: 0.8800\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3455 - accuracy: 0.8533 - val_loss: 0.3210 - val_accuracy: 0.8800\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.3445 - accuracy: 0.8533 - val_loss: 0.3204 - val_accuracy: 0.8800\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.3438 - accuracy: 0.8533 - val_loss: 0.3197 - val_accuracy: 0.8800\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.3429 - accuracy: 0.8533 - val_loss: 0.3193 - val_accuracy: 0.8800\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3420 - accuracy: 0.8533 - val_loss: 0.3186 - val_accuracy: 0.8800\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3411 - accuracy: 0.8533 - val_loss: 0.3179 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.3404 - accuracy: 0.8533 - val_loss: 0.3172 - val_accuracy: 0.8800\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.3396 - accuracy: 0.8533 - val_loss: 0.3167 - val_accuracy: 0.8800\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.3388 - accuracy: 0.8533 - val_loss: 0.3161 - val_accuracy: 0.8800\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.3380 - accuracy: 0.8533 - val_loss: 0.3155 - val_accuracy: 0.8800\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.3373 - accuracy: 0.8533 - val_loss: 0.3148 - val_accuracy: 0.8800\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.3365 - accuracy: 0.8533 - val_loss: 0.3142 - val_accuracy: 0.8800\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3358 - accuracy: 0.8533 - val_loss: 0.3138 - val_accuracy: 0.8800\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.3351 - accuracy: 0.8533 - val_loss: 0.3132 - val_accuracy: 0.8800\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.3344 - accuracy: 0.8533 - val_loss: 0.3127 - val_accuracy: 0.8800\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.3336 - accuracy: 0.8533 - val_loss: 0.3124 - val_accuracy: 0.8800\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3329 - accuracy: 0.8533 - val_loss: 0.3117 - val_accuracy: 0.8800\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.3323 - accuracy: 0.8533 - val_loss: 0.3109 - val_accuracy: 0.8800\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.3315 - accuracy: 0.8533 - val_loss: 0.3103 - val_accuracy: 0.8800\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 234us/sample - loss: 0.3309 - accuracy: 0.8533 - val_loss: 0.3098 - val_accuracy: 0.8800\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.3302 - accuracy: 0.8533 - val_loss: 0.3095 - val_accuracy: 0.8800\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.3296 - accuracy: 0.8533 - val_loss: 0.3090 - val_accuracy: 0.8800\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.3289 - accuracy: 0.8533 - val_loss: 0.3083 - val_accuracy: 0.8800\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3283 - accuracy: 0.8533 - val_loss: 0.3076 - val_accuracy: 0.8800\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.3277 - accuracy: 0.8533 - val_loss: 0.3072 - val_accuracy: 0.8800\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.3271 - accuracy: 0.8533 - val_loss: 0.3069 - val_accuracy: 0.8800\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.3264 - accuracy: 0.8533 - val_loss: 0.3063 - val_accuracy: 0.8800\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 242us/sample - loss: 0.3257 - accuracy: 0.8533 - val_loss: 0.3059 - val_accuracy: 0.8800\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.3251 - accuracy: 0.8533 - val_loss: 0.3053 - val_accuracy: 0.8800\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 489us/sample - loss: 0.3250 - accuracy: 0.8400 - val_loss: 0.3050 - val_accuracy: 0.8800\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.3238 - accuracy: 0.8400 - val_loss: 0.3044 - val_accuracy: 0.8800\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3232 - accuracy: 0.8400 - val_loss: 0.3040 - val_accuracy: 0.8800\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.3227 - accuracy: 0.8400 - val_loss: 0.3036 - val_accuracy: 0.8800\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.3220 - accuracy: 0.8400 - val_loss: 0.3030 - val_accuracy: 0.8800\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.3214 - accuracy: 0.8400 - val_loss: 0.3023 - val_accuracy: 0.8800\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.3208 - accuracy: 0.8400 - val_loss: 0.3020 - val_accuracy: 0.8800\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 224us/sample - loss: 0.3202 - accuracy: 0.8533 - val_loss: 0.3016 - val_accuracy: 0.8800\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.3195 - accuracy: 0.8533 - val_loss: 0.3010 - val_accuracy: 0.8800\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3189 - accuracy: 0.8533 - val_loss: 0.3006 - val_accuracy: 0.8800\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3183 - accuracy: 0.8533 - val_loss: 0.3004 - val_accuracy: 0.8800\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.3177 - accuracy: 0.8533 - val_loss: 0.3000 - val_accuracy: 0.8800\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.3171 - accuracy: 0.8533 - val_loss: 0.2997 - val_accuracy: 0.8800\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 473us/sample - loss: 0.3164 - accuracy: 0.8533 - val_loss: 0.2991 - val_accuracy: 0.8800\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.3161 - accuracy: 0.8533 - val_loss: 0.2986 - val_accuracy: 0.8800\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.3154 - accuracy: 0.8533 - val_loss: 0.2980 - val_accuracy: 0.8800\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.3148 - accuracy: 0.8533 - val_loss: 0.2974 - val_accuracy: 0.8800\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.3144 - accuracy: 0.8533 - val_loss: 0.2968 - val_accuracy: 0.8800\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3138 - accuracy: 0.8533 - val_loss: 0.2965 - val_accuracy: 0.8933\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.3131 - accuracy: 0.8533 - val_loss: 0.2961 - val_accuracy: 0.8933\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.3126 - accuracy: 0.8533 - val_loss: 0.2958 - val_accuracy: 0.8933\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.3119 - accuracy: 0.8533 - val_loss: 0.2954 - val_accuracy: 0.8933\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.3114 - accuracy: 0.8533 - val_loss: 0.2950 - val_accuracy: 0.8933\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.3108 - accuracy: 0.8533 - val_loss: 0.2943 - val_accuracy: 0.8933\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.3102 - accuracy: 0.8533 - val_loss: 0.2939 - val_accuracy: 0.8933\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3096 - accuracy: 0.8533 - val_loss: 0.2934 - val_accuracy: 0.8933\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.3091 - accuracy: 0.8533 - val_loss: 0.2930 - val_accuracy: 0.8933\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.3085 - accuracy: 0.8533 - val_loss: 0.2924 - val_accuracy: 0.8933\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.3079 - accuracy: 0.8533 - val_loss: 0.2919 - val_accuracy: 0.8933\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.3074 - accuracy: 0.8533 - val_loss: 0.2916 - val_accuracy: 0.8933\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3068 - accuracy: 0.8533 - val_loss: 0.2914 - val_accuracy: 0.8933\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.3062 - accuracy: 0.8533 - val_loss: 0.2908 - val_accuracy: 0.8933\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 387us/sample - loss: 0.3057 - accuracy: 0.8533 - val_loss: 0.2906 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3051 - accuracy: 0.8533 - val_loss: 0.2901 - val_accuracy: 0.8933\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.3046 - accuracy: 0.8533 - val_loss: 0.2897 - val_accuracy: 0.8933\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.3041 - accuracy: 0.8533 - val_loss: 0.2891 - val_accuracy: 0.8933\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.3037 - accuracy: 0.8533 - val_loss: 0.2889 - val_accuracy: 0.8933\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.3031 - accuracy: 0.8533 - val_loss: 0.2885 - val_accuracy: 0.8933\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.3026 - accuracy: 0.8533 - val_loss: 0.2883 - val_accuracy: 0.8933\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.3021 - accuracy: 0.8533 - val_loss: 0.2878 - val_accuracy: 0.8933\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3014 - accuracy: 0.8533 - val_loss: 0.2873 - val_accuracy: 0.8933\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.3009 - accuracy: 0.8533 - val_loss: 0.2868 - val_accuracy: 0.8933\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.3005 - accuracy: 0.8533 - val_loss: 0.2864 - val_accuracy: 0.8933\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.2998 - accuracy: 0.8533 - val_loss: 0.2859 - val_accuracy: 0.8933\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.2993 - accuracy: 0.8533 - val_loss: 0.2856 - val_accuracy: 0.8933\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.2987 - accuracy: 0.8533 - val_loss: 0.2853 - val_accuracy: 0.8933\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.2983 - accuracy: 0.8533 - val_loss: 0.2850 - val_accuracy: 0.8933\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.2979 - accuracy: 0.8533 - val_loss: 0.2847 - val_accuracy: 0.8933\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 547us/sample - loss: 0.2973 - accuracy: 0.8533 - val_loss: 0.2843 - val_accuracy: 0.8933\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.2968 - accuracy: 0.8533 - val_loss: 0.2838 - val_accuracy: 0.8933\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.2965 - accuracy: 0.8533 - val_loss: 0.2833 - val_accuracy: 0.8933\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.2959 - accuracy: 0.8533 - val_loss: 0.2827 - val_accuracy: 0.8933\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.2953 - accuracy: 0.8533 - val_loss: 0.2824 - val_accuracy: 0.8933\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.2949 - accuracy: 0.8533 - val_loss: 0.2820 - val_accuracy: 0.8933\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.2945 - accuracy: 0.8533 - val_loss: 0.2815 - val_accuracy: 0.8933\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.2939 - accuracy: 0.8533 - val_loss: 0.2811 - val_accuracy: 0.8933\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.2935 - accuracy: 0.8667 - val_loss: 0.2806 - val_accuracy: 0.8933\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.2930 - accuracy: 0.8667 - val_loss: 0.2802 - val_accuracy: 0.8933\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.2925 - accuracy: 0.8800 - val_loss: 0.2795 - val_accuracy: 0.8933\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.2920 - accuracy: 0.8800 - val_loss: 0.2794 - val_accuracy: 0.8933\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.2916 - accuracy: 0.8800 - val_loss: 0.2791 - val_accuracy: 0.8933\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.2911 - accuracy: 0.8800 - val_loss: 0.2788 - val_accuracy: 0.8933\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.2906 - accuracy: 0.8800 - val_loss: 0.2785 - val_accuracy: 0.8933\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.2901 - accuracy: 0.8800 - val_loss: 0.2780 - val_accuracy: 0.8933\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.2895 - accuracy: 0.8800 - val_loss: 0.2774 - val_accuracy: 0.8933\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.2889 - accuracy: 0.8800 - val_loss: 0.2770 - val_accuracy: 0.8933\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.2885 - accuracy: 0.8800 - val_loss: 0.2764 - val_accuracy: 0.8933\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.2879 - accuracy: 0.8800 - val_loss: 0.2761 - val_accuracy: 0.8933\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.2873 - accuracy: 0.8800 - val_loss: 0.2756 - val_accuracy: 0.8933\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.2868 - accuracy: 0.8933 - val_loss: 0.2753 - val_accuracy: 0.8933\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2863 - accuracy: 0.8933 - val_loss: 0.2750 - val_accuracy: 0.8933\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.2858 - accuracy: 0.8933 - val_loss: 0.2745 - val_accuracy: 0.8933\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.2853 - accuracy: 0.8933 - val_loss: 0.2739 - val_accuracy: 0.8933\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.2848 - accuracy: 0.8933 - val_loss: 0.2736 - val_accuracy: 0.8933\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.2844 - accuracy: 0.8933 - val_loss: 0.2731 - val_accuracy: 0.8933\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2840 - accuracy: 0.8933 - val_loss: 0.2728 - val_accuracy: 0.8933\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.2835 - accuracy: 0.8933 - val_loss: 0.2723 - val_accuracy: 0.8933\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.2829 - accuracy: 0.8933 - val_loss: 0.2720 - val_accuracy: 0.8933\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2824 - accuracy: 0.8933 - val_loss: 0.2715 - val_accuracy: 0.8933\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.2820 - accuracy: 0.8933 - val_loss: 0.2711 - val_accuracy: 0.8933\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.2816 - accuracy: 0.8933 - val_loss: 0.2707 - val_accuracy: 0.8933\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.2811 - accuracy: 0.8933 - val_loss: 0.2705 - val_accuracy: 0.8933\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.2806 - accuracy: 0.8933 - val_loss: 0.2699 - val_accuracy: 0.9067\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.2802 - accuracy: 0.9067 - val_loss: 0.2696 - val_accuracy: 0.9067\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2797 - accuracy: 0.9067 - val_loss: 0.2694 - val_accuracy: 0.9067\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.2793 - accuracy: 0.9067 - val_loss: 0.2691 - val_accuracy: 0.9067\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2789 - accuracy: 0.9067 - val_loss: 0.2689 - val_accuracy: 0.9067\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2784 - accuracy: 0.8933 - val_loss: 0.2683 - val_accuracy: 0.9067\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.2780 - accuracy: 0.9067 - val_loss: 0.2679 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.2776 - accuracy: 0.9067 - val_loss: 0.2672 - val_accuracy: 0.9067\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.2774 - accuracy: 0.9067 - val_loss: 0.2669 - val_accuracy: 0.9067\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.2768 - accuracy: 0.9067 - val_loss: 0.2667 - val_accuracy: 0.9067\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.2764 - accuracy: 0.9067 - val_loss: 0.2664 - val_accuracy: 0.9067\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.2760 - accuracy: 0.9067 - val_loss: 0.2661 - val_accuracy: 0.9067\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.2756 - accuracy: 0.9067 - val_loss: 0.2660 - val_accuracy: 0.9067\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.2751 - accuracy: 0.9067 - val_loss: 0.2659 - val_accuracy: 0.9067\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 366us/sample - loss: 0.2747 - accuracy: 0.9067 - val_loss: 0.2655 - val_accuracy: 0.9067\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.2743 - accuracy: 0.9067 - val_loss: 0.2650 - val_accuracy: 0.9067\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.2738 - accuracy: 0.9067 - val_loss: 0.2647 - val_accuracy: 0.9067\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.2737 - accuracy: 0.9067 - val_loss: 0.2643 - val_accuracy: 0.9067\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.2729 - accuracy: 0.9067 - val_loss: 0.2639 - val_accuracy: 0.9067\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.2726 - accuracy: 0.9067 - val_loss: 0.2634 - val_accuracy: 0.9067\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.2722 - accuracy: 0.9067 - val_loss: 0.2628 - val_accuracy: 0.9067\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2717 - accuracy: 0.9067 - val_loss: 0.2623 - val_accuracy: 0.9067\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.2714 - accuracy: 0.9067 - val_loss: 0.2619 - val_accuracy: 0.9067\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.2709 - accuracy: 0.9067 - val_loss: 0.2614 - val_accuracy: 0.9067\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.2706 - accuracy: 0.9067 - val_loss: 0.2611 - val_accuracy: 0.9067\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2700 - accuracy: 0.9067 - val_loss: 0.2605 - val_accuracy: 0.9067\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.2697 - accuracy: 0.9067 - val_loss: 0.2600 - val_accuracy: 0.9067\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.2693 - accuracy: 0.9067 - val_loss: 0.2598 - val_accuracy: 0.9067\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.2691 - accuracy: 0.9067 - val_loss: 0.2595 - val_accuracy: 0.9067\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.2686 - accuracy: 0.9067 - val_loss: 0.2594 - val_accuracy: 0.9067\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.2681 - accuracy: 0.9067 - val_loss: 0.2590 - val_accuracy: 0.9067\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.2679 - accuracy: 0.9067 - val_loss: 0.2589 - val_accuracy: 0.9067\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.2675 - accuracy: 0.9067 - val_loss: 0.2587 - val_accuracy: 0.9067\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.2671 - accuracy: 0.9067 - val_loss: 0.2585 - val_accuracy: 0.9067\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.2667 - accuracy: 0.9067 - val_loss: 0.2581 - val_accuracy: 0.9067\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 227us/sample - loss: 0.2662 - accuracy: 0.9067 - val_loss: 0.2576 - val_accuracy: 0.9067\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.2660 - accuracy: 0.9067 - val_loss: 0.2574 - val_accuracy: 0.9067\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.2656 - accuracy: 0.9067 - val_loss: 0.2569 - val_accuracy: 0.9067\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2652 - accuracy: 0.9067 - val_loss: 0.2566 - val_accuracy: 0.9200\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.2647 - accuracy: 0.9067 - val_loss: 0.2563 - val_accuracy: 0.9200\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.2643 - accuracy: 0.9067 - val_loss: 0.2559 - val_accuracy: 0.9200\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.2641 - accuracy: 0.9067 - val_loss: 0.2553 - val_accuracy: 0.9200\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.2637 - accuracy: 0.9067 - val_loss: 0.2549 - val_accuracy: 0.9200\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.2632 - accuracy: 0.9067 - val_loss: 0.2546 - val_accuracy: 0.9200\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2628 - accuracy: 0.9067 - val_loss: 0.2544 - val_accuracy: 0.9200\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2624 - accuracy: 0.9067 - val_loss: 0.2543 - val_accuracy: 0.9200\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.2622 - accuracy: 0.9067 - val_loss: 0.2537 - val_accuracy: 0.9200\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.2617 - accuracy: 0.9067 - val_loss: 0.2534 - val_accuracy: 0.9200\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.2615 - accuracy: 0.9067 - val_loss: 0.2527 - val_accuracy: 0.9200\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.2609 - accuracy: 0.9067 - val_loss: 0.2522 - val_accuracy: 0.9200\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2606 - accuracy: 0.9067 - val_loss: 0.2520 - val_accuracy: 0.9200\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.2602 - accuracy: 0.9067 - val_loss: 0.2517 - val_accuracy: 0.9200\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.2598 - accuracy: 0.9067 - val_loss: 0.2512 - val_accuracy: 0.9200\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.2594 - accuracy: 0.9067 - val_loss: 0.2508 - val_accuracy: 0.9200\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.2591 - accuracy: 0.9067 - val_loss: 0.2508 - val_accuracy: 0.9200\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.2586 - accuracy: 0.9067 - val_loss: 0.2505 - val_accuracy: 0.9200\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.2583 - accuracy: 0.9067 - val_loss: 0.2499 - val_accuracy: 0.9200\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.2582 - accuracy: 0.9067 - val_loss: 0.2495 - val_accuracy: 0.9200\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.2576 - accuracy: 0.9067 - val_loss: 0.2491 - val_accuracy: 0.9200\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.2572 - accuracy: 0.9067 - val_loss: 0.2490 - val_accuracy: 0.9200\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.2568 - accuracy: 0.9067 - val_loss: 0.2487 - val_accuracy: 0.9200\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2565 - accuracy: 0.9067 - val_loss: 0.2483 - val_accuracy: 0.9200\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.2561 - accuracy: 0.9067 - val_loss: 0.2480 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 239us/sample - loss: 0.2558 - accuracy: 0.9067 - val_loss: 0.2477 - val_accuracy: 0.9200\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2554 - accuracy: 0.9067 - val_loss: 0.2475 - val_accuracy: 0.9200\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.2549 - accuracy: 0.9067 - val_loss: 0.2470 - val_accuracy: 0.9200\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.2545 - accuracy: 0.9067 - val_loss: 0.2467 - val_accuracy: 0.9200\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 237us/sample - loss: 0.2540 - accuracy: 0.9067 - val_loss: 0.2460 - val_accuracy: 0.9333\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.2536 - accuracy: 0.9067 - val_loss: 0.2456 - val_accuracy: 0.9333\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.2532 - accuracy: 0.9067 - val_loss: 0.2454 - val_accuracy: 0.9333\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.2527 - accuracy: 0.9067 - val_loss: 0.2453 - val_accuracy: 0.9333\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.2524 - accuracy: 0.9067 - val_loss: 0.2449 - val_accuracy: 0.9333\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.2520 - accuracy: 0.9067 - val_loss: 0.2448 - val_accuracy: 0.9333\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 249us/sample - loss: 0.2517 - accuracy: 0.9067 - val_loss: 0.2447 - val_accuracy: 0.9200\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 243us/sample - loss: 0.2512 - accuracy: 0.9067 - val_loss: 0.2444 - val_accuracy: 0.9333\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.2509 - accuracy: 0.9067 - val_loss: 0.2439 - val_accuracy: 0.9333\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2505 - accuracy: 0.9067 - val_loss: 0.2436 - val_accuracy: 0.9333\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.2502 - accuracy: 0.9067 - val_loss: 0.2435 - val_accuracy: 0.9333\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.2499 - accuracy: 0.9067 - val_loss: 0.2433 - val_accuracy: 0.9333\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.2495 - accuracy: 0.9067 - val_loss: 0.2429 - val_accuracy: 0.9333\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.2490 - accuracy: 0.9067 - val_loss: 0.2424 - val_accuracy: 0.9333\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.2487 - accuracy: 0.9067 - val_loss: 0.2419 - val_accuracy: 0.9333\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.2483 - accuracy: 0.9067 - val_loss: 0.2416 - val_accuracy: 0.9333\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.2481 - accuracy: 0.9067 - val_loss: 0.2411 - val_accuracy: 0.9333\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.2479 - accuracy: 0.9067 - val_loss: 0.2408 - val_accuracy: 0.9333\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.2475 - accuracy: 0.9067 - val_loss: 0.2404 - val_accuracy: 0.9333\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.2471 - accuracy: 0.9067 - val_loss: 0.2403 - val_accuracy: 0.9333\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.2468 - accuracy: 0.9067 - val_loss: 0.2404 - val_accuracy: 0.9333\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2464 - accuracy: 0.9067 - val_loss: 0.2398 - val_accuracy: 0.9333\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.2460 - accuracy: 0.9067 - val_loss: 0.2395 - val_accuracy: 0.9333\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.2457 - accuracy: 0.9067 - val_loss: 0.2390 - val_accuracy: 0.9333\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 379us/sample - loss: 0.2454 - accuracy: 0.9067 - val_loss: 0.2387 - val_accuracy: 0.9333\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 243us/sample - loss: 0.2451 - accuracy: 0.9067 - val_loss: 0.2383 - val_accuracy: 0.9333\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.2447 - accuracy: 0.9067 - val_loss: 0.2378 - val_accuracy: 0.9333\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.2444 - accuracy: 0.9067 - val_loss: 0.2373 - val_accuracy: 0.9333\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.2440 - accuracy: 0.9067 - val_loss: 0.2367 - val_accuracy: 0.9333\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.2438 - accuracy: 0.9067 - val_loss: 0.2364 - val_accuracy: 0.9333\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.2433 - accuracy: 0.9067 - val_loss: 0.2360 - val_accuracy: 0.9333\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 410us/sample - loss: 0.2430 - accuracy: 0.9067 - val_loss: 0.2358 - val_accuracy: 0.9333\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.2426 - accuracy: 0.9067 - val_loss: 0.2355 - val_accuracy: 0.9333\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.2423 - accuracy: 0.9067 - val_loss: 0.2350 - val_accuracy: 0.9333\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2419 - accuracy: 0.9067 - val_loss: 0.2347 - val_accuracy: 0.9333\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.2415 - accuracy: 0.9067 - val_loss: 0.2346 - val_accuracy: 0.9333\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.2411 - accuracy: 0.9067 - val_loss: 0.2341 - val_accuracy: 0.9333\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.2407 - accuracy: 0.9067 - val_loss: 0.2338 - val_accuracy: 0.9333\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.2403 - accuracy: 0.9067 - val_loss: 0.2334 - val_accuracy: 0.9333\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.2401 - accuracy: 0.9067 - val_loss: 0.2331 - val_accuracy: 0.9333\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.2396 - accuracy: 0.9067 - val_loss: 0.2328 - val_accuracy: 0.9333\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2392 - accuracy: 0.9067 - val_loss: 0.2323 - val_accuracy: 0.9333\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.2388 - accuracy: 0.9067 - val_loss: 0.2320 - val_accuracy: 0.9333\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 247us/sample - loss: 0.2384 - accuracy: 0.9067 - val_loss: 0.2317 - val_accuracy: 0.9333\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 242us/sample - loss: 0.2380 - accuracy: 0.9067 - val_loss: 0.2311 - val_accuracy: 0.9333\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2377 - accuracy: 0.9067 - val_loss: 0.2307 - val_accuracy: 0.9333\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.2373 - accuracy: 0.9067 - val_loss: 0.2301 - val_accuracy: 0.9333\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2369 - accuracy: 0.9067 - val_loss: 0.2300 - val_accuracy: 0.9333\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.2365 - accuracy: 0.9067 - val_loss: 0.2298 - val_accuracy: 0.9333\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.2362 - accuracy: 0.9200 - val_loss: 0.2294 - val_accuracy: 0.9333\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.2358 - accuracy: 0.9200 - val_loss: 0.2289 - val_accuracy: 0.9333\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.2355 - accuracy: 0.9200 - val_loss: 0.2288 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.2351 - accuracy: 0.9200 - val_loss: 0.2284 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.2348 - accuracy: 0.9200 - val_loss: 0.2279 - val_accuracy: 0.9333\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.2345 - accuracy: 0.9200 - val_loss: 0.2277 - val_accuracy: 0.9333\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.2342 - accuracy: 0.9200 - val_loss: 0.2276 - val_accuracy: 0.9333\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.2339 - accuracy: 0.9200 - val_loss: 0.2271 - val_accuracy: 0.9333\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2336 - accuracy: 0.9200 - val_loss: 0.2271 - val_accuracy: 0.9333\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 239us/sample - loss: 0.2333 - accuracy: 0.9200 - val_loss: 0.2266 - val_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.2330 - accuracy: 0.9200 - val_loss: 0.2261 - val_accuracy: 0.9333\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.2328 - accuracy: 0.9200 - val_loss: 0.2260 - val_accuracy: 0.9333\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.2324 - accuracy: 0.9200 - val_loss: 0.2259 - val_accuracy: 0.9333\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.2320 - accuracy: 0.9200 - val_loss: 0.2257 - val_accuracy: 0.9333\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.2317 - accuracy: 0.9200 - val_loss: 0.2253 - val_accuracy: 0.9333\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.2315 - accuracy: 0.9200 - val_loss: 0.2251 - val_accuracy: 0.9333\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 249us/sample - loss: 0.2311 - accuracy: 0.9200 - val_loss: 0.2248 - val_accuracy: 0.9333\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.2309 - accuracy: 0.9200 - val_loss: 0.2244 - val_accuracy: 0.9333\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.2306 - accuracy: 0.9200 - val_loss: 0.2239 - val_accuracy: 0.9333\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.2303 - accuracy: 0.9200 - val_loss: 0.2238 - val_accuracy: 0.9333\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2300 - accuracy: 0.9200 - val_loss: 0.2235 - val_accuracy: 0.9333\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2297 - accuracy: 0.9200 - val_loss: 0.2232 - val_accuracy: 0.9333\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.2293 - accuracy: 0.9200 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.2290 - accuracy: 0.9200 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.2288 - accuracy: 0.9200 - val_loss: 0.2228 - val_accuracy: 0.9333\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2284 - accuracy: 0.9200 - val_loss: 0.2226 - val_accuracy: 0.9333\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.2280 - accuracy: 0.9200 - val_loss: 0.2224 - val_accuracy: 0.9333\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2277 - accuracy: 0.9200 - val_loss: 0.2219 - val_accuracy: 0.9333\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.2274 - accuracy: 0.9200 - val_loss: 0.2214 - val_accuracy: 0.9333\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.2270 - accuracy: 0.9200 - val_loss: 0.2211 - val_accuracy: 0.9333\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.2267 - accuracy: 0.9200 - val_loss: 0.2209 - val_accuracy: 0.9333\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.2265 - accuracy: 0.9200 - val_loss: 0.2205 - val_accuracy: 0.9333\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.2262 - accuracy: 0.9200 - val_loss: 0.2204 - val_accuracy: 0.9333\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.2258 - accuracy: 0.9200 - val_loss: 0.2199 - val_accuracy: 0.9333\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.2255 - accuracy: 0.9200 - val_loss: 0.2195 - val_accuracy: 0.9333\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.2252 - accuracy: 0.9200 - val_loss: 0.2191 - val_accuracy: 0.9333\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.2249 - accuracy: 0.9200 - val_loss: 0.2190 - val_accuracy: 0.9333\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2246 - accuracy: 0.9200 - val_loss: 0.2188 - val_accuracy: 0.9333\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.2243 - accuracy: 0.9200 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.2240 - accuracy: 0.9200 - val_loss: 0.2181 - val_accuracy: 0.9333\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.2239 - accuracy: 0.9200 - val_loss: 0.2177 - val_accuracy: 0.9333\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.2235 - accuracy: 0.9200 - val_loss: 0.2174 - val_accuracy: 0.9333\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 506us/sample - loss: 0.2231 - accuracy: 0.9200 - val_loss: 0.2170 - val_accuracy: 0.9333\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.2229 - accuracy: 0.9200 - val_loss: 0.2169 - val_accuracy: 0.9333\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 468us/sample - loss: 0.2225 - accuracy: 0.9200 - val_loss: 0.2165 - val_accuracy: 0.9333\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.2223 - accuracy: 0.9200 - val_loss: 0.2160 - val_accuracy: 0.9333\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.2219 - accuracy: 0.9200 - val_loss: 0.2159 - val_accuracy: 0.9333\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.2216 - accuracy: 0.9200 - val_loss: 0.2158 - val_accuracy: 0.9333\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.2213 - accuracy: 0.9200 - val_loss: 0.2153 - val_accuracy: 0.9333\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 240us/sample - loss: 0.2210 - accuracy: 0.9200 - val_loss: 0.2149 - val_accuracy: 0.9333\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.2208 - accuracy: 0.9200 - val_loss: 0.2148 - val_accuracy: 0.9333\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.2206 - accuracy: 0.9200 - val_loss: 0.2143 - val_accuracy: 0.9333\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2202 - accuracy: 0.9200 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.2199 - accuracy: 0.9200 - val_loss: 0.2138 - val_accuracy: 0.9333\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.2196 - accuracy: 0.9200 - val_loss: 0.2136 - val_accuracy: 0.9333\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.2195 - accuracy: 0.9333 - val_loss: 0.2136 - val_accuracy: 0.9333\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2190 - accuracy: 0.9333 - val_loss: 0.2131 - val_accuracy: 0.9333\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.2189 - accuracy: 0.9333 - val_loss: 0.2130 - val_accuracy: 0.9333\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.2185 - accuracy: 0.9333 - val_loss: 0.2125 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.2182 - accuracy: 0.9333 - val_loss: 0.2124 - val_accuracy: 0.9333\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.2179 - accuracy: 0.9333 - val_loss: 0.2121 - val_accuracy: 0.9333\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.2176 - accuracy: 0.9333 - val_loss: 0.2119 - val_accuracy: 0.9333\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.2174 - accuracy: 0.9467 - val_loss: 0.2115 - val_accuracy: 0.9333\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.2170 - accuracy: 0.9333 - val_loss: 0.2114 - val_accuracy: 0.9333\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2167 - accuracy: 0.9467 - val_loss: 0.2112 - val_accuracy: 0.9333\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.2167 - accuracy: 0.9467 - val_loss: 0.2111 - val_accuracy: 0.9333\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.2163 - accuracy: 0.9467 - val_loss: 0.2111 - val_accuracy: 0.9333\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.2159 - accuracy: 0.9467 - val_loss: 0.2110 - val_accuracy: 0.9333\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.2157 - accuracy: 0.9467 - val_loss: 0.2109 - val_accuracy: 0.9333\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.2155 - accuracy: 0.9467 - val_loss: 0.2105 - val_accuracy: 0.9333\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 236us/sample - loss: 0.2154 - accuracy: 0.9467 - val_loss: 0.2102 - val_accuracy: 0.9333\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.2150 - accuracy: 0.9467 - val_loss: 0.2097 - val_accuracy: 0.9333\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.2148 - accuracy: 0.9467 - val_loss: 0.2097 - val_accuracy: 0.9333\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.2145 - accuracy: 0.9467 - val_loss: 0.2094 - val_accuracy: 0.9333\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 246us/sample - loss: 0.2143 - accuracy: 0.9467 - val_loss: 0.2092 - val_accuracy: 0.9333\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.2140 - accuracy: 0.9467 - val_loss: 0.2090 - val_accuracy: 0.9333\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.2138 - accuracy: 0.9467 - val_loss: 0.2084 - val_accuracy: 0.9333\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.2135 - accuracy: 0.9467 - val_loss: 0.2081 - val_accuracy: 0.9333\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.2133 - accuracy: 0.9467 - val_loss: 0.2080 - val_accuracy: 0.9333\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.2131 - accuracy: 0.9467 - val_loss: 0.2078 - val_accuracy: 0.9333\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.2129 - accuracy: 0.9467 - val_loss: 0.2076 - val_accuracy: 0.9333\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.2127 - accuracy: 0.9467 - val_loss: 0.2071 - val_accuracy: 0.9333\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2124 - accuracy: 0.9467 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.2122 - accuracy: 0.9467 - val_loss: 0.2071 - val_accuracy: 0.9333\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 392us/sample - loss: 0.2118 - accuracy: 0.9467 - val_loss: 0.2069 - val_accuracy: 0.9333\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.2116 - accuracy: 0.9467 - val_loss: 0.2068 - val_accuracy: 0.9333\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 245us/sample - loss: 0.2114 - accuracy: 0.9467 - val_loss: 0.2067 - val_accuracy: 0.9333\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.2113 - accuracy: 0.9467 - val_loss: 0.2066 - val_accuracy: 0.9333\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.2109 - accuracy: 0.9467 - val_loss: 0.2063 - val_accuracy: 0.9333\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2107 - accuracy: 0.9467 - val_loss: 0.2064 - val_accuracy: 0.9333\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 229us/sample - loss: 0.2104 - accuracy: 0.9467 - val_loss: 0.2062 - val_accuracy: 0.9333\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.2104 - accuracy: 0.9467 - val_loss: 0.2060 - val_accuracy: 0.9333\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 244us/sample - loss: 0.2101 - accuracy: 0.9467 - val_loss: 0.2056 - val_accuracy: 0.9333\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 233us/sample - loss: 0.2098 - accuracy: 0.9467 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.2095 - accuracy: 0.9467 - val_loss: 0.2054 - val_accuracy: 0.9333\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.2093 - accuracy: 0.9467 - val_loss: 0.2053 - val_accuracy: 0.9333\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.2090 - accuracy: 0.9467 - val_loss: 0.2052 - val_accuracy: 0.9333\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.2089 - accuracy: 0.9467 - val_loss: 0.2049 - val_accuracy: 0.9333\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.2085 - accuracy: 0.9467 - val_loss: 0.2045 - val_accuracy: 0.9333\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.2083 - accuracy: 0.9467 - val_loss: 0.2044 - val_accuracy: 0.9333\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 251us/sample - loss: 0.2081 - accuracy: 0.9467 - val_loss: 0.2040 - val_accuracy: 0.9333\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.2078 - accuracy: 0.9467 - val_loss: 0.2036 - val_accuracy: 0.9333\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.2075 - accuracy: 0.9467 - val_loss: 0.2032 - val_accuracy: 0.9333\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.2073 - accuracy: 0.9467 - val_loss: 0.2029 - val_accuracy: 0.9333\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.2071 - accuracy: 0.9467 - val_loss: 0.2024 - val_accuracy: 0.9333\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.2068 - accuracy: 0.9467 - val_loss: 0.2024 - val_accuracy: 0.9333\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.2066 - accuracy: 0.9467 - val_loss: 0.2020 - val_accuracy: 0.9333\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.2065 - accuracy: 0.9467 - val_loss: 0.2016 - val_accuracy: 0.9333\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.2061 - accuracy: 0.9467 - val_loss: 0.2013 - val_accuracy: 0.9333\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.2060 - accuracy: 0.9467 - val_loss: 0.2009 - val_accuracy: 0.9333\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.2056 - accuracy: 0.9467 - val_loss: 0.2006 - val_accuracy: 0.9333\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.2054 - accuracy: 0.9467 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.2051 - accuracy: 0.9467 - val_loss: 0.2002 - val_accuracy: 0.9333\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 252us/sample - loss: 0.2048 - accuracy: 0.9467 - val_loss: 0.1999 - val_accuracy: 0.9333\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.2045 - accuracy: 0.9467 - val_loss: 0.1997 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "multinomial_log_reg_model = Sequential()\n",
    "\n",
    "\n",
    "# 3 klasser kräver 3 output neuroner, input_dim är fortfarande 4\n",
    "multinomial_log_reg_model.add(Dense(n_classes, input_dim=n_features, activation='softmax')) #activation är förändrad\n",
    "\n",
    "multinomial_log_reg_model.compile(optimizers='sgd',\n",
    "             loss='categorical_crossentropy', #Loss-funktionen är förändrad\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "multinomial_log_reg_model.summary()\n",
    "\n",
    "history = multinomial_log_reg_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " #### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.9066667\n",
      "accuracy, test:  0.9066667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [0 0 2 0 0]\n",
      "\n",
      "Sannolikheter bakom prediktioner\n",
      " ['setosa' 'versicolor' 'virginica'] \n",
      " [[9.979e-01 2.058e-03 5.229e-06]\n",
      " [9.898e-01 1.015e-02 1.494e-05]\n",
      " [1.719e-04 3.684e-01 6.315e-01]\n",
      " [9.806e-01 1.937e-02 1.930e-05]\n",
      " [9.952e-01 4.798e-03 1.331e-05]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = multinomial_log_reg_model.predict_classes(X_test[0:5])\n",
    "\n",
    "probabilities = multinomial_log_reg_model.predict_proba(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktioner\\n\",names,\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuralt nätverk\n",
    "\n",
    "- Vi har nu utvärderat likheterna mellan ett neuralt nätverk och logistisk regression\n",
    "- Neurala nätverks styrka är inte att replikera logistisk regression, utan att kunna hantera komplexare samband än en logistisk regression genom att introducera icke-linjaritet med hjälp av ett antal hidden layers, inte bara ett lager som vi använt ovan \n",
    "\n",
    "\n",
    "Skillnaden mot multinomial regression är att vi nu har flera lager (5) istället för 1: \n",
    "- Ett input lager som hanterar våra fyra features som input, har 5 noder och ReLU-aktivering\n",
    "- 3 efterföljande hidden layers med 5 noder, ReLU-aktivering\n",
    "- Det output lager som vi känner igen: softmax-aktivering som beräknar 3 värden, 0-1 hur sannolik observationen är var och en av våra 3 blomkategorier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Skapar återigen ett tomt, sekventiellt nätverk\n",
    "neural_network_model = Sequential()\n",
    "\n",
    "\n",
    "nodes = 5 # Noder i hidden layer. TESTA ATT ÄNDRA ANTALET NODER\n",
    "\n",
    "# Input lager, n_features=4\n",
    "neural_network_model.add(Dense(nodes, input_dim=n_features, activation='relu'))\n",
    "\n",
    "#Hidden lager\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "neural_network_model.add(Dense(nodes, activation='relu'))\n",
    "\n",
    "\n",
    "#Output lager, n_classes=3\n",
    "neural_network_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "neural_network_model.compile(optimizers='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "neural_network_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Träning av modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 14ms/sample - loss: 1.0944 - accuracy: 0.3333 - val_loss: 1.0920 - val_accuracy: 0.6267\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 1.0925 - accuracy: 0.5733 - val_loss: 1.0909 - val_accuracy: 0.6667\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 1.0911 - accuracy: 0.6533 - val_loss: 1.0896 - val_accuracy: 0.6667\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 415us/sample - loss: 1.0900 - accuracy: 0.6667 - val_loss: 1.0883 - val_accuracy: 0.6667\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 559us/sample - loss: 1.0887 - accuracy: 0.6667 - val_loss: 1.0871 - val_accuracy: 0.6667\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 1.0872 - accuracy: 0.6667 - val_loss: 1.0857 - val_accuracy: 0.6667\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 1.0857 - accuracy: 0.6667 - val_loss: 1.0839 - val_accuracy: 0.6667\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 1.0840 - accuracy: 0.6667 - val_loss: 1.0819 - val_accuracy: 0.6667\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 1.0824 - accuracy: 0.6667 - val_loss: 1.0806 - val_accuracy: 0.6667\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 1.0809 - accuracy: 0.6667 - val_loss: 1.0788 - val_accuracy: 0.6667\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 1.0791 - accuracy: 0.6667 - val_loss: 1.0769 - val_accuracy: 0.6667\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 1.0771 - accuracy: 0.6667 - val_loss: 1.0745 - val_accuracy: 0.6667\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 1.0749 - accuracy: 0.6667 - val_loss: 1.0721 - val_accuracy: 0.6667\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 1.0727 - accuracy: 0.6667 - val_loss: 1.0692 - val_accuracy: 0.6667\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.0702 - accuracy: 0.6667 - val_loss: 1.0664 - val_accuracy: 0.6667\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 1.0676 - accuracy: 0.6667 - val_loss: 1.0638 - val_accuracy: 0.6667\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 1.0651 - accuracy: 0.6667 - val_loss: 1.0607 - val_accuracy: 0.6667\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.0625 - accuracy: 0.6667 - val_loss: 1.0581 - val_accuracy: 0.6667\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 1.0596 - accuracy: 0.6667 - val_loss: 1.0547 - val_accuracy: 0.6667\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.0567 - accuracy: 0.6667 - val_loss: 1.0521 - val_accuracy: 0.6667\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 1.0540 - accuracy: 0.6667 - val_loss: 1.0488 - val_accuracy: 0.6667\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 1.0508 - accuracy: 0.6667 - val_loss: 1.0447 - val_accuracy: 0.6667\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 1.0470 - accuracy: 0.6667 - val_loss: 1.0408 - val_accuracy: 0.6667\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 1.0434 - accuracy: 0.6667 - val_loss: 1.0367 - val_accuracy: 0.6667\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 481us/sample - loss: 1.0394 - accuracy: 0.6667 - val_loss: 1.0318 - val_accuracy: 0.6667\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 1.0353 - accuracy: 0.6667 - val_loss: 1.0276 - val_accuracy: 0.6667\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 1.0312 - accuracy: 0.6667 - val_loss: 1.0227 - val_accuracy: 0.6667\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 1.0266 - accuracy: 0.6667 - val_loss: 1.0181 - val_accuracy: 0.6667\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 1.0223 - accuracy: 0.6667 - val_loss: 1.0131 - val_accuracy: 0.6667\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 1.0175 - accuracy: 0.6667 - val_loss: 1.0069 - val_accuracy: 0.6667\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 1.0121 - accuracy: 0.6667 - val_loss: 1.0015 - val_accuracy: 0.6667\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 1.0074 - accuracy: 0.6667 - val_loss: 0.9974 - val_accuracy: 0.6667\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 1.0032 - accuracy: 0.6667 - val_loss: 0.9916 - val_accuracy: 0.6667\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.9978 - accuracy: 0.6667 - val_loss: 0.9859 - val_accuracy: 0.6667\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.9926 - accuracy: 0.6667 - val_loss: 0.9801 - val_accuracy: 0.6667\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.9870 - accuracy: 0.6667 - val_loss: 0.9725 - val_accuracy: 0.6667\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.9805 - accuracy: 0.6667 - val_loss: 0.9669 - val_accuracy: 0.6667\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.9753 - accuracy: 0.6667 - val_loss: 0.9612 - val_accuracy: 0.6667\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.9697 - accuracy: 0.6667 - val_loss: 0.9539 - val_accuracy: 0.6667\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.9632 - accuracy: 0.6667 - val_loss: 0.9472 - val_accuracy: 0.6667\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 262us/sample - loss: 0.9571 - accuracy: 0.6667 - val_loss: 0.9398 - val_accuracy: 0.6667\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.9502 - accuracy: 0.6667 - val_loss: 0.9328 - val_accuracy: 0.6667\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.9437 - accuracy: 0.6667 - val_loss: 0.9248 - val_accuracy: 0.6667\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.9363 - accuracy: 0.6667 - val_loss: 0.9157 - val_accuracy: 0.6667\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 242us/sample - loss: 0.9287 - accuracy: 0.6667 - val_loss: 0.9088 - val_accuracy: 0.6667\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 234us/sample - loss: 0.9213 - accuracy: 0.6667 - val_loss: 0.9003 - val_accuracy: 0.6667\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.9133 - accuracy: 0.6933 - val_loss: 0.8913 - val_accuracy: 0.7867\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 526us/sample - loss: 0.9051 - accuracy: 0.8667 - val_loss: 0.8825 - val_accuracy: 0.8400\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.8967 - accuracy: 0.9067 - val_loss: 0.8733 - val_accuracy: 0.8800\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.8883 - accuracy: 0.9467 - val_loss: 0.8640 - val_accuracy: 0.8667\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.8802 - accuracy: 0.8667 - val_loss: 0.8548 - val_accuracy: 0.8667\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.8715 - accuracy: 0.8667 - val_loss: 0.8455 - val_accuracy: 0.8667\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.8632 - accuracy: 0.8533 - val_loss: 0.8367 - val_accuracy: 0.8667\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.8550 - accuracy: 0.8533 - val_loss: 0.8272 - val_accuracy: 0.8533\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.8470 - accuracy: 0.8400 - val_loss: 0.8183 - val_accuracy: 0.8533\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.8386 - accuracy: 0.8533 - val_loss: 0.8095 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.8309 - accuracy: 0.8667 - val_loss: 0.8010 - val_accuracy: 0.8933\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.8232 - accuracy: 0.8667 - val_loss: 0.7916 - val_accuracy: 0.9067\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.8150 - accuracy: 0.8000 - val_loss: 0.7825 - val_accuracy: 0.8933\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.8073 - accuracy: 0.8667 - val_loss: 0.7747 - val_accuracy: 0.8933\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.8002 - accuracy: 0.8667 - val_loss: 0.7664 - val_accuracy: 0.9067\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.7927 - accuracy: 0.8667 - val_loss: 0.7580 - val_accuracy: 0.9067\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.7855 - accuracy: 0.8533 - val_loss: 0.7502 - val_accuracy: 0.9067\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.7784 - accuracy: 0.8667 - val_loss: 0.7420 - val_accuracy: 0.8933\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 258us/sample - loss: 0.7713 - accuracy: 0.8533 - val_loss: 0.7342 - val_accuracy: 0.8933\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.7645 - accuracy: 0.8400 - val_loss: 0.7261 - val_accuracy: 0.8933\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.7577 - accuracy: 0.8533 - val_loss: 0.7191 - val_accuracy: 0.7600\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.7515 - accuracy: 0.7867 - val_loss: 0.7126 - val_accuracy: 0.8933\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.7457 - accuracy: 0.8267 - val_loss: 0.7059 - val_accuracy: 0.7600\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.7399 - accuracy: 0.7733 - val_loss: 0.6992 - val_accuracy: 0.7600\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.7340 - accuracy: 0.7600 - val_loss: 0.6931 - val_accuracy: 0.8933\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.7285 - accuracy: 0.8267 - val_loss: 0.6867 - val_accuracy: 0.8933\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.7229 - accuracy: 0.8267 - val_loss: 0.6803 - val_accuracy: 0.8933\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.7175 - accuracy: 0.8133 - val_loss: 0.6748 - val_accuracy: 0.8933\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 0.7125 - accuracy: 0.8267 - val_loss: 0.6684 - val_accuracy: 0.8933\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.7071 - accuracy: 0.8267 - val_loss: 0.6632 - val_accuracy: 0.8933\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.7024 - accuracy: 0.8267 - val_loss: 0.6579 - val_accuracy: 0.7600\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.6977 - accuracy: 0.7733 - val_loss: 0.6530 - val_accuracy: 0.8933\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.6931 - accuracy: 0.8133 - val_loss: 0.6483 - val_accuracy: 0.8933\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.6888 - accuracy: 0.8267 - val_loss: 0.6441 - val_accuracy: 0.8933\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.6848 - accuracy: 0.8267 - val_loss: 0.6395 - val_accuracy: 0.8933\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.6804 - accuracy: 0.8267 - val_loss: 0.6350 - val_accuracy: 0.8933\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.6762 - accuracy: 0.8267 - val_loss: 0.6307 - val_accuracy: 0.8933\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.6722 - accuracy: 0.8267 - val_loss: 0.6263 - val_accuracy: 0.8933\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.6681 - accuracy: 0.8267 - val_loss: 0.6220 - val_accuracy: 0.8933\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.6641 - accuracy: 0.8267 - val_loss: 0.6181 - val_accuracy: 0.8933\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.6603 - accuracy: 0.8267 - val_loss: 0.6138 - val_accuracy: 0.8933\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 485us/sample - loss: 0.6563 - accuracy: 0.8267 - val_loss: 0.6098 - val_accuracy: 0.8933\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.6526 - accuracy: 0.8267 - val_loss: 0.6068 - val_accuracy: 0.8800\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.6495 - accuracy: 0.8267 - val_loss: 0.6038 - val_accuracy: 0.8800\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.6460 - accuracy: 0.8400 - val_loss: 0.6004 - val_accuracy: 0.8800\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.6432 - accuracy: 0.8400 - val_loss: 0.5970 - val_accuracy: 0.8800\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.6396 - accuracy: 0.8400 - val_loss: 0.5937 - val_accuracy: 0.8800\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.6362 - accuracy: 0.8533 - val_loss: 0.5905 - val_accuracy: 0.8933\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.6328 - accuracy: 0.8533 - val_loss: 0.5869 - val_accuracy: 0.8933\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.6296 - accuracy: 0.8533 - val_loss: 0.5838 - val_accuracy: 0.8933\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.6264 - accuracy: 0.8533 - val_loss: 0.5810 - val_accuracy: 0.8933\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 243us/sample - loss: 0.6231 - accuracy: 0.8667 - val_loss: 0.5772 - val_accuracy: 0.8933\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.6198 - accuracy: 0.8533 - val_loss: 0.5741 - val_accuracy: 0.8933\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.6166 - accuracy: 0.8667 - val_loss: 0.5711 - val_accuracy: 0.8933\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.6135 - accuracy: 0.8533 - val_loss: 0.5692 - val_accuracy: 0.8933\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.6105 - accuracy: 0.8667 - val_loss: 0.5664 - val_accuracy: 0.8933\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.6074 - accuracy: 0.8667 - val_loss: 0.5639 - val_accuracy: 0.9067\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.6044 - accuracy: 0.8667 - val_loss: 0.5611 - val_accuracy: 0.9067\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.6014 - accuracy: 0.8667 - val_loss: 0.5586 - val_accuracy: 0.9200\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.5983 - accuracy: 0.8667 - val_loss: 0.5553 - val_accuracy: 0.9200\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.5951 - accuracy: 0.8667 - val_loss: 0.5525 - val_accuracy: 0.9200\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.5920 - accuracy: 0.8800 - val_loss: 0.5491 - val_accuracy: 0.9200\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.5887 - accuracy: 0.8800 - val_loss: 0.5468 - val_accuracy: 0.9200\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.5853 - accuracy: 0.8933 - val_loss: 0.5438 - val_accuracy: 0.9200\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.5819 - accuracy: 0.8933 - val_loss: 0.5408 - val_accuracy: 0.9200\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.5785 - accuracy: 0.8933 - val_loss: 0.5390 - val_accuracy: 0.9200\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 316us/sample - loss: 0.5752 - accuracy: 0.8933 - val_loss: 0.5366 - val_accuracy: 0.9200\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.5715 - accuracy: 0.8933 - val_loss: 0.5341 - val_accuracy: 0.9200\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.5679 - accuracy: 0.8933 - val_loss: 0.5304 - val_accuracy: 0.9200\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.5645 - accuracy: 0.8933 - val_loss: 0.5275 - val_accuracy: 0.9200\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.5613 - accuracy: 0.8933 - val_loss: 0.5252 - val_accuracy: 0.9200\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.5577 - accuracy: 0.9067 - val_loss: 0.5222 - val_accuracy: 0.9200\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.5543 - accuracy: 0.9067 - val_loss: 0.5196 - val_accuracy: 0.9200\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.5509 - accuracy: 0.9067 - val_loss: 0.5166 - val_accuracy: 0.9200\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.5476 - accuracy: 0.9067 - val_loss: 0.5147 - val_accuracy: 0.9067\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.5443 - accuracy: 0.9067 - val_loss: 0.5122 - val_accuracy: 0.9067\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.5409 - accuracy: 0.9067 - val_loss: 0.5104 - val_accuracy: 0.9200\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.5380 - accuracy: 0.9067 - val_loss: 0.5067 - val_accuracy: 0.9200\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.5344 - accuracy: 0.9067 - val_loss: 0.5051 - val_accuracy: 0.9200\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.5307 - accuracy: 0.9200 - val_loss: 0.5022 - val_accuracy: 0.9200\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.93 - 0s 294us/sample - loss: 0.5276 - accuracy: 0.9200 - val_loss: 0.5008 - val_accuracy: 0.9200\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.5246 - accuracy: 0.9200 - val_loss: 0.4984 - val_accuracy: 0.9200\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.5214 - accuracy: 0.9333 - val_loss: 0.4954 - val_accuracy: 0.9200\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.5185 - accuracy: 0.9333 - val_loss: 0.4916 - val_accuracy: 0.9200\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.5154 - accuracy: 0.9333 - val_loss: 0.4894 - val_accuracy: 0.9200\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.5117 - accuracy: 0.9333 - val_loss: 0.4864 - val_accuracy: 0.9200\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.5086 - accuracy: 0.9333 - val_loss: 0.4829 - val_accuracy: 0.9200\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.5056 - accuracy: 0.9333 - val_loss: 0.4803 - val_accuracy: 0.9200\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.5026 - accuracy: 0.9333 - val_loss: 0.4774 - val_accuracy: 0.9200\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.4993 - accuracy: 0.9333 - val_loss: 0.4747 - val_accuracy: 0.9200\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.4962 - accuracy: 0.9333 - val_loss: 0.4720 - val_accuracy: 0.9200\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.4934 - accuracy: 0.9333 - val_loss: 0.4700 - val_accuracy: 0.9200\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.4899 - accuracy: 0.9333 - val_loss: 0.4680 - val_accuracy: 0.9200\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.4872 - accuracy: 0.9333 - val_loss: 0.4647 - val_accuracy: 0.9200\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.4843 - accuracy: 0.9333 - val_loss: 0.4620 - val_accuracy: 0.9200\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.4814 - accuracy: 0.9333 - val_loss: 0.4594 - val_accuracy: 0.9200\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.4783 - accuracy: 0.9333 - val_loss: 0.4580 - val_accuracy: 0.9200\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.4753 - accuracy: 0.9467 - val_loss: 0.4558 - val_accuracy: 0.9200\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.4723 - accuracy: 0.9333 - val_loss: 0.4542 - val_accuracy: 0.9200\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.4689 - accuracy: 0.9467 - val_loss: 0.4523 - val_accuracy: 0.9200\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.4658 - accuracy: 0.9467 - val_loss: 0.4484 - val_accuracy: 0.9200\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.4628 - accuracy: 0.9467 - val_loss: 0.4455 - val_accuracy: 0.9200\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.4596 - accuracy: 0.9467 - val_loss: 0.4442 - val_accuracy: 0.9200\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.4562 - accuracy: 0.9467 - val_loss: 0.4405 - val_accuracy: 0.9200\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.4530 - accuracy: 0.9467 - val_loss: 0.4382 - val_accuracy: 0.9200\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.4500 - accuracy: 0.9467 - val_loss: 0.4352 - val_accuracy: 0.9200\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.4471 - accuracy: 0.9467 - val_loss: 0.4321 - val_accuracy: 0.9200\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.4441 - accuracy: 0.9467 - val_loss: 0.4303 - val_accuracy: 0.9200\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.4410 - accuracy: 0.9467 - val_loss: 0.4277 - val_accuracy: 0.9200\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 438us/sample - loss: 0.4380 - accuracy: 0.9467 - val_loss: 0.4258 - val_accuracy: 0.9200\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.4352 - accuracy: 0.9467 - val_loss: 0.4225 - val_accuracy: 0.9200\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.4321 - accuracy: 0.9467 - val_loss: 0.4205 - val_accuracy: 0.9200\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.4299 - accuracy: 0.9467 - val_loss: 0.4177 - val_accuracy: 0.9200\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.4269 - accuracy: 0.9467 - val_loss: 0.4147 - val_accuracy: 0.9200\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.4238 - accuracy: 0.9467 - val_loss: 0.4132 - val_accuracy: 0.9200\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.4207 - accuracy: 0.9467 - val_loss: 0.4110 - val_accuracy: 0.9200\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.4177 - accuracy: 0.9467 - val_loss: 0.4092 - val_accuracy: 0.9200\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.4145 - accuracy: 0.9467 - val_loss: 0.4062 - val_accuracy: 0.9200\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.4116 - accuracy: 0.9467 - val_loss: 0.4032 - val_accuracy: 0.9200\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.4092 - accuracy: 0.9467 - val_loss: 0.4011 - val_accuracy: 0.9200\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.4067 - accuracy: 0.9467 - val_loss: 0.3983 - val_accuracy: 0.9200\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.4034 - accuracy: 0.9467 - val_loss: 0.3972 - val_accuracy: 0.9200\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.4005 - accuracy: 0.9467 - val_loss: 0.3954 - val_accuracy: 0.9200\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.3977 - accuracy: 0.9467 - val_loss: 0.3938 - val_accuracy: 0.9200\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.3953 - accuracy: 0.9467 - val_loss: 0.3926 - val_accuracy: 0.9200\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.3925 - accuracy: 0.9600 - val_loss: 0.3892 - val_accuracy: 0.9200\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.3895 - accuracy: 0.9600 - val_loss: 0.3868 - val_accuracy: 0.9200\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 454us/sample - loss: 0.3867 - accuracy: 0.9600 - val_loss: 0.3852 - val_accuracy: 0.9200\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.3841 - accuracy: 0.9600 - val_loss: 0.3814 - val_accuracy: 0.9200\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3813 - accuracy: 0.9467 - val_loss: 0.3800 - val_accuracy: 0.9200\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.3781 - accuracy: 0.9600 - val_loss: 0.3773 - val_accuracy: 0.9200\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3760 - accuracy: 0.9600 - val_loss: 0.3774 - val_accuracy: 0.9200\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.3732 - accuracy: 0.9600 - val_loss: 0.3764 - val_accuracy: 0.9200\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.3707 - accuracy: 0.9600 - val_loss: 0.3731 - val_accuracy: 0.9200\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.3682 - accuracy: 0.9600 - val_loss: 0.3702 - val_accuracy: 0.9200\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.3657 - accuracy: 0.9600 - val_loss: 0.3676 - val_accuracy: 0.9200\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.3632 - accuracy: 0.9600 - val_loss: 0.3664 - val_accuracy: 0.9200\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.3609 - accuracy: 0.9600 - val_loss: 0.3647 - val_accuracy: 0.9200\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3583 - accuracy: 0.9600 - val_loss: 0.3634 - val_accuracy: 0.9200\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.3556 - accuracy: 0.9600 - val_loss: 0.3631 - val_accuracy: 0.9467\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.3528 - accuracy: 0.9733 - val_loss: 0.3604 - val_accuracy: 0.9467\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.3516 - accuracy: 0.9733 - val_loss: 0.3580 - val_accuracy: 0.9333\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.3477 - accuracy: 0.9733 - val_loss: 0.3553 - val_accuracy: 0.9200\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3453 - accuracy: 0.9600 - val_loss: 0.3540 - val_accuracy: 0.9467\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3430 - accuracy: 0.9733 - val_loss: 0.3530 - val_accuracy: 0.9333\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3403 - accuracy: 0.9867 - val_loss: 0.3500 - val_accuracy: 0.9333\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3380 - accuracy: 0.9733 - val_loss: 0.3474 - val_accuracy: 0.9333\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.3348 - accuracy: 0.9867 - val_loss: 0.3467 - val_accuracy: 0.9333\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.3321 - accuracy: 0.9867 - val_loss: 0.3445 - val_accuracy: 0.9333\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3298 - accuracy: 0.9867 - val_loss: 0.3413 - val_accuracy: 0.9333\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3273 - accuracy: 0.9867 - val_loss: 0.3410 - val_accuracy: 0.9333\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.3247 - accuracy: 0.9867 - val_loss: 0.3407 - val_accuracy: 0.9333\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 253us/sample - loss: 0.3220 - accuracy: 0.9867 - val_loss: 0.3386 - val_accuracy: 0.9333\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.3190 - accuracy: 0.9867 - val_loss: 0.3380 - val_accuracy: 0.9467\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.3164 - accuracy: 0.9867 - val_loss: 0.3350 - val_accuracy: 0.9333\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.3139 - accuracy: 0.9867 - val_loss: 0.3330 - val_accuracy: 0.9333\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.3120 - accuracy: 0.9867 - val_loss: 0.3306 - val_accuracy: 0.9333\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.3090 - accuracy: 0.9867 - val_loss: 0.3270 - val_accuracy: 0.9333\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3070 - accuracy: 0.9867 - val_loss: 0.3256 - val_accuracy: 0.9333\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.3037 - accuracy: 0.9867 - val_loss: 0.3260 - val_accuracy: 0.9333\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.3008 - accuracy: 0.9867 - val_loss: 0.3243 - val_accuracy: 0.9333\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.2986 - accuracy: 0.9867 - val_loss: 0.3233 - val_accuracy: 0.9467\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.2960 - accuracy: 0.9867 - val_loss: 0.3212 - val_accuracy: 0.9467\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.2932 - accuracy: 0.9867 - val_loss: 0.3199 - val_accuracy: 0.9467\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.2908 - accuracy: 0.9867 - val_loss: 0.3143 - val_accuracy: 0.9333\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.2883 - accuracy: 0.9867 - val_loss: 0.3156 - val_accuracy: 0.9467\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.2858 - accuracy: 0.9867 - val_loss: 0.3123 - val_accuracy: 0.9467\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.2830 - accuracy: 0.9867 - val_loss: 0.3121 - val_accuracy: 0.9467\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.2804 - accuracy: 0.9867 - val_loss: 0.3085 - val_accuracy: 0.9467\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.2782 - accuracy: 0.9867 - val_loss: 0.3067 - val_accuracy: 0.9467\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.2756 - accuracy: 0.9867 - val_loss: 0.3071 - val_accuracy: 0.9467\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.2733 - accuracy: 0.9867 - val_loss: 0.3054 - val_accuracy: 0.9467\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2704 - accuracy: 0.9867 - val_loss: 0.3041 - val_accuracy: 0.9467\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.2680 - accuracy: 0.9867 - val_loss: 0.3027 - val_accuracy: 0.9467\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.2659 - accuracy: 0.9867 - val_loss: 0.2983 - val_accuracy: 0.9467\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.2628 - accuracy: 0.9867 - val_loss: 0.2957 - val_accuracy: 0.9467\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.2602 - accuracy: 0.9867 - val_loss: 0.2944 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.2581 - accuracy: 0.9867 - val_loss: 0.2959 - val_accuracy: 0.9467\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2552 - accuracy: 0.9867 - val_loss: 0.2932 - val_accuracy: 0.9467\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.2530 - accuracy: 0.9867 - val_loss: 0.2942 - val_accuracy: 0.9467\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2503 - accuracy: 0.9867 - val_loss: 0.2910 - val_accuracy: 0.9467\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2474 - accuracy: 0.9867 - val_loss: 0.2871 - val_accuracy: 0.9467\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.2448 - accuracy: 0.9867 - val_loss: 0.2851 - val_accuracy: 0.9467\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.2422 - accuracy: 0.9867 - val_loss: 0.2842 - val_accuracy: 0.9467\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.2395 - accuracy: 0.9867 - val_loss: 0.2818 - val_accuracy: 0.9467\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.2375 - accuracy: 0.9867 - val_loss: 0.2831 - val_accuracy: 0.9467\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.2350 - accuracy: 0.9867 - val_loss: 0.2799 - val_accuracy: 0.9467\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.96 - 0s 320us/sample - loss: 0.2322 - accuracy: 0.9867 - val_loss: 0.2793 - val_accuracy: 0.9467\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2301 - accuracy: 0.9867 - val_loss: 0.2785 - val_accuracy: 0.9467\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.2281 - accuracy: 0.9867 - val_loss: 0.2773 - val_accuracy: 0.9467\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.2251 - accuracy: 0.9867 - val_loss: 0.2752 - val_accuracy: 0.9467\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.2235 - accuracy: 0.9867 - val_loss: 0.2724 - val_accuracy: 0.9467\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.2197 - accuracy: 0.9867 - val_loss: 0.2702 - val_accuracy: 0.9467\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.2180 - accuracy: 0.9867 - val_loss: 0.2688 - val_accuracy: 0.9467\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.2155 - accuracy: 0.9867 - val_loss: 0.2650 - val_accuracy: 0.9467\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.2126 - accuracy: 0.9867 - val_loss: 0.2638 - val_accuracy: 0.9467\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.2105 - accuracy: 0.9867 - val_loss: 0.2650 - val_accuracy: 0.9467\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.2079 - accuracy: 0.9867 - val_loss: 0.2610 - val_accuracy: 0.9467\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.2059 - accuracy: 0.9867 - val_loss: 0.2620 - val_accuracy: 0.9467\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.2038 - accuracy: 0.9867 - val_loss: 0.2585 - val_accuracy: 0.9467\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.2022 - accuracy: 0.9867 - val_loss: 0.2601 - val_accuracy: 0.9467\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.1997 - accuracy: 0.9867 - val_loss: 0.2597 - val_accuracy: 0.9467\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.1977 - accuracy: 0.9867 - val_loss: 0.2576 - val_accuracy: 0.9467\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.1953 - accuracy: 0.9867 - val_loss: 0.2560 - val_accuracy: 0.9467\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.1932 - accuracy: 0.9867 - val_loss: 0.2537 - val_accuracy: 0.9467\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.1910 - accuracy: 0.9867 - val_loss: 0.2515 - val_accuracy: 0.9467\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.1889 - accuracy: 0.9867 - val_loss: 0.2503 - val_accuracy: 0.9467\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.1868 - accuracy: 0.9867 - val_loss: 0.2495 - val_accuracy: 0.9467\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.1841 - accuracy: 0.9867 - val_loss: 0.2478 - val_accuracy: 0.9467\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.1825 - accuracy: 0.9867 - val_loss: 0.2466 - val_accuracy: 0.9467\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.1795 - accuracy: 0.9867 - val_loss: 0.2463 - val_accuracy: 0.9467\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.1775 - accuracy: 0.9867 - val_loss: 0.2456 - val_accuracy: 0.9467\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.1754 - accuracy: 0.9867 - val_loss: 0.2439 - val_accuracy: 0.9467\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.1731 - accuracy: 0.9867 - val_loss: 0.2428 - val_accuracy: 0.9467\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.1724 - accuracy: 0.9867 - val_loss: 0.2415 - val_accuracy: 0.9467\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.1698 - accuracy: 0.9867 - val_loss: 0.2380 - val_accuracy: 0.9467\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.1685 - accuracy: 0.9867 - val_loss: 0.2385 - val_accuracy: 0.9467\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.1662 - accuracy: 0.9867 - val_loss: 0.2379 - val_accuracy: 0.9467\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.1636 - accuracy: 0.9867 - val_loss: 0.2378 - val_accuracy: 0.9467\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.1619 - accuracy: 0.9867 - val_loss: 0.2371 - val_accuracy: 0.9467\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.1611 - accuracy: 0.9867 - val_loss: 0.2395 - val_accuracy: 0.9467\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.1588 - accuracy: 0.9867 - val_loss: 0.2383 - val_accuracy: 0.9467\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.1571 - accuracy: 0.9867 - val_loss: 0.2380 - val_accuracy: 0.9467\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.1559 - accuracy: 0.9867 - val_loss: 0.2365 - val_accuracy: 0.9467\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.1549 - accuracy: 0.9867 - val_loss: 0.2354 - val_accuracy: 0.9467\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.1535 - accuracy: 0.9867 - val_loss: 0.2377 - val_accuracy: 0.9467\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.1520 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9333\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9467\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.1488 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9467\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.1471 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9467\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.1464 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9467\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.1451 - accuracy: 0.9867 - val_loss: 0.2282 - val_accuracy: 0.9467\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.1435 - accuracy: 0.9867 - val_loss: 0.2290 - val_accuracy: 0.9467\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.1424 - accuracy: 0.9867 - val_loss: 0.2315 - val_accuracy: 0.9467\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.1411 - accuracy: 0.9867 - val_loss: 0.2309 - val_accuracy: 0.9467\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.1400 - accuracy: 0.9867 - val_loss: 0.2334 - val_accuracy: 0.9333\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.1385 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9333\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 380us/sample - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9333\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 396us/sample - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 534us/sample - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9333\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 552us/sample - loss: 0.1345 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9333\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 475us/sample - loss: 0.1331 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9333\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 721us/sample - loss: 0.1315 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9333\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 686us/sample - loss: 0.1313 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9333\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 490us/sample - loss: 0.1297 - accuracy: 0.9867 - val_loss: 0.2263 - val_accuracy: 0.9333\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.1290 - accuracy: 0.9867 - val_loss: 0.2248 - val_accuracy: 0.9333\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.1276 - accuracy: 0.9867 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.1261 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9333\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.1248 - accuracy: 0.9867 - val_loss: 0.2183 - val_accuracy: 0.9333\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.1242 - accuracy: 0.9867 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.1215 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9333\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9333\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.1197 - accuracy: 0.9867 - val_loss: 0.2159 - val_accuracy: 0.9333\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9333\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9333\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9333\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.1168 - accuracy: 0.9867 - val_loss: 0.2220 - val_accuracy: 0.9333\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9333\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9333\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9333\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9333\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.1117 - accuracy: 0.9867 - val_loss: 0.2141 - val_accuracy: 0.9333\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.1107 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9333\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9333\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9467\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9333\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 382us/sample - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9467\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9467\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9467\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9467\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9467\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.1033 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9467\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9467\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9467\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9467\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9467\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9467\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9467\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9467\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9467\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9467\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9467\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9467\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9467\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9467\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9467\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9467\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9467\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9467\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9467\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9467\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9467\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9467\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9467\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 494us/sample - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9467\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9467\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9467\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9467\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9467\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9467\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9467\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 363us/sample - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9467\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9467\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 425us/sample - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9467\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9467\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9467\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9467\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9467\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9467\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9467\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9467\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 250us/sample - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9467\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 1.00 - 0s 379us/sample - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9467\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9467\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9467\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9467\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9467\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9467\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9467\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9467\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9467\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9467\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9467\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9467\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 555us/sample - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9467\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9467\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9467\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9467\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9467\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9467\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9467\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9467\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9467\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9467\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 257us/sample - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9467\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9467\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9467\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 259us/sample - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9467\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9467\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9467\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 450us/sample - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9467\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9467\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9467\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9467\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 362us/sample - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9467\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9467\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 254us/sample - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9467\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9467\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9467\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9467\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 296us/sample - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9467\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9467\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 1.00 - 0s 396us/sample - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9467\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 400us/sample - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9467\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9467\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9467\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9467\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9467\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9467\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9467\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9467\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9467\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9467\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9467\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9467\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9467\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9467\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9467\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9467\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9467\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9467\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9467\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9467\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9467\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9467\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9467\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9467\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9467\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9467\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 421us/sample - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9333\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9467\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9333\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9467\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9467\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9467\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 386us/sample - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9467\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9467\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9467\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9333\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9333\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9333\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9467\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9467\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9467\n",
      "Epoch 445/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 318us/sample - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9333\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9333\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9467\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9467\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9333\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9333\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9333\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9333\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9333\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9333\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9333\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9333\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9467\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9333\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9333\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 462us/sample - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9333\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9333\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9333\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9467\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9333\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9333\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9333\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9200\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9200\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9200\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9200\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9200\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9200\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9200\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 293us/sample - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9333\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9200\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9200\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9067\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9200\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9200\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 277us/sample - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9067\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9067\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9067\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9067\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9067\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9067\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9200\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 287us/sample - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9067\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9200\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9067\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9067\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9067\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.9067\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9067\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9067\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9200\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9067\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 297us/sample - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9067\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9067\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9067\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "history = neural_network_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?\n",
    " - med 5 lager och 5 noder i varje lager utom output-lagret har vi 133 träningsbara parametrar. Är det rimligt givet 75 obs i träningsdata setet?\n",
    " - Övertränar nätverket på träningsdatat?\n",
    " - Vad händer om du förändrar antalet noder i vår modell, hur påverkar det accuracy för tränings och valideringsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  1.0\n",
      "accuracy, test:  0.9066667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediktion och tolkning\n",
    "\n",
    "Vi predicerar de 5 första observationerna från vårt test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicerad kategori\n",
      " [0 0 1 0 0]\n",
      "\n",
      "Sannolikheter bakom prediktionerna\n",
      " ['setosa' 'versicolor' 'virginica'] \n",
      " [[9.993e-01 6.696e-04 0.000e+00]\n",
      " [9.974e-01 2.612e-03 0.000e+00]\n",
      " [3.062e-02 5.647e-01 4.046e-01]\n",
      " [9.967e-01 3.251e-03 0.000e+00]\n",
      " [9.987e-01 1.289e-03 0.000e+00]]\n",
      "\n",
      "Den sanna kategorin\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Anger vilken kategori , tillbaka till 0 = 'setosa' 1 = 'versicolor', 2 = 'virginica'\n",
    "category = neural_network_model.predict_classes(X_test[0:5])\n",
    "\n",
    "probabilities = neural_network_model.predict_proba(X_test[0:5])\n",
    "\n",
    "\n",
    "print(\"\\nPredicerad kategori\\n\",category)\n",
    "\n",
    "print(\"\\nSannolikheter bakom prediktionerna\\n\",names,\"\\n\",probabilities)\n",
    "\n",
    "print(\"\\nDen sanna kategorin\\n\",Y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurala nätverk - Regularisering\n",
    "\n",
    "Vi testar att köra vårat överdrivet stora neurala nätverk igen, denna gång med L1 och L2-regularisering\n",
    "- Vi utvärderar om introduktion av L1 och L2-regularisering kan mitigera överträning på träningsdatat\n",
    "- Testa gärna att förändra  antal_hidden_layer, antal_noder samt l1- / l2_reg_rate och utforska vad som händer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 17ms/sample - loss: 1.4700 - accuracy: 0.3600 - val_loss: 1.4872 - val_accuracy: 0.3067\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 1.4580 - accuracy: 0.3467 - val_loss: 1.4798 - val_accuracy: 0.3067\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 416us/sample - loss: 1.4498 - accuracy: 0.3467 - val_loss: 1.4734 - val_accuracy: 0.3067\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 1.4438 - accuracy: 0.3467 - val_loss: 1.4674 - val_accuracy: 0.3067\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 1.4380 - accuracy: 0.3333 - val_loss: 1.4628 - val_accuracy: 0.3067\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 1.4321 - accuracy: 0.3333 - val_loss: 1.4575 - val_accuracy: 0.3067\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 1.4268 - accuracy: 0.3467 - val_loss: 1.4527 - val_accuracy: 0.3067\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 1.4220 - accuracy: 0.3333 - val_loss: 1.4478 - val_accuracy: 0.3067\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 1.4174 - accuracy: 0.3200 - val_loss: 1.4430 - val_accuracy: 0.3067\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 1.4119 - accuracy: 0.3200 - val_loss: 1.4383 - val_accuracy: 0.3067\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 1.4069 - accuracy: 0.3200 - val_loss: 1.4333 - val_accuracy: 0.3200\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 1.4016 - accuracy: 0.3200 - val_loss: 1.4275 - val_accuracy: 0.3067\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 384us/sample - loss: 1.3961 - accuracy: 0.3467 - val_loss: 1.4224 - val_accuracy: 0.3067\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 1.3912 - accuracy: 0.3600 - val_loss: 1.4165 - val_accuracy: 0.3067\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 1.3860 - accuracy: 0.3733 - val_loss: 1.4118 - val_accuracy: 0.3067\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 1.3811 - accuracy: 0.3733 - val_loss: 1.4062 - val_accuracy: 0.3067\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 1.3755 - accuracy: 0.3733 - val_loss: 1.4004 - val_accuracy: 0.2933\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 1.3705 - accuracy: 0.3600 - val_loss: 1.3952 - val_accuracy: 0.2933\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 1.3645 - accuracy: 0.3867 - val_loss: 1.3900 - val_accuracy: 0.3067\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 1.3594 - accuracy: 0.4000 - val_loss: 1.3840 - val_accuracy: 0.3333\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 1.3532 - accuracy: 0.4000 - val_loss: 1.3776 - val_accuracy: 0.2933\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 1.3473 - accuracy: 0.3867 - val_loss: 1.3719 - val_accuracy: 0.2933\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 1.3417 - accuracy: 0.4000 - val_loss: 1.3668 - val_accuracy: 0.3467\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 1.3362 - accuracy: 0.4667 - val_loss: 1.3604 - val_accuracy: 0.3333\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 1.3305 - accuracy: 0.5067 - val_loss: 1.3547 - val_accuracy: 0.4133\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 1.3249 - accuracy: 0.5733 - val_loss: 1.3491 - val_accuracy: 0.4267\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 1.3198 - accuracy: 0.5333 - val_loss: 1.3436 - val_accuracy: 0.4267\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 1.3133 - accuracy: 0.5733 - val_loss: 1.3378 - val_accuracy: 0.4533\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 1.3074 - accuracy: 0.6133 - val_loss: 1.3310 - val_accuracy: 0.4400\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.3009 - accuracy: 0.6133 - val_loss: 1.3246 - val_accuracy: 0.4933\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 1.2952 - accuracy: 0.6400 - val_loss: 1.3179 - val_accuracy: 0.5067\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 1.2888 - accuracy: 0.6533 - val_loss: 1.3116 - val_accuracy: 0.5200\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 1.2822 - accuracy: 0.6267 - val_loss: 1.3055 - val_accuracy: 0.5467\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 1.2764 - accuracy: 0.6267 - val_loss: 1.3002 - val_accuracy: 0.5467\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 1.2706 - accuracy: 0.6533 - val_loss: 1.2936 - val_accuracy: 0.5467\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 1.2646 - accuracy: 0.6267 - val_loss: 1.2871 - val_accuracy: 0.5867\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 1.2592 - accuracy: 0.6400 - val_loss: 1.2820 - val_accuracy: 0.6000\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 1.2532 - accuracy: 0.6533 - val_loss: 1.2753 - val_accuracy: 0.5733\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 1.2470 - accuracy: 0.6533 - val_loss: 1.2690 - val_accuracy: 0.6133\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 1.2409 - accuracy: 0.6533 - val_loss: 1.2619 - val_accuracy: 0.6000\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 1.2349 - accuracy: 0.6400 - val_loss: 1.2547 - val_accuracy: 0.5867\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 1.2286 - accuracy: 0.6000 - val_loss: 1.2490 - val_accuracy: 0.6000\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 1.2228 - accuracy: 0.6133 - val_loss: 1.2416 - val_accuracy: 0.5733\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 1.2164 - accuracy: 0.5600 - val_loss: 1.2349 - val_accuracy: 0.5600\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 270us/sample - loss: 1.2103 - accuracy: 0.5867 - val_loss: 1.2297 - val_accuracy: 0.5733\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 1.2043 - accuracy: 0.5867 - val_loss: 1.2240 - val_accuracy: 0.5733\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 1.1987 - accuracy: 0.6267 - val_loss: 1.2183 - val_accuracy: 0.5867\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 1.1927 - accuracy: 0.6267 - val_loss: 1.2120 - val_accuracy: 0.6000\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 1.1867 - accuracy: 0.6400 - val_loss: 1.2051 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 1.1805 - accuracy: 0.5867 - val_loss: 1.1986 - val_accuracy: 0.6267\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 1.1752 - accuracy: 0.6000 - val_loss: 1.1931 - val_accuracy: 0.6267\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 1.1695 - accuracy: 0.6000 - val_loss: 1.1869 - val_accuracy: 0.6267\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 1.1637 - accuracy: 0.6000 - val_loss: 1.1819 - val_accuracy: 0.6267\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 1.1583 - accuracy: 0.6000 - val_loss: 1.1760 - val_accuracy: 0.6267\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 1.1539 - accuracy: 0.6133 - val_loss: 1.1718 - val_accuracy: 0.6400\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 1.1479 - accuracy: 0.6133 - val_loss: 1.1654 - val_accuracy: 0.6267\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 1.1427 - accuracy: 0.6000 - val_loss: 1.1611 - val_accuracy: 0.6267\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 548us/sample - loss: 1.1377 - accuracy: 0.6000 - val_loss: 1.1557 - val_accuracy: 0.6533\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 1.1332 - accuracy: 0.6000 - val_loss: 1.1514 - val_accuracy: 0.7333\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 343us/sample - loss: 1.1284 - accuracy: 0.6667 - val_loss: 1.1467 - val_accuracy: 0.7333\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 276us/sample - loss: 1.1235 - accuracy: 0.6533 - val_loss: 1.1409 - val_accuracy: 0.7200\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 1.1178 - accuracy: 0.6533 - val_loss: 1.1363 - val_accuracy: 0.7200\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 1.1133 - accuracy: 0.6667 - val_loss: 1.1323 - val_accuracy: 0.7333\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 1.1085 - accuracy: 0.6933 - val_loss: 1.1268 - val_accuracy: 0.7200\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 1.1036 - accuracy: 0.6667 - val_loss: 1.1227 - val_accuracy: 0.7333\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 1.0995 - accuracy: 0.7200 - val_loss: 1.1173 - val_accuracy: 0.7200\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 1.0945 - accuracy: 0.7200 - val_loss: 1.1113 - val_accuracy: 0.7067\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 1.0890 - accuracy: 0.6533 - val_loss: 1.1065 - val_accuracy: 0.7067\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 1.0844 - accuracy: 0.6667 - val_loss: 1.1008 - val_accuracy: 0.6933\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 1.0795 - accuracy: 0.6267 - val_loss: 1.0955 - val_accuracy: 0.6933\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 1.0754 - accuracy: 0.6400 - val_loss: 1.0923 - val_accuracy: 0.6933\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 1.0712 - accuracy: 0.6533 - val_loss: 1.0876 - val_accuracy: 0.7067\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 1.0665 - accuracy: 0.6533 - val_loss: 1.0831 - val_accuracy: 0.7067\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 1.0622 - accuracy: 0.6533 - val_loss: 1.0786 - val_accuracy: 0.7200\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 374us/sample - loss: 1.0588 - accuracy: 0.6667 - val_loss: 1.0733 - val_accuracy: 0.7067\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 1.0538 - accuracy: 0.6400 - val_loss: 1.0703 - val_accuracy: 0.7333\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 1.0501 - accuracy: 0.6667 - val_loss: 1.0651 - val_accuracy: 0.7067\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 1.0455 - accuracy: 0.6533 - val_loss: 1.0614 - val_accuracy: 0.7333\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 1.0417 - accuracy: 0.6800 - val_loss: 1.0584 - val_accuracy: 0.7467\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 1.0381 - accuracy: 0.7467 - val_loss: 1.0544 - val_accuracy: 0.7467\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 1.0338 - accuracy: 0.7600 - val_loss: 1.0499 - val_accuracy: 0.7467\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 1.0300 - accuracy: 0.7733 - val_loss: 1.0453 - val_accuracy: 0.7467\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 1.0257 - accuracy: 0.7067 - val_loss: 1.0418 - val_accuracy: 0.7733\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 1.0218 - accuracy: 0.7733 - val_loss: 1.0387 - val_accuracy: 0.8400\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 348us/sample - loss: 1.0180 - accuracy: 0.8000 - val_loss: 1.0332 - val_accuracy: 0.8133\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 1.0138 - accuracy: 0.7733 - val_loss: 1.0294 - val_accuracy: 0.8267\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 1.0098 - accuracy: 0.7733 - val_loss: 1.0245 - val_accuracy: 0.8000\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 418us/sample - loss: 1.0061 - accuracy: 0.7733 - val_loss: 1.0199 - val_accuracy: 0.7600\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 1.0023 - accuracy: 0.7733 - val_loss: 1.0177 - val_accuracy: 0.8400\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.9987 - accuracy: 0.7867 - val_loss: 1.0150 - val_accuracy: 0.8400\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.9950 - accuracy: 0.8000 - val_loss: 1.0124 - val_accuracy: 0.8533\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.9927 - accuracy: 0.8000 - val_loss: 1.0099 - val_accuracy: 0.8133\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 510us/sample - loss: 0.9881 - accuracy: 0.8133 - val_loss: 1.0054 - val_accuracy: 0.8400\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 307us/sample - loss: 0.9841 - accuracy: 0.8000 - val_loss: 1.0017 - val_accuracy: 0.8400\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.9806 - accuracy: 0.8000 - val_loss: 0.9975 - val_accuracy: 0.8400\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.9778 - accuracy: 0.8000 - val_loss: 0.9936 - val_accuracy: 0.8400\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 325us/sample - loss: 0.9736 - accuracy: 0.8000 - val_loss: 0.9916 - val_accuracy: 0.8267\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.9695 - accuracy: 0.8133 - val_loss: 0.9861 - val_accuracy: 0.8400\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 540us/sample - loss: 0.9661 - accuracy: 0.8133 - val_loss: 0.9831 - val_accuracy: 0.8133\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 406us/sample - loss: 0.9631 - accuracy: 0.8000 - val_loss: 0.9813 - val_accuracy: 0.8267\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 420us/sample - loss: 0.9597 - accuracy: 0.8133 - val_loss: 0.9792 - val_accuracy: 0.8267\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 513us/sample - loss: 0.9560 - accuracy: 0.8000 - val_loss: 0.9763 - val_accuracy: 0.8133\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 641us/sample - loss: 0.9525 - accuracy: 0.8000 - val_loss: 0.9728 - val_accuracy: 0.8133\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.9492 - accuracy: 0.8133 - val_loss: 0.9700 - val_accuracy: 0.8133\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.9470 - accuracy: 0.8000 - val_loss: 0.9674 - val_accuracy: 0.8133\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 338us/sample - loss: 0.9427 - accuracy: 0.8133 - val_loss: 0.9640 - val_accuracy: 0.8133\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 466us/sample - loss: 0.9395 - accuracy: 0.8133 - val_loss: 0.9604 - val_accuracy: 0.8133\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 498us/sample - loss: 0.9365 - accuracy: 0.8133 - val_loss: 0.9568 - val_accuracy: 0.8133\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.9338 - accuracy: 0.8000 - val_loss: 0.9540 - val_accuracy: 0.8133\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 548us/sample - loss: 0.9295 - accuracy: 0.8133 - val_loss: 0.9493 - val_accuracy: 0.8267\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.9256 - accuracy: 0.8133 - val_loss: 0.9458 - val_accuracy: 0.8267\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 699us/sample - loss: 0.9231 - accuracy: 0.8400 - val_loss: 0.9436 - val_accuracy: 0.8133\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 558us/sample - loss: 0.9193 - accuracy: 0.8267 - val_loss: 0.9411 - val_accuracy: 0.8133\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.9159 - accuracy: 0.8267 - val_loss: 0.9387 - val_accuracy: 0.8267\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 411us/sample - loss: 0.9127 - accuracy: 0.8400 - val_loss: 0.9334 - val_accuracy: 0.8267\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 461us/sample - loss: 0.9102 - accuracy: 0.8267 - val_loss: 0.9293 - val_accuracy: 0.8267\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 453us/sample - loss: 0.9067 - accuracy: 0.8133 - val_loss: 0.9291 - val_accuracy: 0.8267\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 405us/sample - loss: 0.9033 - accuracy: 0.8400 - val_loss: 0.9238 - val_accuracy: 0.8267\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 479us/sample - loss: 0.9004 - accuracy: 0.8400 - val_loss: 0.9195 - val_accuracy: 0.8267\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.8980 - accuracy: 0.8400 - val_loss: 0.9168 - val_accuracy: 0.8267\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 261us/sample - loss: 0.8945 - accuracy: 0.8267 - val_loss: 0.9136 - val_accuracy: 0.8267\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 505us/sample - loss: 0.8915 - accuracy: 0.8267 - val_loss: 0.9116 - val_accuracy: 0.8267\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.8886 - accuracy: 0.8267 - val_loss: 0.9112 - val_accuracy: 0.8400\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 644us/sample - loss: 0.8851 - accuracy: 0.8533 - val_loss: 0.9075 - val_accuracy: 0.8267\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 738us/sample - loss: 0.8829 - accuracy: 0.8267 - val_loss: 0.9044 - val_accuracy: 0.8267\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 641us/sample - loss: 0.8791 - accuracy: 0.8400 - val_loss: 0.9022 - val_accuracy: 0.8400\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 563us/sample - loss: 0.8768 - accuracy: 0.8400 - val_loss: 0.9017 - val_accuracy: 0.8400\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.8735 - accuracy: 0.8533 - val_loss: 0.8988 - val_accuracy: 0.8400\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.8707 - accuracy: 0.8533 - val_loss: 0.8954 - val_accuracy: 0.8400\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.8686 - accuracy: 0.8533 - val_loss: 0.8905 - val_accuracy: 0.8400\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 378us/sample - loss: 0.8653 - accuracy: 0.8400 - val_loss: 0.8888 - val_accuracy: 0.8400\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.8619 - accuracy: 0.8533 - val_loss: 0.8841 - val_accuracy: 0.8400\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.8599 - accuracy: 0.8533 - val_loss: 0.8801 - val_accuracy: 0.8267\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.8575 - accuracy: 0.8267 - val_loss: 0.8786 - val_accuracy: 0.8400\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 354us/sample - loss: 0.8539 - accuracy: 0.8533 - val_loss: 0.8758 - val_accuracy: 0.8400\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.8516 - accuracy: 0.8533 - val_loss: 0.8718 - val_accuracy: 0.8400\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.8486 - accuracy: 0.8267 - val_loss: 0.8708 - val_accuracy: 0.8400\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 368us/sample - loss: 0.8470 - accuracy: 0.8533 - val_loss: 0.8670 - val_accuracy: 0.8400\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.8216 - accuracy: 0.93 - 0s 798us/sample - loss: 0.8431 - accuracy: 0.8533 - val_loss: 0.8659 - val_accuracy: 0.8400\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 647us/sample - loss: 0.8402 - accuracy: 0.8533 - val_loss: 0.8618 - val_accuracy: 0.8533\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 663us/sample - loss: 0.8381 - accuracy: 0.8533 - val_loss: 0.8591 - val_accuracy: 0.8533\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 484us/sample - loss: 0.8356 - accuracy: 0.8533 - val_loss: 0.8585 - val_accuracy: 0.8400\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 407us/sample - loss: 0.8319 - accuracy: 0.8533 - val_loss: 0.8564 - val_accuracy: 0.8400\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.8300 - accuracy: 0.8533 - val_loss: 0.8549 - val_accuracy: 0.8533\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 0.8261 - accuracy: 0.8533 - val_loss: 0.8537 - val_accuracy: 0.8667\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 447us/sample - loss: 0.8240 - accuracy: 0.8533 - val_loss: 0.8517 - val_accuracy: 0.8667\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 478us/sample - loss: 0.8207 - accuracy: 0.8533 - val_loss: 0.8463 - val_accuracy: 0.8533\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 451us/sample - loss: 0.8180 - accuracy: 0.8533 - val_loss: 0.8455 - val_accuracy: 0.8667\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 337us/sample - loss: 0.8152 - accuracy: 0.8533 - val_loss: 0.8414 - val_accuracy: 0.8667\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.8128 - accuracy: 0.8533 - val_loss: 0.8370 - val_accuracy: 0.8533\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.8169 - accuracy: 0.81 - 0s 299us/sample - loss: 0.8093 - accuracy: 0.8533 - val_loss: 0.8356 - val_accuracy: 0.8667\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.8066 - accuracy: 0.8533 - val_loss: 0.8334 - val_accuracy: 0.8667\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.8057 - accuracy: 0.8533 - val_loss: 0.8285 - val_accuracy: 0.8533\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.8017 - accuracy: 0.8533 - val_loss: 0.8255 - val_accuracy: 0.8400\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.7990 - accuracy: 0.8533 - val_loss: 0.8234 - val_accuracy: 0.8533\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 573us/sample - loss: 0.7970 - accuracy: 0.8533 - val_loss: 0.8206 - val_accuracy: 0.8533\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.7944 - accuracy: 0.8533 - val_loss: 0.8177 - val_accuracy: 0.8533\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.7913 - accuracy: 0.8533 - val_loss: 0.8174 - val_accuracy: 0.8667\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 300us/sample - loss: 0.7894 - accuracy: 0.8533 - val_loss: 0.8144 - val_accuracy: 0.8533\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.7860 - accuracy: 0.8533 - val_loss: 0.8121 - val_accuracy: 0.8667\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.7840 - accuracy: 0.8533 - val_loss: 0.8096 - val_accuracy: 0.8667\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.7803 - accuracy: 0.8533 - val_loss: 0.8093 - val_accuracy: 0.8800\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.7775 - accuracy: 0.8533 - val_loss: 0.8061 - val_accuracy: 0.8800\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.7750 - accuracy: 0.8533 - val_loss: 0.8020 - val_accuracy: 0.8667\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.7735 - accuracy: 0.8533 - val_loss: 0.7981 - val_accuracy: 0.8533\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.7702 - accuracy: 0.8533 - val_loss: 0.7991 - val_accuracy: 0.8800\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 353us/sample - loss: 0.7673 - accuracy: 0.8533 - val_loss: 0.7958 - val_accuracy: 0.8800\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.7650 - accuracy: 0.8533 - val_loss: 0.7944 - val_accuracy: 0.8800\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 320us/sample - loss: 0.7633 - accuracy: 0.8400 - val_loss: 0.7914 - val_accuracy: 0.8800\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 355us/sample - loss: 0.7598 - accuracy: 0.8533 - val_loss: 0.7881 - val_accuracy: 0.8800\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 338us/sample - loss: 0.7577 - accuracy: 0.8533 - val_loss: 0.7907 - val_accuracy: 0.8800\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.7553 - accuracy: 0.8533 - val_loss: 0.7871 - val_accuracy: 0.8800\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.7527 - accuracy: 0.8533 - val_loss: 0.7853 - val_accuracy: 0.8800\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.7509 - accuracy: 0.8400 - val_loss: 0.7870 - val_accuracy: 0.8800\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 526us/sample - loss: 0.7484 - accuracy: 0.8400 - val_loss: 0.7806 - val_accuracy: 0.8800\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 0.7468 - accuracy: 0.8400 - val_loss: 0.7761 - val_accuracy: 0.8800\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 458us/sample - loss: 0.7440 - accuracy: 0.8533 - val_loss: 0.7723 - val_accuracy: 0.8800\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.7418 - accuracy: 0.8533 - val_loss: 0.7716 - val_accuracy: 0.8800\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 874us/sample - loss: 0.7394 - accuracy: 0.8533 - val_loss: 0.7734 - val_accuracy: 0.8800\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 813us/sample - loss: 0.7366 - accuracy: 0.8400 - val_loss: 0.7688 - val_accuracy: 0.8800\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 912us/sample - loss: 0.7352 - accuracy: 0.8533 - val_loss: 0.7648 - val_accuracy: 0.8800\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 653us/sample - loss: 0.7333 - accuracy: 0.8400 - val_loss: 0.7613 - val_accuracy: 0.8800\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 785us/sample - loss: 0.7303 - accuracy: 0.8533 - val_loss: 0.7614 - val_accuracy: 0.8800\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 478us/sample - loss: 0.7285 - accuracy: 0.8533 - val_loss: 0.7640 - val_accuracy: 0.8800\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.7254 - accuracy: 0.8400 - val_loss: 0.7589 - val_accuracy: 0.8800\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 487us/sample - loss: 0.7230 - accuracy: 0.8400 - val_loss: 0.7589 - val_accuracy: 0.8800\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.7208 - accuracy: 0.8400 - val_loss: 0.7548 - val_accuracy: 0.8800\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 419us/sample - loss: 0.7258 - accuracy: 0.8533 - val_loss: 0.7551 - val_accuracy: 0.8800\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.7166 - accuracy: 0.8400 - val_loss: 0.7524 - val_accuracy: 0.8800\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.7145 - accuracy: 0.8400 - val_loss: 0.7502 - val_accuracy: 0.8800\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.7136 - accuracy: 0.8400 - val_loss: 0.7516 - val_accuracy: 0.8800\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.7117 - accuracy: 0.8533 - val_loss: 0.7446 - val_accuracy: 0.8800\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.7088 - accuracy: 0.8400 - val_loss: 0.7413 - val_accuracy: 0.8800\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.7070 - accuracy: 0.8533 - val_loss: 0.7436 - val_accuracy: 0.8800\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 352us/sample - loss: 0.7049 - accuracy: 0.8533 - val_loss: 0.7434 - val_accuracy: 0.8800\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.7023 - accuracy: 0.8533 - val_loss: 0.7385 - val_accuracy: 0.8800\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 547us/sample - loss: 0.7001 - accuracy: 0.8533 - val_loss: 0.7389 - val_accuracy: 0.8800\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 477us/sample - loss: 0.6992 - accuracy: 0.8533 - val_loss: 0.7414 - val_accuracy: 0.8933\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 439us/sample - loss: 0.6979 - accuracy: 0.8533 - val_loss: 0.7391 - val_accuracy: 0.8800\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 452us/sample - loss: 0.6955 - accuracy: 0.8533 - val_loss: 0.7408 - val_accuracy: 0.8933\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.6926 - accuracy: 0.8533 - val_loss: 0.7346 - val_accuracy: 0.8800\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 327us/sample - loss: 0.6918 - accuracy: 0.8533 - val_loss: 0.7299 - val_accuracy: 0.8800\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 291us/sample - loss: 0.6884 - accuracy: 0.8533 - val_loss: 0.7254 - val_accuracy: 0.8800\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 532us/sample - loss: 0.6861 - accuracy: 0.8533 - val_loss: 0.7216 - val_accuracy: 0.8800\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.6855 - accuracy: 0.8533 - val_loss: 0.7190 - val_accuracy: 0.8933\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.6827 - accuracy: 0.8667 - val_loss: 0.7222 - val_accuracy: 0.8800\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.6797 - accuracy: 0.8533 - val_loss: 0.7187 - val_accuracy: 0.8800\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.6777 - accuracy: 0.8533 - val_loss: 0.7199 - val_accuracy: 0.8933\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.6756 - accuracy: 0.8533 - val_loss: 0.7170 - val_accuracy: 0.8800\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 349us/sample - loss: 0.6734 - accuracy: 0.8533 - val_loss: 0.7172 - val_accuracy: 0.8933\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.6724 - accuracy: 0.8533 - val_loss: 0.7084 - val_accuracy: 0.8933\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.6697 - accuracy: 0.8667 - val_loss: 0.7072 - val_accuracy: 0.8800\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.6673 - accuracy: 0.8533 - val_loss: 0.7043 - val_accuracy: 0.8933\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.6654 - accuracy: 0.8800 - val_loss: 0.7035 - val_accuracy: 0.8933\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.6630 - accuracy: 0.8533 - val_loss: 0.6991 - val_accuracy: 0.8933\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.6609 - accuracy: 0.8800 - val_loss: 0.6979 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.6594 - accuracy: 0.8800 - val_loss: 0.7006 - val_accuracy: 0.8933\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 267us/sample - loss: 0.6564 - accuracy: 0.8533 - val_loss: 0.7040 - val_accuracy: 0.8933\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 323us/sample - loss: 0.6543 - accuracy: 0.8533 - val_loss: 0.6951 - val_accuracy: 0.8933\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.6524 - accuracy: 0.8667 - val_loss: 0.6991 - val_accuracy: 0.8933\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 422us/sample - loss: 0.6501 - accuracy: 0.8533 - val_loss: 0.6944 - val_accuracy: 0.8933\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.6494 - accuracy: 0.8533 - val_loss: 0.6916 - val_accuracy: 0.8933\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.6461 - accuracy: 0.8533 - val_loss: 0.6860 - val_accuracy: 0.8933\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.6448 - accuracy: 0.8800 - val_loss: 0.6881 - val_accuracy: 0.8933\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.6420 - accuracy: 0.8533 - val_loss: 0.6877 - val_accuracy: 0.8933\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.6400 - accuracy: 0.8667 - val_loss: 0.6887 - val_accuracy: 0.8933\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.6388 - accuracy: 0.8533 - val_loss: 0.6844 - val_accuracy: 0.8933\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.6356 - accuracy: 0.8533 - val_loss: 0.6800 - val_accuracy: 0.9067\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 318us/sample - loss: 0.6335 - accuracy: 0.8800 - val_loss: 0.6788 - val_accuracy: 0.9067\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.6327 - accuracy: 0.8800 - val_loss: 0.6795 - val_accuracy: 0.9067\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.6298 - accuracy: 0.8667 - val_loss: 0.6735 - val_accuracy: 0.9067\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.6274 - accuracy: 0.8800 - val_loss: 0.6778 - val_accuracy: 0.8933\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.6249 - accuracy: 0.8933 - val_loss: 0.6733 - val_accuracy: 0.9067\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.6234 - accuracy: 0.8933 - val_loss: 0.6729 - val_accuracy: 0.9067\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.6227 - accuracy: 0.8800 - val_loss: 0.6699 - val_accuracy: 0.9067\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.6190 - accuracy: 0.8933 - val_loss: 0.6671 - val_accuracy: 0.9067\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 260us/sample - loss: 0.6180 - accuracy: 0.8933 - val_loss: 0.6652 - val_accuracy: 0.9067\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.6182 - accuracy: 0.8933 - val_loss: 0.6617 - val_accuracy: 0.9067\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.6142 - accuracy: 0.8933 - val_loss: 0.6566 - val_accuracy: 0.9200\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 424us/sample - loss: 0.6112 - accuracy: 0.8933 - val_loss: 0.6583 - val_accuracy: 0.9067\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.6090 - accuracy: 0.9067 - val_loss: 0.6553 - val_accuracy: 0.9200\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 361us/sample - loss: 0.6071 - accuracy: 0.9067 - val_loss: 0.6520 - val_accuracy: 0.9200\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 543us/sample - loss: 0.6062 - accuracy: 0.9067 - val_loss: 0.6537 - val_accuracy: 0.9067\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 513us/sample - loss: 0.6040 - accuracy: 0.9067 - val_loss: 0.6482 - val_accuracy: 0.9200\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 520us/sample - loss: 0.6018 - accuracy: 0.9067 - val_loss: 0.6473 - val_accuracy: 0.9200\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 465us/sample - loss: 0.6000 - accuracy: 0.9067 - val_loss: 0.6407 - val_accuracy: 0.9200\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 433us/sample - loss: 0.5982 - accuracy: 0.8800 - val_loss: 0.6465 - val_accuracy: 0.9200\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 507us/sample - loss: 0.5954 - accuracy: 0.9067 - val_loss: 0.6460 - val_accuracy: 0.9200\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.5938 - accuracy: 0.9067 - val_loss: 0.6459 - val_accuracy: 0.9200\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 383us/sample - loss: 0.5927 - accuracy: 0.9200 - val_loss: 0.6428 - val_accuracy: 0.9200\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 385us/sample - loss: 0.5897 - accuracy: 0.9200 - val_loss: 0.6396 - val_accuracy: 0.9200\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.5875 - accuracy: 0.9200 - val_loss: 0.6354 - val_accuracy: 0.9200\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.5853 - accuracy: 0.9200 - val_loss: 0.6354 - val_accuracy: 0.9200\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 776us/sample - loss: 0.5848 - accuracy: 0.9067 - val_loss: 0.6339 - val_accuracy: 0.9200\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 519us/sample - loss: 0.5810 - accuracy: 0.9200 - val_loss: 0.6364 - val_accuracy: 0.9333\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 467us/sample - loss: 0.5798 - accuracy: 0.9333 - val_loss: 0.6365 - val_accuracy: 0.9333\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 565us/sample - loss: 0.5782 - accuracy: 0.9467 - val_loss: 0.6339 - val_accuracy: 0.9333\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 585us/sample - loss: 0.5767 - accuracy: 0.9333 - val_loss: 0.6316 - val_accuracy: 0.9333\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 345us/sample - loss: 0.5740 - accuracy: 0.9467 - val_loss: 0.6263 - val_accuracy: 0.9333\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 408us/sample - loss: 0.5706 - accuracy: 0.9467 - val_loss: 0.6191 - val_accuracy: 0.9333\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.5700 - accuracy: 0.9200 - val_loss: 0.6236 - val_accuracy: 0.9333\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 609us/sample - loss: 0.5686 - accuracy: 0.9467 - val_loss: 0.6186 - val_accuracy: 0.9333\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.5691 - accuracy: 0.9333 - val_loss: 0.6188 - val_accuracy: 0.9333\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.5657 - accuracy: 0.9467 - val_loss: 0.6163 - val_accuracy: 0.9333\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 436us/sample - loss: 0.5624 - accuracy: 0.9467 - val_loss: 0.6201 - val_accuracy: 0.9333\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.5598 - accuracy: 0.9467 - val_loss: 0.6133 - val_accuracy: 0.9333\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 472us/sample - loss: 0.5581 - accuracy: 0.9467 - val_loss: 0.6148 - val_accuracy: 0.9333\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 681us/sample - loss: 0.5571 - accuracy: 0.9467 - val_loss: 0.6146 - val_accuracy: 0.9333\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.5550 - accuracy: 0.9467 - val_loss: 0.6133 - val_accuracy: 0.9333\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.5529 - accuracy: 0.9467 - val_loss: 0.6031 - val_accuracy: 0.9333\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.5508 - accuracy: 0.9467 - val_loss: 0.6037 - val_accuracy: 0.9333\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.5485 - accuracy: 0.9467 - val_loss: 0.6067 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 326us/sample - loss: 0.5495 - accuracy: 0.9467 - val_loss: 0.6060 - val_accuracy: 0.9333\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 288us/sample - loss: 0.5456 - accuracy: 0.9467 - val_loss: 0.6064 - val_accuracy: 0.9333\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 399us/sample - loss: 0.5439 - accuracy: 0.9467 - val_loss: 0.5946 - val_accuracy: 0.9333\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 423us/sample - loss: 0.5414 - accuracy: 0.9467 - val_loss: 0.5942 - val_accuracy: 0.9333\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 412us/sample - loss: 0.5414 - accuracy: 0.9467 - val_loss: 0.5873 - val_accuracy: 0.9333\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 413us/sample - loss: 0.5410 - accuracy: 0.9467 - val_loss: 0.5865 - val_accuracy: 0.9333\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 459us/sample - loss: 0.5367 - accuracy: 0.9467 - val_loss: 0.5889 - val_accuracy: 0.9333\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.5346 - accuracy: 0.9467 - val_loss: 0.5900 - val_accuracy: 0.9333\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 409us/sample - loss: 0.5328 - accuracy: 0.9467 - val_loss: 0.5895 - val_accuracy: 0.9333\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 643us/sample - loss: 0.5315 - accuracy: 0.9467 - val_loss: 0.5946 - val_accuracy: 0.9333\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 695us/sample - loss: 0.5300 - accuracy: 0.9467 - val_loss: 0.5960 - val_accuracy: 0.9333\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 455us/sample - loss: 0.5295 - accuracy: 0.9600 - val_loss: 0.5894 - val_accuracy: 0.9333\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 588us/sample - loss: 0.5283 - accuracy: 0.9467 - val_loss: 0.5841 - val_accuracy: 0.9333\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 427us/sample - loss: 0.5241 - accuracy: 0.9467 - val_loss: 0.5845 - val_accuracy: 0.9333\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 426us/sample - loss: 0.5257 - accuracy: 0.9467 - val_loss: 0.5798 - val_accuracy: 0.9333\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.5203 - accuracy: 0.9467 - val_loss: 0.5798 - val_accuracy: 0.9333\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.5198 - accuracy: 0.9467 - val_loss: 0.5753 - val_accuracy: 0.9333\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 592us/sample - loss: 0.5179 - accuracy: 0.9467 - val_loss: 0.5676 - val_accuracy: 0.9333\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 486us/sample - loss: 0.5157 - accuracy: 0.9467 - val_loss: 0.5688 - val_accuracy: 0.9333\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 567us/sample - loss: 0.5141 - accuracy: 0.9467 - val_loss: 0.5698 - val_accuracy: 0.9333\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 430us/sample - loss: 0.5125 - accuracy: 0.9467 - val_loss: 0.5652 - val_accuracy: 0.9333\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 516us/sample - loss: 0.5134 - accuracy: 0.9467 - val_loss: 0.5685 - val_accuracy: 0.9333\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 495us/sample - loss: 0.5087 - accuracy: 0.9467 - val_loss: 0.5610 - val_accuracy: 0.9333\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 500us/sample - loss: 0.5080 - accuracy: 0.9467 - val_loss: 0.5588 - val_accuracy: 0.9333\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 651us/sample - loss: 0.5066 - accuracy: 0.9467 - val_loss: 0.5664 - val_accuracy: 0.9333\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 573us/sample - loss: 0.5051 - accuracy: 0.9600 - val_loss: 0.5622 - val_accuracy: 0.9333\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 469us/sample - loss: 0.5029 - accuracy: 0.9600 - val_loss: 0.5662 - val_accuracy: 0.9333\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 552us/sample - loss: 0.5004 - accuracy: 0.9600 - val_loss: 0.5601 - val_accuracy: 0.9333\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 545us/sample - loss: 0.5005 - accuracy: 0.9467 - val_loss: 0.5638 - val_accuracy: 0.9333\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 475us/sample - loss: 0.4977 - accuracy: 0.9600 - val_loss: 0.5627 - val_accuracy: 0.9333\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 942us/sample - loss: 0.4968 - accuracy: 0.9600 - val_loss: 0.5678 - val_accuracy: 0.9333\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 967us/sample - loss: 0.4961 - accuracy: 0.9733 - val_loss: 0.5588 - val_accuracy: 0.9333\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 854us/sample - loss: 0.4924 - accuracy: 0.9733 - val_loss: 0.5551 - val_accuracy: 0.9333\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 791us/sample - loss: 0.4916 - accuracy: 0.9600 - val_loss: 0.5601 - val_accuracy: 0.9333\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 914us/sample - loss: 0.4908 - accuracy: 0.9733 - val_loss: 0.5486 - val_accuracy: 0.9333\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 890us/sample - loss: 0.4883 - accuracy: 0.9600 - val_loss: 0.5515 - val_accuracy: 0.9333\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 483us/sample - loss: 0.4862 - accuracy: 0.9733 - val_loss: 0.5519 - val_accuracy: 0.9333\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 485us/sample - loss: 0.4848 - accuracy: 0.9733 - val_loss: 0.5450 - val_accuracy: 0.9333\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 536us/sample - loss: 0.4857 - accuracy: 0.9600 - val_loss: 0.5403 - val_accuracy: 0.9333\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 463us/sample - loss: 0.4833 - accuracy: 0.9733 - val_loss: 0.5435 - val_accuracy: 0.9333\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.4813 - accuracy: 0.9733 - val_loss: 0.5442 - val_accuracy: 0.9333\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 498us/sample - loss: 0.4788 - accuracy: 0.9733 - val_loss: 0.5493 - val_accuracy: 0.9333\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.4783 - accuracy: 0.9733 - val_loss: 0.5515 - val_accuracy: 0.9333\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.4767 - accuracy: 0.9733 - val_loss: 0.5394 - val_accuracy: 0.9333\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 301us/sample - loss: 0.4739 - accuracy: 0.9733 - val_loss: 0.5395 - val_accuracy: 0.9333\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.4748 - accuracy: 0.9733 - val_loss: 0.5328 - val_accuracy: 0.9333\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 564us/sample - loss: 0.4708 - accuracy: 0.9733 - val_loss: 0.5284 - val_accuracy: 0.9333\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.4703 - accuracy: 0.9600 - val_loss: 0.5317 - val_accuracy: 0.9333\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.4677 - accuracy: 0.9733 - val_loss: 0.5276 - val_accuracy: 0.9333\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 314us/sample - loss: 0.4665 - accuracy: 0.9733 - val_loss: 0.5256 - val_accuracy: 0.9333\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.4649 - accuracy: 0.9733 - val_loss: 0.5209 - val_accuracy: 0.9333\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 440us/sample - loss: 0.4643 - accuracy: 0.9733 - val_loss: 0.5314 - val_accuracy: 0.9333\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 770us/sample - loss: 0.4617 - accuracy: 0.9733 - val_loss: 0.5302 - val_accuracy: 0.9333\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 448us/sample - loss: 0.4615 - accuracy: 0.9733 - val_loss: 0.5190 - val_accuracy: 0.9333\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 497us/sample - loss: 0.4618 - accuracy: 0.9733 - val_loss: 0.5162 - val_accuracy: 0.9333\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 431us/sample - loss: 0.4589 - accuracy: 0.9733 - val_loss: 0.5154 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.4567 - accuracy: 0.9733 - val_loss: 0.5223 - val_accuracy: 0.9333\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 542us/sample - loss: 0.4555 - accuracy: 0.9733 - val_loss: 0.5249 - val_accuracy: 0.9333\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 672us/sample - loss: 0.4538 - accuracy: 0.9733 - val_loss: 0.5192 - val_accuracy: 0.9333\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.4522 - accuracy: 0.9733 - val_loss: 0.5148 - val_accuracy: 0.9333\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.4521 - accuracy: 0.9733 - val_loss: 0.5066 - val_accuracy: 0.9333\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.4502 - accuracy: 0.9733 - val_loss: 0.5147 - val_accuracy: 0.9333\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.4482 - accuracy: 0.9733 - val_loss: 0.5098 - val_accuracy: 0.9333\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 371us/sample - loss: 0.4468 - accuracy: 0.9733 - val_loss: 0.5108 - val_accuracy: 0.9333\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 375us/sample - loss: 0.4451 - accuracy: 0.9733 - val_loss: 0.5079 - val_accuracy: 0.9333\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 346us/sample - loss: 0.4435 - accuracy: 0.9733 - val_loss: 0.5077 - val_accuracy: 0.9333\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 631us/sample - loss: 0.4445 - accuracy: 0.9733 - val_loss: 0.5113 - val_accuracy: 0.9333\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 441us/sample - loss: 0.4411 - accuracy: 0.9733 - val_loss: 0.5171 - val_accuracy: 0.9333\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 332us/sample - loss: 0.4399 - accuracy: 0.9733 - val_loss: 0.5133 - val_accuracy: 0.9333\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.4397 - accuracy: 0.9733 - val_loss: 0.5150 - val_accuracy: 0.9333\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.4386 - accuracy: 0.9733 - val_loss: 0.5198 - val_accuracy: 0.9333\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.4378 - accuracy: 0.9733 - val_loss: 0.5125 - val_accuracy: 0.9333\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 279us/sample - loss: 0.4353 - accuracy: 0.9733 - val_loss: 0.4980 - val_accuracy: 0.9333\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.4326 - accuracy: 0.9733 - val_loss: 0.4982 - val_accuracy: 0.9333\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 319us/sample - loss: 0.4322 - accuracy: 0.9733 - val_loss: 0.5075 - val_accuracy: 0.9333\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.4317 - accuracy: 0.9733 - val_loss: 0.5078 - val_accuracy: 0.9333\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 305us/sample - loss: 0.4296 - accuracy: 0.9733 - val_loss: 0.5029 - val_accuracy: 0.9333\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 364us/sample - loss: 0.4278 - accuracy: 0.9733 - val_loss: 0.4963 - val_accuracy: 0.9333\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 491us/sample - loss: 0.4263 - accuracy: 0.9733 - val_loss: 0.4893 - val_accuracy: 0.9333\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 388us/sample - loss: 0.4254 - accuracy: 0.9733 - val_loss: 0.4988 - val_accuracy: 0.9333\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.4253 - accuracy: 0.9733 - val_loss: 0.4874 - val_accuracy: 0.9333\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.4272 - accuracy: 0.9733 - val_loss: 0.4897 - val_accuracy: 0.9333\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.4236 - accuracy: 0.9733 - val_loss: 0.4906 - val_accuracy: 0.9333\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.4228 - accuracy: 0.9733 - val_loss: 0.4921 - val_accuracy: 0.9333\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.4213 - accuracy: 0.9733 - val_loss: 0.4997 - val_accuracy: 0.9333\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 359us/sample - loss: 0.4200 - accuracy: 0.9733 - val_loss: 0.4868 - val_accuracy: 0.9333\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 574us/sample - loss: 0.4175 - accuracy: 0.9733 - val_loss: 0.4834 - val_accuracy: 0.9333\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.4164 - accuracy: 0.9733 - val_loss: 0.4835 - val_accuracy: 0.9333\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.4152 - accuracy: 0.9733 - val_loss: 0.4845 - val_accuracy: 0.9333\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.4138 - accuracy: 0.9733 - val_loss: 0.4819 - val_accuracy: 0.9333\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 390us/sample - loss: 0.4130 - accuracy: 0.9733 - val_loss: 0.4741 - val_accuracy: 0.9333\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.4142 - accuracy: 0.9733 - val_loss: 0.4762 - val_accuracy: 0.9333\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.4108 - accuracy: 0.9733 - val_loss: 0.4728 - val_accuracy: 0.9333\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 514us/sample - loss: 0.4117 - accuracy: 0.9733 - val_loss: 0.4754 - val_accuracy: 0.9333\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 286us/sample - loss: 0.4090 - accuracy: 0.9733 - val_loss: 0.4703 - val_accuracy: 0.9333\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 377us/sample - loss: 0.4073 - accuracy: 0.9733 - val_loss: 0.4734 - val_accuracy: 0.9333\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 342us/sample - loss: 0.4057 - accuracy: 0.9733 - val_loss: 0.4720 - val_accuracy: 0.9333\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.4071 - accuracy: 0.9733 - val_loss: 0.4672 - val_accuracy: 0.9333\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.4038 - accuracy: 0.9733 - val_loss: 0.4722 - val_accuracy: 0.9333\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 476us/sample - loss: 0.4023 - accuracy: 0.9733 - val_loss: 0.4773 - val_accuracy: 0.9333\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 241us/sample - loss: 0.4017 - accuracy: 0.9733 - val_loss: 0.4639 - val_accuracy: 0.9333\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 310us/sample - loss: 0.4006 - accuracy: 0.9733 - val_loss: 0.4682 - val_accuracy: 0.9333\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 248us/sample - loss: 0.3989 - accuracy: 0.9733 - val_loss: 0.4595 - val_accuracy: 0.9333\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 255us/sample - loss: 0.3987 - accuracy: 0.9600 - val_loss: 0.4685 - val_accuracy: 0.9333\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 474us/sample - loss: 0.3973 - accuracy: 0.9733 - val_loss: 0.4598 - val_accuracy: 0.9333\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 299us/sample - loss: 0.3958 - accuracy: 0.9733 - val_loss: 0.4595 - val_accuracy: 0.9333\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3970 - accuracy: 0.9733 - val_loss: 0.4663 - val_accuracy: 0.9333\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.3935 - accuracy: 0.9733 - val_loss: 0.4666 - val_accuracy: 0.9333\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 522us/sample - loss: 0.3923 - accuracy: 0.9733 - val_loss: 0.4591 - val_accuracy: 0.9333\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3921 - accuracy: 0.9733 - val_loss: 0.4504 - val_accuracy: 0.9333\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3931 - accuracy: 0.9733 - val_loss: 0.4467 - val_accuracy: 0.9333\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3921 - accuracy: 0.9600 - val_loss: 0.4556 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 499us/sample - loss: 0.3890 - accuracy: 0.9733 - val_loss: 0.4629 - val_accuracy: 0.9333\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 449us/sample - loss: 0.3880 - accuracy: 0.9733 - val_loss: 0.4540 - val_accuracy: 0.9333\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 358us/sample - loss: 0.3873 - accuracy: 0.9733 - val_loss: 0.4517 - val_accuracy: 0.9333\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 316us/sample - loss: 0.3871 - accuracy: 0.9733 - val_loss: 0.4550 - val_accuracy: 0.9333\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.3862 - accuracy: 0.9733 - val_loss: 0.4526 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3850 - accuracy: 0.9733 - val_loss: 0.4433 - val_accuracy: 0.9333\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.3848 - accuracy: 0.9600 - val_loss: 0.4481 - val_accuracy: 0.9333\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3827 - accuracy: 0.9733 - val_loss: 0.4529 - val_accuracy: 0.9333\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.3825 - accuracy: 0.9733 - val_loss: 0.4473 - val_accuracy: 0.9333\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 313us/sample - loss: 0.3813 - accuracy: 0.9733 - val_loss: 0.4571 - val_accuracy: 0.9333\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 330us/sample - loss: 0.3800 - accuracy: 0.9733 - val_loss: 0.4516 - val_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.3799 - accuracy: 0.9733 - val_loss: 0.4455 - val_accuracy: 0.9333\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 488us/sample - loss: 0.3799 - accuracy: 0.9733 - val_loss: 0.4547 - val_accuracy: 0.9333\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 381us/sample - loss: 0.3779 - accuracy: 0.9733 - val_loss: 0.4585 - val_accuracy: 0.9333\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 401us/sample - loss: 0.3771 - accuracy: 0.9733 - val_loss: 0.4558 - val_accuracy: 0.9333\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 613us/sample - loss: 0.3759 - accuracy: 0.9733 - val_loss: 0.4460 - val_accuracy: 0.9333\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 403us/sample - loss: 0.3765 - accuracy: 0.9733 - val_loss: 0.4466 - val_accuracy: 0.9333\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 351us/sample - loss: 0.3738 - accuracy: 0.9733 - val_loss: 0.4441 - val_accuracy: 0.9333\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 394us/sample - loss: 0.3731 - accuracy: 0.9733 - val_loss: 0.4381 - val_accuracy: 0.9333\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 341us/sample - loss: 0.3725 - accuracy: 0.9733 - val_loss: 0.4352 - val_accuracy: 0.9333\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.3719 - accuracy: 0.9733 - val_loss: 0.4454 - val_accuracy: 0.9333\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 302us/sample - loss: 0.3711 - accuracy: 0.9733 - val_loss: 0.4351 - val_accuracy: 0.9333\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.3723 - accuracy: 0.9600 - val_loss: 0.4386 - val_accuracy: 0.9333\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.3684 - accuracy: 0.9733 - val_loss: 0.4396 - val_accuracy: 0.9333\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.3688 - accuracy: 0.9733 - val_loss: 0.4478 - val_accuracy: 0.9333\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.3678 - accuracy: 0.9733 - val_loss: 0.4508 - val_accuracy: 0.9333\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 445us/sample - loss: 0.3670 - accuracy: 0.9733 - val_loss: 0.4460 - val_accuracy: 0.9333\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.3661 - accuracy: 0.9733 - val_loss: 0.4409 - val_accuracy: 0.9333\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 395us/sample - loss: 0.3651 - accuracy: 0.9733 - val_loss: 0.4279 - val_accuracy: 0.9333\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 321us/sample - loss: 0.3643 - accuracy: 0.9733 - val_loss: 0.4288 - val_accuracy: 0.9333\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3636 - accuracy: 0.9733 - val_loss: 0.4247 - val_accuracy: 0.9333\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 333us/sample - loss: 0.3625 - accuracy: 0.9600 - val_loss: 0.4327 - val_accuracy: 0.9333\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 264us/sample - loss: 0.3632 - accuracy: 0.9733 - val_loss: 0.4275 - val_accuracy: 0.9333\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 331us/sample - loss: 0.3623 - accuracy: 0.9733 - val_loss: 0.4295 - val_accuracy: 0.9333\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3600 - accuracy: 0.9733 - val_loss: 0.4266 - val_accuracy: 0.9333\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.3590 - accuracy: 0.9733 - val_loss: 0.4246 - val_accuracy: 0.9333\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 315us/sample - loss: 0.3592 - accuracy: 0.9733 - val_loss: 0.4200 - val_accuracy: 0.9333\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 370us/sample - loss: 0.3576 - accuracy: 0.9600 - val_loss: 0.4313 - val_accuracy: 0.9333\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 284us/sample - loss: 0.3571 - accuracy: 0.9733 - val_loss: 0.4353 - val_accuracy: 0.9333\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 328us/sample - loss: 0.3562 - accuracy: 0.9733 - val_loss: 0.4328 - val_accuracy: 0.9333\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.3567 - accuracy: 0.9733 - val_loss: 0.4176 - val_accuracy: 0.9333\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.3576 - accuracy: 0.9600 - val_loss: 0.4193 - val_accuracy: 0.9333\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.3560 - accuracy: 0.9733 - val_loss: 0.4141 - val_accuracy: 0.9333\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.3542 - accuracy: 0.9600 - val_loss: 0.4147 - val_accuracy: 0.9333\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 295us/sample - loss: 0.3532 - accuracy: 0.9600 - val_loss: 0.4213 - val_accuracy: 0.9333\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 402us/sample - loss: 0.3516 - accuracy: 0.9733 - val_loss: 0.4264 - val_accuracy: 0.9333\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 356us/sample - loss: 0.3517 - accuracy: 0.9733 - val_loss: 0.4214 - val_accuracy: 0.9333\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 294us/sample - loss: 0.3507 - accuracy: 0.9733 - val_loss: 0.4296 - val_accuracy: 0.9333\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 274us/sample - loss: 0.3513 - accuracy: 0.9733 - val_loss: 0.4306 - val_accuracy: 0.9333\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.3506 - accuracy: 0.9733 - val_loss: 0.4149 - val_accuracy: 0.9333\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 275us/sample - loss: 0.3488 - accuracy: 0.9733 - val_loss: 0.4099 - val_accuracy: 0.9333\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 376us/sample - loss: 0.3487 - accuracy: 0.9600 - val_loss: 0.4148 - val_accuracy: 0.9333\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 268us/sample - loss: 0.3482 - accuracy: 0.9733 - val_loss: 0.4070 - val_accuracy: 0.9333\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 398us/sample - loss: 0.3481 - accuracy: 0.9600 - val_loss: 0.4101 - val_accuracy: 0.9333\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3465 - accuracy: 0.9733 - val_loss: 0.4115 - val_accuracy: 0.9333\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.3456 - accuracy: 0.9733 - val_loss: 0.4143 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 306us/sample - loss: 0.3452 - accuracy: 0.9733 - val_loss: 0.4238 - val_accuracy: 0.9333\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3453 - accuracy: 0.9733 - val_loss: 0.4090 - val_accuracy: 0.9333\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 292us/sample - loss: 0.3448 - accuracy: 0.9600 - val_loss: 0.4148 - val_accuracy: 0.9333\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 290us/sample - loss: 0.3438 - accuracy: 0.9733 - val_loss: 0.4066 - val_accuracy: 0.9333\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 344us/sample - loss: 0.3431 - accuracy: 0.9733 - val_loss: 0.4155 - val_accuracy: 0.9333\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 360us/sample - loss: 0.3433 - accuracy: 0.9733 - val_loss: 0.4128 - val_accuracy: 0.9333\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 278us/sample - loss: 0.3423 - accuracy: 0.9733 - val_loss: 0.4059 - val_accuracy: 0.9333\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 530us/sample - loss: 0.3420 - accuracy: 0.9733 - val_loss: 0.4023 - val_accuracy: 0.9333\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.3409 - accuracy: 0.9600 - val_loss: 0.4136 - val_accuracy: 0.9333\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 256us/sample - loss: 0.3399 - accuracy: 0.9733 - val_loss: 0.4192 - val_accuracy: 0.9333\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3395 - accuracy: 0.9733 - val_loss: 0.4164 - val_accuracy: 0.9333\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 272us/sample - loss: 0.3411 - accuracy: 0.9733 - val_loss: 0.4252 - val_accuracy: 0.9333\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 265us/sample - loss: 0.3400 - accuracy: 0.9733 - val_loss: 0.4125 - val_accuracy: 0.9333\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 311us/sample - loss: 0.3378 - accuracy: 0.9733 - val_loss: 0.4199 - val_accuracy: 0.9333\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.3374 - accuracy: 0.9733 - val_loss: 0.4128 - val_accuracy: 0.9333\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 357us/sample - loss: 0.3394 - accuracy: 0.9733 - val_loss: 0.4059 - val_accuracy: 0.9333\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.3364 - accuracy: 0.9733 - val_loss: 0.4004 - val_accuracy: 0.9333\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 266us/sample - loss: 0.3361 - accuracy: 0.9733 - val_loss: 0.4061 - val_accuracy: 0.9333\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 414us/sample - loss: 0.3348 - accuracy: 0.9733 - val_loss: 0.4022 - val_accuracy: 0.9333\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 335us/sample - loss: 0.3365 - accuracy: 0.9733 - val_loss: 0.4062 - val_accuracy: 0.9333\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 347us/sample - loss: 0.3337 - accuracy: 0.9733 - val_loss: 0.4103 - val_accuracy: 0.9333\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 324us/sample - loss: 0.3336 - accuracy: 0.9733 - val_loss: 0.3983 - val_accuracy: 0.9333\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.3362 - accuracy: 0.9733 - val_loss: 0.3945 - val_accuracy: 0.9333\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 404us/sample - loss: 0.3328 - accuracy: 0.9600 - val_loss: 0.4055 - val_accuracy: 0.9333\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 329us/sample - loss: 0.3319 - accuracy: 0.9733 - val_loss: 0.4121 - val_accuracy: 0.9333\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 309us/sample - loss: 0.3316 - accuracy: 0.9733 - val_loss: 0.3987 - val_accuracy: 0.9333\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3307 - accuracy: 0.9733 - val_loss: 0.3991 - val_accuracy: 0.9333\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 367us/sample - loss: 0.3317 - accuracy: 0.9733 - val_loss: 0.4132 - val_accuracy: 0.9333\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 312us/sample - loss: 0.3312 - accuracy: 0.9733 - val_loss: 0.4139 - val_accuracy: 0.9333\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 271us/sample - loss: 0.3301 - accuracy: 0.9733 - val_loss: 0.4049 - val_accuracy: 0.9333\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 282us/sample - loss: 0.3285 - accuracy: 0.9733 - val_loss: 0.4057 - val_accuracy: 0.9333\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 350us/sample - loss: 0.3284 - accuracy: 0.9733 - val_loss: 0.4093 - val_accuracy: 0.9333\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.3282 - accuracy: 0.9733 - val_loss: 0.4036 - val_accuracy: 0.9333\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 283us/sample - loss: 0.3286 - accuracy: 0.9733 - val_loss: 0.3986 - val_accuracy: 0.9333\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 273us/sample - loss: 0.3278 - accuracy: 0.9733 - val_loss: 0.4119 - val_accuracy: 0.9333\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 429us/sample - loss: 0.3272 - accuracy: 0.9733 - val_loss: 0.4089 - val_accuracy: 0.9333\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 304us/sample - loss: 0.3279 - accuracy: 0.9733 - val_loss: 0.4049 - val_accuracy: 0.9333\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 563us/sample - loss: 0.3257 - accuracy: 0.9733 - val_loss: 0.3978 - val_accuracy: 0.9333\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 340us/sample - loss: 0.3247 - accuracy: 0.9733 - val_loss: 0.3992 - val_accuracy: 0.9333\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 269us/sample - loss: 0.3248 - accuracy: 0.9733 - val_loss: 0.4013 - val_accuracy: 0.9333\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 263us/sample - loss: 0.3254 - accuracy: 0.9733 - val_loss: 0.4109 - val_accuracy: 0.9333\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 280us/sample - loss: 0.3258 - accuracy: 0.9867 - val_loss: 0.4019 - val_accuracy: 0.9333\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 369us/sample - loss: 0.3231 - accuracy: 0.9733 - val_loss: 0.4010 - val_accuracy: 0.9333\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 339us/sample - loss: 0.3224 - accuracy: 0.9733 - val_loss: 0.3956 - val_accuracy: 0.9333\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3221 - accuracy: 0.9733 - val_loss: 0.4036 - val_accuracy: 0.9333\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 285us/sample - loss: 0.3222 - accuracy: 0.9733 - val_loss: 0.3975 - val_accuracy: 0.9333\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 365us/sample - loss: 0.3208 - accuracy: 0.9733 - val_loss: 0.3946 - val_accuracy: 0.9333\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 501us/sample - loss: 0.3203 - accuracy: 0.9733 - val_loss: 0.3942 - val_accuracy: 0.9333\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 308us/sample - loss: 0.3198 - accuracy: 0.9733 - val_loss: 0.3884 - val_accuracy: 0.9333\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 434us/sample - loss: 0.3215 - accuracy: 0.9733 - val_loss: 0.3982 - val_accuracy: 0.9333\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 298us/sample - loss: 0.3198 - accuracy: 0.9733 - val_loss: 0.3971 - val_accuracy: 0.9333\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 322us/sample - loss: 0.3210 - accuracy: 0.9733 - val_loss: 0.3964 - val_accuracy: 0.9333\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 281us/sample - loss: 0.3201 - accuracy: 0.9733 - val_loss: 0.3870 - val_accuracy: 0.9333\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 428us/sample - loss: 0.3187 - accuracy: 0.9600 - val_loss: 0.3935 - val_accuracy: 0.9333\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 336us/sample - loss: 0.3186 - accuracy: 0.9867 - val_loss: 0.3789 - val_accuracy: 0.9333\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 317us/sample - loss: 0.3167 - accuracy: 0.9733 - val_loss: 0.3803 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 516us/sample - loss: 0.3163 - accuracy: 0.9600 - val_loss: 0.3915 - val_accuracy: 0.9333\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 303us/sample - loss: 0.3155 - accuracy: 0.9867 - val_loss: 0.3906 - val_accuracy: 0.9333\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 334us/sample - loss: 0.3158 - accuracy: 0.9867 - val_loss: 0.3945 - val_accuracy: 0.9333\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 289us/sample - loss: 0.3156 - accuracy: 0.9733 - val_loss: 0.3940 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Storlek på Neuralt Nätverk\n",
    "antal_hidden_layer = 3 # Djup\n",
    "antal_noder = 5 # Bredd per lager\n",
    "\n",
    "#Regulariseringsparametrar\n",
    "l1_reg_rate = 0.01\n",
    "l2_reg_rate = 0.01\n",
    "\n",
    "# Definiera forward propagation\n",
    "neural_network_model = Sequential()\n",
    "\n",
    "# Input lager \n",
    "neural_network_model.add(Dense(antal_noder, input_dim=4, activation='relu'))\n",
    "\n",
    "#Hidden lager\n",
    "for l in range(antal_hidden_layer):\n",
    "    neural_network_model.add(Dense(antal_noder, activation='relu', kernel_regularizer=L1L2(l1=l1_reg_rate, l2=l2_reg_rate)))\n",
    "\n",
    "#Output lager\n",
    "neural_network_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "neural_network_model.compile(optimizers='sgd',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "neural_network_model.summary()\n",
    "\n",
    "history = neural_network_model.fit(X_train,Y_train, epochs=500, validation_data=(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Utvärdering\n",
    " - Hur ser accuracy och loss ut för tränings- och valideringsdata?\n",
    " - Löser regularisering vårt problem med överträning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, train:  0.85333335\n",
      "accuracy, test:  0.8933333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xd0XNW5/vHvq1G3enOT5d4LxpYNxqZDYkMgQCCUkAAxYZECuZeQC7nJLyGkQJKbUJMQQigJoffQTA8Qg3tvuFuyZas3y7LK7N8fZyyEkW3JmtFIo+ez1izNnHM08x4j9Gifffbe5pxDREQEICrcBYiISPehUBARkRYKBRERaaFQEBGRFgoFERFpoVAQEZEWCgWRdjCzIWbmzCy6HcdeaWYfdvZ9RMJBoSARx8y2mVmDmWUdtH154BfykPBUJtL9KRQkUm0FLj3wwswmAgnhK0ekZ1AoSKT6B/CNVq+vAP7e+gAzSzWzv5tZiZltN7OfmFlUYJ/PzP7PzErNbAtwdhvf+zczKzKznWb2SzPzdbRIMxtgZi+ZWbmZbTKzb7XaN93MFptZtZntMbM/BLbHm9mjZlZmZpVmtsjM+nb0s0XaolCQSPUxkGJmYwO/rC8GHj3omHuAVGAYcDJeiFwV2Pct4EvAsUA+cOFB3/sI0ASMCBzzBeDqo6jzcaAQGBD4jF+b2emBfXcBdznnUoDhwFOB7VcE6h4EZALXAvuO4rNFPkehIJHsQGvhTGA9sPPAjlZB8SPnXI1zbhvwe+DrgUO+CtzpnCtwzpUDt7X63r7AHOC/nHN7nXPFwB3AJR0pzswGAbOAm5xz9c655cADrWpoBEaYWZZzrtY593Gr7ZnACOdcs3NuiXOuuiOfLXIoCgWJZP8ALgOu5KBLR0AWEAtsb7VtOzAw8HwAUHDQvgMGAzFAUeDyTSXwFyCng/UNAMqdczWHqGEuMApYH7hE9KVW5zUPeMLMdpnZb80spoOfLdImhYJELOfcdrwO57OA5w7aXYr3F/fgVtvy+LQ1UYR3eab1vgMKgP1AlnMuLfBIcc6N72CJu4AMM0tuqwbn3Ebn3KV4YfMb4Bkz6+Oca3TO/dw5Nw44Ae8y1zcQCQKFgkS6ucBpzrm9rTc655rxrtH/ysySzWwwcAOf9js8BVxvZrlmlg7c3Op7i4A3gN+bWYqZRZnZcDM7uSOFOecKgPnAbYHO40mBev8JYGaXm1m2c84PVAa+rdnMTjWziYFLYNV44dbckc8WORSFgkQ059xm59ziQ+y+DtgLbAE+BB4DHgzs+yveJZoVwFI+39L4Bt7lp7VABfAM0P8oSrwUGILXange+Jlz7s3AvtnAGjOrxet0vsQ5Vw/0C3xeNbAO+Def70QXOSqmRXZEROQAtRRERKSFQkFERFooFEREpIVCQUREWvS46XuzsrLckCFDwl2GiEiPsmTJklLnXPaRjutxoTBkyBAWLz7UHYYiItIWM9t+5KN0+UhERFpRKIiISAuFgoiItOhxfQptaWxspLCwkPr6+nCX0mXi4+PJzc0lJkaTY4pI8EREKBQWFpKcnMyQIUMws3CXE3LOOcrKyigsLGTo0KHhLkdEIkhEXD6qr68nMzOzVwQCgJmRmZnZq1pGItI1IiIUgF4TCAf0tvMVka4RMaFwJPWNzRRV7sPv16ywIiKH0mtCoaHJT0ntfuoag78WSVlZGZMnT2by5Mn069ePgQMHtrxuaGho13tcddVVbNiwIei1iYh0RER0NLdHYmwUSeyjbn88SXHBPe3MzEyWL18OwC233EJSUhI33njjZ45xzuGcIyqq7Rx+6KGHglqTiMjR6DUthej6SoZF7aaxfu+RDw6STZs2MWHCBK699lqmTJlCUVER11xzDfn5+YwfP55bb7215dhZs2axfPlympqaSEtL4+abb+aYY45hxowZFBcXd1nNItK7RVxL4ef/WsPaXdVt7HHQsJdGKoiOTaAj3bTjBqTws3M6uia7Z+3atTz00EPcd999ANx+++1kZGTQ1NTEqaeeyoUXXsi4ceM+8z1VVVWcfPLJ3H777dxwww08+OCD3HzzzW29vYhIUPWalgIYmI9o/DQ1+7vsU4cPH860adNaXj/++ONMmTKFKVOmsG7dOtauXfu570lISGDOnDkATJ06lW3btnVVuSLSy0VcS+Gwf9Hvq4SKreyM6s+Avn275LbOPn36tDzfuHEjd911FwsXLiQtLY3LL7+8zbEGsbGxLc99Ph9NTU0hr1NEBHpVSwGIT6HZoklprmDv/uDfhXQk1dXVJCcnk5KSQlFREfPmzevyGkREDifiWgqHZVFYUg7JNbvYWV1FUnxml378lClTGDduHBMmTGDYsGHMnDmzSz9fRORIzLmeNZgrPz/fHbzIzrp16xg7dmz73sDfhH/3GmpcArHZw0iI7bm52KHzFpFezcyWOOfyj3Rc77p8BBAVDX2ySbW9VFbXhLsaEZFupfeFAhCVlIOfKBL2l1AfghHOIiI9Va8MBXzR0CeLVPZSXtXWmAYRkd6pd4YCEJXUF2dR9NlfzL4G3fIpIgK9OBTwRUNSX1KtjsrKinBXIyLSLfTeUMDrW2i2GFIbi6mtbwx3OSIiYderQ4GoKCx1AInWwN7KEo729txgTJ0N8OCDD7J79+6jqkFEJBh67k36QRKVkE5TTTHpTaVU12WQ2ie+w+/Rnqmz2+PBBx9kypQp9OvXr8PfKyISDCFrKZjZg2ZWbGarj3DcNDNrNrMLQ1XLYZnhS8sl1pppqN6DP8iD+R555BGmT5/O5MmT+c53voPf76epqYmvf/3rTJw4kQkTJnD33Xfz5JNPsnz5ci6++OIOtzBERIIllC2Fh4F7gb8f6gAz8wG/AYI3CdBrN8PuVR36FgP8jfvIcs00+RKI8vk+e0C/iTDn9g6Xsnr1ap5//nnmz59PdHQ011xzDU888QTDhw+ntLSUVau8OisrK0lLS+Oee+7h3nvvZfLkyR3+LBGRYAhZS8E59z5QfoTDrgOeBcK+ioxFxwEOmhtwBKe18NZbb7Fo0SLy8/OZPHky//73v9m8eTMjRoxgw4YNfP/732fevHmkpqYG5fNERDorbH0KZjYQOB84DZh2hGOvAa4ByMvLO/wbH8Vf9OC1FhrLdxC9r4yyxGFkpXf+F7Vzjm9+85v84he/+Ny+lStX8tprr3H33Xfz7LPPcv/993f680REOiucdx/dCdzknDviPBPOufudc/nOufzs7OyQFRST2h9nUcTW7aYxCAvxnHHGGTz11FOUlpYC3l1KO3bsoKTEu9Ppoosu4uc//zlLly4FIDk5mZoazcckIuETzruP8oEnAgvdZAFnmVmTc+6FsFXki8HfJ4eUvbspqSgnOyurU283ceJEfvazn3HGGWfg9/uJiYnhvvvuw+fzMXfuXJxzmBm/+c1vALjqqqu4+uqrSUhIYOHChZ9ZbEdEpCuEdOpsMxsCvOycm3CE4x4OHPfMkd6z01NnH4nfT9OeNTT4fUTljCI+pvvetaups0WkvcI+dbaZPQ58BIw2s0Izm2tm15rZtaH6zKCIisJSBpBo+6kpLz7qAW0iIj1RyP4Mds5d2oFjrwxVHUfDl5hBY20J6U0l1OxLJyUxIdwliYh0iYiZ5iKof9Gb4UvPw2d+mit34fd3v9aCWjAiEgoREQrx8fGUlZUF9RdlVGwijXGZpLlqKqurgva+weCco6ysjPj4jk/JISJyON23F7UDcnNzKSwspKSkJLhv7Pz4q0ppooJdKf3wRVlw378T4uPjyc3NDXcZIhJhIiIUYmJiGDp0aEjeu+z9+WS+cyN/H/D/+MY1HZ/kTkSkJ4mIy0ehlDnrm+zuM5ozd/6RZZsKw12OiEhIKRSOJMpH6gV30N/K2fDsL7plp7OISLAoFNohYfhMCnLP5vy6Z3n1g4/CXY6ISMgoFNop96Lf4iyKxPduoVpLd4pIhFIotJOl5lI59XpOcwt46bnHw12OiEhIKBQ6oN/sGymL6c+09b9l0+7KcJcjIhJ0CoWOiIkn5qzbGB1VwEdP/lajikUk4igUOihl8nnszDiOc8sf4oMV68NdjohIUCkUOsqM7IvuJMnqqXj5FvY3HXGNIBGRHkOhcBRi+4+jaNTlfKlxHi/NeyPc5YiIBI1C4Sjlnn8rdb5khiz8OcVV+8JdjohIUCgUjlZCOvtP+jHTbB2vP3VfuKsREQkKhUInZJ30LXYnjuL0wntYvmVXuMsREek0hUJnRPlIueAPDLQy1j2jeZFEpOdTKHRS4ogTKRgwh/P2PsOr85eGuxwRkU5RKATBwK/cRrT5aX77l9Tubwp3OSIiR02hEARRmUMpn3AV5/jf5YmXXw13OSIiR02hECR9z/4x9b4kRq/4HdtK94a7HBGRo6JQCJaEdJpP+iEnRq3kX8/9I9zViIgcFYVCECXP+jaV8bmcWXgvi7eUhLscEZEOUygEU3QsCXN+wZioAj5+7h7NoioiPU7IQsHMHjSzYjNbfYj9XzOzlYHHfDM7JlS1dKW4SedTmn4MF9U8wuvLNoe7HBGRDgllS+FhYPZh9m8FTnbOTQJ+Adwfwlq6jhnp5/2OvlbJrtd+p1lURaRHCVkoOOfeB8oPs3++c64i8PJjIDdUtXQ13+DjKMmbwyUNz/P0u4vDXY6ISLt1lz6FucBrh9ppZteY2WIzW1xS0jM6cLPP+zVx1kzCf26nYm9DuMsREWmXsIeCmZ2KFwo3HeoY59z9zrl851x+dnZ21xXXGRnDqJ54Bee5d3nslTfDXY2ISLuENRTMbBLwAPBl51xZOGsJhYzZP6bRl8jI1X9gqwa0iUgPELZQMLM84Dng6865T8JVR0j1yaTphOv5QtRinn3hmXBXIyJyRKG8JfVx4CNgtJkVmtlcM7vWzK4NHPJTIBP4k5ktN7OI7JFNOuk6amOyOHnHvawurAx3OSIihxUdqjd2zl16hP1XA1eH6vO7jdg++E67mWnzbuTOFx9hwne/H+6KREQOKewdzb1BwvQrqUzIY86e+1m4uWfcPSUivZNCoSv4YkiYfQujowpZ+NJ9mv5CRLothUIXiZt0AaUp4zmv8mE+WL8z3OWIiLRJodBVzEg951fkWinr/3Wn1nMWkW5JodCFYkaeyp7sE/jK3id4fenGcJcjIvI5CoUulvXlX5NpNRS//jsamvzhLkdE5DMUCl3Ml3sse/LO4qLGF3nu/aXhLkdE5DMUCmGQc+4viLMm7IPfUbu/KdzliIi0UCiEgWWNoGLMJVzgf5On33g/3OWIiLRQKIRJ9tk/xR8VQ87i/6O0dn+4yxERARQK4ZPcj73Hfouz7T888/Ir4a5GRARQKIRVxhd+SJ0vhXFr76CgvC7c5YiIKBTCKj6Vppk3cFLUSl564YlwVyMiolAIt5QTv01VbF9mbruXtTurwl2OiPRyCoVwi4kn5vQfMzlqM+88/0C4qxGRXk6h0A0kTruc8sRhzCn+Kx9v2hPuckSkF1ModAdRPpLOupXhUUUsfuFeTa0tImGjUOgmYsd/idL0yXyl5lFeW7413OWISC+lUOguzEg/99f0t3K2v3oH9Y3N4a5IRHohhUI34hs6k/IBp3JZwzM8/u+V4S5HRHohhUI3k/HlX5Fs+/B/cAdlmv5CRLqYQqG76Tue2lEX8DVe5cHX5oe7GhHpZRQK3VDKnJ8SHeUYtPJuNhXXhLscEelFFArdUfoQGo+9iguj3uPBF98MdzUi0osoFLqphNNuwh8dz6wdf+bDjaXhLkdEegmFQneVlI2dcB1n+Rby1Isv0OzXgDYRCb2QhYKZPWhmxWa2+hD7zczuNrNNZrbSzKaEqpaeKmbWdeyPy+DSqr/x7OKCcJcjIr1AKFsKDwOzD7N/DjAy8LgG+HMIa+mZ4pKJPf1/meFby+J5j7BX6zmLSIiFLBScc+8D5Yc55MvA353nYyDNzPqHqp6eyqZeRV36GK5vepi/vbMm3OWISIQLZ5/CQKD1NZHCwLbPMbNrzGyxmS0uKSnpkuK6DV80iefdQa6V4vvoTq3QJiIhFc5QsDa2tdmb6py73zmX75zLz87ODnFZ3dDgE6gbfQFX27+4/8W3w12NiESwdoWCmQ03s7jA81PM7HozS+vkZxcCg1q9zgV2dfI9I1bi2b/GfNHM3HIX/9mkW1RFJDTa21J4Fmg2sxHA34ChwGOd/OyXgG8E7kI6HqhyzhV18j0jV0p/7MQbmO1bxAvPP05jsz/cFYlIBGpvKPidc03A+cCdzrn/Bg7bKWxmjwMfAaPNrNDM5prZtWZ2beCQV4EtwCbgr8B3juoMepGYWdexL3EgV9X8lX9+tCXc5YhIBIpu53GNZnYpcAVwTmBbzOG+wTl36RH2O+C77fx8AYhJIP6sXzHumSt5+q2/UDr5l2QlxYW7KhGJIO1tKVwFzAB+5ZzbamZDgUdDV5Ycio0/j339j+N77gnueXVJuMsRkQjTrlBwzq11zl3vnHvczNKBZOfc7SGuTdpiRsI5vyXDahi48l5WFlaGuyIRiSDtvfvoPTNLMbMMYAXwkJn9IbSlySENmEzjpMu4Knoef3nuDfyaF0lEgqS9l49SnXPVwAXAQ865qcAZoStLjiT2zJ+BL5bzSu7jheU7w12OiESI9oZCdGAKiq8CL4ewHmmv5L74Tv4hZ/qW8NbLT1JV1xjuikQkArQ3FG4F5gGbnXOLzGwYsDF0ZUl7RM34Dg3Jg/h+00Pc9srKcJcjIhGgvR3NTzvnJjnnvh14vcU595XQliZHFBNP7JxfMzqqgLjlj/Dm2j3hrkhEerj2djTnmtnzgfUR9pjZs2aWG+ripB3GnoN/2KncFPMUdz/3NlX7dBlJRI5eey8fPYQ3LcUAvJlM/xXYJuFmRtQ5dxEXbfz3/vv5/Rsbwl2RiPRg7Q2FbOfcQ865psDjYaAXTlfaTaUPxnfa/3Kabxk7Fz7P8gKNXRCRo9PeUCg1s8vNzBd4XA6UhbIw6aDjrqU5cxQ/j/kH//vUIuobm8NdkYj0QO0NhW/i3Y66GygCLsSb+kK6C18MvrN/Ry57OK38SV1GEpGj0t67j3Y45851zmU753Kcc+fhDWST7mTYKTDuPK6PfYl5H37Mgi1qzIlIx3Rm5bUbglaFBM8Xf01MTAy/T3iYG59eTu3+pnBXJCI9SGdCoa3lNCXcUgdiZ9zCNP8KZlS/zq9eWRfuikSkB+lMKGgWtu4qfy4MnsUv4h7lg0VLeH21FrQTkfY5bCiYWY2ZVbfxqMEbsyDdUVQUnP9nYqOjeKDPn7n56aVsKakNd1Ui0gMcNhScc8nOuZQ2HsnOufau2ibhkJaHnXsPY5rW8wN7jG8/upS6BvUviMjhdebykXR3Ey6A/LlcziuklCziJ8+vDndFItLNKRQi3Zm3Yml53J/yEK8v28zTiwvCXZGIdGMKhUgXlwTn/Ym0+kL+lP44P35hNUt3VIS7KhHpphQKvcGQWdjJ/8Mp+97k64kf861HFlNQXhfuqkSkG1Io9BYn/Q/kncCP3V8Z0LyLKx9aqGm2ReRzFAq9hS8avvJXoqJjeTzjfnaXV/HtR5fQ0OQPd2Ui0o0oFHqT1Fz48p9IKl/Ni6PmMX9zGT95YRXOaRyiiHhCGgpmNtvMNpjZJjO7uY39eWb2rpktM7OVZnZWKOsRYMxZcPx3GbH1n/x5wic8tbiQe9/ZFO6qRKSbCFkomJkP+CMwBxgHXGpm4w467CfAU865Y4FLgD+Fqh5p5cxbYciJzN52O9eN2cvv3/yEBz7YEu6qRKQbCGVLYTqwyTm3xTnXADwBfPmgYxyQEnieCuwKYT1ygC8aLnoY65PNDRU/5+KxCfzylXX8/aNt4a5MRMIslKEwEGg9UqowsK21W4DLzawQeBW4rq03MrNrzGyxmS0uKSkJRa29T58suPhRbG8pt7k/MHtsJj99cQ2PLdgR7spEJIxCGQptTa19cI/mpcDDzrlc4CzgH2b2uZqcc/c75/Kdc/nZ2VoaOmgGTIZz7iJq2wf8Mf6PnD46k/99fhVPadSzSK8VykntCoFBrV7n8vnLQ3OB2QDOuY/MLB7IAopDWJe0dswlUFuM783/x19OGMZV/rO46dmVREcZF0zJDXd1ItLFQtlSWASMNLOhZhaL15H80kHH7ABOBzCzsUA8oOtDXe2E62DqlUTPv5O/TdnOjGGZ/ODpFdz11kbdrirSy4QsFJxzTcD3gHnAOry7jNaY2a1mdm7gsB8A3zKzFcDjwJVOv4W6nhnM+R3knUDsK9fx0OnNnDd5IHe89Qk/eWG1BriJ9CLW034H5+fnu8WLF4e7jMi0txT+9gWo2Y3/sqf4zbpM/vL+FqYNSedPX5tKdnJcuCsUkaNkZkucc/lHOk4jmuVTfbLgqlchdSBR/7yQH43Zw92XHsuqnVWce++HLNleHu4KRSTEFAryWcn94MpXIGMoPHYx5yas4plrT8AXZVx030f8+tV11Dc2h7tKEQkRhYJ8XlIOXPEyZI+Gxy9lQvHLvP5fJ3HJ9Dzuf38LZ939gdZkEIlQCgVpW59Mr8Uw9CR48TskLfsrvz5/Iv+YO536hmYu/PN8blOrQSTiKBTk0OKS4bInYey58PrN8O5tnDgii3n/fRIXTxvEX97fwtl3f8CS7Wo1iEQKhYIcXnQcXPgQTL4c/n07vPIDkmPgtgsm8cg3p1PX0MyF983nJy+s0qI9IhFAoSBH5ouGc++Bmd+HxX+Df5wPe8s4eVQ2b95wMledMJTHFuzgjD/8m7fW7gl3tSLSCQoFaZ+oKG/K7fPug4KF8OcTYPM7JMVF89NzxvHS92aRkxzH1X9fzHcfW8qOMq0BLdITKRSkYyZfCle/BfGpXoth3o+haT8TBqby7LdP4PrTR/LOumJO/8N7/PLltVTWNYS7YhHpAI1olqPTuA/e+AksegD6H+O1IPp6ayjtqa7nD298wlNLCkiJj+E7pwzn4mmDSEuMDXPRIr1Xe0c0KxSkc9a9DP+6Huqr4ZSbYOZ/gS/G21VUzW2vref9T0pIiotm7qyhfHPWUFITYsJctEjvo1CQrrO3FF69EdY8D/0mwXl/gn4TW3av3lnFH9/dxGurd5MY6+OSaXlcf/oItRxEupBCQbre2pfglRtgXwXMugFmXu+NdTiwe1c1D3y4hReW7aRPbDSXTB/EVTOHMiAtIYxFi/QOCgUJj7pyeO0mWPUUpAyEL90Jo77wmUM27K7h3nc38eqqIgDOntifubOGcsygtHBULNIrKBQkvAoWwkvXQ8k6mPhV+MIvvMn2WimsqOOh/2zjyUUF1O5vIn9wOt+cNZQzx/Ulxqcb40SCSaEg4de0H97/P/jwDm9k9Ik3wHHfhtjEzxxWU9/IU4sLeXj+VgrK95GVFMdF+blcMm0QgzP7hKl4kciiUJDuo2yzd/vqhlchuT+cfBMce3nLXUoHNPsd720o5vGFBbyzfg9+BzNHZHLp9DzOHNeXuGhfmE5ApOdTKEj3s30+vHULFCyAjOFw2k9g3HneaOmD7K6q5+nFBTyxqICdlfvI6BPLhVNzuXjaIFITYshK0ipwIh2hUJDuyTnY8Bq8favX3zBwKpz0Qxg121sr+iDNfseHm0p5fMEO3lq3hya/9/N6w5mjuPz4wWT00W2tIu2hUJDuzd8MK56Ad34JNbtgwLEw5Qo45hKIafsW1eKaev61oojHFmxnc8leAI4flsFlxw3mtDE5JMVFd+UZiPQoCgXpGZqbYOWTXmd02UZISIdJl3id0kk5bX6Lc441u6p5a90eHluwg+Ka/cRGR3HSyGzmTOjHGWP7kpqoUdMirSkUpGdxDrZ9CEsegjUveHcrTb0Spl0NmcMP+W3NfsfSHRW8tmo3r68uYldVPdFRxgkjspgzoR9fGNeXTPU/iCgUpAcr3QT//g2seQ78TTD8dJj+Le9r9KH7EJxzrCis4rXVRby+ejfby+rwRRkzR2Rx1oR+nD62L9nJCgjpnRQK0vPV7IYlj3ith5oiiEuFsefAMRfD4Flt3rV0gHOOtUXVvLKyiJdW7KKwYh9mMHlQGmeM7cuZ4/oyMicJa6NzWyQSKRQkcjQ3wqa3Ye2LsO4laKiFlFyYdBEc+/XDXl4CLyDW767hrbV7eGvdHlYUVgGQl5HIiSOzmDE8k+OHZeo2V4loCgWJTA113iC4FU/A5nfANUPmCBh/AYw4HQbme8uHHsae6nreWreHd9YV8/GWMvY2NAMwqm8SM4ZlMmN4JscNzSRdt7tKBOkWoWBms4G7AB/wgHPu9jaO+SpwC+CAFc65yw73ngoFaVGzG1Y+BZvegm0fgPNDXAqMPde7e+kILQiApmY/q3ZW8dGWMj7aXMbibRXsa2zGDMb0S2HGsEymDUlnZN8kRuQkH/H9RLqrsIeCmfmAT4AzgUJgEXCpc25tq2NGAk8BpznnKswsxzlXfLj3VShIm2qLvRHTG9+E1c9AcwOMmgOjZ8P48z8zhffhNDT5WVFYyUebvZBYsqOChiY/AMOy+pCbkciZ4/oyc3gmgzISNXGf9BjdIRRmALc4574YeP0jAOfcba2O+S3wiXPugfa+r0JBjqi2GD7+Myx9BOrKwBcLg46DMV/yOqkT0tv9VvWNzazfXcOHG0tYtbOKT/bUsrV0b8v+KXlpjBuQwjG5aRybl8awrCSiotR5Ld1PdwiFC4HZzrmrA6+/DhznnPteq2NewGtNzMS7xHSLc+71Nt7rGuAagLy8vKnbt28PSc0SYfzNsHMprH0BtrwHe1ZDdLw339LUK2HQdIjq2CR7zjk2l+xlyfZytpTsZdG2cjbuqaVmfxMAfWJ9jB+QysTcVCblpjIpN43BGYkKCgm77hAKFwFfPCgUpjvnrmt1zMtAI/BVIBf4AJjgnKs81PuqpSBHrWglLHnY64doqIHYZMjNh7wZMPJMb6qNo7hF1e93bC6pZXlBJat3VrFqZxVri6qpb/QuOyXHRzMpN5WJA9M4JtcLjIFpCbodVrpUdwiF9lw+ug/42Dn3cOD128DNzrlFh3pfhYJ02v5a+OR1rw+iYAHsWQM4SB0EQ0+GnDHe5aaccRAR7ogVAAASj0lEQVSXdFQf0dTsZ2NxLSsLK1lZWMXKwirW766msdn7/y2zTyyDMhI5flgmY/olMyk3laFZfRQUEjLdIRSi8S4NnQ7sxOtovsw5t6bVMbPxOp+vMLMsYBkw2TlXdqj3VShI0NWVeyGx7l9QuBj2Bu518MVBvwkw4kzofwzkHQ+JGUf9MfubmllfVMPKnVWsKqxkW2kdS3ZU0ByY+TUlPpqclHjmTOjHiJwkRuYkM7JvkjqzJSjCHgqBIs4C7sTrL3jQOfcrM7sVWOyce8m8P4t+D8wGmoFfOeeeONx7KhQk5Gr2QOEi2PGRt6xo4SLAgflgxBnepabcadB3whHHRBxJXUMTO8rrWFFQyYrCqpbLTwf+t+wT6yMnJZ78wemcPrYvk3JTGZDW9iyyIofTLUIhFBQK0uXqq2DPWq81seppqN7pbU/IgHFfhr7jvQ7s3HzIHnNU/RKf+bjGZraX1bFhTw0LtpSxbEcl63dXE2hQkJMcx9j+KYwbkMLw7CRmjciiX2p8J09SIp1CQSQUnIPKHV4L4pPXvdHVjXWf7s8YBqPPgoyhkDvda00cZo6m9qqub2RLyV6Wbq9g9a4q1hfVsLG4hsZmhxnkpicwbUgGkwamcmxeOmP7pxAbrctO8imFgkhXaNoP9dWwv9q77XX9K7D1ffA3evsT0mHYqd5lp+GnQXK/TrckDqhvbGZb2V7eWLOHNbuqWLK9ktLa/QDERkcxYUAKx+alM3mQN4ZCdzz1bgoFkXBp3OcNoNvxsRcUm9+G2j3ePl+c1yeR3A/6TfL6JjKHe+tHBMGuyn0sL6hkeUEly3ZUsLKwiv2BEdnZyXEtATF9SAYjcpJIS9T8Tr2FQkGku3DOGzi35T3v9tfCRV5ndkPNp8ekD/HWqR5xhhcYmHenU1K/Tl1+amz2s76ohuUFFSzbUcmygsqWEdkxPmNcf681kZIQw0VTcxmUkdipU5XuS6Eg0p05B7uWQtlmKP0Edq/yQqOp/rPHpeTCjO96a1d34nbY1ir2NrBgqzf538rCqs/cFjumXzJj+6cwqm8yX5rUXyERQRQKIj1NQx3sXAz7Kr0ZX/eWwOrnYMd8b//AfC8cRp7ptSyCpLHZT2ntfp5bupOPt5TxyZ4a9lR7fRMDUuOZNjSDGcMymTAwlUHpiVr/uodSKIhEip1LvbUjVjwOZZu8bVmjvOk5MoZ6t8Ym5Xi3xWaPhpQBnf7IbaV7eW9DMYu2V7BgS3lLB3ZcdBTTh2YwbkAKA9MSOHV0jloTPYRCQSTSOOeFwsY3YdObXljUHzxNmEFantc3kTMWJl8GsX06+bHe3E5rdlWzdHsFC7dVsKHVuIlBGQkkxcUwbUg6syf0Y/KgNBJjOzeoT4JPoSDSG+wt/fRup8Y6b8GhXUth13LvNtnELOg7DmISYepVMOxkiOn8iGjnHFtL9/LO+mKWF1RSU9/ER1vKaGjy44vyOrCnDk4nf0g6o/smk5Mcr8tOYaZQEOntdnzsrStRUwRVhd5I7NhkGHmGd+lp/AWQlB20j6uub2TJtgqWbPceywsq2dfoLXWaEONj5ogsjs3zbomdkpdOfEzHpi2XzlEoiMinmhpg4xveCOyt70NVgbc9qS9kjoRx53ozxGaNCsoIbPA6sNfuqmb97mqWbq9k0bZytgRuh42NjmJc/xQGpMVz9sQBTB+aQXZycMZqSNsUCiJyaMXrvGk6yjZB0QrvlliAxEyvP6LfJG809ogzILlv0D62qq6RJTvK+XhLOSsKKtlcsrelE3vCwBROGJ7FtCEZDM1K1JrYQaZQEJH227XMC4ot73kd2fvKve0xid6lpqQc6DfRW2Ni2ClBm6qjqdlbE3v+pjI+2FTK8h2VNDR7I7DzMhI5YXgmUwenM35AKiNykjSfUycoFETk6Pj90FALldth/j3e4LrSTZ+OwE7Lg6zR3sjrMV+CUV8M6nxOq3dWsWBrOQu2lrN8RwXV9d5Sp7G+KMb0T2ZMv2Qm5gZWsRuYqvmc2kmhICLB09wI+2vgk3nemte1e6B8izeteGwSjD8fskZ6czuNON17HgR+v2NTSS3riqpZu6u6ZanTyjpvwsGEGB8TBqZw3NBMjhuWwZS8dPrE6XbYtigURCS0mhu9EdfrX/YuO+2v/nTfgCkwcIo3ffiEr3R6MaLWmpr9FFXV89GWMtbuqmbZjgpW76qm2e9NIz66bzKzRmQxZXA6xwxKIyc5TqvXoVAQka5WXwX7KmD1s7Dhda+fwt8ImSO8YBh6sres6VGue304tfubWLq9gqU7KvhocxnLCippCMwOmxjr45TR2Rw31OufGNs/BV9U77vkpFAQkfBqboKN8+A/d0PhQm8+J4CoGEjNhfTB3kp1w06FwSdAfErQPrqhyc/aompWBy43vbu+mKIqb7LB5PhoBqQmMKZ/MqeMzuakkdlkJkX+7bAKBRHpPurKvSnDdy2Dhr3eOImSDd4dTzjAYPx5MPYc71bYQcdDbPDmVHLOsbNyH0u2V/DBxlJ2V9Wzfnc1pbUNmMGEAalMyUvj2Lx0js1LIy8jMeI6sBUKItL9NdZ7U3MUfAyLH/LuegJvUN2g6TDkRK8lkTkcooI7Atrvd6zeVcV7G0qYv7mUlYVV1DV4I7BzkuMY1TeZ8QO8tbBnjsgiq4e3JhQKItKzNNRBxVao2AYL7vO+Vu7w9iUPgNyp3kJEfbK9kdcZQ4P68U3NfjYW17J0RwXzN5exvqiazSV7W/aPH5DCSaOyyUqKY1hWH04cmUV0D+rAViiISM9XtNKb4G/tS96qdbW7P9036HiYeoU3mC4+LaiXmw6o3d/E5uJaPthYwvuflLJ0RwVNgelhk+Ki6Zcaz+RBaZw4MiswbUdCt70lVqEgIpHF3+ytVFdf5S08tPQfULYxsNO8sRF9ssGivIF1I86EPlkw9CTwBWeG1rqGJsr3NrCioIoFW8vYVVnPfzaVtkz8B16LYky/FEb2TSInOY4JA1MZ1Tf8U3YoFEQksjkH2//jtSb2V3vrSzTWeeMnyjZBXal3XEqu14k9/FTvec6YoJbR2Oxnc0kta3dVs62sjsXbytlUXEtxzf6WY3KS4xjTP4Wx/ZIDo7JTGJGT1KXjJxQKItJ7NdZD0XJv1PWa572V6/zedBn0mwSDjvP6J4adHLRWxMGq6hoprKzj4y3lLbPFbtxT2zK3U2afWG+J04wEZg7PYsbwTNISY0NSC3STUDCz2cBdgA94wDl3+yGOuxB4GpjmnDvsb3yFgoh0WG0JlG/2WhXLH4U9a72BdZh3l5MvFgZMhkkXQ874oE0ffrDGZj/bSveyZlc1724oZsPuGgor9lG73wuskTlJTMxNJTctgbzMPsyZ0C9ofRRhDwUz8wGfAGcChcAi4FLn3NqDjksGXgFige8pFEQk5Jr2w5oXoHitdwmqaX9g+nDn9UuM/AKkDPQuNfWfDBnDgjbp38Eam/0s3V7B4u0VLNxazsY9NeyursfvvHUnJg5MJX9IOtMGZzB1cDrpfY6uNdEdQmEGcItz7ouB1z8CcM7ddtBxdwJvATcCNyoURCQsqnd5czhtest71Fd9ui8tzwuH9CFeWJR+4oXEqNnemhNBDozGZj8rCiqZt2Y3S7ZXsGpnFY3Njm/OHMpPzxl3VO/Z3lAI5b1TA4GCVq8LgeNaH2BmxwKDnHMvm9mNh3ojM7sGuAYgLy8vBKWKSK+XMgAmX+Y9mpu8qcJ3LYPyrd4aE7tXwbp/AQ7iUr2vix7w1phIHwrRsZAxHE68AWL7eO954I/uDoZGjC+K/CEZ5A/JALwpxVcWVpFxlK2EjghlKLT1r9DSLDGzKOAO4MojvZFz7n7gfvBaCkGqT0Skbb5ob7qN4afBcGDaXG97Q503qC57jNdxvfIJWPaot62uzOvU/uD/ILm/N79T8XqISfAuSfmivZbFxK9C1ogOlRMf42P60Ixgn2Wbwnb5yMxSgc1AYFw7/YBy4NzDXULS5SMR6ba2f+Qtc1pb7C1SlDHMmwhwX6XXf1GxFTDIzYc+ORAdB0NmwYBjIS6lw2HREd3h8tEiYKSZDQV2ApcAlx3Y6ZyrArIOvDaz92hHn4KISLc1eIb3OJTaYm8KjwOXo/yNsOY5b59FwezbYcoVEBPfNfW2IWSh4JxrMrPvAfPwbkl90Dm3xsxuBRY7514K1WeLiHRLSTlw+k+9xwE7FnitiqV/h9f+B+b92Lt0Nfky7zbZQcd7EwVmDA/ZrbKtafCaiEh34BxsfR+W/xOqCr1bZVtL6gsnXOc9jkJ3uHwkIiLtZeaNsB52sve6rty79bVggTe4btcySOoX8jIUCiIi3VFiBuQd7z26UM+ZDFxEREJOoSAiIi0UCiIi0kKhICIiLRQKIiLSQqEgIiItFAoiItJCoSAiIi163DQXZlYCbD/Kb88CSoNYTk+gc+4ddM69Q2fOebBzLvtIB/W4UOgMM1vcnrk/IonOuXfQOfcOXXHOunwkIiItFAoiItKit4XC/eEuIAx0zr2Dzrl3CPk596o+BRERObze1lIQEZHDUCiIiEiLXhMKZjbbzDaY2SYzuznc9QSLmT1oZsVmtrrVtgwze9PMNga+pge2m5ndHfg3WGlmU8JX+dEzs0Fm9q6ZrTOzNWb2/cD2iD1vM4s3s4VmtiJwzj8PbB9qZgsC5/ykmcUGtscFXm8K7B8SzvqPlpn5zGyZmb0ceB3R5wtgZtvMbJWZLTezxYFtXfaz3StCwcx8wB+BOcA44FIzGxfeqoLmYWD2QdtuBt52zo0E3g68Bu/8RwYe1wB/7qIag60J+IFzbixwPPDdwH/PSD7v/cBpzrljgMnAbDM7HvgNcEfgnCuAuYHj5wIVzrkRwB2B43qi7wPrWr2O9PM94FTn3ORWYxK67mfbORfxD2AGMK/V6x8BPwp3XUE8vyHA6lavNwD9A8/7AxsCz/8CXNrWcT35AbwInNlbzhtIBJYCx+GNbo0ObG/5OQfmATMCz6MDx1m4a+/geeYGfgGeBrwMWCSfb6vz3gZkHbSty362e0VLARgIFLR6XRjYFqn6OueKAAJfcwLbI+7fIXCZ4FhgARF+3oFLKcuBYuBNYDNQ6ZxrChzS+rxazjmwvwrI7NqKO+1O4H8Af+B1JpF9vgc44A0zW2Jm1wS2ddnPdnRnvrkHsTa29cZ7cSPq38HMkoBngf9yzlWbtXV63qFtbOtx5+2cawYmm1ka8Dwwtq3DAl979Dmb2ZeAYufcEjM75cDmNg6NiPM9yEzn3C4zywHeNLP1hzk26OfdW1oKhcCgVq9zgV1hqqUr7DGz/gCBr8WB7RHz72BmMXiB8E/n3HOBzRF/3gDOuUrgPbz+lDQzO/DHXevzajnnwP5UoLxrK+2UmcC5ZrYNeALvEtKdRO75tnDO7Qp8LcYL/+l04c92bwmFRcDIwJ0LscAlwEthrimUXgKuCDy/Au+a+4Ht3wjcsXA8UHWgSdqTmNck+Buwzjn3h1a7Iva8zSw70ELAzBKAM/A6YN8FLgwcdvA5H/i3uBB4xwUuOvcEzrkfOedynXND8P5/fcc59zUi9HwPMLM+ZpZ84DnwBWA1XfmzHe5OlS7svDkL+ATvOuyPw11PEM/rcaAIaMT7q2Eu3rXUt4GNga8ZgWMN7y6szcAqID/c9R/lOc/CayKvBJYHHmdF8nkDk4BlgXNeDfw0sH0YsBDYBDwNxAW2xwdebwrsHxbuc+jEuZ8CvNwbzjdwfisCjzUHfld15c+2prkQEZEWveXykYiItINCQUREWigURESkhUJBRERaKBRERKSFQkHkIGbWHJih8sAjaLPqmtkQazWjrUh301umuRDpiH3OucnhLkIkHNRSEGmnwDz3vwmsa7DQzEYEtg82s7cD89m/bWZ5ge19zez5wBoIK8zshMBb+czsr4F1Ed4IjFAW6RYUCiKfl3DQ5aOLW+2rds5NB+7Fm4uHwPO/O+cmAf8E7g5svxv4t/PWQJiCN0IVvLnv/+icGw9UAl8J8fmItJtGNIscxMxqnXNJbWzfhrfQzZbAhHy7nXOZZlaKN4d9Y2B7kXMuy8xKgFzn3P5W7zEEeNN5i6VgZjcBMc65X4b+zESOTC0FkY5xh3h+qGPasr/V82bUtyfdiEJBpGMubvX1o8Dz+XgzeQJ8Dfgw8Pxt4NvQskBOSlcVKXK09BeKyOclBFY4O+B159yB21LjzGwB3h9Ulwa2XQ88aGY/BEqAqwLbvw/cb2Zz8VoE38ab0Vak21Kfgkg7BfoU8p1zpeGuRSRUdPlIRERaqKUgIiIt1FIQEZEWCgUREWmhUBARkRYKBRERaaFQEBGRFv8f3dnprB53XeAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slutsats\n",
    "\n",
    "- I denna övning har vi utforskat likheterna mellan neurala nätverk och logistisk regression\n",
    "\n",
    "\n",
    "- Introducerat större neurala nätverk och de komplexa samband som kan hanteras mha icke-linjaritet\n",
    "\n",
    "\n",
    "- Utforskat vad som händer om du bygger för stort neuralt nätverk relativt till träningsdata\n",
    "\n",
    "\n",
    "- Redovisat att regularisering kan öka neurala nätverkets generaliserbarhet till test-datat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
